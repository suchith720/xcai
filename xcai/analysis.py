# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/16_analysis.ipynb.

# %% auto 0
__all__ = ['pointwise_eval', 'equal_volume_split', 'get_decile_stats', 'barplot', 'decile_plot', 'get_pred_dset',
           'get_pred_sparse', 'load_pred_sparse', 'get_output', 'html', 'TextColumns', 'display_text', 'compare_text']

# %% ../nbs/16_analysis.ipynb 2
import os,torch, torch.multiprocessing as mp, pickle, numpy as np, re
from typing import Optional, Dict, List, Tuple
from torch.utils.data import Dataset
from scipy import sparse
import matplotlib.pyplot as plt

from fastcore.dispatch import *

from .basics import *
from .data import *
from .learner import XCPredictionOutput

import xclib.utils.sparse as xc_sparse
import xclib.evaluation.xc_metrics as xc_metrics
import xclib.data.data_utils as du 

from IPython.display import HTML

# %% ../nbs/16_analysis.ipynb 8
def pointwise_eval(pred_lbl:sparse.csr_matrix, data_lbl:sparse.csr_matrix, data_lbl_filterer:Optional[np.ndarray]=None,
                   topk:Optional[int]=5, metric:Optional[str]='P', return_type:Optional[str]='M'):
    
    if data_lbl_filterer is not None:
        pred_lbl = Filterer.apply(pred_lbl, data_lbl_filterer)
        data_lbl = Filterer.apply(data_lbl, data_lbl_filterer)
        
    pred_lbl = xc_sparse.retain_topk(pred_lbl, k=topk)
        
    scores = pred_lbl.multiply(data_lbl)
    scores.data[:] = 1
        
    if metric == 'P':
        scores = scores.multiply(1/(topk * data_lbl.shape[0]))
    elif metric == 'R':
        d = data_lbl.getnnz(axis=1) * data_lbl.shape[0]
        scores = scores.multiply(1/d.reshape(-1,1))
    elif metric == 'FN':
        scores = data_lbl - scores
        scores.eliminate_zeros()
        lbl_cnt = data_lbl.getnnz(axis=0)
        scores = scores.multiply(1/(lbl_cnt * data_lbl.shape[1]))

    if return_type == 'M': return scores
    elif return_type == 'L': return np.ravel(scores.sum(axis=0))
    else: return np.ravel(scores.sum(axis=1))
    

# %% ../nbs/16_analysis.ipynb 10
def equal_volume_split(data_lbl:sparse.csr_matrix, n_split:int):
    lbl_cnt = data_lbl.getnnz(axis=0)
    lbl_idx = np.argsort(-lbl_cnt)
    thresh = lbl_cnt.sum()/n_split
    
    splits,split,cnt = [],[],0
    for idx in lbl_idx:
        cnt += lbl_cnt[idx]
        split.append(idx)

        if cnt > thresh: 
            splits.append(split)
            split,cnt = [],0

    if len(split): splits.append(split)
    
    if len(splits) != n_split: raise ValueError(f'Number of splits created less than {n_split}.')
    splits.append(lbl_idx.tolist())
    
    lbl_cnt = lbl_cnt.astype(np.float32)
    lbl_cnt[lbl_cnt == 0] = np.nan
    info = [f'{i+1}\n{len(split)//1000}K\n{np.nanmean(lbl_cnt[split]):.2f}' for i,split in enumerate(splits)]
    return splits,info
    

# %% ../nbs/16_analysis.ipynb 11
def get_decile_stats(pred_lbl:sparse.csr_matrix, data_lbl:sparse.csr_matrix, data_lbl_filterer:np.ndarray, 
                     n_split:Optional[int]=5, topk:Optional[int]=5, metric:Optional[str]='P'):
    
    evals = pointwise_eval(pred_lbl, data_lbl, data_lbl_filterer, topk=topk, metric=metric)
    splits, info = equal_volume_split(data_lbl, n_split)
    values = [evals[:, split].sum()*100 for split in splits]
    return info, values


# %% ../nbs/16_analysis.ipynb 12
def barplot(scores:Dict, title:Optional[str]='', ylabel:Optional[str]='', figsize:Optional[Tuple]=(15,10), fname:Optional[str]=None):
    n_proc,n_split = len(scores),len(list(scores.values())[0][0])
    idx, width = np.arange(n_split), 0.8/n_proc
    
    fig, ax = plt.subplots(figsize=figsize)
    ax.grid()

    shift = 0
    for proc,(info,values) in scores.items(): 
        x = idx + shift
        ax.bar(x=x, height=values, width=width, alpha=1, label=proc)
        shift += width

    shift = (n_proc//2)*width if n_proc%2 else width/2 + ((n_proc-1)//2)*width

    ax.set_title(title, fontsize=22)

    ax.set_xlabel('Quantiles \n (Increasing Freq.)', fontsize=18)
    ax.set_ylabel(ylabel, fontsize=18)

    ax.set_xticks(idx + shift, info, fontsize=14)
    for o in ax.get_yticklabels(): o.set_fontsize(14)

    ax.legend(fontsize=14)
    
    if fname is not None: plt.savefig(fname)
    

# %% ../nbs/16_analysis.ipynb 13
def decile_plot(preds:Dict, data_lbl:sparse.csr_matrix, data_lbl_filterer:Optional[np.array]=None, 
                n_split:Optional[int]=5, topk:Optional[int]=5, metric:Optional[str]='P', figsize:Optional[Tuple]=(15,10), 
                title:Optional[str]='', fname:Optional[str]=None):
    scores = {}

    for method, pred in preds.items():
        info, values = get_decile_stats(pred, data_lbl, data_lbl_filterer, n_split=5, topk=5, metric='P')
        scores[method] = (info,values)
    
    barplot(scores, title, f'{metric}@{topk}', figsize, fname)
    

# %% ../nbs/16_analysis.ipynb 22
@typedispatch
def get_pred_dset(pred:sparse.csr_matrix, block:XCDataBlock):
    data = MainXCDataset(block.test.dset.data.data_info, pred, block.test.dset.data.lbl_info, 
                         block.test.dset.data.data_lbl_filterer)
    return XCDataset(data, **block.test.dset.meta)


@typedispatch
def get_pred_dset(pred:sparse.csr_matrix, dset:XCDataset):
    data = MainXCDataset(dset.data.data_info, pred, dset.data.lbl_info, dset.data.data_lbl_filterer)
    return XCDataset(data, **dset.meta)

@typedispatch
def get_pred_dset(pred:sparse.csr_matrix, dset:MainXCDataset):
    return MainXCDataset(dset.data_info, pred, dset.lbl_info, dset.data_lbl_filterer)
    

# %% ../nbs/16_analysis.ipynb 28
@typedispatch
def get_pred_sparse(out:XCPredictionOutput, n_lbl:int):
    pred_ptr = torch.concat([torch.zeros((1,), dtype=torch.long), out.pred_ptr.cumsum(dim=0)])
    return sparse.csr_matrix((out.pred_score, out.pred_idx, pred_ptr), shape=(len(out.pred_ptr), n_lbl))

@typedispatch
def get_pred_sparse(fname:str, n_lbl:int):
    with open(fname, 'rb') as f: out = pickle.load(f)
    pred_ptr = torch.concat([torch.zeros((1,), dtype=torch.long), out.pred_ptr.cumsum(dim=0)])
    return sparse.csr_matrix((out.pred_score, out.pred_idx, pred_ptr), shape=(len(out.pred_ptr), n_lbl))

@typedispatch
def load_pred_sparse(fname:str):
    o = np.load(fname)
    return sparse.csr_matrix((o['data'], o['indices'], o['indptr']), dtype=float, shape=o['shape'])

def get_output(fname:str, n_lbl:int, pred_type:Optional[str]='repr_output'):
    with open(pname, 'rb') as f: out = pickle.load(f)
    preds,targ = get_output_sparse(**getattr(out,pred_type), n_lbl=n_lbl)
    return preds, targ
    

# %% ../nbs/16_analysis.ipynb 36
def html(text:str, c='green'): return f'<text style=color:{c}>{text}</text>'

# %% ../nbs/16_analysis.ipynb 37
class TextColumns(Dataset):
    
    def __init__(self, x, pat='.*_text$'):
        self.x, self.pat = x, pat
    
    def __getitem__(self, idx):
        o = self.x[idx]
        return {k:v for k,v in o.items() if re.match(self.pat, k)}
    

# %% ../nbs/16_analysis.ipynb 38
def display_text(pred_dset:Dataset, data_dset:Dataset, idxs:List):
    color = [('red','green'), ('black','blue')]
    text = []
    for i,idx in enumerate(idxs):
        c = color[i%len(color)]
        pred_text = "<br>".join([f'{html(k,color[0][0])}: {html(v,color[0][1])}' for k,v in pred_dset[idx].items()])
        data_text = "<br>".join([f'{html(k,color[1][0])}: {html(v,color[1][1])}' for k,v in data_dset[idx].items()])
        text.append("<br>".join([pred_text,data_text]))
    return "<br><br>".join(text)


def compare_text(pred1_dset:Dataset, pred2_dset:Dataset, data_dset:Dataset, idxs:List):
    color = [('red','green'), ('black','blue'), ('orange', 'brown')]
    text = []
    for i,idx in enumerate(idxs):
        c = color[i%len(color)]
        pred1_text = "<br>".join([f'{html(k,color[0][0])}: {html(v,color[0][1])}' for k,v in pred1_dset[idx].items()])
        pred2_text = "<br>".join([f'{html(k,color[1][0])}: {html(v,color[1][1])}' for k,v in pred2_dset[idx].items()])
        data_text = "<br>".join([f'{html(k,color[2][0])}: {html(v,color[2][1])}' for k,v in data_dset[idx].items()])
        text.append("<br>".join([pred1_text,pred2_text,data_text]))
    return "<br><br>".join(text)
    
