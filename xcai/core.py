# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['show_data', 'Info', 'Filterer', 'store_attr']

# %% ../nbs/00_core.ipynb 2
import pandas as pd, numpy as np, logging, sys, re, os
from scipy import sparse
from IPython.display import display
from transformers import AutoTokenizer, PreTrainedTokenizerBase
from typing import List, Dict, Union, Optional
from fastcore.dispatch import *
from fastcore.basics import *

# %% ../nbs/00_core.ipynb 5
def show_data(x:Dict, n:Optional[int]=10, seed:Optional[int]=None):
    with pd.option_context('display.max_colwidth', None):
        display(pd.DataFrame(x).sample(n, random_state=seed))

# %% ../nbs/00_core.ipynb 6
class Info():

    def __init__(self):
        self.tokz, self.info = None, None
        
    @staticmethod
    def _read_text(fname:str, enc:Optional[str]='latin-1'):
        with open(fname, encoding=enc) as f:
            info = [o[:-1] for o in f]
        return info
        
    @staticmethod
    def _read_info(fname:str, sep:Optional[str]='->', cols:Optional[List]=None, enc:Optional[str]='latin-1'):
        info = Info._read_text(fname, enc=enc)
        info = list(zip(*[o.split(sep) for o in info]))
        cols = list(range(len(info))) if cols is None else cols
        if len(cols) != len(info): raise ValueError(f'`cols` and `info` should have same number of elements.')
        return {p:q for p,q in zip(cols, info)}

    def read_info(self, fname:Optional[str], sep:Optional[str]='->', cols:Optional[List]=None, enc:Optional[str]='latin-1'):
        self.info = Info._read_info(fname, sep, cols, enc)
        return self.info
    
    def tokenize(self, fld:Union[int, str], tokz:Union[str, PreTrainedTokenizerBase], max_len:Optional[int]=None):
        if self.tokz is None: self.tokz = tokz if isinstance(tokz, PreTrainedTokenizerBase) else AutoTokenizer.from_pretrained(tokz)
        fld = list(self.info.keys())[0] if fld is None else fld
        if fld is None: logging.info(f'`fld` not given as input, so value set to {fld}.')
        if fld not in self.info: raise ValueError(f'`{fld}` is invalid `fld` value.')
        self.info.update(self.tokz(self.info[fld], truncation=True, max_length=max_len))
        return self.info

    def show_data(self, n:Optional[int]=10, seed:Optional[int]=None):
        with pd.option_context('display.max_colwidth', None):
            display(pd.DataFrame(self.info).sample(n, random_state=seed))

    def __len__(self):
        if self.info is None: return 0
        n_info = [len(v) for v in self.info.values()]
        if len(n_info) == 0: raise ValueError('`info` cannot be empty.')
        if not np.all([o == n_info[0] for o in n_info]): raise ValueError('`info` should contain features with same length.')
        return n_info[0]

    @classmethod
    def from_txt(cls, 
                 fname:str, 
                 sep:Optional[str]='->', 
                 cols:Optional[List]=None, 
                 enc:Optional[str]='latin-1',
                 use_tokz:Optional[bool]=False,
                 tokz:Optional[Union[str,PreTrainedTokenizerBase]]=None,
                 fld:Optional[str]=None,
                 max_len:Optional[int]=None, 
                 **kwargs):
        self = cls()
        self.info = self.read_info(fname, sep, cols, enc)
        if use_tokz: self.tokenize(fld, tokz, max_len)
        return self.info
        

# %% ../nbs/00_core.ipynb 15
class Filterer:

    @staticmethod
    def load_filter(fname:str):
        if fname is not None and os.path.exists(fname): return np.loadtxt(fname, dtype=np.int64)
        
    @staticmethod
    def generate(train_id:List, test_id:List, lbl_id:List, train_lbl:sparse.csr_matrix, test_lbl:sparse.csr_matrix):
        _, train_idx, lbl2train_idx = np.intersect1d(train_id, lbl_id, return_indices=True)
        train_lbl_filterer = np.vstack([train_idx, lbl2train_idx]).T
        
        _, test_idx, lbl2test_idx = np.intersect1d(test_id, lbl_id, return_indices=True)
        test_lbl_filterer = np.vstack([test_idx, lbl2test_idx]).T
        
        train_udx, train_udx2idx = np.unique(train_idx, return_index=True)
        lbl2test_udx, lbl2test_udx2idx = np.unique(lbl2test_idx, return_index=True)
        
        _test_lbl_filterer = train_lbl[train_udx][:, lbl2test_udx].T
        
        rows, cols = _test_lbl_filterer.nonzero()
        test_idx = test_idx[lbl2test_udx2idx[rows]]
        lbl2test_idx = lbl2train_idx[train_udx2idx[cols]]
        
        _test_lbl_filterer = np.vstack([test_idx, lbl2test_idx]).T
        test_lbl_filterer = np.vstack([test_lbl_filterer, _test_lbl_filterer])
    
        return train_lbl_filterer, test_lbl_filterer

    @staticmethod
    def sample(f:np.array, sz:tuple, idx:List):
        f = sparse.coo_matrix((np.full(f.shape[0],1), (f[:, 0], f[:, 1])), shape=sz).tocsr()
        f = f[idx].tocoo()
        return np.vstack([f.row, f.col]).T

    @staticmethod
    def prune(data:sparse.csr_matrix, data_filterer:np.array):
        data = data.copy()
        data[data_filterer[:,0], data_filterer[:,1]] = 0
        data.eliminate_zeros()
        
        idx = np.where(data.getnnz(axis=1) > 0)[0]
        return data[idx], Filterer.sample(data_filterer, data.shape, idx), idx

    @staticmethod
    def apply(data:sparse.csr_matrix, data_filterer:np.array):
        data[data_filterer[:,0], data_filterer[:,1]] = 0
        data.eliminate_zeros()
        return data

        

# %% ../nbs/00_core.ipynb 17
def store_attr(names=None, self=None, but='', cast=False, store_args=None, is_none=True, **attrs):
    fr = sys._getframe(1)
    args = argnames(fr, True)
    if self: args = ('self', *args)
    else: self = fr.f_locals[args[0]]
    if store_args is None: store_args = not hasattr(self,'__slots__')
    if store_args and not hasattr(self, '__stored_args__'): self.__stored_args__ = {}
    anno = annotations(self) if cast else {}
    if names and isinstance(names,str): names = re.split(', *', names)
    ns = names if names is not None else getattr(self, '__slots__', args[1:])
    added = {n:fr.f_locals[n] for n in ns}
    attrs = {**attrs, **added}
    if isinstance(but,str): but = re.split(', *', but)
    attrs = {k:v for k,v in attrs.items() if k not in but}
    return _store_attr(self, anno, is_none, **attrs)
    

# %% ../nbs/00_core.ipynb 18
def _store_attr(self, anno, is_none, **attrs):
    stored = getattr(self, '__stored_args__', None)
    for n,v in attrs.items():
        if n in anno: v = anno[n](v)
        if is_none or v is not None: setattr(self, n, v)
        if stored is not None: stored[n] = v
       
