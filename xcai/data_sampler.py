# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/19_data_sampler.ipynb.

# %% auto 0
__all__ = ['XCSamplerFeatTfm', 'NGAMESamplerFeatTfm', 'OAKSamplerFeatTfm', 'CrossSamplerFeatTfm']

# %% ../nbs/19_data_sampler.ipynb 3
import os,pickle,torch,re, numpy as np
from typing import Optional, List, Dict
from itertools import chain

from transformers import BatchEncoding, AutoTokenizer

from fastcore.utils import *

from .transform import PadFeatTfm,CollapseTfm
from .core import store_attr

# %% ../nbs/19_data_sampler.ipynb 18
class XCSamplerFeatTfm:

    def __init__(
        self,
        pad_token:Optional[int]=0,
        oversample:Optional[bool]=False,
        sampling_features:Optional[List]=None,
        **kwargs
    ):
        store_attr('sampling_features,oversample')
        self.pad_proc = PadFeatTfm(pad_tok=pad_token, in_place=False, drop=False)
        self.col_proc = CollapseTfm()

    # sample_base_feature

    def collate_feature_idx(self, x, name, sampling_name=None):
        level = name.count('2')
        o = self.pad_proc(x, prefix=f'{name}_idx', lev=level)
    
        if f'{name}_idx' in o:
            if sampling_name is not None and f'{sampling_name}_idx' not in o:
                o[f'{sampling_name}_idx'] = o.pop(f'{name}_idx')
            o = self.rename_idx_ptr(o, name, sampling_name)
            o = {f'p{k}':v for k,v in o.items()}
            
        return o

    def get_rnd_idx_from_ptr(self, x:List, n_samples:int, oversample:Optional[bool]=True):
        if oversample: return [torch.randint(i, size=(n_samples,)) if i>0 else torch.tensor([-1]) for i in x]
        else: return [torch.randperm(i)[:n_samples] if i>0 else torch.tensor([-1]) for i in x]

    def rename_idx_ptr(self, x:Dict, prefix:str, sampling_prefix:Optional[str]=None):
        prefixes = prefix.split('2')
        for i,n in enumerate(range(len(prefixes)-1,0,-1)):
            s = '2'.join(prefixes[n:])
            p = prefix if sampling_prefix is None else sampling_prefix
            x[f'{p}_{s}2ptr'] = x.pop(f'{prefix}_idx_ptr-{i+1}')
        return x

    def get_features(self, x:Dict, prefix:str):
        pat = f'^({prefix.replace(",","|")})_.*'
        return [o for o in x if re.match(pat, o)]

    def sample_batch(self, batch:List, features:List, idxs:List, level:int):
        sbatch = []
        for b,idx in zip(batch, idxs):
            sfeatures = {}
            for feature in features:
                cfeature = self.col_proc(b[feature], level)[0]
                sfeatures[feature] = [] if idx[0] == -1 else [cfeature[i] for i in idx]
            sbatch.append(sfeatures)
        return sbatch

    def remove_unwanted_ptr(self, x:Dict):
        return {k:v for k,v in x.items() if not re.match('.*_ptr-[0-9]+$', k)}
    
    def rename_keys(self, x:Dict, prefix:str):
        keys = list(x.keys())
        for k in keys:
            nk = k.split('_', maxsplit=1)[1]
            nk = f'{prefix}_{nk}'
            if nk not in x:
                x[nk] = x[k]
                del x[k]
        return x
    
    def collate_features(self, x:List, name:str, sampling_name:Optional[str]=None):
        level = name.count('2')

        o = self.pad_proc.coll_proc(x, prefix=name, lev=level)
        if f'{name}_input_ids' in o and f'{name}_attention_mask' not in o: 
            o[f'{name}_attention_mask'] = [[1]*len(i) for i in o[f'{name}_input_ids']]
        o = self.pad_proc.proc(o)
        
        o = self.rename_idx_ptr(o, name, sampling_name)
        o = self.remove_unwanted_ptr(o)
        if sampling_name is not None: o = self.rename_keys(o, sampling_name)
        return o
                
    def sample_base_feature(self, batch:List, prefix_names:str, name:str, n_sample:int, 
                            oversample:Optional[bool]=True):
        sampled_batch, sbatch = {}, {}
        
        feat_prefix = name.split('2')
        sampling_name,ptr_name = f'{feat_prefix[0]}2{feat_prefix[-1]}',feat_prefix[-1]
        
        o = self.collate_feature_idx(batch, name=name, sampling_name=sampling_name)
        
        if len(o):
            sampling_idx = self.get_rnd_idx_from_ptr(o[f'p{sampling_name}_{ptr_name}2ptr'], n_sample, oversample=oversample)
            
            sampled_batch.update(o)
            
            feats,level = self.get_features(batch[0], prefix_names), name.count('2')-1
            sbatch = self.sample_batch(batch, feats, sampling_idx, level)
        
            o = self.collate_features(sbatch, name=name, sampling_name=sampling_name)
            sampled_batch.update(o)
        
        return sampled_batch, sbatch
        
    # sample_dep_features

    def sample_sbatch(self, batch:List, features:List, n_samples:int, oversample:Optional[bool]=True):
        sbatch = []
        for b in batch:
            
            idxs = []
            for val in b[features[0]]:
                if oversample: idx = np.random.randint(len(val), size=n_samples) if len(val) > 0 else []
                else: idx = np.random.permutation(len(val))[:n_samples]
                idxs.append(idx)
            
            sfeatures = {}
            for feature in features:
                
                svalues = []
                for val,idx in zip(b[feature],idxs):
                    svalues.append([val[i] for i in idx])
                    
                sfeatures[feature] = svalues
                
            sbatch.append(sfeatures)
        return sbatch
    
    def sample_dep_features(
        self, 
        sampled_batch:List, 
        sbatch:List, 
        names:List, 
        n_samples:List, 
        oversample:Optional[bool]=True,
    ):
        for name,n_sample in zip(names,n_samples):
            sampling_name = '2'.join(name.split('2')[:2])
            o = self.collate_feature_idx(sbatch, name=name, sampling_name=sampling_name)
    
            if len(o):
                sampled_batch.update(o)
                
                feats = self.get_features(sbatch[0], name)
                o = self.sample_sbatch(sbatch, feats, n_sample, oversample=oversample)
                o = self.collate_features(o, name=name, sampling_name=sampling_name)
                sampled_batch.update(o)
    
        return sampled_batch

    # sample features

    def sample_feature(self, batch:List, names:str, n_samples:Union[int, List], oversample:Optional[bool]=False):
        feature_names = names.split(',')
        
        if isinstance(n_samples, int): 
            n_samples = (n_samples,)*len(feature_names)

        if len(feature_names) != len(n_samples):
            raise ValueError(f'`feature_names` and `n_samples` should have same length.')
        
        base_name, dep_names = feature_names[0], feature_names[1:]
        base_n_sample, dep_n_samples = n_samples[0], n_samples[1:]

        if f'{base_name}_input_ids' in batch[0]: self.add_attention_mask = True

        for p in dep_names:
            if not p.endswith(base_name): 
                raise ValueError(f'{p} does not end with the base prefix `{base_name}`.')

        sampled_batch, sbatch = self.sample_base_feature(batch, names, base_name, base_n_sample, oversample)
        return self.sample_dep_features(sampled_batch, sbatch, dep_names, dep_n_samples, oversample)

    # left-over features
    
    def process_features(self, sampled_batch:BatchEncoding, batch:BatchEncoding, names:List):
        for name in names:
            o = self.collate_features(batch, name=name)
            sampled_batch.update(o)
        return sampled_batch


# %% ../nbs/19_data_sampler.ipynb 19
@patch
def __call__(
    self:XCSamplerFeatTfm, 
    batch:List, 
    sampling_features:Optional[List]=None,
    oversample:Optional[bool]=None,
):  
    store_attr('sampling_features,oversample', is_none=False)

    sampled_features = set()
    out = BatchEncoding({})
    for name, n_sample in self.sampling_features:
        o = self.sample_feature(batch, name, n_sample, self.oversample)
        out.update(o)

        sampled_features.update(name.split(','))

    all_features = set([k.split('_')[0] for k in batch[0].keys()])
    remaining_features = all_features.difference(sampled_features)
    out = self.process_features(out, batch, remaining_features)
    
    return out
    

# %% ../nbs/19_data_sampler.ipynb 54
class NGAMESamplerFeatTfm:

    def __init__(self, sampler_num_labels:Optional[int]=1, sampler_lbl_oversample:Optional[bool]=False, 
                 pad_token:Optional[int]=0, **kwargs):
        self.n_labels, self.lbl_oversample = sampler_num_labels, sampler_lbl_oversample
        self.pad_proc = PadFeatTfm(pad_tok=pad_token, in_place=False, drop=False)

    def sample_ids(self, x:Dict, prefix:str, idxs:torch.Tensor, data_info:Optional[Dict]=None):
        if idxs is None:
            if f'{prefix}_attention_mask' not in x: x[f'{prefix}_attention_mask'] = [[1]*len(i) for i in x[f'{prefix}_input_ids']]
        else:
            x[f'{prefix}_input_ids'] = [x[f'{prefix}_input_ids'][i] for i in idxs]
            x[f'{prefix}_attention_mask'] = [x[f'{prefix}_attention_mask'][i] for i in idxs] if f'{prefix}_attention_mask' in x else [[1]*len(i) for i in x[f'{prefix}_input_ids']]

    def align_features(self, features:List, prefix:str, level:int, idxs:Optional[torch.Tensor]=None, 
                       data_info:Optional[Dict]=None):
        if f'{prefix}_input_ids' not in features[0]: return {}

        if f'{prefix}_input_ids' in features[0] and f'{prefix}_attention_mask' in features[0]:
            features = [{f'{prefix}_input_ids': o[f'{prefix}_input_ids'], f'{prefix}_attention_mask': o[f'{prefix}_attention_mask']} for o in features]        
        else:
            features = [{f'{prefix}_input_ids': o[f'{prefix}_input_ids']} for o in features]
        
        o = self.pad_proc.coll_proc(features, prefix=prefix, lev=level)
        self.sample_ids(o, prefix, idxs, data_info)
        return self.pad_proc.proc(o)

    def sample_features(self, batch:Dict, features:List, name:str, level:int, n_samples:Optional[int]=1,
                       oversample:Optional[bool]=False, perform_cross:Optional[bool]=False):
        if f'{name}_idx' in features[0]:
            batch[f'p{name}_data2ptr'] = torch.tensor([len(o[f'{name}_idx']) for o in features], dtype=torch.int64)
            batch[f'p{name}_idx'] = torch.tensor(list(chain(*[o[f'{name}_idx'] for o in features])), dtype=torch.int64)

            indptr = torch.cat([torch.zeros((1,), dtype=torch.int64), batch[f'p{name}_data2ptr'].cumsum(dim=0)])
            if oversample: 
                idx = torch.hstack([torch.randint(n, size=(n_samples,))+offset for n,offset in zip(batch[f'p{name}_data2ptr'], indptr)])
                batch[f'{name}_data2ptr'] = torch.full(batch[f'p{name}_data2ptr'].shape, n_samples)
            else: 
                idx = torch.hstack([torch.randperm(n)[:n_samples]+offset for n,offset in zip(batch[f'p{name}_data2ptr'], indptr)])
                batch[f'{name}_data2ptr'] = torch.clamp(batch[f'p{name}_data2ptr'], max=n_samples)

            data_info = dict()
            if perform_cross:
                data_info = {
                    'data_idx': torch.arange(len(batch[f'{name}_data2ptr'])).repeat_interleave(batch[f'{name}_data2ptr']),
                    'data_input_ids': [o['data_input_ids'] for o in features],
                }
                data_info['data_attention_mask'] = [o['data_attention_mask'] for o in features] if 'data_attention_mask' in features[0] else [[1]*len(i) for i in data_info['data_input_ids']]
                
                
            batch[f'{name}_idx'] = batch[f'p{name}_idx'][idx]
            batch.update(self.align_features(features, name, level, idx, data_info))

    def collate_data(self, batch:Dict, features:List):
        if 'data_idx' in features[0]:
            batch['data_idx'] = torch.tensor([o['data_idx'] for o in features], dtype=torch.int64)
            
        o =  self.align_features(features, 'data', 0)    
        batch['data_input_ids'], batch['data_attention_mask'] = o['data_input_ids'], o['data_attention_mask']

    def collate_labels(self, batch:Dict, features:List):
        self.sample_features(batch, features, 'lbl2data', level=1, n_samples=self.n_labels, 
                             oversample=self.lbl_oversample)

    def __call__(self, features:List):
        batch = BatchEncoding({})
        self.collate_data(batch, features)
        self.collate_labels(batch, features)
        return batch


# %% ../nbs/19_data_sampler.ipynb 68
class OAKSamplerFeatTfm(NGAMESamplerFeatTfm):

    def __init__(
        self, 
        sampler_meta_name:Union[List, str], 
        sampler_num_meta:Optional[Union[Dict, int]]=1, 
        sampler_meta_oversample:Optional[Union[Dict, int]]=False, 
        **kwargs
    ):
        super().__init__(**kwargs)
        self.meta_name = sampler_meta_name if isinstance(sampler_meta_name, list) else [sampler_meta_name]
        self.n_meta, self.meta_oversample = sampler_num_meta, sampler_meta_oversample

    def collate_metadata(self, batch:Dict, features:List):
        for meta_name in self.meta_name:
            n_meta = self.n_meta if isinstance(self.n_meta, int) else self.n_meta.get(meta_name, 1)
            oversample = self.meta_oversample if isinstance(self.meta_oversample, int) else self.meta_oversample.get(meta_name, False)
            self.sample_features(batch, features, f'{meta_name}2data', level=1, n_samples=n_meta, oversample=oversample)

    def __call__(self, features:List):
        batch = BatchEncoding({})
        self.collate_data(batch, features)
        self.collate_labels(batch, features)
        self.collate_metadata(batch, features)
        return batch
        

# %% ../nbs/19_data_sampler.ipynb 81
class CrossSamplerFeatTfm(OAKSamplerFeatTfm):

    def __init__(
        self, 
        sampler_use_sep:Optional[bool]=True, 
        **kwargs
    ):
        super().__init__(**kwargs)
        self.use_sep = sampler_use_sep

    def sample_ids(self, x:Dict, prefix:str, idxs:torch.Tensor, data_info:Optional[Dict]=None):
        if idxs is None:
            if f'{prefix}_attention_mask' not in x: x[f'{prefix}_attention_mask'] = [[1]*len(i) for i in x[f'{prefix}_input_ids']]
        else:
            if self.use_sep:
                x[f'{prefix}_input_ids'] = [data_info['data_input_ids'][i]+x[f'{prefix}_input_ids'][j][1:] for i,j in zip(data_info['data_idx'], idxs)]
                x[f'{prefix}_attention_mask'] = [data_info['data_input_ids'][i]+x[f'{prefix}_attention_mask'][j][1:] for i,j in zip(data_info['data_idx'], idxs)] if f'{prefix}_attention_mask' in x else [[1]*len(i) for i in x[f'{prefix}_input_ids']]
            else:
                x[f'{prefix}_input_ids'] = [data_info['data_input_ids'][i][:-1]+x[f'{prefix}_input_ids'][j][1:] for i,j in zip(data_info['data_idx'], idxs)]
                x[f'{prefix}_attention_mask'] = [data_info['data_input_ids'][i][:-1]+x[f'{prefix}_attention_mask'][j][1:] for i,j in zip(data_info['data_idx'], idxs)] if f'{prefix}_attention_mask' in x else [[1]*len(i) for i in x[f'{prefix}_input_ids']]

    def collate_labels(self, batch:Dict, features:List):
        self.sample_features(batch, features, 'lbl2data', level=1, n_samples=self.n_labels, 
                             oversample=self.lbl_oversample, perform_cross=True)
        
    def collate_metadata(self, batch:Dict, features:List):
        for meta_name in self.meta_name:
            n_meta = self.n_meta if isinstance(self.n_meta, int) else self.n_meta.get(meta_name, 1)
            oversample = self.meta_oversample if isinstance(self.meta_oversample, int) else self.meta_oversample.get(meta_name, False)
            self.sample_features(batch, features, f'{meta_name}2data', level=1, n_samples=n_meta, oversample=oversample, perform_cross=True)

