# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/43_conflation.ipynb.

# %% auto 0
__all__ = ['display_items', 'compare_items', 'get_conflated_text', 'Operations', 'Filter', 'Cluster', 'Conflation', 'SaveData']

# %% ../nbs/43_conflation.ipynb 2
import numpy as np, pandas as pd, scipy.sparse as sp, torch, json, os, re
import matplotlib.pyplot as plt
from IPython.display import display

from tqdm.auto import tqdm
from typing import Optional, Union, Dict, List
from IPython.display import display
from xclib.utils.sparse import retain_topk
from collections import Counter

# %% ../nbs/43_conflation.ipynb 4
def display_items(matrix:sp.csr_matrix, info:Dict, n_data:Optional[int]=10, n_view_data:Optional[int]=20, 
                          seed:Optional[int]=1000):
    np.random.seed(seed)
    rnd_idx = np.random.permutation(matrix.shape[0])[:n_data]
    
    outputs = list()
    for idx in rnd_idx:
        sort_idx = np.argsort(matrix[idx].data)[:-n_view_data:-1]
        scores = matrix[idx].data[sort_idx]
        indices = matrix[idx].indices[sort_idx]
        labels = [info['text'][i] for i in indices]
        o = {
            "Substring": info['text'][idx],
            "Predictions": [(x, float(y)) for x,y in zip(labels, scores)]
        }
        outputs.append(o)
    return outputs
    

# %% ../nbs/43_conflation.ipynb 5
def compare_items(output_1, output_2):
    rows, index = [], []
    for x,y in zip(linker_output, pretrn_output):
        assert x["Substring"] == y["Substring"]
    
        index.extend([(x["Substring"], i+1) for i in range(len(x["Predictions"]))])
        rows.extend([(a[0], b[0]) for a,b in zip(x["Predictions"], y["Predictions"])])
        
    df = pd.DataFrame(
        rows,
        index=pd.MultiIndex.from_tuples(
            index,
            names=["Query", "Index"],
        ),
        columns=["Output 1", "Output 2"],
    )
    return df
    

# %% ../nbs/43_conflation.ipynb 6
def get_conflated_text(clusters:List, meta_info:Dict):
    texts = [[meta_info["text"][i] for i in c] for c in clusters]
    idx = np.argsort([len(c) for c in clusters])[::-1]
    return [texts[i] for i in idx]
        

# %% ../nbs/43_conflation.ipynb 7
class Operations:

    @staticmethod
    def compute_yty(mat:sp.csr_matrix, bsz:Optional[int]=1000, normalize=True):
        mat_t = mat.transpose()
        out = sp.vstack([mat[i:i+bsz]@mat_t for i in tqdm(range(0, mat.shape[0], bsz))])
        def invert(a):
            return np.divide(1.0, a, out=np.zeros_like(a), where=a!=0)
        return out.multiply(invert(out.sum(axis=1))).multiply(invert(out.sum(axis=0))).tocsr()

    @staticmethod
    def minimum(matrix:sp.csr_matrix):
        return np.array([matrix.data[i:j].min() for i,j in zip(matrix.indptr, matrix.indptr[1:])])

    @staticmethod
    def min_clamp(matrix:sp.csr_matrix, value:float, inplace:Optional[bool]=True):
        if not inplace:
            matrix = matrix.copy()
        matrix.data[matrix.data <= value] = 0
        matrix.eliminate_zeros()
        return matrix

    @staticmethod
    def max_clamp(matrix:sp.csr_matrix, value:float, inplace:Optional[bool]=True):
        if not inplace:
            matrix = matrix.copy()
        matrix.data[matrix.data >= value] = 0
        matrix.eliminate_zeros()
        return matrix

    @staticmethod
    def diff_threshold(matrix:sp.csr_matrix, value:float):
        for i,j in zip(matrix.indptr, matrix.indptr[1:]):
            data = matrix.data[i:j]
            if len(data):
                idx = np.where(data.max() - data > value)[0]
                data[idx] = 0.0
                matrix.data[i:j] = data
        matrix.eliminate_zeros()
        return matrix

    @staticmethod
    def get_clusters(groups:np.array, lbl_idx:Optional[np.array]=None):
        lbl_idx = np.arange(groups.shape[0]) if lbl_idx is None else lbl_idx
        assert groups.shape == lbl_idx.shape, "`groups` and `lbl_idx` must have the same shape."
        clusters = dict()
        for k,v in zip(groups, lbl_idx): 
            clusters.setdefault(k, []).append(v)
        clusters = list(clusters.values())
        
        cluster_sz = [len(c) for c in clusters]
        sort_idx = np.argsort(cluster_sz)[::-1]
        return [clusters[i] for i in sort_idx]
    

# %% ../nbs/43_conflation.ipynb 8
class Filter:

    @staticmethod
    def from_max_size(clusters:List, size:int):
        return [c for c in clusters if len(c) < size]

    @staticmethod
    def from_min_size(clusters:List, size:int):
        return [c for c in clusters if len(c) > size]

    @staticmethod
    def remove_top_clusters(clusters:List, topk:int):
        sort_idx = np.argsort([len(c) for c in clusters])[-topk-1::-1]
        return [clusters[i] for i in sort_idx]
        

# %% ../nbs/43_conflation.ipynb 48
class Cluster:

    @staticmethod
    def from_similarity(lbl_lbl:sp.csr_matrix, score_thresh:Optional[float]=0.3, diff_thresh:Optional[float]=0.2, 
                        sim_topk:Optional[int]=20):
        lbl_lbl = retain_topk(lbl_lbl, k=sim_topk)
        lbl_lbl = Operations.min_clamp(lbl_lbl, score_thresh)
        lbl_lbl = Operations.diff_threshold(lbl_lbl, diff_thresh)
        
        n, groups = sp.csgraph.connected_components(lbl_lbl)
        return Operations.get_clusters(groups)

    @staticmethod
    def from_predictions(data_lbl:sp.csr_matrix, score_thresh:Optional[float]=0.3, diff_thresh:Optional[float]=0.2, 
                         pred_topk:Optional[int]=3):
        data_lbl = retain_topk(data_lbl, k=pred_topk)
        data_lbl = Operations.min_clamp(data_lbl, score_thresh)
        data_lbl = Operations.diff_threshold(data_lbl, diff_thresh)
        
        lbl_mat = Operations.compute_yty(data_lbl.transpose())
        n, groups = sp.csgraph.connected_components(lbl_mat)
        return Operations.get_clusters(groups)

    @staticmethod
    def from_derived_phrases(lbl_phrases:sp.csr_matrix):
        lbl_mat = Operations.compute_yty(lbl_phrases)
        n, groups = sp.csgraph.connected_components(lbl_mat)
        return Operations.get_clusters(groups)
        

# %% ../nbs/43_conflation.ipynb 51
class Conflation:

    @staticmethod
    def get_groups(clusters:List, n_lbl:int):
        groups = np.full(n_lbl, -1)
        for i,idx in enumerate(clusters):
            groups[idx] = i
        idxs = np.where(groups == -1)[0]
        groups[idxs] = np.arange(len(clusters), len(clusters) + idxs.shape[0])
        return groups

    @staticmethod
    def get_conflated_matrix(matrix:sp.csr_matrix, groups:np.array, n_lbl:Optional[int]=None):
        data, indptr = matrix.data, matrix.indptr
        indices = [groups[i] for i in matrix.indices]
        shape = None if n_lbl is None else (matrix.shape[0], n_lbl)
        return sp.csr_matrix((data, indices, indptr), shape=shape)

    @staticmethod
    def get_conflated_info(clusters:List, info:Dict):
        conflated_info, flag, lbl_idx = dict(), np.zeros(len(info["identifier"])), []
        
        for idxs in clusters:
            idx = np.random.choice(idxs)
            conflated_info.setdefault("identifier", []).append(info["identifier"][idx])
            conflated_info.setdefault("text", []).append(info["text"][idx])
            lbl_idx.append(idx)
            flag[idxs] = 1
            
        idxs = np.where(flag == 0)[0]
        for idx in idxs:
            conflated_info.setdefault("identifier", []).append(info["identifier"][idx])
            conflated_info.setdefault("text", []).append(info["text"][idx])
            lbl_idx.append(idx)
            flag[idx] = 1
            
        assert flag.all(), "All items should be covered."
        return conflated_info, lbl_idx

    @staticmethod
    def perform_conflation(clusters:List, trn_lbl:sp.csr_matrix, lbl_info:Dict, tst_lbl:Optional[sp.csr_matrix]=None):
        groups = Conflation.get_groups(clusters, n_lbl=trn_lbl.shape[1])

        conflated_trn_lbl = Conflation.get_conflated_matrix(trn_lbl, groups)
        conflated_tst_lbl = None if tst_lbl is None else Conflation.get_conflated_matrix(tst_lbl, groups, n_lbl=conflated_trn_lbl.shape[1])
        conflated_lbl_info, lbl_idx = Conflation.get_conflated_info(clusters, lbl_info)

        return conflated_trn_lbl, conflated_lbl_info, lbl_idx, conflated_tst_lbl
    

# %% ../nbs/43_conflation.ipynb 66
class SaveData:

    @staticmethod
    def save_raw(fname:str, ids:List, txt:List):
        df = pd.DataFrame({"identifier": ids, "text": txt})
        df.to_csv(fname, index=False)

    @staticmethod
    def proc(save_dir:str, trn_file:str, trn_lbl:sp.csr_matrix, info_file:str, lbl_info:Dict, 
             tst_file:Optional[str]=None, tst_lbl:Optional[sp.csr_matrix]=None):
        n = len([o for o in os.listdir(save_dir) if re.match(r'conflation_[0-9]{2}', o)]) + 1
        save_dir = f"{save_dir}/conflation_{n:02d}"
        
        raw_dir = f"{save_dir}/raw_data"
        os.makedirs(raw_dir, exist_ok=True)

        sp.save_npz(f"{save_dir}/{os.path.basename(trn_file)}", trn_lbl)
        if tst_lbl is not None:
            sp.save_npz(f"{save_dir}/{os.path.basename(tst_file)}", tst_lbl)

        raw_file = f"{raw_dir}/{os.path.basename(info_file)}"
        save_raw(raw_file, lbl_info["identifier"], lbl_info["text"])
        
