{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd48060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.oak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d95873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2fc4a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import torch, re, inspect, pickle, os, torch.nn as nn, math\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Tuple, Mapping, Any, Union\n",
    "from transformers import (\n",
    "    PretrainedConfig,\n",
    "    DistilBertForMaskedLM,\n",
    "    DistilBertModel,\n",
    "    DistilBertPreTrainedModel,\n",
    ")\n",
    "from transformers.utils.generic import ModelOutput\n",
    "from transformers.activations import get_activation\n",
    "\n",
    "from fastcore.meta import *\n",
    "from fastcore.utils import *\n",
    "\n",
    "from xcai.losses import *\n",
    "from xcai.core import store_attr\n",
    "from xcai.learner import XCDataParallel\n",
    "from xcai.models.modeling_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee9b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c00009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from xcai.block import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ede14",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff9c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04c1d105-6978-44b6-a9c9-851220d03e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealsotitles_data-meta_distilbert-base-uncased_xcs.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bd6b8e-d62c-4455-8baa-9dabc778afb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843bd7a-d18c-4f44-bd4b-c56064ee937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'wb') as file: pickle.dump(block, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e9f4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c50e879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(5)\n",
    "for i,batch in enumerate(block.train.dl):\n",
    "    if i > 2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f9f36e-bf56-4af0-8a38-89860721f191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'cat2data_idx', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'cat2data_data2ptr', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'data_idx', 'cat2lbl2data_idx', 'cat2lbl2data_identifier', 'cat2lbl2data_input_text', 'cat2lbl2data_input_ids', 'cat2lbl2data_attention_mask', 'cat2lbl2data_data2ptr', 'cat2lbl2data_lbl2data2ptr'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f97b11c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a92acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrossAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__()\n",
    "        self.config, self.n_h, self.dim = config, config.n_heads, config.dim\n",
    "        self.dropout = nn.Dropout(p=config.attention_dropout)\n",
    "\n",
    "        if self.dim % self.n_h != 0:\n",
    "            raise ValueError(f\"self.n_heads: {self.n_h} must divide self.dim: {self.dim} evenly.\")\n",
    "            \n",
    "        self.q = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.k = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.v = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.o = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "\n",
    "    def post_init(self):\n",
    "        self.q.weight.data = torch.eye(self.q.out_features, self.q.in_features, dtype=self.q.weight.dtype)\n",
    "        self.k.weight.data = torch.eye(self.k.out_features, self.k.in_features, dtype=self.k.weight.dtype)\n",
    "        self.v.weight.data = torch.eye(self.v.out_features, self.v.in_features, dtype=self.v.weight.dtype)\n",
    "        self.o.weight.data = torch.eye(self.o.out_features, self.o.in_features, dtype=self.o.weight.dtype)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        q: torch.Tensor,\n",
    "        q_m: torch.Tensor,\n",
    "        k: torch.Tensor, \n",
    "        k_m: torch.Tensor,\n",
    "        output_attentions:Optional[bool] = False,\n",
    "    ):\n",
    "        bs, q_len, dim = q.size()\n",
    "        v, k_len = k, k.size(1) \n",
    "\n",
    "        h_dim = self.dim//self.n_h\n",
    "\n",
    "        def shape(x: torch.Tensor): return x.view(bs, -1, self.n_h, h_dim).transpose(1, 2)\n",
    "\n",
    "        def unshape(x: torch.Tensor): return x.transpose(1, 2).contiguous().view(bs, -1, self.n_h * h_dim)\n",
    "\n",
    "        q = shape(self.q(q))  # (bs, n_h, q_len, h_dim)\n",
    "        k = shape(self.k(k))  # (bs, n_h, k_len, h_dim)\n",
    "        v = shape(self.v(v))  # (bs, n_h, k_len, h_dim)\n",
    "\n",
    "        q = q / math.sqrt(h_dim)  # (bs, n_h, q_len, h_dim)\n",
    "        sc = torch.matmul(q, k.transpose(2, 3))  # (bs, n_h, q_len, k_len)\n",
    "        \n",
    "        q_m, k_m = q_m.view(bs, 1, -1, 1).to(q.dtype), k_m.view(bs, 1, 1, -1).to(q.dtype)\n",
    "        mask = torch.matmul(q_m, k_m).expand_as(sc)  # (bs, n_h, q_len, k_len)\n",
    "        \n",
    "        sc = sc.masked_fill(mask == 0, torch.tensor(torch.finfo(sc.dtype).min))  # (bs, n_h, q_len, k_len)\n",
    "\n",
    "        w = nn.functional.softmax(sc, dim=-1)  # (bs, n_h, q_len, k_len)\n",
    "        w = self.dropout(w)  # (bs, n_h, q_len, k_len)\n",
    "\n",
    "        o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
    "        \n",
    "        if output_attentions: return (o, w)\n",
    "        else: return (o,)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258a231",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('distilbert-base-uncased')\n",
    "fuser = CrossAttention(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec047a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz, data_seq_len, n_meta, dim, dtype = 2, 3, 2, config.dim, torch.float32\n",
    "data, meta = torch.randn(bsz, data_seq_len, dim, dtype=dtype), torch.randn(bsz, n_meta, dim, dtype=dtype)\n",
    "data_mask = torch.randint(0, 2, size=(bsz,data_seq_len), dtype=dtype)\n",
    "meta_mask = torch.randint(0, 2, size=(bsz,n_meta), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = fuser(data, data_mask, meta, meta_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d426e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936fdbda-95ff-4531-ad45-09f0f5793534",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## NormCrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8691b3-0fdd-4e04-a1f7-a9442fcc3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NormCrossAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, config: PretrainedConfig, tau:Optional[float]=0.1, dropout:Optional[float]=0.1):\n",
    "        super().__init__()\n",
    "        self.tau = nn.Parameter(torch.tensor(tau, dtype=torch.float32))\n",
    "        \n",
    "        self.config, self.n_h, self.dim = config, config.n_heads, config.dim\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        if self.dim % self.n_h != 0:\n",
    "            raise ValueError(f\"self.n_heads: {self.n_h} must divide self.dim: {self.dim} evenly.\")\n",
    "            \n",
    "        self.q = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.k = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.v = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.o = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "\n",
    "    def post_init(self):\n",
    "        self.q.weight.data = torch.eye(self.q.out_features, self.q.in_features, dtype=self.q.weight.dtype)\n",
    "        self.k.weight.data = torch.eye(self.k.out_features, self.k.in_features, dtype=self.k.weight.dtype)\n",
    "        self.v.weight.data = torch.eye(self.v.out_features, self.v.in_features, dtype=self.v.weight.dtype)\n",
    "        self.o.weight.data = torch.eye(self.o.out_features, self.o.in_features, dtype=self.o.weight.dtype)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        q: torch.Tensor,\n",
    "        q_m: torch.Tensor,\n",
    "        k: torch.Tensor, \n",
    "        k_m: torch.Tensor,\n",
    "        output_attentions:Optional[bool] = False,\n",
    "    ):\n",
    "        bs, q_len, dim = q.size()\n",
    "        v, k_len = k, k.size(1) \n",
    "\n",
    "        h_dim = self.dim//self.n_h\n",
    "\n",
    "        def shape(x: torch.Tensor): return x.view(bs, -1, self.n_h, h_dim).transpose(1, 2)\n",
    "\n",
    "        def unshape(x: torch.Tensor): return x.transpose(1, 2).contiguous().view(bs, -1, self.n_h * h_dim)\n",
    "\n",
    "        q = shape(self.q(q))  # (bs, n_h, q_len, h_dim)\n",
    "        k = shape(self.k(k))  # (bs, n_h, k_len, h_dim)\n",
    "        v = shape(self.v(v))  # (bs, n_h, k_len, h_dim)\n",
    "\n",
    "        q = q / math.sqrt(h_dim)  # (bs, n_h, q_len, h_dim)\n",
    "        sc = torch.matmul(q, k.transpose(2, 3))  # (bs, n_h, q_len, k_len)\n",
    "        sc = sc * self.tau\n",
    "        \n",
    "        q_m, k_m = q_m.view(bs, 1, -1, 1).to(q.dtype), k_m.view(bs, 1, 1, -1).to(q.dtype)\n",
    "        mask = torch.matmul(q_m, k_m).expand_as(sc)  # (bs, n_h, q_len, k_len)\n",
    "        \n",
    "        sc = sc.masked_fill(mask == 0, torch.tensor(torch.finfo(sc.dtype).min))  # (bs, n_h, q_len, k_len)\n",
    "        \n",
    "        w = nn.functional.softmax(sc, dim=-1)  # (bs, n_h, q_len, k_len)\n",
    "        w = self.dropout(w)  # (bs, n_h, q_len, k_len)\n",
    "\n",
    "        o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
    "        \n",
    "        if output_attentions: return (o, w)\n",
    "        else: return (o,)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c937d-803e-419b-91a2-3002edd103b9",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a282707-094c-429c-97db-f0080d44c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('distilbert-base-uncased')\n",
    "fuser = NormCrossAttention(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61a60e-c6e4-4822-9f7e-f29c52fd7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz, data_seq_len, n_meta, dim, dtype = 2, 3, 2, config.dim, torch.float32\n",
    "\n",
    "data, meta = torch.randn(bsz, data_seq_len, dim, dtype=dtype), torch.randn(bsz, n_meta, dim, dtype=dtype)\n",
    "data_mask = torch.randint(0, 2, size=(bsz,data_seq_len), dtype=dtype)\n",
    "meta_mask = torch.randint(0, 2, size=(bsz,n_meta), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb2581-f3c5-4635-a9e3-943074ba7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = fuser(data, data_mask, meta, meta_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9419a3bc-5e8f-46b9-b98f-95d07076b09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a8737b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5ed7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder(DistilBertPreTrainedModel):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig, \n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        \n",
    "        self.dr_head = RepresentationHead(config)\n",
    "        self.dr_fused_head = RepresentationHead(config)\n",
    "        self.meta_head = RepresentationHead(config)\n",
    "        self.cross_head = CrossAttention(config)\n",
    "        self.meta_embeddings = nn.Embedding(num_metadata, config.dim)\n",
    "\n",
    "        self.ones = torch.ones(resize_length, dtype=torch.long, device=self.device) if resize_length is not None else None\n",
    "        self.post_init()\n",
    "\n",
    "    def freeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(True)\n",
    "\n",
    "    def set_meta_embeddings(self, embed:torch.Tensor):\n",
    "        self.meta_embeddings.weight.data = embed\n",
    "        \n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        return self.distilbert.get_position_embeddings()\n",
    "    \n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "        self.distilbert.resize_position_embeddings(new_num_position_embeddings)\n",
    "    \n",
    "    def encode(self, input_ids:torch.Tensor, attention_mask:torch.Tensor, **kwargs):\n",
    "        return self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    def dr(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.dr_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "\n",
    "    def dr_fused(self, embed:torch.Tensor):\n",
    "        embed = self.dr_fused_head(embed)\n",
    "        return F.normalize(embed, dim=1)\n",
    "\n",
    "    def meta(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.meta_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "    \n",
    "    def meta_unnormalized(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.meta_head(embed)\n",
    "        return Pooling.mean_pooling(embed, attention_mask)\n",
    "\n",
    "    def resize(self, idx:torch.Tensor, num_inputs:torch.Tensor):\n",
    "        if torch.any(num_inputs == 0): raise ValueError(\"`num_inputs` should be non-zero positive integer.\")\n",
    "        bsz, total_num_inputs = num_inputs.shape[0], idx.shape[0]\n",
    "        \n",
    "        self.ones = self.ones.to(idx.device)\n",
    "        ones = (\n",
    "            torch.ones(total_num_inputs, dtype=torch.long, device=idx.device) \n",
    "            if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
    "        )\n",
    "\n",
    "        max_num_inputs = num_inputs.max()\n",
    "        if (num_inputs == max_num_inputs).all():\n",
    "            return idx,ones\n",
    "        \n",
    "        xnum_inputs = max_num_inputs-num_inputs+1\n",
    "\n",
    "        inputs_ptr = num_inputs.cumsum(dim=0)-1\n",
    "        repeat_inputs = ones.scatter(0, inputs_ptr, xnum_inputs)\n",
    "        \n",
    "        resized_idx = idx.repeat_interleave(repeat_inputs, dim=0)\n",
    "        ignore_mask = ones.scatter(0, inputs_ptr, 0).repeat_interleave(repeat_inputs, dim=0).view(bsz, -1)\n",
    "        ignore_mask[:, -1] = 1; ignore_mask = ignore_mask.flatten()\n",
    "        \n",
    "        return resized_idx,ignore_mask\n",
    "\n",
    "    \n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
    "            \n",
    "            if len(idx):\n",
    "                m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
    "                m_repr = F.normalize(self.meta_embeddings(m_idx), dim=1)\n",
    "                \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
    "                meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "                \n",
    "                fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                data_fused_repr[idx] += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_type:Optional[str]=None,\n",
    "        data_unnormalized:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        \n",
    "        if data_type is not None and data_type == \"meta\":\n",
    "            data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
    "        else: \n",
    "            data_repr = self.dr(data_o[0], data_attention_mask)\n",
    "        \n",
    "        data_fused_repr = meta_repr = None\n",
    "        if data_aug_meta_prefix is not None:\n",
    "            meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
    "            if len(meta_kwargs):\n",
    "                data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
    "                                                                            torch.any(data_attention_mask, dim=1), \n",
    "                                                                            meta_kwargs)\n",
    "                data_fused_repr = self.dr_fused(data_fused_repr)\n",
    "                \n",
    "        return EncoderOutput(\n",
    "            rep=data_repr,\n",
    "            fused_rep=data_fused_repr,\n",
    "            meta_repr=meta_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba618800-3966-4b2a-b887-96faa1cda5b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf51c610-41c8-4752-b2e6-5ac4cd5492ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK000(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, config,\n",
    "\n",
    "        data_aug_meta_prefix:Optional[str]=None, \n",
    "        lbl2data_aug_meta_prefix:Optional[str]=None, \n",
    "\n",
    "        data_pred_meta_prefix:Optional[str]=None,\n",
    "        lbl2data_pred_meta_prefix:Optional[str]=None,\n",
    "        \n",
    "        num_batch_labels:Optional[int]=None, \n",
    "        batch_size:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        num_negatives:Optional[int]=5,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=True,\n",
    "\n",
    "        calib_margin:Optional[float]=0.3,\n",
    "        calib_num_negatives:Optional[int]=10,\n",
    "        calib_tau:Optional[float]=0.1,\n",
    "        calib_apply_softmax:Optional[bool]=False,\n",
    "        calib_loss_weight:Optional[float]=0.1,\n",
    "        use_calib_loss:Optional[float]=False,\n",
    "        \n",
    "        meta_loss_weight:Optional[Union[List,float]]=0.3,\n",
    "        \n",
    "        use_fusion_loss:Optional[bool]=False,\n",
    "        fusion_loss_weight:Optional[float]=0.15,\n",
    "\n",
    "        use_query_loss:Optional[float]=True,\n",
    "        \n",
    "        use_encoder_parallel:Optional[bool]=True,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        store_attr('meta_loss_weight,fusion_loss_weight,calib_loss_weight')\n",
    "        store_attr('data_pred_meta_prefix,lbl2data_pred_meta_prefix')\n",
    "        store_attr('data_aug_meta_prefix,lbl2data_aug_meta_prefix')\n",
    "        store_attr('use_fusion_loss,use_query_loss,use_calib_loss,use_encoder_parallel')\n",
    "        \n",
    "        self.encoder = None\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=batch_size, tn_targ=num_batch_labels, margin=margin, n_negatives=num_negatives, \n",
    "                                        tau=tau, apply_softmax=apply_softmax, reduce='mean')\n",
    "        self.cab_loss_fn = Calibration(margin=calib_margin, tau=calib_tau, n_negatives=calib_num_negatives, \n",
    "                                       apply_softmax=calib_apply_softmax, reduce='mean')\n",
    "        \n",
    "    def init_retrieval_head(self):\n",
    "        if self.encoder is None: raise ValueError('`self.encoder` is not initialized.')\n",
    "        self.encoder.dr_head.post_init()\n",
    "        self.encoder.meta_head.post_init()\n",
    "        self.encoder.dr_fused_head.post_init()\n",
    "\n",
    "    def init_cross_head(self):\n",
    "        if self.encoder is None: raise ValueError('`self.encoder` is not initialized.')\n",
    "        self.encoder.cross_head.post_init()\n",
    "        \n",
    "\n",
    "    def compute_loss(self, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.rep_loss_fn(inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "\n",
    "    def calibration_loss(self, einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.calib_loss_weight * self.cab_loss_fn(einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "    \n",
    "    def compute_meta_loss(self, data_repr, lbl2data_repr, **kwargs):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "            \n",
    "        data_meta_inputs = Parameters.from_meta_pred_prefix(self.data_pred_meta_prefix, **kwargs)\n",
    "        lbl2data_meta_inputs = Parameters.from_meta_pred_prefix(self.lbl2data_pred_meta_prefix, **kwargs)\n",
    "        meta_inputs = {**data_meta_inputs, **lbl2data_meta_inputs}\n",
    "\n",
    "        m_lw = Parameters.get_meta_loss_weights(self.meta_loss_weight, len(meta_inputs)) if len(meta_inputs) else []\n",
    "        \n",
    "        loss = 0.0\n",
    "        for inputs,lw in zip(meta_inputs.values(), m_lw):\n",
    "            if 'lbl2data2ptr' in inputs:\n",
    "                idx = torch.where(inputs['lbl2data2ptr'])[0]\n",
    "                if len(idx) > 0:\n",
    "                    inputs_o = encoder(data_input_ids=inputs['input_ids'], data_attention_mask=inputs['attention_mask'], \n",
    "                                       data_type=\"meta\")\n",
    "                    m_loss = self.rep_loss_fn(lbl2data_repr[idx], inputs_o.rep, inputs['lbl2data2ptr'][idx],\n",
    "                                              inputs['idx'], inputs['plbl2data2ptr'][idx], inputs['pidx'])\n",
    "                    loss += lw * m_loss\n",
    "\n",
    "            elif 'data2ptr' in inputs:\n",
    "                idx = torch.where(inputs['data2ptr'])[0]\n",
    "                if len(idx) > 0:\n",
    "                    inputs_o = encoder(data_input_ids=inputs['input_ids'], data_attention_mask=inputs['attention_mask'], \n",
    "                                       data_type=\"meta\")\n",
    "                    m_loss = self.rep_loss_fn(data_repr[idx], inputs_o.rep, inputs['data2ptr'][idx], inputs['idx'], \n",
    "                                              inputs['pdata2ptr'][idx], inputs['pidx'])\n",
    "                    loss += lw * m_loss       \n",
    "\n",
    "            else: raise ValueError('Invalid metadata input arguments.')\n",
    "        return loss\n",
    "\n",
    "    def compute_fusion_loss(self, data_repr, meta_repr:Dict, prefix:str, **kwargs):\n",
    "        meta_inputs = Parameters.from_meta_pred_prefix(prefix, **kwargs)\n",
    "        \n",
    "        loss = 0.0\n",
    "        if meta_repr is not None:\n",
    "            for key,input_repr in meta_repr.items():\n",
    "                inputs = meta_inputs[key]\n",
    "                if 'lbl2data2ptr' in inputs:\n",
    "                    idx = torch.where(inputs['lbl2data2ptr'])[0]\n",
    "                    if len(idx) > 0:\n",
    "                        m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['lbl2data2ptr'][idx],\n",
    "                                                  inputs['idx'], inputs['plbl2data2ptr'][idx], inputs['pidx'])\n",
    "                        loss += self.fusion_loss_weight * m_loss\n",
    "    \n",
    "                elif 'data2ptr' in inputs:\n",
    "                    idx = torch.where(inputs['data2ptr'])[0]\n",
    "                    if len(idx) > 0:\n",
    "                        m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['data2ptr'][idx], inputs['idx'], \n",
    "                                                  inputs['pdata2ptr'][idx], inputs['pidx'])\n",
    "                        loss += self.fusion_loss_weight * m_loss       \n",
    "    \n",
    "                else: raise ValueError('Invalid metadata input arguments.')\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def get_meta_representation(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "            \n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_unnormalized=True, data_type=\"meta\")\n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    \n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c613ba79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca974424-8b53-4c3c-94f0-53bca3373924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK001(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder(config, num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad29670-b8a1-4c4a-9ed1-688cf1688942",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c3368-2fa0-4de1-9f08-af5457072ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OAK001.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=True, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474229a6-5dfe-4313-8074-e569293188c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_meta_embeddings(torch.zeros(656086, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a579f5-3283-4d1e-82fe-b32b8a0937ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7739b8c-6990-46e8-92a7-3e798638f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c12e8-f39c-4011-a7ca-da0ee84e07af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1532b1a3-2907-4b68-978a-e726b26ec553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95b39d-540a-4394-a293-8bc3fcaa4d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0194cf-d96d-4f72-bd40-f6e42c875b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0670, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742e7f0-ecda-4ea0-9b83-84df4fdc206c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f75036b-836a-4d23-8eea-88394679eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder002(Encoder):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        cross_tau:Optional[float]=0.1, \n",
    "        cross_dropout:Optional[float]=0.1, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.cross_head = NormCrossAttention(config, tau=cross_tau, dropout=cross_dropout)\n",
    "        self.post_init()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc3dd5-0c74-44ec-9f6f-876ac0c67f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK002(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        \n",
    "        cross_tau:Optional[float]=0.1,\n",
    "        cross_dropout:Optional[float]=0.1,\n",
    "        \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder002(config, cross_tau=cross_tau, cross_dropout=cross_dropout,\n",
    "                                  num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2320138-217b-40f9-bc48-0401099feafe",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da5d9f-c843-4c50-93ff-cb50b0ac2cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK002 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.tau', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK002.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=True, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               cross_tau=1.0, cross_dropout=0.1,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2cfce-8697-4a12-8192-8554195b0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_meta_embeddings(torch.zeros(656086, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29930733-8b3c-4c96-9221-78ef3e55eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ef1ee-45fc-435e-81f8-0c3f55ff701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ede8f-8d77-4c8a-8445-8dff479d70e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36176/2795290057.py(33)forward()\n",
      "     31         output_attentions:Optional[bool] = False,\n",
      "     32     ):\n",
      "---> 33         bs, q_len, dim = q.size()\n",
      "     34         v, k_len = k, k.size(1)\n",
      "     35 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36176/2795290057.py(34)forward()\n",
      "     32     ):\n",
      "     33         bs, q_len, dim = q.size()\n",
      "---> 34         v, k_len = k, k.size(1)\n",
      "     35 \n",
      "     36         h_dim = self.dim//self.n_h\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c128f070-2891-4540-a589-4f8195addeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae7ddb-b7bb-4633-9238-c081ecd049ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d670ddf9-64f7-49c8-b70a-486d993acaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder003(Encoder):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, num_metadata=num_metadata, **kwargs)\n",
    "        self.pretrained_meta_embeddings = nn.Embedding(num_metadata, config.dim)\n",
    "        self.post_init()\n",
    "\n",
    "    def freeze_pretrained_meta_embeddings(self):\n",
    "        self.pretrained_meta_embeddings.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_pretrained_meta_embeddings(self):\n",
    "        self.pretrained_meta_embeddings.requires_grad_(True)\n",
    "\n",
    "    def set_pretrained_meta_embeddings(self, embed:torch.Tensor):\n",
    "        self.pretrained_meta_embeddings.weight.data = embed\n",
    "\n",
    "    def init_meta_embeddings(self):\n",
    "        self.meta_embeddings.weight.data = torch.zeros_like(self.meta_embeddings.weight.data)\n",
    "\n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
    "            \n",
    "            if len(idx):\n",
    "                m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
    "                m_repr = F.normalize(self.meta_embeddings(m_idx) + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
    "                \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
    "                meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "                \n",
    "                fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                data_fused_repr[idx] += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c92804f4-bccf-4aa4-bf5e-8ab7cabf1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK003(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder003(config, num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_meta_embeddings(self):\n",
    "        self.encoder.init_meta_embeddings()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b6bbef-d971-42d2-8c2b-63e2d8f91101",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86864591-7758-4b37-8702-fabfe8f872a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK003 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK003.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2d36d-4e8c-4827-b535-db7c509dd187",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5e54c-df22-4186-8b2d-61371a17a985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d585ba-dd70-4988-90ff-2fbed155f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca4074-7bbd-4c10-aa36-3896a339fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b2ca2-86b3-442c-be01-0235cbf4081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dcdfea-660c-4726-a9d4-03eef45e0c97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(65)resize()\n",
      "     63         #debug\n",
      "     64 \n",
      "---> 65         if torch.any(num_inputs == 0): raise ValueError(\"`num_inputs` should be non-zero positive integer.\")\n",
      "     66         bsz, total_num_inputs = num_inputs.shape[0], idx.shape[0]\n",
      "     67 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  num_inputs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 3, 3, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(66)resize()\n",
      "     64 \n",
      "     65         if torch.any(num_inputs == 0): raise ValueError(\"`num_inputs` should be non-zero positive integer.\")\n",
      "---> 66         bsz, total_num_inputs = num_inputs.shape[0], idx.shape[0]\n",
      "     67 \n",
      "     68         self.ones = self.ones.to(idx.device)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(68)resize()\n",
      "     66         bsz, total_num_inputs = num_inputs.shape[0], idx.shape[0]\n",
      "     67 \n",
      "---> 68         self.ones = self.ones.to(idx.device)\n",
      "     69         ones = (\n",
      "     70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(71)resize()\n",
      "     69         ones = (\n",
      "     70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "---> 71             if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
      "     72         )\n",
      "     73 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(70)resize()\n",
      "     68         self.ones = self.ones.to(idx.device)\n",
      "     69         ones = (\n",
      "---> 70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "     71             if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
      "     72         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(71)resize()\n",
      "     69         ones = (\n",
      "     70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "---> 71             if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
      "     72         )\n",
      "     73 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(70)resize()\n",
      "     68         self.ones = self.ones.to(idx.device)\n",
      "     69         ones = (\n",
      "---> 70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "     71             if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
      "     72         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(71)resize()\n",
      "     69         ones = (\n",
      "     70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "---> 71             if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
      "     72         )\n",
      "     73 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(69)resize()\n",
      "     67 \n",
      "     68         self.ones = self.ones.to(idx.device)\n",
      "---> 69         ones = (\n",
      "     70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "     71             if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(74)resize()\n",
      "     72         )\n",
      "     73 \n",
      "---> 74         max_num_inputs = num_inputs.max()\n",
      "     75         if (num_inputs == max_num_inputs).all():\n",
      "     76             return idx,ones\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(75)resize()\n",
      "     73 \n",
      "     74         max_num_inputs = num_inputs.max()\n",
      "---> 75         if (num_inputs == max_num_inputs).all():\n",
      "     76             return idx,ones\n",
      "     77 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(76)resize()\n",
      "     74         max_num_inputs = num_inputs.max()\n",
      "     75         if (num_inputs == max_num_inputs).all():\n",
      "---> 76             return idx,ones\n",
      "     77 \n",
      "     78         xnum_inputs = max_num_inputs-num_inputs+1\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  idx.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  ones.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([16184...4875,  84879]), tensor([1, 1,..., 1, 1, 1, 1]))\n",
      "> /tmp/ipykernel_26893/4002658968.py(76)resize()\n",
      "     74         max_num_inputs = num_inputs.max()\n",
      "     75         if (num_inputs == max_num_inputs).all():\n",
      "---> 76             return idx,ones\n",
      "     77 \n",
      "     78         xnum_inputs = max_num_inputs-num_inputs+1\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/3123686291.py(36)fuse_meta_into_embeddings()\n",
      "     34             if len(idx):\n",
      "     35                 m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
      "---> 36                 m_repr = F.normalize(self.meta_embeddings(m_idx) + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "     37 \n",
      "     38                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_idx.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr_mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/3123686291.py(38)fuse_meta_into_embeddings()\n",
      "     36                 m_repr = F.normalize(self.meta_embeddings(m_idx) + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "     37 \n",
      "---> 38                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "     39                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "     40 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3415984d-3419-4b98-9a43-59c2128fb81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0675, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd6642-f9d6-489a-882e-e519eb8cf229",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK004`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0828ad34-448c-4e4c-864a-9a0c7149f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder004(Encoder003):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        cross_tau:Optional[float]=0.1, \n",
    "        cross_dropout:Optional[float]=0.1, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.cross_head = NormCrossAttention(config, tau=cross_tau, dropout=cross_dropout)\n",
    "        self.post_init()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3416e8d-5b8e-4732-81f3-1fe8b02debf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK004(OAK003, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK003.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        \n",
    "        cross_tau:Optional[float]=1.0,\n",
    "        cross_dropout:Optional[float]=0.1,\n",
    "        \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs, num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.encoder = Encoder004(config, cross_tau=cross_tau, cross_dropout=cross_dropout,\n",
    "                                  num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc4adc-31a9-4d7b-b633-bbb1937c6463",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23465467-1945-4a16-bd88-29f79711b9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK004 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.tau', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK004.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.05, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               cross_tau=1.0, cross_dropout=0.1,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ab9e7-19cb-43e7-8a7c-da168e49700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()\n",
    "\n",
    "model.init_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3881124-08cc-4adb-a601-183e2e7969fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8f71e-587c-4d1a-b17d-1e1a22fda709",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76e225-f12e-43fc-b1d8-99c509b750c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62779de8-398f-4c8d-96b6-8c655c983c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cdbaaf-074a-4f9b-87f5-91dec694d99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7db880-e7b1-45a6-8ab8-fdfc8e4ff732",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK005`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786c265-3153-4ca7-9a0c-d9b6c6f9cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder005(Encoder003):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.gen_head = GenerationHead(config)\n",
    "        \n",
    "    def get_output_embeddings(self) -> nn.Module:\n",
    "        return self.gen_head.projector\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings: nn.Module):\n",
    "        self.gen_head.projector = new_embeddings\n",
    "    \n",
    "    def gen(self, x:torch.Tensor):\n",
    "        return self.gen_head(x)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_type:Optional[str]=None,\n",
    "        data_unnormalized:Optional[bool]=False,\n",
    "\n",
    "        data_gen_idx:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        **kwargs\n",
    "    ):  \n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        \n",
    "        if data_type is not None and data_type == \"meta\":\n",
    "            data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
    "        else: \n",
    "            data_repr = self.dr(data_o[0], data_attention_mask)\n",
    "        \n",
    "        data_fused_repr = meta_repr = None\n",
    "        if data_aug_meta_prefix is not None:\n",
    "            meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
    "            if len(meta_kwargs):\n",
    "                data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
    "                                                                            torch.any(data_attention_mask, dim=1), \n",
    "                                                                            meta_kwargs)\n",
    "                data_fused_repr = self.dr_fused(data_fused_repr)\n",
    "\n",
    "        data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx]) \n",
    "                \n",
    "        return EncoderOutput(\n",
    "            rep=data_repr,\n",
    "            fused_rep=data_fused_repr,\n",
    "            meta_repr=meta_repr,\n",
    "            \n",
    "            logits=data_logits,\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d283d6b-8ba8-4824-8bd3-65906d511c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK005(OAK003, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = True,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK003.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "\n",
    "        num_batch_labels:Optional[int]=None, \n",
    "        ignore_token:Optional[int]=0,\n",
    "        gen_loss_weight:Optional[float]=1.0,\n",
    "        use_gen_loss:Optional[bool]=True,\n",
    "        \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs, num_metadata=num_metadata, resize_length=resize_length, num_batch_labels=num_batch_labels)\n",
    "        store_attr('use_gen_loss')\n",
    "        self.g_lw = gen_loss_weight\n",
    "        self.encoder = Encoder005(config, num_metadata=num_metadata, resize_length=resize_length)\n",
    "\n",
    "        self.gen_loss_fn = MultiCrossEntropy(tn_targ=num_batch_labels, ig_tok=ignore_token, reduce='mean')\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "\n",
    "    def compute_gen_loss(self, inp_logits, targ_logits, inp_input_ids, targ_input_ids, targ_ptr):\n",
    "        gen_loss = self.gen_loss_fn(inp_logits, targ_input_ids, targ_ptr) + self.gen_loss_fn(targ_logits, inp_input_ids)\n",
    "        return self.g_lw * gen_loss\n",
    "\n",
    "    def init_generation_head(self):\n",
    "        self.encoder.gen_head.projector.weight.data = self.get_input_embeddings().weight.data.clone()\n",
    "\n",
    "    def get_last_item_mask(self, num_input:torch.Tensor, input_sz:int):\n",
    "        idx = torch.where(num_input > 0)[0]\n",
    "        input_ptr = num_input[idx].cumsum(dim=0)-1\n",
    "        return torch.zeros(input_sz, dtype=torch.bool, device=num_input.device).scatter(0, input_ptr, 1)\n",
    "\n",
    "    def freeze(self):\n",
    "        for n,p in self.named_parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    def unfreeze(self):\n",
    "        for n,p in self.named_parameters():\n",
    "            p.requires_grad_(True)\n",
    "\n",
    "    def unfreeze_head(self):\n",
    "        for n,p in self.encoder.gen_head.named_parameters():\n",
    "            p.requires_grad_(True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_gen_idx = self.get_last_item_mask(lbl2data_data2ptr, len(lbl2data_idx))\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
    "                                 **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_gen_loss:\n",
    "                loss += self.compute_gen_loss(data_o.logits, lbl2data_o.logits, data_input_ids,lbl2data_input_ids,\n",
    "                                              lbl2data_data2ptr)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "\n",
    "            logits=data_o.logits,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642eb0d-db4d-4a5f-87f3-83bf2afd2ae6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc019bf2-f127-4c18-8a0b-0660db9aab90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK005 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.gen_head.layer_norm.bias', 'encoder.gen_head.layer_norm.weight', 'encoder.gen_head.projector.bias', 'encoder.gen_head.projector.weight', 'encoder.gen_head.transform.bias', 'encoder.gen_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK005.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.05, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "                               \n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "\n",
    "                               ignore_token=0, gen_loss_weight=1.0, use_gen_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_generation_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9e8b4c-e107-403b-8a2e-a87e84b7a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze()\n",
    "model.unfreeze_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f1aaa0-394c-46be-84c5-ff18a039e296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53c228-bb52-4721-b9a8-55e706a0562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "\n",
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d2e0b-cf35-4d78-aa0b-e3b1836b6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bac920-062c-4dff-a7a4-37a699a346c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457b653-416e-4b74-87bb-c80dd35e50a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(58)forward()\n",
      "     56         **kwargs\n",
      "     57     ):  \n",
      "---> 58         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     59 \n",
      "     60         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(33)forward()\n",
      "     31         **kwargs\n",
      "     32     ):  \n",
      "---> 33         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "     34 \n",
      "     35         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(33)forward()\n",
      "     31         **kwargs\n",
      "     32     ):  \n",
      "---> 33         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "     34 \n",
      "     35         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452f591-907c-4bc0-bee9-4134c6487e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ccab6-e02d-478e-8480-2d0ef0f1e604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/3657616883.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b.to(model.device))\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 1 at /tmp/ipykernel_3071/2330200620.py:43\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.encoder.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 2 at /tmp/ipykernel_3071/1501785349.py:21\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(58)forward()\n",
      "     56         **kwargs\n",
      "     57     ):  \n",
      "---> 58         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     59 \n",
      "     60         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(60)forward()\n",
      "     58         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     59 \n",
      "---> 60         if self.use_encoder_parallel:\n",
      "     61             encoder = XCDataParallel(module=self.encoder)\n",
      "     62         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(62)forward()\n",
      "     60         if self.use_encoder_parallel:\n",
      "     61             encoder = XCDataParallel(module=self.encoder)\n",
      "---> 62         else: encoder = self.encoder\n",
      "     63 \n",
      "     64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(64)forward()\n",
      "     62         else: encoder = self.encoder\n",
      "     63 \n",
      "---> 64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     65         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     66                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(65)forward()\n",
      "     63 \n",
      "     64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 65         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     66                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     67 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(66)forward()\n",
      "     64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     65         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 66                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     67 \n",
      "     68 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(65)forward()\n",
      "     63 \n",
      "     64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 65         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     66                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     67 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(66)forward()\n",
      "     64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     65         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 66                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     67 \n",
      "     68 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(65)forward()\n",
      "     63 \n",
      "     64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 65         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     66                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     67 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1507)_wrapped_call_impl()\n",
      "   1505         return result\n",
      "   1506 \n",
      "-> 1507     def _wrapped_call_impl(self, *args, **kwargs):\n",
      "   1508         if self._compiled_call_impl is not None:\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(33)forward()\n",
      "     31         **kwargs\n",
      "     32     ):  \n",
      "---> 33         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "     34 \n",
      "     35         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(35)forward()\n",
      "     33         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "     34 \n",
      "---> 35         if data_type is not None and data_type == \"meta\":\n",
      "     36             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "     37         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_o.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'BaseModelOutput' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_o[0].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(38)forward()\n",
      "     36             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "     37         else:\n",
      "---> 38             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "     39 \n",
      "     40         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(40)forward()\n",
      "     38             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "     39 \n",
      "---> 40         data_fused_repr = meta_repr = None\n",
      "     41         if data_aug_meta_prefix is not None:\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(41)forward()\n",
      "     39 \n",
      "     40         data_fused_repr = meta_repr = None\n",
      "---> 41         if data_aug_meta_prefix is not None:\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "     43             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(42)forward()\n",
      "     40         data_fused_repr = meta_repr = None\n",
      "     41         if data_aug_meta_prefix is not None:\n",
      "---> 42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "     43             if len(meta_kwargs):\n",
      "     44                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(43)forward()\n",
      "     41         if data_aug_meta_prefix is not None:\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "---> 43             if len(meta_kwargs):\n",
      "     44                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "     45                                                                             torch.any(data_attention_mask, dim=1),\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(44)forward()\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "     43             if len(meta_kwargs):\n",
      "---> 44                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "     45                                                                             torch.any(data_attention_mask, dim=1),\n",
      "     46                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(45)forward()\n",
      "     43             if len(meta_kwargs):\n",
      "     44                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "---> 45                                                                             torch.any(data_attention_mask, dim=1),\n",
      "     46                                                                             meta_kwargs)\n",
      "     47                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(46)forward()\n",
      "     44                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "     45                                                                             torch.any(data_attention_mask, dim=1),\n",
      "---> 46                                                                             meta_kwargs)\n",
      "     47                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "     48 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(44)forward()\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "     43             if len(meta_kwargs):\n",
      "---> 44                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "     45                                                                             torch.any(data_attention_mask, dim=1),\n",
      "     46                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(47)forward()\n",
      "     45                                                                             torch.any(data_attention_mask, dim=1),\n",
      "     46                                                                             meta_kwargs)\n",
      "---> 47                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "     48 \n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(49)forward()\n",
      "     47                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "     48 \n",
      "---> 49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "     51         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(51)forward()\n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "---> 51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_logits.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5, 30522])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_gen_idx\n",
      "ipdb>  data_gen_idx is None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(52)forward()\n",
      "     50 \n",
      "     51         return EncoderOutput(\n",
      "---> 52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "     54             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(53)forward()\n",
      "     51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "---> 53             fused_rep=data_fused_repr,\n",
      "     54             meta_repr=meta_repr,\n",
      "     55 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(54)forward()\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "---> 54             meta_repr=meta_repr,\n",
      "     55 \n",
      "     56             logits=data_logits,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(56)forward()\n",
      "     54             meta_repr=meta_repr,\n",
      "     55 \n",
      "---> 56             logits=data_logits,\n",
      "     57         )\n",
      "     58 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(51)forward()\n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "---> 51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...xBackward0>)})\n",
      "> /tmp/ipykernel_3071/1501785349.py(51)forward()\n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "---> 51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...xBackward0>)})\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1511)_wrapped_call_impl()\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1510         else:\n",
      "-> 1511             return self._call_impl(*args, **kwargs)\n",
      "   1512 \n",
      "   1513     def _call_impl(self, *args, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(69)forward()\n",
      "     67 \n",
      "     68 \n",
      "---> 69         loss = None; lbl2data_o = EncoderOutput()\n",
      "     70         if lbl2data_input_ids is not None:\n",
      "     71             lbl2data_gen_idx = self.get_last_item_mask(lbl2data_data2ptr, len(lbl2data_idx))\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(70)forward()\n",
      "     68 \n",
      "     69         loss = None; lbl2data_o = EncoderOutput()\n",
      "---> 70         if lbl2data_input_ids is not None:\n",
      "     71             lbl2data_gen_idx = self.get_last_item_mask(lbl2data_data2ptr, len(lbl2data_idx))\n",
      "     72             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(71)forward()\n",
      "     69         loss = None; lbl2data_o = EncoderOutput()\n",
      "     70         if lbl2data_input_ids is not None:\n",
      "---> 71             lbl2data_gen_idx = self.get_last_item_mask(lbl2data_data2ptr, len(lbl2data_idx))\n",
      "     72             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     73 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_data2ptr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(72)forward()\n",
      "     70         if lbl2data_input_ids is not None:\n",
      "     71             lbl2data_gen_idx = self.get_last_item_mask(lbl2data_data2ptr, len(lbl2data_idx))\n",
      "---> 72             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     73 \n",
      "     74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_gen_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(74)forward()\n",
      "     72             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     73 \n",
      "---> 74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
      "     76                                  **lbl2data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(75)forward()\n",
      "     73 \n",
      "     74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "---> 75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
      "     76                                  **lbl2data_meta_kwargs)\n",
      "     77 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(74)forward()\n",
      "     72             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     73 \n",
      "---> 74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
      "     76                                  **lbl2data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(76)forward()\n",
      "     74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
      "---> 76                                  **lbl2data_meta_kwargs)\n",
      "     77 \n",
      "     78             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(74)forward()\n",
      "     72             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     73 \n",
      "---> 74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
      "     76                                  **lbl2data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(33)forward()\n",
      "     31         **kwargs\n",
      "     32     ):  \n",
      "---> 33         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "     34 \n",
      "     35         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(35)forward()\n",
      "     33         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "     34 \n",
      "---> 35         if data_type is not None and data_type == \"meta\":\n",
      "     36             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "     37         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(38)forward()\n",
      "     36             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "     37         else:\n",
      "---> 38             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "     39 \n",
      "     40         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(40)forward()\n",
      "     38             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "     39 \n",
      "---> 40         data_fused_repr = meta_repr = None\n",
      "     41         if data_aug_meta_prefix is not None:\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(41)forward()\n",
      "     39 \n",
      "     40         data_fused_repr = meta_repr = None\n",
      "---> 41         if data_aug_meta_prefix is not None:\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "     43             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(49)forward()\n",
      "     47                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "     48 \n",
      "---> 49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "     51         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_gen_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(51)forward()\n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "---> 51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_logits.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 11, 30522])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(52)forward()\n",
      "     50 \n",
      "     51         return EncoderOutput(\n",
      "---> 52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "     54             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(53)forward()\n",
      "     51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "---> 53             fused_rep=data_fused_repr,\n",
      "     54             meta_repr=meta_repr,\n",
      "     55 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(54)forward()\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "---> 54             meta_repr=meta_repr,\n",
      "     55 \n",
      "     56             logits=data_logits,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(56)forward()\n",
      "     54             meta_repr=meta_repr,\n",
      "     55 \n",
      "---> 56             logits=data_logits,\n",
      "     57         )\n",
      "     58 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(51)forward()\n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "---> 51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> /tmp/ipykernel_3071/1501785349.py(51)forward()\n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "---> 51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(78)forward()\n",
      "     76                                  **lbl2data_meta_kwargs)\n",
      "     77 \n",
      "---> 78             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     79                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     80 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(79)forward()\n",
      "     77 \n",
      "     78             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "---> 79                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     80 \n",
      "     81             if self.use_gen_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(78)forward()\n",
      "     76                                  **lbl2data_meta_kwargs)\n",
      "     77 \n",
      "---> 78             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     79                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     80 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(81)forward()\n",
      "     79                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     80 \n",
      "---> 81             if self.use_gen_loss:\n",
      "     82                 loss += self.compute_gen_loss(data_o.logits, lbl2data_o.logits, data_input_ids,lbl2data_input_ids,\n",
      "     83                                               lbl2data_data2ptr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.use_gen_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(82)forward()\n",
      "     80 \n",
      "     81             if self.use_gen_loss:\n",
      "---> 82                 loss += self.compute_gen_loss(data_o.logits, lbl2data_o.logits, data_input_ids,lbl2data_input_ids,\n",
      "     83                                               lbl2data_data2ptr)\n",
      "     84 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_input_ids.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_input_ids.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 11])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_data2ptr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(83)forward()\n",
      "     81             if self.use_gen_loss:\n",
      "     82                 loss += self.compute_gen_loss(data_o.logits, lbl2data_o.logits, data_input_ids,lbl2data_input_ids,\n",
      "---> 83                                               lbl2data_data2ptr)\n",
      "     84 \n",
      "     85             if self.use_query_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(82)forward()\n",
      "     80 \n",
      "     81             if self.use_gen_loss:\n",
      "---> 82                 loss += self.compute_gen_loss(data_o.logits, lbl2data_o.logits, data_input_ids,lbl2data_input_ids,\n",
      "     83                                               lbl2data_data2ptr)\n",
      "     84 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(85)forward()\n",
      "     83                                               lbl2data_data2ptr)\n",
      "     84 \n",
      "---> 85             if self.use_query_loss:\n",
      "     86                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     87                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(86)forward()\n",
      "     84 \n",
      "     85             if self.use_query_loss:\n",
      "---> 86                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     87                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     88 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(87)forward()\n",
      "     85             if self.use_query_loss:\n",
      "     86                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "---> 87                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     88 \n",
      "     89             if self.use_calib_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(86)forward()\n",
      "     84 \n",
      "     85             if self.use_query_loss:\n",
      "---> 86                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     87                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     88 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(89)forward()\n",
      "     87                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     88 \n",
      "---> 89             if self.use_calib_loss:\n",
      "     90                 loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     91                                               plbl2data_data2ptr,plbl2data_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(93)forward()\n",
      "     91                                               plbl2data_data2ptr,plbl2data_idx)\n",
      "     92 \n",
      "---> 93             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "     94 \n",
      "     95             if self.use_fusion_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(95)forward()\n",
      "     93             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "     94 \n",
      "---> 95             if self.use_fusion_loss:\n",
      "     96                 loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
      "     97                 loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(100)forward()\n",
      "     98 \n",
      "     99 \n",
      "--> 100         if not return_dict:\n",
      "    101             o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
      "    102             return ((loss,) + o) if loss is not None else o\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(105)forward()\n",
      "    103 \n",
      "    104 \n",
      "--> 105         return XCModelOutput(\n",
      "    106             loss=loss,\n",
      "    107 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(106)forward()\n",
      "    104 \n",
      "    105         return XCModelOutput(\n",
      "--> 106             loss=loss,\n",
      "    107 \n",
      "    108             data_repr=data_o.rep,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(108)forward()\n",
      "    106             loss=loss,\n",
      "    107 \n",
      "--> 108             data_repr=data_o.rep,\n",
      "    109             data_fused_repr=data_o.fused_rep,\n",
      "    110 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(109)forward()\n",
      "    107 \n",
      "    108             data_repr=data_o.rep,\n",
      "--> 109             data_fused_repr=data_o.fused_rep,\n",
      "    110 \n",
      "    111             logits=data_o.logits,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(111)forward()\n",
      "    109             data_fused_repr=data_o.fused_rep,\n",
      "    110 \n",
      "--> 111             logits=data_o.logits,\n",
      "    112 \n",
      "    113             lbl2data_repr=lbl2data_o.rep,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(113)forward()\n",
      "    111             logits=data_o.logits,\n",
      "    112 \n",
      "--> 113             lbl2data_repr=lbl2data_o.rep,\n",
      "    114             lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
      "    115         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(114)forward()\n",
      "    112 \n",
      "    113             lbl2data_repr=lbl2data_o.rep,\n",
      "--> 114             lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
      "    115         )\n",
      "    116 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(105)forward()\n",
      "    103 \n",
      "    104 \n",
      "--> 105         return XCModelOutput(\n",
      "    106             loss=loss,\n",
      "    107 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "XCModelOutput...sed_repr=None)\n",
      "> /tmp/ipykernel_3071/2330200620.py(105)forward()\n",
      "    103 \n",
      "    104 \n",
      "--> 105         return XCModelOutput(\n",
      "    106             loss=loss,\n",
      "    107 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "XCModelOutput...sed_repr=None)\n",
      "> /tmp/ipykernel_3071/3657616883.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b.to(model.device))\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> /tmp/ipykernel_3071/492731717.py(1)<module>()\n",
      "----> 1 o = func()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "o = func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b98fe-12a9-47ff-922b-4cb16d3b2f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21.9783, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347a851-2056-4833-b40d-eabe5b4f4a04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK006`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30fbd64-34b1-4371-9a8f-ed30f6ba2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder006(DistilBertPreTrainedModel):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig, \n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        \n",
    "        self.dr_head = RepresentationHead(config)\n",
    "        self.dr_fused_head = RepresentationHead(config)\n",
    "        self.meta_head = RepresentationHead(config)\n",
    "        self.cross_head = CrossAttention(config)\n",
    "        self.meta_embeddings = nn.Embedding(num_metadata, config.dim, sparse=True)\n",
    "        self.pretrained_meta_embeddings = nn.Embedding(num_metadata, config.dim)\n",
    "\n",
    "        self.ones = torch.ones(resize_length, dtype=torch.long, device=self.device) if resize_length is not None else None\n",
    "        self.post_init()\n",
    "\n",
    "    def freeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(True)\n",
    "\n",
    "    def set_meta_embeddings(self, embed:torch.Tensor):\n",
    "        self.meta_embeddings.weight.data = embed\n",
    "\n",
    "    def init_meta_embeddings(self):\n",
    "        self.meta_embeddings.weight.data = torch.zeros_like(self.meta_embeddings.weight.data)\n",
    "\n",
    "    def freeze_pretrained_meta_embeddings(self):\n",
    "        self.pretrained_meta_embeddings.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_pretrained_meta_embeddings(self):\n",
    "        self.pretrained_meta_embeddings.requires_grad_(True)\n",
    "\n",
    "    def set_pretrained_meta_embeddings(self, embed:torch.Tensor):\n",
    "        self.pretrained_meta_embeddings.weight.data = embed\n",
    "        \n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        return self.distilbert.get_position_embeddings()\n",
    "    \n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "        self.distilbert.resize_position_embeddings(new_num_position_embeddings)\n",
    "    \n",
    "    def encode(self, input_ids:torch.Tensor, attention_mask:torch.Tensor, **kwargs):\n",
    "        return self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    def dr(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.dr_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "\n",
    "    def dr_fused(self, embed:torch.Tensor):\n",
    "        embed = self.dr_fused_head(embed)\n",
    "        return F.normalize(embed, dim=1)\n",
    "\n",
    "    def meta(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.meta_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "    \n",
    "    def meta_unnormalized(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.meta_head(embed)\n",
    "        return Pooling.mean_pooling(embed, attention_mask)\n",
    "\n",
    "    def resize(self, idx:torch.Tensor, num_inputs:torch.Tensor):\n",
    "        if torch.any(num_inputs == 0): raise ValueError(\"`num_inputs` should be non-zero positive integer.\")\n",
    "        bsz, total_num_inputs = num_inputs.shape[0], idx.shape[0]\n",
    "        \n",
    "        self.ones = self.ones.to(idx.device)\n",
    "        ones = (\n",
    "            torch.ones(total_num_inputs, dtype=torch.long, device=idx.device) \n",
    "            if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
    "        )\n",
    "\n",
    "        max_num_inputs = num_inputs.max()\n",
    "        if (num_inputs == max_num_inputs).all():\n",
    "            return idx,ones\n",
    "        \n",
    "        xnum_inputs = max_num_inputs-num_inputs+1\n",
    "\n",
    "        inputs_ptr = num_inputs.cumsum(dim=0)-1\n",
    "        repeat_inputs = ones.scatter(0, inputs_ptr, xnum_inputs)\n",
    "        \n",
    "        resized_idx = idx.repeat_interleave(repeat_inputs, dim=0)\n",
    "        ignore_mask = ones.scatter(0, inputs_ptr, 0).repeat_interleave(repeat_inputs, dim=0).view(bsz, -1)\n",
    "        ignore_mask[:, -1] = 1; ignore_mask = ignore_mask.flatten()\n",
    "        \n",
    "        return resized_idx,ignore_mask\n",
    "\n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
    "            \n",
    "            if len(idx):\n",
    "                m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
    "                m_repr = F.normalize(self.meta_embeddings(m_idx) + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
    "                \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
    "                meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "                \n",
    "                fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                data_fused_repr[idx] += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_type:Optional[str]=None,\n",
    "        data_unnormalized:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        \n",
    "        if data_type is not None and data_type == \"meta\":\n",
    "            data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
    "        else: \n",
    "            data_repr = self.dr(data_o[0], data_attention_mask)\n",
    "        \n",
    "        data_fused_repr = meta_repr = None\n",
    "        if data_aug_meta_prefix is not None:\n",
    "            meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
    "            if len(meta_kwargs):\n",
    "                data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
    "                                                                            torch.any(data_attention_mask, dim=1), \n",
    "                                                                            meta_kwargs)\n",
    "                data_fused_repr = self.dr_fused(data_fused_repr)\n",
    "                \n",
    "        return EncoderOutput(\n",
    "            rep=data_repr,\n",
    "            fused_rep=data_fused_repr,\n",
    "            meta_repr=meta_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cfafaf-5c11-4b42-b929-914abf7c54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK006(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder006(config, num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_meta_embeddings(self):\n",
    "        self.encoder.init_meta_embeddings()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6f29fb-90b3-4c5a-8d63-719f93208a52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa32fee-b90c-42ea-bd0b-a2b034ac618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK006 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK006.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9d2382-5897-4296-a817-2d762e2202b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91145947-3b61-4e10-98bf-c5283b6f7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce1fff-42f0-4c3c-abf7-d0f8cf5096a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea885d-0d18-4d0c-8839-472e00bfd757",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb4fbb-ea90-4316-acc5-d30dc939e316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c373ce-db05-4722-8f56-e58de7a5cbeb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK007`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d70229ff-d190-4612-a9a4-ab3edf67ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK007(OAK003, DistilBertPreTrainedModel):\n",
    "    \n",
    "    @delegates(OAK003.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        n_labels:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.label_embeddings = nn.Embedding(n_labels, config.dim)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_label_embeddings(self):\n",
    "        self.label_embeddings.weight.data = torch.zeros_like(self.label_embeddings.weight.data)\n",
    "\n",
    "    def get_label_representation(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask)\n",
    "        data_o.rep = F.normalize(data_o.rep + self.label_embeddings(data_idx), dim=1)\n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "\n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(lbl2data_idx), dim=1)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "\n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3136404-4e43-4c42-b82e-13fab74ae9d9",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc2d6605-bfb5-4eef-a589-ff1efc9ef828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK007 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight', 'label_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK007.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000, n_labels=block.n_lbl,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "model.init_label_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1ce81-defd-4d55-8319-c9ed46ae7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e6df69-708d-4d15-a1b9-0fc9ef1e7780",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e164cab6-542a-4b41-b69e-b4f40917e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "751086b3-b407-45d7-b9cf-d530ad7b8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f39f730c-9a76-4856-8c35-6eaa72ed3747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3794ee9-c571-4e09-bf54-aefcc0e17de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfde215-1ab1-4a87-8fbd-288d767ddc69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04009803-ce62-49bb-80c0-819df9c6f2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
