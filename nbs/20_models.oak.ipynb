{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd48060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.oak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d95873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2fc4a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, re, inspect, pickle, os, torch.nn as nn, math\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Tuple, Mapping, Any, Union\n",
    "from transformers import (\n",
    "    PretrainedConfig,\n",
    "    DistilBertForMaskedLM,\n",
    "    DistilBertModel,\n",
    "    DistilBertPreTrainedModel,\n",
    "    DistilBertConfig,\n",
    ")\n",
    "from transformers.utils.generic import ModelOutput\n",
    "from transformers.activations import get_activation\n",
    "\n",
    "from fastcore.meta import *\n",
    "from fastcore.utils import *\n",
    "\n",
    "from xcai.losses import *\n",
    "from xcai.core import store_attr\n",
    "from xcai.learner import XCDataParallel\n",
    "from xcai.models.modeling_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee9b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c00009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from transformers import AutoConfig\n",
    "from xcai.block import *\n",
    "from xcai.main import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ede14",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2702fcc1-055a-41d1-813b-bd6c71682c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.core import prepare_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ff9c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c24e44-8f52-4345-91c5-b0cbb84f7af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/suchith720/Projects/data'\n",
    "config_file = 'wikiseealsotitles'\n",
    "config_key = 'data_meta'\n",
    "\n",
    "mname = 'sentence-transformers/msmarco-distilbert-base-v4'\n",
    "\n",
    "pkl_dir = '/Users/suchith720/Projects/data/processed/mogicX'\n",
    "os.makedirs(pkl_dir, exist_ok=True)\n",
    "\n",
    "pkl_file = f'{pkl_dir}/wikiseealsotitles_data_distilbert-base-uncased_sxc.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84bd6b8e-d62c-4455-8baa-9dabc778afb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "block = build_block(pkl_file, config_file, True, config_key, data_dir=data_dir, n_slbl_samples=1, do_build=False, \n",
    "                    main_oversample=True, meta_oversample=True, return_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf79ca-48c4-4e8b-808c-a6bb42b742e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f843bd7a-d18c-4f44-bd4b-c56064ee937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "block.train.dset.meta['neg_meta'] = copy.deepcopy(block.train.dset.meta['cat_meta'])\n",
    "block.train.dset.meta['neg_meta'].prefix = 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ace1c8-4576-4d75-b984-1072f6a6384b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1acf57c7-3b04-48da-a63b-f3e932716a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c50e879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch in enumerate(block.train.dl):\n",
    "    if i > 2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5f9f36e-bf56-4af0-8a38-89860721f191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_idx', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_scores', 'lbl2data_data2ptr', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_scores', 'cat2data_data2ptr', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'pcat2lbl_idx', 'pcat2lbl_lbl2ptr', 'cat2lbl_idx', 'cat2lbl_scores', 'cat2lbl_lbl2ptr', 'cat2lbl_identifier', 'cat2lbl_input_text', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'cat2lbl_data2ptr', 'pcat2lbl_data2ptr', 'pneg2data_idx', 'pneg2data_data2ptr', 'neg2data_idx', 'neg2data_scores', 'neg2data_data2ptr', 'neg2data_identifier', 'neg2data_input_text', 'neg2data_input_ids', 'neg2data_attention_mask', 'pneg2lbl_idx', 'pneg2lbl_lbl2ptr', 'neg2lbl_idx', 'neg2lbl_scores', 'neg2lbl_lbl2ptr', 'neg2lbl_identifier', 'neg2lbl_input_text', 'neg2lbl_input_ids', 'neg2lbl_attention_mask', 'neg2lbl_data2ptr', 'pneg2lbl_data2ptr'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0ade052-8b4d-410c-8a75-ba382bfa6587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lbl2data_scores',\n",
       " 'cat2data_scores',\n",
       " 'cat2lbl_scores',\n",
       " 'neg2data_scores',\n",
       " 'neg2lbl_scores']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o for o in batch.keys() if 'scores' in o]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f97b11c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a92acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrossAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__()\n",
    "        self.config, self.n_h, self.dim = config, config.n_heads, config.dim\n",
    "        self.dropout = nn.Dropout(p=config.attention_dropout)\n",
    "\n",
    "        if self.dim % self.n_h != 0:\n",
    "            raise ValueError(f\"self.n_heads: {self.n_h} must divide self.dim: {self.dim} evenly.\")\n",
    "            \n",
    "        self.q = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.k = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.v = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.o = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def post_init(self):\n",
    "        nn.init.eye_(self.q.weight.data)\n",
    "        nn.init.eye_(self.k.weight.data)\n",
    "        nn.init.eye_(self.v.weight.data)\n",
    "        nn.init.eye_(self.o.weight.data)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        q: torch.Tensor,\n",
    "        q_m: torch.Tensor,\n",
    "        k: torch.Tensor, \n",
    "        k_m: torch.Tensor,\n",
    "        output_attentions:Optional[bool] = False,\n",
    "    ):\n",
    "        bs, q_len, dim = q.size()\n",
    "        v, k_len = k, k.size(1) \n",
    "\n",
    "        h_dim = self.dim//self.n_h\n",
    "\n",
    "        def shape(x: torch.Tensor): return x.view(bs, -1, self.n_h, h_dim).transpose(1, 2)\n",
    "\n",
    "        def unshape(x: torch.Tensor): return x.transpose(1, 2).contiguous().view(bs, -1, self.n_h * h_dim)\n",
    "\n",
    "        q = shape(self.q(q))  # (bs, n_h, q_len, h_dim)\n",
    "        k = shape(self.k(k))  # (bs, n_h, k_len, h_dim)\n",
    "        v = shape(self.v(v))  # (bs, n_h, k_len, h_dim)\n",
    "\n",
    "        q = q / math.sqrt(h_dim)  # (bs, n_h, q_len, h_dim)\n",
    "        sc = torch.matmul(q, k.transpose(2, 3))  # (bs, n_h, q_len, k_len)\n",
    "        \n",
    "        q_m, k_m = q_m.view(bs, 1, -1, 1).to(q.dtype), k_m.view(bs, 1, 1, -1).to(q.dtype)\n",
    "        mask = torch.matmul(q_m, k_m).expand_as(sc)  # (bs, n_h, q_len, k_len)\n",
    "        \n",
    "        sc = sc.masked_fill(mask == 0, torch.tensor(torch.finfo(sc.dtype).min))  # (bs, n_h, q_len, k_len)\n",
    "\n",
    "        w = nn.functional.softmax(sc, dim=-1)  # (bs, n_h, q_len, k_len)\n",
    "        w = self.dropout(w)  # (bs, n_h, q_len, k_len)\n",
    "\n",
    "        o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
    "        \n",
    "        if output_attentions: return (o, w)\n",
    "        else: return (o,)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258a231",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('distilbert-base-uncased')\n",
    "fuser = CrossAttention(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec047a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz, data_seq_len, n_meta, dim, dtype = 2, 3, 2, config.dim, torch.float32\n",
    "data, meta = torch.randn(bsz, data_seq_len, dim, dtype=dtype), torch.randn(bsz, n_meta, dim, dtype=dtype)\n",
    "data_mask = torch.randint(0, 2, size=(bsz,data_seq_len), dtype=dtype)\n",
    "meta_mask = torch.randint(0, 2, size=(bsz,n_meta), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = fuser(data, data_mask, meta, meta_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d426e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936fdbda-95ff-4531-ad45-09f0f5793534",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## NormCrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8691b3-0fdd-4e04-a1f7-a9442fcc3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NormCrossAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, config: PretrainedConfig, tau:Optional[float]=0.1, dropout:Optional[float]=0.1):\n",
    "        super().__init__()\n",
    "        self.tau = nn.Parameter(torch.tensor(tau, dtype=torch.float32))\n",
    "        \n",
    "        self.config, self.n_h, self.dim = config, config.n_heads, config.dim\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        if self.dim % self.n_h != 0:\n",
    "            raise ValueError(f\"self.n_heads: {self.n_h} must divide self.dim: {self.dim} evenly.\")\n",
    "            \n",
    "        self.q = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.k = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.v = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.o = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "\n",
    "    def post_init(self):\n",
    "        self.q.weight.data = torch.eye(self.q.out_features, self.q.in_features, dtype=self.q.weight.dtype)\n",
    "        self.k.weight.data = torch.eye(self.k.out_features, self.k.in_features, dtype=self.k.weight.dtype)\n",
    "        self.v.weight.data = torch.eye(self.v.out_features, self.v.in_features, dtype=self.v.weight.dtype)\n",
    "        self.o.weight.data = torch.eye(self.o.out_features, self.o.in_features, dtype=self.o.weight.dtype)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        q: torch.Tensor,\n",
    "        q_m: torch.Tensor,\n",
    "        k: torch.Tensor, \n",
    "        k_m: torch.Tensor,\n",
    "        output_attentions:Optional[bool] = False,\n",
    "    ):\n",
    "        bs, q_len, dim = q.size()\n",
    "        v, k_len = k, k.size(1) \n",
    "\n",
    "        h_dim = self.dim//self.n_h\n",
    "\n",
    "        def shape(x: torch.Tensor): return x.view(bs, -1, self.n_h, h_dim).transpose(1, 2)\n",
    "\n",
    "        def unshape(x: torch.Tensor): return x.transpose(1, 2).contiguous().view(bs, -1, self.n_h * h_dim)\n",
    "\n",
    "        q = shape(self.q(q))  # (bs, n_h, q_len, h_dim)\n",
    "        k = shape(self.k(k))  # (bs, n_h, k_len, h_dim)\n",
    "        v = shape(self.v(v))  # (bs, n_h, k_len, h_dim)\n",
    "\n",
    "        q = q / math.sqrt(h_dim)  # (bs, n_h, q_len, h_dim)\n",
    "        sc = torch.matmul(q, k.transpose(2, 3))  # (bs, n_h, q_len, k_len)\n",
    "        sc = sc * self.tau\n",
    "        \n",
    "        q_m, k_m = q_m.view(bs, 1, -1, 1).to(q.dtype), k_m.view(bs, 1, 1, -1).to(q.dtype)\n",
    "        mask = torch.matmul(q_m, k_m).expand_as(sc)  # (bs, n_h, q_len, k_len)\n",
    "        \n",
    "        sc = sc.masked_fill(mask == 0, torch.tensor(torch.finfo(sc.dtype).min))  # (bs, n_h, q_len, k_len)\n",
    "        \n",
    "        w = nn.functional.softmax(sc, dim=-1)  # (bs, n_h, q_len, k_len)\n",
    "        w = self.dropout(w)  # (bs, n_h, q_len, k_len)\n",
    "\n",
    "        o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
    "        \n",
    "        if output_attentions: return (o, w)\n",
    "        else: return (o,)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c937d-803e-419b-91a2-3002edd103b9",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a282707-094c-429c-97db-f0080d44c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('distilbert-base-uncased')\n",
    "fuser = NormCrossAttention(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61a60e-c6e4-4822-9f7e-f29c52fd7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz, data_seq_len, n_meta, dim, dtype = 2, 3, 2, config.dim, torch.float32\n",
    "\n",
    "data, meta = torch.randn(bsz, data_seq_len, dim, dtype=dtype), torch.randn(bsz, n_meta, dim, dtype=dtype)\n",
    "data_mask = torch.randint(0, 2, size=(bsz,data_seq_len), dtype=dtype)\n",
    "meta_mask = torch.randint(0, 2, size=(bsz,n_meta), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb2581-f3c5-4635-a9e3-943074ba7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = fuser(data, data_mask, meta, meta_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9419a3bc-5e8f-46b9-b98f-95d07076b09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a8737b",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5ed7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder(DistilBertPreTrainedModel):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig, \n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        normalize:Optional[bool]=True,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        store_attr('normalize')\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        \n",
    "        self.dr_head = RepresentationHead(config)\n",
    "        self.dr_fused_head = RepresentationHead(config)\n",
    "        \n",
    "        self.meta_head = RepresentationHead(config)\n",
    "        \n",
    "        self.cross_head = CrossAttention(config)\n",
    "        \n",
    "        self.meta_embeddings = nn.Embedding(num_metadata, config.dim)\n",
    "\n",
    "        if resize_length is None: self.ones = None\n",
    "        else: self.register_buffer('ones', torch.ones(resize_length, dtype=torch.long, device=self.device))\n",
    "        \n",
    "        self.post_init()\n",
    "\n",
    "    def freeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def set_meta_embeddings(self, embed:torch.Tensor):\n",
    "        self.meta_embeddings.weight.data.copy_(embed)\n",
    "        \n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        return self.distilbert.get_position_embeddings()\n",
    "    \n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "        self.distilbert.resize_position_embeddings(new_num_position_embeddings)\n",
    "    \n",
    "    def encode(self, input_ids:torch.Tensor, attention_mask:torch.Tensor, **kwargs):\n",
    "        return self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    def dr(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.dr_head(embed)\n",
    "        embed = Pooling.mean_pooling(embed, attention_mask)\n",
    "        return F.normalize(embed, dim=1) if self.normalize else embed\n",
    "\n",
    "    def dr_fused(self, embed:torch.Tensor):\n",
    "        embed = self.dr_fused_head(embed)\n",
    "        return F.normalize(embed, dim=1) if self.normalize else embed\n",
    "\n",
    "    def meta(self, embed:torch.Tensor, attention_mask:torch.Tensor, normalize:Optional[bool]=True):\n",
    "        embed = self.meta_head(embed)\n",
    "        embed = Pooling.mean_pooling(embed, attention_mask)\n",
    "        return F.normalize(embed, dim=1) if normalize else embed\n",
    "\n",
    "    def resize(self, idx:torch.Tensor, num_inputs:torch.Tensor):\n",
    "        if torch.any(num_inputs == 0): raise ValueError(\"`num_inputs` should be non-zero positive integer.\")\n",
    "        bsz, total_num_inputs = num_inputs.shape[0], idx.shape[0]\n",
    "        \n",
    "        self.ones = self.ones.to(idx.device)\n",
    "        ones = (\n",
    "            torch.ones(total_num_inputs, dtype=torch.long, device=idx.device) \n",
    "            if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
    "        )\n",
    "\n",
    "        max_num_inputs = num_inputs.max()\n",
    "        if (num_inputs == max_num_inputs).all():\n",
    "            return idx,ones\n",
    "        \n",
    "        xnum_inputs = max_num_inputs-num_inputs+1\n",
    "\n",
    "        inputs_ptr = num_inputs.cumsum(dim=0)-1\n",
    "        repeat_inputs = ones.scatter(0, inputs_ptr, xnum_inputs)\n",
    "        \n",
    "        resized_idx = idx.repeat_interleave(repeat_inputs, dim=0)\n",
    "        ignore_mask = ones.scatter(0, inputs_ptr, 0).repeat_interleave(repeat_inputs, dim=0).view(bsz, -1)\n",
    "        ignore_mask[:, -1] = 1; ignore_mask = ignore_mask.flatten()\n",
    "        \n",
    "        return resized_idx,ignore_mask\n",
    "\n",
    "    \n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
    "            \n",
    "            if len(idx):\n",
    "                m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
    "                m_repr = self.meta_embeddings(m_idx)\n",
    "                m_repr = F.normalize(m_repr, dim=1) if self.normalize else m_repr\n",
    "                \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
    "                meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "                \n",
    "                fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                data_fused_repr[idx] += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_type:Optional[str]=None,\n",
    "        data_unnormalized:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        \n",
    "        if data_type is not None and data_type == \"meta\":\n",
    "            data_repr = self.meta(data_o[0], data_attention_mask, not data_unnormalized)\n",
    "        else: \n",
    "            data_repr = self.dr(data_o[0], data_attention_mask)\n",
    "        \n",
    "        data_fused_repr = meta_repr = None\n",
    "        if data_aug_meta_prefix is not None:\n",
    "            meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
    "            if len(meta_kwargs):\n",
    "                data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
    "                                                                            torch.any(data_attention_mask, dim=1), \n",
    "                                                                            meta_kwargs)\n",
    "                data_fused_repr = self.dr_fused(data_fused_repr)\n",
    "                \n",
    "        return EncoderOutput(\n",
    "            rep=data_repr,\n",
    "            fused_rep=data_fused_repr,\n",
    "            meta_repr=meta_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba618800-3966-4b2a-b887-96faa1cda5b5",
   "metadata": {},
   "source": [
    "## `OAK000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf51c610-41c8-4752-b2e6-5ac4cd5492ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK000(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, config,\n",
    "\n",
    "        data_aug_meta_prefix:Optional[str]=None, \n",
    "        lbl2data_aug_meta_prefix:Optional[str]=None, \n",
    "\n",
    "        data_pred_meta_prefix:Optional[str]=None,\n",
    "        lbl2data_pred_meta_prefix:Optional[str]=None,\n",
    "        \n",
    "        margin:Optional[float]=0.3,\n",
    "        num_negatives:Optional[int]=5,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=True,\n",
    "\n",
    "        calib_margin:Optional[float]=0.3,\n",
    "        calib_num_negatives:Optional[int]=10,\n",
    "        calib_tau:Optional[float]=0.1,\n",
    "        calib_apply_softmax:Optional[bool]=False,\n",
    "        calib_loss_weight:Optional[float]=0.1,\n",
    "        use_calib_loss:Optional[float]=False,\n",
    "        \n",
    "        meta_loss_weight:Optional[Union[List,float]]=0.3,\n",
    "        \n",
    "        use_fusion_loss:Optional[bool]=False,\n",
    "        fusion_loss_weight:Optional[float]=0.15,\n",
    "\n",
    "        use_query_loss:Optional[float]=True,\n",
    "        \n",
    "        use_encoder_parallel:Optional[bool]=True,\n",
    "        \n",
    "        normalize:Optional[bool]=True,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        store_attr('meta_loss_weight,fusion_loss_weight,calib_loss_weight')\n",
    "        store_attr('data_pred_meta_prefix,lbl2data_pred_meta_prefix')\n",
    "        store_attr('data_aug_meta_prefix,lbl2data_aug_meta_prefix')\n",
    "        store_attr('use_fusion_loss,use_query_loss,use_calib_loss,use_encoder_parallel')\n",
    "        store_attr('normalize')\n",
    "        \n",
    "        self.encoder = None\n",
    "        self.rep_loss_fn = MultiTriplet(margin=margin, n_negatives=num_negatives, tau=tau, \n",
    "                                        apply_softmax=apply_softmax, reduce='mean')\n",
    "        self.cab_loss_fn = Calibration(margin=calib_margin, tau=calib_tau, n_negatives=calib_num_negatives, \n",
    "                                       apply_softmax=calib_apply_softmax, reduce='mean')\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def init_retrieval_head(self):\n",
    "        assert self.encoder is not None, \"`self.encoder` is not initialized.\"\n",
    "        self.encoder.dr_head.post_init()\n",
    "        self.encoder.meta_head.post_init()\n",
    "        self.encoder.dr_fused_head.post_init()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_cross_head(self):\n",
    "        assert self.encoder is not None, \"`self.encoder` is not initialized.\"\n",
    "        self.encoder.cross_head.post_init()\n",
    "\n",
    "    def compute_loss(self, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.rep_loss_fn(inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "\n",
    "    def calibration_loss(self, einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.calib_loss_weight * self.cab_loss_fn(einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "    \n",
    "    def compute_meta_loss(self, data_repr, lbl2data_repr, **kwargs):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "            \n",
    "        data_meta_inputs = Parameters.from_meta_pred_prefix(self.data_pred_meta_prefix, **kwargs)\n",
    "        lbl2data_meta_inputs = Parameters.from_meta_pred_prefix(self.lbl2data_pred_meta_prefix, **kwargs)\n",
    "        meta_inputs = {**data_meta_inputs, **lbl2data_meta_inputs}\n",
    "\n",
    "        m_lw = Parameters.get_meta_loss_weights(self.meta_loss_weight, len(meta_inputs)) if len(meta_inputs) else []\n",
    "        \n",
    "        loss = 0.0\n",
    "        for inputs,lw in zip(meta_inputs.values(), m_lw):\n",
    "            if 'lbl2data2ptr' in inputs:\n",
    "                idx = torch.where(inputs['lbl2data2ptr'])[0]\n",
    "                if len(idx) > 0:\n",
    "                    inputs_o = encoder(data_input_ids=inputs['input_ids'], data_attention_mask=inputs['attention_mask'], \n",
    "                                       data_type=\"meta\")\n",
    "                    m_loss = self.rep_loss_fn(lbl2data_repr[idx], inputs_o.rep, inputs['lbl2data2ptr'][idx],\n",
    "                                              inputs['idx'], inputs['plbl2data2ptr'][idx], inputs['pidx'])\n",
    "                    loss += lw * m_loss\n",
    "\n",
    "            elif 'data2ptr' in inputs:\n",
    "                idx = torch.where(inputs['data2ptr'])[0]\n",
    "                if len(idx) > 0:\n",
    "                    inputs_o = encoder(data_input_ids=inputs['input_ids'], data_attention_mask=inputs['attention_mask'], \n",
    "                                       data_type=\"meta\")\n",
    "                    m_loss = self.rep_loss_fn(data_repr[idx], inputs_o.rep, inputs['data2ptr'][idx], inputs['idx'], \n",
    "                                              inputs['pdata2ptr'][idx], inputs['pidx'])\n",
    "                    loss += lw * m_loss       \n",
    "\n",
    "            else: raise ValueError('Invalid metadata input arguments.')\n",
    "        return loss\n",
    "\n",
    "    def compute_fusion_loss(self, data_repr, meta_repr:Dict, prefix:str, **kwargs):\n",
    "        meta_inputs = Parameters.from_meta_pred_prefix(prefix, **kwargs)\n",
    "        \n",
    "        loss = 0.0\n",
    "        if meta_repr is not None:\n",
    "            for key,input_repr in meta_repr.items():\n",
    "                inputs = meta_inputs[key]\n",
    "                if 'lbl2data2ptr' in inputs:\n",
    "                    idx = torch.where(inputs['lbl2data2ptr'])[0]\n",
    "                    if len(idx) > 0:\n",
    "                        m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['lbl2data2ptr'][idx],\n",
    "                                                  inputs['idx'], inputs['plbl2data2ptr'][idx], inputs['pidx'])\n",
    "                        loss += self.fusion_loss_weight * m_loss\n",
    "    \n",
    "                elif 'data2ptr' in inputs:\n",
    "                    idx = torch.where(inputs['data2ptr'])[0]\n",
    "                    if len(idx) > 0:\n",
    "                        m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['data2ptr'][idx], inputs['idx'], \n",
    "                                                  inputs['pdata2ptr'][idx], inputs['pidx'])\n",
    "                        loss += self.fusion_loss_weight * m_loss       \n",
    "    \n",
    "                else: raise ValueError('Invalid metadata input arguments.')\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def get_meta_representation(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "            \n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_unnormalized=True, data_type=\"meta\")\n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c613ba79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca974424-8b53-4c3c-94f0-53bca3373924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK001(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder(config, num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad29670-b8a1-4c4a-9ed1-688cf1688942",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac6c3368-2fa0-4de1-9f08-af5457072ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK001 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK001.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=True, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "474229a6-5dfe-4313-8074-e569293188c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_meta_embeddings(torch.zeros(656086, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81a579f5-3283-4d1e-82fe-b32b8a0937ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7739b8c-6990-46e8-92a7-3e798638f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e63c12e8-f39c-4011-a7ca-da0ee84e07af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1532b1a3-2907-4b68-978a-e726b26ec553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c95b39d-540a-4394-a293-8bc3fcaa4d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/3657616883.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b.to(model.device))\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 1 at /tmp/ipykernel_5515/3933810934.py:143\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.encoder.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 2 at /tmp/ipykernel_5515/4122862164.py:106\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.encoder.fuse_meta_into_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 3 at /tmp/ipykernel_5515/4122862164.py:86\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/3933810934.py(158)forward()\n",
      "    156         **kwargs\n",
      "    157     ):  \n",
      "--> 158         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "    159 \n",
      "    160         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/4122862164.py(115)forward()\n",
      "    113         **kwargs\n",
      "    114     ):  \n",
      "--> 115         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    116 \n",
      "    117         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/4122862164.py(87)fuse_meta_into_embeddings()\n",
      "     85 \n",
      "3    86     def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "---> 87         meta_repr = {}\n",
      "     88 \n",
      "     89         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/4122862164.py(89)fuse_meta_into_embeddings()\n",
      "     87         meta_repr = {}\n",
      "     88 \n",
      "---> 89         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     90         for m_key, m_args in meta_kwargs.items():\n",
      "     91             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/4122862164.py(90)fuse_meta_into_embeddings()\n",
      "     88 \n",
      "     89         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "---> 90         for m_key, m_args in meta_kwargs.items():\n",
      "     91             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     92             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_fused_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/4122862164.py(91)fuse_meta_into_embeddings()\n",
      "     89         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     90         for m_key, m_args in meta_kwargs.items():\n",
      "---> 91             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     92             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     93 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/4122862164.py(92)fuse_meta_into_embeddings()\n",
      "     90         for m_key, m_args in meta_kwargs.items():\n",
      "     91             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "---> 92             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     93 \n",
      "     94             if len(idx):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/4122862164.py(94)fuse_meta_into_embeddings()\n",
      "     92             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     93 \n",
      "---> 94             if len(idx):\n",
      "     95                 m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
      "     96                 m_repr = F.normalize(self.meta_embeddings(m_idx), dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/4122862164.py(95)fuse_meta_into_embeddings()\n",
      "     93 \n",
      "     94             if len(idx):\n",
      "---> 95                 m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
      "     96                 m_repr = F.normalize(self.meta_embeddings(m_idx), dim=1)\n",
      "     97 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/4122862164.py(96)fuse_meta_into_embeddings()\n",
      "     94             if len(idx):\n",
      "     95                 m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
      "---> 96                 m_repr = F.normalize(self.meta_embeddings(m_idx), dim=1)\n",
      "     97 \n",
      "     98                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([161850,  72729, 161852, 120509, 306634, 355897, 110482,  68899, 102557,\n",
      "         74011,  93075, 272047,  84732,  68113,  84876], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr_mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/4122862164.py(98)fuse_meta_into_embeddings()\n",
      "     96                 m_repr = F.normalize(self.meta_embeddings(m_idx), dim=1)\n",
      "     97 \n",
      "---> 98                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "     99                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "    100 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/4122862164.py(99)fuse_meta_into_embeddings()\n",
      "     97 \n",
      "     98                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "---> 99                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "    100 \n",
      "    101                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr_mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5515/4122862164.py(101)fuse_meta_into_embeddings()\n",
      "     99                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "    100 \n",
      "--> 101                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "    102                 data_fused_repr[idx] += fused_repr\n",
      "    103 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "o = func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0194cf-d96d-4f72-bd40-f6e42c875b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0670, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742e7f0-ecda-4ea0-9b83-84df4fdc206c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f75036b-836a-4d23-8eea-88394679eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder002(Encoder):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        cross_tau:Optional[float]=0.1, \n",
    "        cross_dropout:Optional[float]=0.1, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.cross_head = NormCrossAttention(config, tau=cross_tau, dropout=cross_dropout)\n",
    "        self.post_init()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc3dd5-0c74-44ec-9f6f-876ac0c67f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK002(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        \n",
    "        cross_tau:Optional[float]=0.1,\n",
    "        cross_dropout:Optional[float]=0.1,\n",
    "        \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder002(config, cross_tau=cross_tau, cross_dropout=cross_dropout,\n",
    "                                  num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2320138-217b-40f9-bc48-0401099feafe",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da5d9f-c843-4c50-93ff-cb50b0ac2cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK002 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.tau', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK002.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=True, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               cross_tau=1.0, cross_dropout=0.1,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2cfce-8697-4a12-8192-8554195b0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_meta_embeddings(torch.zeros(656086, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29930733-8b3c-4c96-9221-78ef3e55eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ef1ee-45fc-435e-81f8-0c3f55ff701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ede8f-8d77-4c8a-8445-8dff479d70e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36176/2795290057.py(33)forward()\n",
      "     31         output_attentions:Optional[bool] = False,\n",
      "     32     ):\n",
      "---> 33         bs, q_len, dim = q.size()\n",
      "     34         v, k_len = k, k.size(1)\n",
      "     35 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36176/2795290057.py(34)forward()\n",
      "     32     ):\n",
      "     33         bs, q_len, dim = q.size()\n",
      "---> 34         v, k_len = k, k.size(1)\n",
      "     35 \n",
      "     36         h_dim = self.dim//self.n_h\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c128f070-2891-4540-a589-4f8195addeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae7ddb-b7bb-4633-9238-c081ecd049ef",
   "metadata": {},
   "source": [
    "## `OAK003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d670ddf9-64f7-49c8-b70a-486d993acaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder003(Encoder):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, num_metadata=num_metadata, **kwargs)\n",
    "        self.pretrained_meta_embeddings = nn.Embedding(num_metadata, config.dim)\n",
    "        self.post_init()\n",
    "\n",
    "    def freeze_pretrained_meta_embeddings(self):\n",
    "        self.pretrained_meta_embeddings.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_pretrained_meta_embeddings(self):\n",
    "        self.pretrained_meta_embeddings.requires_grad_(True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def set_pretrained_meta_embeddings(self, embed:torch.Tensor):\n",
    "        self.pretrained_meta_embeddings.weight.data.copy_(embed)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_meta_embeddings(self):\n",
    "        nn.init.zeros_(self.meta_embeddings.weight.data)\n",
    "\n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
    "            \n",
    "            if len(idx):\n",
    "                m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
    "                m_repr = self.meta_embeddings(m_idx) + self.pretrained_meta_embeddings(m_idx)\n",
    "                m_repr = F.normalize(m_repr, dim=1) if self.normalize else m_repr\n",
    "                \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
    "                meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "                \n",
    "                fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                data_fused_repr[idx] += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c92804f4-bccf-4aa4-bf5e-8ab7cabf1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK003(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder003(config, num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_meta_embeddings(self):\n",
    "        self.encoder.init_meta_embeddings()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b6bbef-d971-42d2-8c2b-63e2d8f91101",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86864591-7758-4b37-8702-fabfe8f872a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK003 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK003.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2d36d-4e8c-4827-b535-db7c509dd187",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5e54c-df22-4186-8b2d-61371a17a985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d585ba-dd70-4988-90ff-2fbed155f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca4074-7bbd-4c10-aa36-3896a339fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b2ca2-86b3-442c-be01-0235cbf4081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dcdfea-660c-4726-a9d4-03eef45e0c97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(65)resize()\n",
      "     63         #debug\n",
      "     64 \n",
      "---> 65         if torch.any(num_inputs == 0): raise ValueError(\"`num_inputs` should be non-zero positive integer.\")\n",
      "     66         bsz, total_num_inputs = num_inputs.shape[0], idx.shape[0]\n",
      "     67 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  num_inputs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 3, 3, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(66)resize()\n",
      "     64 \n",
      "     65         if torch.any(num_inputs == 0): raise ValueError(\"`num_inputs` should be non-zero positive integer.\")\n",
      "---> 66         bsz, total_num_inputs = num_inputs.shape[0], idx.shape[0]\n",
      "     67 \n",
      "     68         self.ones = self.ones.to(idx.device)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(68)resize()\n",
      "     66         bsz, total_num_inputs = num_inputs.shape[0], idx.shape[0]\n",
      "     67 \n",
      "---> 68         self.ones = self.ones.to(idx.device)\n",
      "     69         ones = (\n",
      "     70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(71)resize()\n",
      "     69         ones = (\n",
      "     70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "---> 71             if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
      "     72         )\n",
      "     73 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(70)resize()\n",
      "     68         self.ones = self.ones.to(idx.device)\n",
      "     69         ones = (\n",
      "---> 70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "     71             if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
      "     72         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(71)resize()\n",
      "     69         ones = (\n",
      "     70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "---> 71             if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
      "     72         )\n",
      "     73 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(70)resize()\n",
      "     68         self.ones = self.ones.to(idx.device)\n",
      "     69         ones = (\n",
      "---> 70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "     71             if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
      "     72         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(71)resize()\n",
      "     69         ones = (\n",
      "     70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "---> 71             if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
      "     72         )\n",
      "     73 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(69)resize()\n",
      "     67 \n",
      "     68         self.ones = self.ones.to(idx.device)\n",
      "---> 69         ones = (\n",
      "     70             torch.ones(total_num_inputs, dtype=torch.long, device=idx.device)\n",
      "     71             if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(74)resize()\n",
      "     72         )\n",
      "     73 \n",
      "---> 74         max_num_inputs = num_inputs.max()\n",
      "     75         if (num_inputs == max_num_inputs).all():\n",
      "     76             return idx,ones\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(75)resize()\n",
      "     73 \n",
      "     74         max_num_inputs = num_inputs.max()\n",
      "---> 75         if (num_inputs == max_num_inputs).all():\n",
      "     76             return idx,ones\n",
      "     77 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/4002658968.py(76)resize()\n",
      "     74         max_num_inputs = num_inputs.max()\n",
      "     75         if (num_inputs == max_num_inputs).all():\n",
      "---> 76             return idx,ones\n",
      "     77 \n",
      "     78         xnum_inputs = max_num_inputs-num_inputs+1\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  idx.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  ones.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([16184...4875,  84879]), tensor([1, 1,..., 1, 1, 1, 1]))\n",
      "> /tmp/ipykernel_26893/4002658968.py(76)resize()\n",
      "     74         max_num_inputs = num_inputs.max()\n",
      "     75         if (num_inputs == max_num_inputs).all():\n",
      "---> 76             return idx,ones\n",
      "     77 \n",
      "     78         xnum_inputs = max_num_inputs-num_inputs+1\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/3123686291.py(36)fuse_meta_into_embeddings()\n",
      "     34             if len(idx):\n",
      "     35                 m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
      "---> 36                 m_repr = F.normalize(self.meta_embeddings(m_idx) + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "     37 \n",
      "     38                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_idx.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr_mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26893/3123686291.py(38)fuse_meta_into_embeddings()\n",
      "     36                 m_repr = F.normalize(self.meta_embeddings(m_idx) + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "     37 \n",
      "---> 38                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "     39                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "     40 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3415984d-3419-4b98-9a43-59c2128fb81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0675, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd6642-f9d6-489a-882e-e519eb8cf229",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK004`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0828ad34-448c-4e4c-864a-9a0c7149f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder004(Encoder003):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        cross_tau:Optional[float]=0.1, \n",
    "        cross_dropout:Optional[float]=0.1, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.cross_head = NormCrossAttention(config, tau=cross_tau, dropout=cross_dropout)\n",
    "        self.post_init()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3416e8d-5b8e-4732-81f3-1fe8b02debf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK004(OAK003, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK003.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        \n",
    "        cross_tau:Optional[float]=1.0,\n",
    "        cross_dropout:Optional[float]=0.1,\n",
    "        \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs, num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.encoder = Encoder004(config, cross_tau=cross_tau, cross_dropout=cross_dropout,\n",
    "                                  num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc4adc-31a9-4d7b-b633-bbb1937c6463",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23465467-1945-4a16-bd88-29f79711b9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK004 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.tau', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK004.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.05, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               cross_tau=1.0, cross_dropout=0.1,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ab9e7-19cb-43e7-8a7c-da168e49700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()\n",
    "\n",
    "model.init_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3881124-08cc-4adb-a601-183e2e7969fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8f71e-587c-4d1a-b17d-1e1a22fda709",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76e225-f12e-43fc-b1d8-99c509b750c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62779de8-398f-4c8d-96b6-8c655c983c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cdbaaf-074a-4f9b-87f5-91dec694d99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7db880-e7b1-45a6-8ab8-fdfc8e4ff732",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK005`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786c265-3153-4ca7-9a0c-d9b6c6f9cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder005(Encoder003):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.gen_head = GenerationHead(config)\n",
    "        \n",
    "    def get_output_embeddings(self) -> nn.Module:\n",
    "        return self.gen_head.projector\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings: nn.Module):\n",
    "        self.gen_head.projector = new_embeddings\n",
    "    \n",
    "    def gen(self, x:torch.Tensor):\n",
    "        return self.gen_head(x)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_type:Optional[str]=None,\n",
    "        data_unnormalized:Optional[bool]=False,\n",
    "\n",
    "        data_gen_idx:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        **kwargs\n",
    "    ):  \n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        \n",
    "        if data_type is not None and data_type == \"meta\":\n",
    "            data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
    "        else: \n",
    "            data_repr = self.dr(data_o[0], data_attention_mask)\n",
    "        \n",
    "        data_fused_repr = meta_repr = None\n",
    "        if data_aug_meta_prefix is not None:\n",
    "            meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
    "            if len(meta_kwargs):\n",
    "                data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
    "                                                                            torch.any(data_attention_mask, dim=1), \n",
    "                                                                            meta_kwargs)\n",
    "                data_fused_repr = self.dr_fused(data_fused_repr)\n",
    "\n",
    "        data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx]) \n",
    "                \n",
    "        return EncoderOutput(\n",
    "            rep=data_repr,\n",
    "            fused_rep=data_fused_repr,\n",
    "            meta_repr=meta_repr,\n",
    "            \n",
    "            logits=data_logits,\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d283d6b-8ba8-4824-8bd3-65906d511c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK005(OAK003, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = True,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK003.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "\n",
    "        num_batch_labels:Optional[int]=None, \n",
    "        ignore_token:Optional[int]=0,\n",
    "        gen_loss_weight:Optional[float]=1.0,\n",
    "        use_gen_loss:Optional[bool]=True,\n",
    "        \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs, num_metadata=num_metadata, resize_length=resize_length, num_batch_labels=num_batch_labels)\n",
    "        store_attr('use_gen_loss')\n",
    "        self.g_lw = gen_loss_weight\n",
    "        self.encoder = Encoder005(config, num_metadata=num_metadata, resize_length=resize_length)\n",
    "\n",
    "        self.gen_loss_fn = MultiCrossEntropy(tn_targ=num_batch_labels, ig_tok=ignore_token, reduce='mean')\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "\n",
    "    def compute_gen_loss(self, inp_logits, targ_logits, inp_input_ids, targ_input_ids, targ_ptr):\n",
    "        gen_loss = self.gen_loss_fn(inp_logits, targ_input_ids, targ_ptr) + self.gen_loss_fn(targ_logits, inp_input_ids)\n",
    "        return self.g_lw * gen_loss\n",
    "\n",
    "    def init_generation_head(self):\n",
    "        self.encoder.gen_head.projector.weight.data = self.get_input_embeddings().weight.data.clone()\n",
    "\n",
    "    def get_last_item_mask(self, num_input:torch.Tensor, input_sz:int):\n",
    "        idx = torch.where(num_input > 0)[0]\n",
    "        input_ptr = num_input[idx].cumsum(dim=0)-1\n",
    "        return torch.zeros(input_sz, dtype=torch.bool, device=num_input.device).scatter(0, input_ptr, 1)\n",
    "\n",
    "    def freeze(self):\n",
    "        for n,p in self.named_parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    def unfreeze(self):\n",
    "        for n,p in self.named_parameters():\n",
    "            p.requires_grad_(True)\n",
    "\n",
    "    def unfreeze_head(self):\n",
    "        for n,p in self.encoder.gen_head.named_parameters():\n",
    "            p.requires_grad_(True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_gen_idx = self.get_last_item_mask(lbl2data_data2ptr, len(lbl2data_idx))\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
    "                                 **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_gen_loss:\n",
    "                loss += self.compute_gen_loss(data_o.logits, lbl2data_o.logits, data_input_ids,lbl2data_input_ids,\n",
    "                                              lbl2data_data2ptr)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "\n",
    "            logits=data_o.logits,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642eb0d-db4d-4a5f-87f3-83bf2afd2ae6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc019bf2-f127-4c18-8a0b-0660db9aab90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK005 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.gen_head.layer_norm.bias', 'encoder.gen_head.layer_norm.weight', 'encoder.gen_head.projector.bias', 'encoder.gen_head.projector.weight', 'encoder.gen_head.transform.bias', 'encoder.gen_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK005.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.05, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "                               \n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "\n",
    "                               ignore_token=0, gen_loss_weight=1.0, use_gen_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_generation_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9e8b4c-e107-403b-8a2e-a87e84b7a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze()\n",
    "model.unfreeze_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f1aaa0-394c-46be-84c5-ff18a039e296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53c228-bb52-4721-b9a8-55e706a0562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "\n",
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d2e0b-cf35-4d78-aa0b-e3b1836b6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bac920-062c-4dff-a7a4-37a699a346c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457b653-416e-4b74-87bb-c80dd35e50a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(58)forward()\n",
      "     56         **kwargs\n",
      "     57     ):  \n",
      "---> 58         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     59 \n",
      "     60         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(33)forward()\n",
      "     31         **kwargs\n",
      "     32     ):  \n",
      "---> 33         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "     34 \n",
      "     35         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(33)forward()\n",
      "     31         **kwargs\n",
      "     32     ):  \n",
      "---> 33         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "     34 \n",
      "     35         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452f591-907c-4bc0-bee9-4134c6487e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ccab6-e02d-478e-8480-2d0ef0f1e604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/3657616883.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b.to(model.device))\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 1 at /tmp/ipykernel_3071/2330200620.py:43\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.encoder.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 2 at /tmp/ipykernel_3071/1501785349.py:21\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(58)forward()\n",
      "     56         **kwargs\n",
      "     57     ):  \n",
      "---> 58         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     59 \n",
      "     60         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(60)forward()\n",
      "     58         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     59 \n",
      "---> 60         if self.use_encoder_parallel:\n",
      "     61             encoder = XCDataParallel(module=self.encoder)\n",
      "     62         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(62)forward()\n",
      "     60         if self.use_encoder_parallel:\n",
      "     61             encoder = XCDataParallel(module=self.encoder)\n",
      "---> 62         else: encoder = self.encoder\n",
      "     63 \n",
      "     64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(64)forward()\n",
      "     62         else: encoder = self.encoder\n",
      "     63 \n",
      "---> 64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     65         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     66                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(65)forward()\n",
      "     63 \n",
      "     64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 65         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     66                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     67 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(66)forward()\n",
      "     64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     65         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 66                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     67 \n",
      "     68 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(65)forward()\n",
      "     63 \n",
      "     64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 65         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     66                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     67 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(66)forward()\n",
      "     64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     65         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 66                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     67 \n",
      "     68 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(65)forward()\n",
      "     63 \n",
      "     64         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 65         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     66                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     67 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1507)_wrapped_call_impl()\n",
      "   1505         return result\n",
      "   1506 \n",
      "-> 1507     def _wrapped_call_impl(self, *args, **kwargs):\n",
      "   1508         if self._compiled_call_impl is not None:\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(33)forward()\n",
      "     31         **kwargs\n",
      "     32     ):  \n",
      "---> 33         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "     34 \n",
      "     35         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(35)forward()\n",
      "     33         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "     34 \n",
      "---> 35         if data_type is not None and data_type == \"meta\":\n",
      "     36             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "     37         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_o.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'BaseModelOutput' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_o[0].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(38)forward()\n",
      "     36             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "     37         else:\n",
      "---> 38             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "     39 \n",
      "     40         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(40)forward()\n",
      "     38             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "     39 \n",
      "---> 40         data_fused_repr = meta_repr = None\n",
      "     41         if data_aug_meta_prefix is not None:\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(41)forward()\n",
      "     39 \n",
      "     40         data_fused_repr = meta_repr = None\n",
      "---> 41         if data_aug_meta_prefix is not None:\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "     43             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(42)forward()\n",
      "     40         data_fused_repr = meta_repr = None\n",
      "     41         if data_aug_meta_prefix is not None:\n",
      "---> 42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "     43             if len(meta_kwargs):\n",
      "     44                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(43)forward()\n",
      "     41         if data_aug_meta_prefix is not None:\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "---> 43             if len(meta_kwargs):\n",
      "     44                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "     45                                                                             torch.any(data_attention_mask, dim=1),\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(44)forward()\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "     43             if len(meta_kwargs):\n",
      "---> 44                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "     45                                                                             torch.any(data_attention_mask, dim=1),\n",
      "     46                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(45)forward()\n",
      "     43             if len(meta_kwargs):\n",
      "     44                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "---> 45                                                                             torch.any(data_attention_mask, dim=1),\n",
      "     46                                                                             meta_kwargs)\n",
      "     47                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(46)forward()\n",
      "     44                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "     45                                                                             torch.any(data_attention_mask, dim=1),\n",
      "---> 46                                                                             meta_kwargs)\n",
      "     47                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "     48 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(44)forward()\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "     43             if len(meta_kwargs):\n",
      "---> 44                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "     45                                                                             torch.any(data_attention_mask, dim=1),\n",
      "     46                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(47)forward()\n",
      "     45                                                                             torch.any(data_attention_mask, dim=1),\n",
      "     46                                                                             meta_kwargs)\n",
      "---> 47                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "     48 \n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(49)forward()\n",
      "     47                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "     48 \n",
      "---> 49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "     51         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(51)forward()\n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "---> 51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_logits.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5, 30522])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_gen_idx\n",
      "ipdb>  data_gen_idx is None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(52)forward()\n",
      "     50 \n",
      "     51         return EncoderOutput(\n",
      "---> 52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "     54             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(53)forward()\n",
      "     51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "---> 53             fused_rep=data_fused_repr,\n",
      "     54             meta_repr=meta_repr,\n",
      "     55 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(54)forward()\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "---> 54             meta_repr=meta_repr,\n",
      "     55 \n",
      "     56             logits=data_logits,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(56)forward()\n",
      "     54             meta_repr=meta_repr,\n",
      "     55 \n",
      "---> 56             logits=data_logits,\n",
      "     57         )\n",
      "     58 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(51)forward()\n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "---> 51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...xBackward0>)})\n",
      "> /tmp/ipykernel_3071/1501785349.py(51)forward()\n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "---> 51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...xBackward0>)})\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1511)_wrapped_call_impl()\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1510         else:\n",
      "-> 1511             return self._call_impl(*args, **kwargs)\n",
      "   1512 \n",
      "   1513     def _call_impl(self, *args, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(69)forward()\n",
      "     67 \n",
      "     68 \n",
      "---> 69         loss = None; lbl2data_o = EncoderOutput()\n",
      "     70         if lbl2data_input_ids is not None:\n",
      "     71             lbl2data_gen_idx = self.get_last_item_mask(lbl2data_data2ptr, len(lbl2data_idx))\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(70)forward()\n",
      "     68 \n",
      "     69         loss = None; lbl2data_o = EncoderOutput()\n",
      "---> 70         if lbl2data_input_ids is not None:\n",
      "     71             lbl2data_gen_idx = self.get_last_item_mask(lbl2data_data2ptr, len(lbl2data_idx))\n",
      "     72             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(71)forward()\n",
      "     69         loss = None; lbl2data_o = EncoderOutput()\n",
      "     70         if lbl2data_input_ids is not None:\n",
      "---> 71             lbl2data_gen_idx = self.get_last_item_mask(lbl2data_data2ptr, len(lbl2data_idx))\n",
      "     72             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     73 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_data2ptr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(72)forward()\n",
      "     70         if lbl2data_input_ids is not None:\n",
      "     71             lbl2data_gen_idx = self.get_last_item_mask(lbl2data_data2ptr, len(lbl2data_idx))\n",
      "---> 72             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     73 \n",
      "     74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_gen_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(74)forward()\n",
      "     72             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     73 \n",
      "---> 74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
      "     76                                  **lbl2data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(75)forward()\n",
      "     73 \n",
      "     74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "---> 75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
      "     76                                  **lbl2data_meta_kwargs)\n",
      "     77 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(74)forward()\n",
      "     72             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     73 \n",
      "---> 74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
      "     76                                  **lbl2data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(76)forward()\n",
      "     74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
      "---> 76                                  **lbl2data_meta_kwargs)\n",
      "     77 \n",
      "     78             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(74)forward()\n",
      "     72             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     73 \n",
      "---> 74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
      "     76                                  **lbl2data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(33)forward()\n",
      "     31         **kwargs\n",
      "     32     ):  \n",
      "---> 33         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "     34 \n",
      "     35         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(35)forward()\n",
      "     33         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "     34 \n",
      "---> 35         if data_type is not None and data_type == \"meta\":\n",
      "     36             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "     37         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(38)forward()\n",
      "     36             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "     37         else:\n",
      "---> 38             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "     39 \n",
      "     40         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(40)forward()\n",
      "     38             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "     39 \n",
      "---> 40         data_fused_repr = meta_repr = None\n",
      "     41         if data_aug_meta_prefix is not None:\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(41)forward()\n",
      "     39 \n",
      "     40         data_fused_repr = meta_repr = None\n",
      "---> 41         if data_aug_meta_prefix is not None:\n",
      "     42             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "     43             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(49)forward()\n",
      "     47                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "     48 \n",
      "---> 49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "     51         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_gen_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(51)forward()\n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "---> 51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_logits.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 11, 30522])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(52)forward()\n",
      "     50 \n",
      "     51         return EncoderOutput(\n",
      "---> 52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "     54             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(53)forward()\n",
      "     51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "---> 53             fused_rep=data_fused_repr,\n",
      "     54             meta_repr=meta_repr,\n",
      "     55 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(54)forward()\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "---> 54             meta_repr=meta_repr,\n",
      "     55 \n",
      "     56             logits=data_logits,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(56)forward()\n",
      "     54             meta_repr=meta_repr,\n",
      "     55 \n",
      "---> 56             logits=data_logits,\n",
      "     57         )\n",
      "     58 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/1501785349.py(51)forward()\n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "---> 51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> /tmp/ipykernel_3071/1501785349.py(51)forward()\n",
      "     49         data_logits = self.gen(data_o[0] if data_gen_idx is None else data_o[0][data_gen_idx])\n",
      "     50 \n",
      "---> 51         return EncoderOutput(\n",
      "     52             rep=data_repr,\n",
      "     53             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(78)forward()\n",
      "     76                                  **lbl2data_meta_kwargs)\n",
      "     77 \n",
      "---> 78             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     79                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     80 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(79)forward()\n",
      "     77 \n",
      "     78             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "---> 79                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     80 \n",
      "     81             if self.use_gen_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(78)forward()\n",
      "     76                                  **lbl2data_meta_kwargs)\n",
      "     77 \n",
      "---> 78             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     79                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     80 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(81)forward()\n",
      "     79                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     80 \n",
      "---> 81             if self.use_gen_loss:\n",
      "     82                 loss += self.compute_gen_loss(data_o.logits, lbl2data_o.logits, data_input_ids,lbl2data_input_ids,\n",
      "     83                                               lbl2data_data2ptr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.use_gen_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(82)forward()\n",
      "     80 \n",
      "     81             if self.use_gen_loss:\n",
      "---> 82                 loss += self.compute_gen_loss(data_o.logits, lbl2data_o.logits, data_input_ids,lbl2data_input_ids,\n",
      "     83                                               lbl2data_data2ptr)\n",
      "     84 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_input_ids.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_input_ids.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 11])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_data2ptr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(83)forward()\n",
      "     81             if self.use_gen_loss:\n",
      "     82                 loss += self.compute_gen_loss(data_o.logits, lbl2data_o.logits, data_input_ids,lbl2data_input_ids,\n",
      "---> 83                                               lbl2data_data2ptr)\n",
      "     84 \n",
      "     85             if self.use_query_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(82)forward()\n",
      "     80 \n",
      "     81             if self.use_gen_loss:\n",
      "---> 82                 loss += self.compute_gen_loss(data_o.logits, lbl2data_o.logits, data_input_ids,lbl2data_input_ids,\n",
      "     83                                               lbl2data_data2ptr)\n",
      "     84 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(85)forward()\n",
      "     83                                               lbl2data_data2ptr)\n",
      "     84 \n",
      "---> 85             if self.use_query_loss:\n",
      "     86                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     87                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(86)forward()\n",
      "     84 \n",
      "     85             if self.use_query_loss:\n",
      "---> 86                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     87                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     88 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(87)forward()\n",
      "     85             if self.use_query_loss:\n",
      "     86                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "---> 87                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     88 \n",
      "     89             if self.use_calib_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(86)forward()\n",
      "     84 \n",
      "     85             if self.use_query_loss:\n",
      "---> 86                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     87                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     88 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(89)forward()\n",
      "     87                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     88 \n",
      "---> 89             if self.use_calib_loss:\n",
      "     90                 loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     91                                               plbl2data_data2ptr,plbl2data_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(93)forward()\n",
      "     91                                               plbl2data_data2ptr,plbl2data_idx)\n",
      "     92 \n",
      "---> 93             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "     94 \n",
      "     95             if self.use_fusion_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(95)forward()\n",
      "     93             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "     94 \n",
      "---> 95             if self.use_fusion_loss:\n",
      "     96                 loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
      "     97                 loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(100)forward()\n",
      "     98 \n",
      "     99 \n",
      "--> 100         if not return_dict:\n",
      "    101             o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
      "    102             return ((loss,) + o) if loss is not None else o\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(105)forward()\n",
      "    103 \n",
      "    104 \n",
      "--> 105         return XCModelOutput(\n",
      "    106             loss=loss,\n",
      "    107 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(106)forward()\n",
      "    104 \n",
      "    105         return XCModelOutput(\n",
      "--> 106             loss=loss,\n",
      "    107 \n",
      "    108             data_repr=data_o.rep,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(108)forward()\n",
      "    106             loss=loss,\n",
      "    107 \n",
      "--> 108             data_repr=data_o.rep,\n",
      "    109             data_fused_repr=data_o.fused_rep,\n",
      "    110 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(109)forward()\n",
      "    107 \n",
      "    108             data_repr=data_o.rep,\n",
      "--> 109             data_fused_repr=data_o.fused_rep,\n",
      "    110 \n",
      "    111             logits=data_o.logits,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(111)forward()\n",
      "    109             data_fused_repr=data_o.fused_rep,\n",
      "    110 \n",
      "--> 111             logits=data_o.logits,\n",
      "    112 \n",
      "    113             lbl2data_repr=lbl2data_o.rep,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(113)forward()\n",
      "    111             logits=data_o.logits,\n",
      "    112 \n",
      "--> 113             lbl2data_repr=lbl2data_o.rep,\n",
      "    114             lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
      "    115         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(114)forward()\n",
      "    112 \n",
      "    113             lbl2data_repr=lbl2data_o.rep,\n",
      "--> 114             lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
      "    115         )\n",
      "    116 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_3071/2330200620.py(105)forward()\n",
      "    103 \n",
      "    104 \n",
      "--> 105         return XCModelOutput(\n",
      "    106             loss=loss,\n",
      "    107 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "XCModelOutput...sed_repr=None)\n",
      "> /tmp/ipykernel_3071/2330200620.py(105)forward()\n",
      "    103 \n",
      "    104 \n",
      "--> 105         return XCModelOutput(\n",
      "    106             loss=loss,\n",
      "    107 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "XCModelOutput...sed_repr=None)\n",
      "> /tmp/ipykernel_3071/3657616883.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b.to(model.device))\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> /tmp/ipykernel_3071/492731717.py(1)<module>()\n",
      "----> 1 o = func()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "o = func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b98fe-12a9-47ff-922b-4cb16d3b2f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21.9783, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347a851-2056-4833-b40d-eabe5b4f4a04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK006`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30fbd64-34b1-4371-9a8f-ed30f6ba2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder006(DistilBertPreTrainedModel):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig, \n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        \n",
    "        self.dr_head = RepresentationHead(config)\n",
    "        self.dr_fused_head = RepresentationHead(config)\n",
    "        self.meta_head = RepresentationHead(config)\n",
    "        self.cross_head = CrossAttention(config)\n",
    "        self.meta_embeddings = nn.Embedding(num_metadata, config.dim, sparse=True)\n",
    "        self.pretrained_meta_embeddings = nn.Embedding(num_metadata, config.dim)\n",
    "\n",
    "        self.ones = torch.ones(resize_length, dtype=torch.long, device=self.device) if resize_length is not None else None\n",
    "        self.post_init()\n",
    "\n",
    "    def freeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(True)\n",
    "\n",
    "    def set_meta_embeddings(self, embed:torch.Tensor):\n",
    "        self.meta_embeddings.weight.data = embed\n",
    "\n",
    "    def init_meta_embeddings(self):\n",
    "        self.meta_embeddings.weight.data = torch.zeros_like(self.meta_embeddings.weight.data)\n",
    "\n",
    "    def freeze_pretrained_meta_embeddings(self):\n",
    "        self.pretrained_meta_embeddings.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_pretrained_meta_embeddings(self):\n",
    "        self.pretrained_meta_embeddings.requires_grad_(True)\n",
    "\n",
    "    def set_pretrained_meta_embeddings(self, embed:torch.Tensor):\n",
    "        self.pretrained_meta_embeddings.weight.data = embed\n",
    "        \n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        return self.distilbert.get_position_embeddings()\n",
    "    \n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "        self.distilbert.resize_position_embeddings(new_num_position_embeddings)\n",
    "    \n",
    "    def encode(self, input_ids:torch.Tensor, attention_mask:torch.Tensor, **kwargs):\n",
    "        return self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    def dr(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.dr_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "\n",
    "    def dr_fused(self, embed:torch.Tensor):\n",
    "        embed = self.dr_fused_head(embed)\n",
    "        return F.normalize(embed, dim=1)\n",
    "\n",
    "    def meta(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.meta_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "    \n",
    "    def meta_unnormalized(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.meta_head(embed)\n",
    "        return Pooling.mean_pooling(embed, attention_mask)\n",
    "\n",
    "    def resize(self, idx:torch.Tensor, num_inputs:torch.Tensor):\n",
    "        if torch.any(num_inputs == 0): raise ValueError(\"`num_inputs` should be non-zero positive integer.\")\n",
    "        bsz, total_num_inputs = num_inputs.shape[0], idx.shape[0]\n",
    "        \n",
    "        self.ones = self.ones.to(idx.device)\n",
    "        ones = (\n",
    "            torch.ones(total_num_inputs, dtype=torch.long, device=idx.device) \n",
    "            if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
    "        )\n",
    "\n",
    "        max_num_inputs = num_inputs.max()\n",
    "        if (num_inputs == max_num_inputs).all():\n",
    "            return idx,ones\n",
    "        \n",
    "        xnum_inputs = max_num_inputs-num_inputs+1\n",
    "\n",
    "        inputs_ptr = num_inputs.cumsum(dim=0)-1\n",
    "        repeat_inputs = ones.scatter(0, inputs_ptr, xnum_inputs)\n",
    "        \n",
    "        resized_idx = idx.repeat_interleave(repeat_inputs, dim=0)\n",
    "        ignore_mask = ones.scatter(0, inputs_ptr, 0).repeat_interleave(repeat_inputs, dim=0).view(bsz, -1)\n",
    "        ignore_mask[:, -1] = 1; ignore_mask = ignore_mask.flatten()\n",
    "        \n",
    "        return resized_idx,ignore_mask\n",
    "\n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
    "            \n",
    "            if len(idx):\n",
    "                m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
    "                m_repr = F.normalize(self.meta_embeddings(m_idx) + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
    "                \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
    "                meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "                \n",
    "                fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                data_fused_repr[idx] += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_type:Optional[str]=None,\n",
    "        data_unnormalized:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        \n",
    "        if data_type is not None and data_type == \"meta\":\n",
    "            data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
    "        else: \n",
    "            data_repr = self.dr(data_o[0], data_attention_mask)\n",
    "        \n",
    "        data_fused_repr = meta_repr = None\n",
    "        if data_aug_meta_prefix is not None:\n",
    "            meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
    "            if len(meta_kwargs):\n",
    "                data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
    "                                                                            torch.any(data_attention_mask, dim=1), \n",
    "                                                                            meta_kwargs)\n",
    "                data_fused_repr = self.dr_fused(data_fused_repr)\n",
    "                \n",
    "        return EncoderOutput(\n",
    "            rep=data_repr,\n",
    "            fused_rep=data_fused_repr,\n",
    "            meta_repr=meta_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cfafaf-5c11-4b42-b929-914abf7c54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK006(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder006(config, num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_meta_embeddings(self):\n",
    "        self.encoder.init_meta_embeddings()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6f29fb-90b3-4c5a-8d63-719f93208a52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa32fee-b90c-42ea-bd0b-a2b034ac618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK006 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK006.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9d2382-5897-4296-a817-2d762e2202b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91145947-3b61-4e10-98bf-c5283b6f7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce1fff-42f0-4c3c-abf7-d0f8cf5096a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea885d-0d18-4d0c-8839-472e00bfd757",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb4fbb-ea90-4316-acc5-d30dc939e316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c373ce-db05-4722-8f56-e58de7a5cbeb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK007`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d70229ff-d190-4612-a9a4-ab3edf67ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK007(OAK003, DistilBertPreTrainedModel):\n",
    "    \n",
    "    @delegates(OAK003.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        n_labels:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.label_embeddings = nn.Embedding(n_labels, config.dim)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_label_embeddings(self):\n",
    "        self.label_embeddings.weight.data = torch.zeros_like(self.label_embeddings.weight.data)\n",
    "\n",
    "    def get_label_representation(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask)\n",
    "        data_o.rep = F.normalize(data_o.rep + self.label_embeddings(data_idx), dim=1)\n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "\n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(lbl2data_idx), dim=1)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "\n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3136404-4e43-4c42-b82e-13fab74ae9d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc2d6605-bfb5-4eef-a589-ff1efc9ef828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK007 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight', 'label_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK007.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000, n_labels=block.n_lbl,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "model.init_label_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1ce81-defd-4d55-8319-c9ed46ae7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e6df69-708d-4d15-a1b9-0fc9ef1e7780",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e164cab6-542a-4b41-b69e-b4f40917e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "751086b3-b407-45d7-b9cf-d530ad7b8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f39f730c-9a76-4856-8c35-6eaa72ed3747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a85e3-74cf-4034-8fa8-2d44d79ebb49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK008`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3276b59-d368-48bd-87ac-71a123dbb3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK008(OAK003, DistilBertPreTrainedModel):\n",
    "    \n",
    "    @delegates(OAK003.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        n_labels:int,\n",
    "        n_clusters:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.label_embeddings = nn.Embedding(n_clusters, config.dim)\n",
    "        self.register_buffer(\"label_remap\", torch.arange(n_labels)%n_clusters, persistent=True)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_label_embeddings(self):\n",
    "        self.label_embeddings.weight.data = torch.zeros_like(self.label_embeddings.weight.data)\n",
    "\n",
    "    def set_label_embeddings(self, embed:torch.Tensor):\n",
    "        self.label_embeddings.weight.data = embed\n",
    "\n",
    "    def set_label_remap(self, label_remap:torch.Tensor):\n",
    "        if label_remap.shape[0] != self.label_remap.shape[0]:\n",
    "            raise ValueError(f'Shape mismatch, `label_remap` should have {self.label_remap.shape[0]} elements.')\n",
    "        self.label_remap = label_remap\n",
    "\n",
    "    def get_label_representation(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask)\n",
    "        data_o.rep = F.normalize(data_o.rep + self.label_embeddings(self.label_remap[data_idx]), dim=1)\n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "\n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "\n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df95993-512b-4472-b77c-d5a63f61f49c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c20e1e04-e65d-4075-a481-c7f1a353a668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK008 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight', 'label_embeddings.weight', 'label_remap']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK008.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000, \n",
    "                               n_labels=block.n_lbl, n_clusters=block.n_lbl//3,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "model.init_label_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "018da684-7a4d-478a-bb23-52ad74739e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c51f95f6-9d99-4dc4-90c8-c5127b4c767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cd05d82-6029-4b28-ae6b-b2c0e9550a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42633e5d-b8bd-4eb3-b54c-aee471ad63ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9db451a6-2e11-4241-b781-da4c74f53458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0260, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea1aa0f-402c-4954-b02b-9cd932a84be6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK009`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03552845-bfc5-45be-be50-2e22f9f5df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK009(OAK008, DistilBertPreTrainedModel):\n",
    "    \n",
    "    @delegates(OAK008.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        embed_dim:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.transform = nn.Linear(config.dim, embed_dim)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_transform(self):\n",
    "        self.transform.weight.data = torch.eye(self.transform.out_features, self.transform.in_features, \n",
    "                                               dtype=self.transform.weight.dtype)\n",
    "\n",
    "    def get_label_representation(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask)\n",
    "        data_o.rep = F.normalize(data_o.rep + self.label_embeddings(self.label_remap[data_idx]), dim=1)\n",
    "\n",
    "        if data_o.rep is not None: data_o.rep = F.normalize(self.transform(data_o.rep), dim=1)\n",
    "        if data_o.fused_rep is not None: data_o.fused_rep = F.normalize(self.transform(data_o.fused_rep), dim=1)\n",
    "        \n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "\n",
    "        if data_o.rep is not None: data_o.rep = F.normalize(self.transform(data_o.rep), dim=1)\n",
    "        if data_o.fused_rep is not None: data_o.fused_rep = F.normalize(self.transform(data_o.fused_rep), dim=1)\n",
    "\n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
    "\n",
    "            if lbl2data_o.rep is not None: lbl2data_o.rep = F.normalize(self.transform(lbl2data_o.rep), dim=1)\n",
    "            if lbl2data_o.fused_rep is not None: lbl2data_o.fused_rep = F.normalize(self.transform(lbl2data_o.fused_rep), dim=1)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "\n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4acc45-1c1c-4cf1-8b62-f3aeeb1067ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "318c7677-88a4-4122-a4f3-b573f10b527f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK009 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight', 'label_embeddings.weight', 'label_remap', 'transform.bias', 'transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK009.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000, \n",
    "                               n_labels=block.n_lbl, n_clusters=block.n_lbl//3, embed_dim=4096,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "model.init_label_embeddings()\n",
    "model.init_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec707a21-8d9e-43f1-82e3-343c1ca81a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "279fa7b3-ea08-42ee-9497-340692262294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e78ca1e8-e720-4e14-bed2-14695ba0a93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e944081-739c-405d-807d-aee583e4b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    o = model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4aa58570-3c41-4519-b052-c78d16b72788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/3721260802.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     o = model(**b.to(model.device))\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 2 at /tmp/ipykernel_18914/134643332.py:19\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(35)forward()\n",
      "     33         **kwargs\n",
      "     34     ):  \n",
      "---> 35         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     36 \n",
      "     37         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(37)forward()\n",
      "     35         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     36 \n",
      "---> 37         if self.use_encoder_parallel:\n",
      "     38             encoder = XCDataParallel(module=self.encoder)\n",
      "     39         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(39)forward()\n",
      "     37         if self.use_encoder_parallel:\n",
      "     38             encoder = XCDataParallel(module=self.encoder)\n",
      "---> 39         else: encoder = self.encoder\n",
      "     40 \n",
      "     41         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(41)forward()\n",
      "     39         else: encoder = self.encoder\n",
      "     40 \n",
      "---> 41         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     42         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     43                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(42)forward()\n",
      "     40 \n",
      "     41         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 42         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     43                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     44 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(43)forward()\n",
      "     41         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     42         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 43                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     44 \n",
      "     45         if data_o.rep is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(42)forward()\n",
      "     40 \n",
      "     41         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 42         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     43                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     44 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(43)forward()\n",
      "     41         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     42         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 43                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     44 \n",
      "     45         if data_o.rep is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(42)forward()\n",
      "     40 \n",
      "     41         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 42         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     43                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     44 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(45)forward()\n",
      "     43                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     44 \n",
      "---> 45         if data_o.rep is not None:\n",
      "     46             data_o.rep = self.transform(data_o.rep)\n",
      "     47         if data_o.fused_rep is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_o.rep.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_o.fused_rep.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(46)forward()\n",
      "     44 \n",
      "     45         if data_o.rep is not None:\n",
      "---> 46             data_o.rep = self.transform(data_o.rep)\n",
      "     47         if data_o.fused_rep is not None:\n",
      "     48             data_o.fused_rep = self.transform(data_o.fused_rep)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(47)forward()\n",
      "     45         if data_o.rep is not None:\n",
      "     46             data_o.rep = self.transform(data_o.rep)\n",
      "---> 47         if data_o.fused_rep is not None:\n",
      "     48             data_o.fused_rep = self.transform(data_o.fused_rep)\n",
      "     49 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(48)forward()\n",
      "     46             data_o.rep = self.transform(data_o.rep)\n",
      "     47         if data_o.fused_rep is not None:\n",
      "---> 48             data_o.fused_rep = self.transform(data_o.fused_rep)\n",
      "     49 \n",
      "     50         loss = None; lbl2data_o = EncoderOutput()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(50)forward()\n",
      "     48             data_o.fused_rep = self.transform(data_o.fused_rep)\n",
      "     49 \n",
      "---> 50         loss = None; lbl2data_o = EncoderOutput()\n",
      "     51         if lbl2data_input_ids is not None:\n",
      "     52             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(51)forward()\n",
      "     49 \n",
      "     50         loss = None; lbl2data_o = EncoderOutput()\n",
      "---> 51         if lbl2data_input_ids is not None:\n",
      "     52             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     53             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(52)forward()\n",
      "     50         loss = None; lbl2data_o = EncoderOutput()\n",
      "     51         if lbl2data_input_ids is not None:\n",
      "---> 52             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     53             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     54                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(53)forward()\n",
      "     51         if lbl2data_input_ids is not None:\n",
      "     52             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "---> 53             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     54                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "     55             lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(54)forward()\n",
      "     52             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     53             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "---> 54                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "     55             lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
      "     56 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(53)forward()\n",
      "     51         if lbl2data_input_ids is not None:\n",
      "     52             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "---> 53             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     54                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "     55             lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(54)forward()\n",
      "     52             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     53             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "---> 54                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "     55             lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
      "     56 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(53)forward()\n",
      "     51         if lbl2data_input_ids is not None:\n",
      "     52             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "---> 53             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     54                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "     55             lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(55)forward()\n",
      "     53             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     54                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "---> 55             lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
      "     56 \n",
      "     57             if lbl2data_o.rep is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(57)forward()\n",
      "     55             lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
      "     56 \n",
      "---> 57             if lbl2data_o.rep is not None:\n",
      "     58                 lbl2data_o.rep = self.transform(lbl2data_o.rep)\n",
      "     59             if lbl2data_o.fused_rep is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(58)forward()\n",
      "     56 \n",
      "     57             if lbl2data_o.rep is not None:\n",
      "---> 58                 lbl2data_o.rep = self.transform(lbl2data_o.rep)\n",
      "     59             if lbl2data_o.fused_rep is not None:\n",
      "     60                 lbl2data_o.fused_rep = self.transform(lbl2data_o.fused_rep)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(59)forward()\n",
      "     57             if lbl2data_o.rep is not None:\n",
      "     58                 lbl2data_o.rep = self.transform(lbl2data_o.rep)\n",
      "---> 59             if lbl2data_o.fused_rep is not None:\n",
      "     60                 lbl2data_o.fused_rep = self.transform(lbl2data_o.fused_rep)\n",
      "     61 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(62)forward()\n",
      "     60                 lbl2data_o.fused_rep = self.transform(lbl2data_o.fused_rep)\n",
      "     61 \n",
      "---> 62             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     63                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     64 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(63)forward()\n",
      "     61 \n",
      "     62             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "---> 63                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     64 \n",
      "     65             if self.use_query_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(62)forward()\n",
      "     60                 lbl2data_o.fused_rep = self.transform(lbl2data_o.fused_rep)\n",
      "     61 \n",
      "---> 62             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     63                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     64 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(65)forward()\n",
      "     63                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     64 \n",
      "---> 65             if self.use_query_loss:\n",
      "     66                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     67                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(66)forward()\n",
      "     64 \n",
      "     65             if self.use_query_loss:\n",
      "---> 66                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     67                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     68 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(67)forward()\n",
      "     65             if self.use_query_loss:\n",
      "     66                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "---> 67                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     68 \n",
      "     69             if self.use_calib_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(66)forward()\n",
      "     64 \n",
      "     65             if self.use_query_loss:\n",
      "---> 66                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     67                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     68 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(69)forward()\n",
      "     67                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     68 \n",
      "---> 69             if self.use_calib_loss:\n",
      "     70                 loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     71                                               plbl2data_data2ptr,plbl2data_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(73)forward()\n",
      "     71                                               plbl2data_data2ptr,plbl2data_idx)\n",
      "     72 \n",
      "---> 73             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "     74 \n",
      "     75             if self.use_fusion_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(75)forward()\n",
      "     73             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "     74 \n",
      "---> 75             if self.use_fusion_loss:\n",
      "     76                 loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
      "     77                 loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(80)forward()\n",
      "     78 \n",
      "     79 \n",
      "---> 80         if not return_dict:\n",
      "     81             o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
      "     82             return ((loss,) + o) if loss is not None else o\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(84)forward()\n",
      "     82             return ((loss,) + o) if loss is not None else o\n",
      "     83 \n",
      "---> 84         return XCModelOutput(\n",
      "     85             loss=loss,\n",
      "     86 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(85)forward()\n",
      "     83 \n",
      "     84         return XCModelOutput(\n",
      "---> 85             loss=loss,\n",
      "     86 \n",
      "     87             data_repr=data_o.rep,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(87)forward()\n",
      "     85             loss=loss,\n",
      "     86 \n",
      "---> 87             data_repr=data_o.rep,\n",
      "     88             data_fused_repr=data_o.fused_rep,\n",
      "     89 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(88)forward()\n",
      "     86 \n",
      "     87             data_repr=data_o.rep,\n",
      "---> 88             data_fused_repr=data_o.fused_rep,\n",
      "     89 \n",
      "     90             lbl2data_repr=lbl2data_o.rep,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(90)forward()\n",
      "     88             data_fused_repr=data_o.fused_rep,\n",
      "     89 \n",
      "---> 90             lbl2data_repr=lbl2data_o.rep,\n",
      "     91             lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
      "     92         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(91)forward()\n",
      "     89 \n",
      "     90             lbl2data_repr=lbl2data_o.rep,\n",
      "---> 91             lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
      "     92         )\n",
      "     93 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18914/134643332.py(84)forward()\n",
      "     82             return ((loss,) + o) if loss is not None else o\n",
      "     83 \n",
      "---> 84         return XCModelOutput(\n",
      "     85             loss=loss,\n",
      "     86 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "XCModelOutput...sed_repr=None)\n",
      "> /tmp/ipykernel_18914/134643332.py(84)forward()\n",
      "     82             return ((loss,) + o) if loss is not None else o\n",
      "     83 \n",
      "---> 84         return XCModelOutput(\n",
      "     85             loss=loss,\n",
      "     86 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> /tmp/ipykernel_18914/3721260802.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     o = model(**b.to(model.device))\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/IPython/core/displayhook.py(258)__call__()\n",
      "    256         sys.stdout.flush()\n",
      "    257 \n",
      "--> 258     def __call__(self, result=None):\n",
      "    259         \"\"\"Printing with history cache management.\n",
      "    260 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c43f02f6-738f-4589-ac59-181f0c608a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41111305-4336-44be-a829-de369c90479c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0260, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8f2bb0-44d9-4797-bded-dc83e4165ef2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK010`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47c4e605-caf9-461c-aaf5-1203d5a2e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder010(Encoder003):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        n_clusters:int,\n",
    "        n_metadata:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, num_metadata=n_clusters, **kwargs)\n",
    "        self.pretrained_meta_embeddings = nn.Embedding(n_metadata, config.dim)\n",
    "        self.register_buffer(\"metadata_remap\", torch.arange(n_metadata)%n_clusters, persistent=True)\n",
    "        self.post_init()\n",
    "\n",
    "    def set_metadata_remap(self, metadata_remap:torch.Tensor):\n",
    "        if metadata_remap.shape[0] != self.metadata_remap.shape[0]:\n",
    "            raise ValueError(f'Shape mismatch, `metadata_remap` should have {self.metadata_remap.shape[0]} elements.')\n",
    "        self.metadata_remap = metadata_remap\n",
    "\n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
    "            \n",
    "            if len(idx):\n",
    "                m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
    "                m_repr = F.normalize(self.meta_embeddings(self.metadata_remap[m_idx]) + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
    "                \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
    "                meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "                \n",
    "                fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                data_fused_repr[idx] += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5f8017d-f276-47d4-8c58-ac28d4e1206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK010(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        n_clusters:int,\n",
    "        n_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder010(config, n_clusters=n_clusters, n_metadata=n_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_meta_embeddings(self):\n",
    "        self.encoder.init_meta_embeddings()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3675a565-18e1-4b31-a1b8-cd3c90254af2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df3ad806-e89c-4a61-87ce-90964cdf567b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK010 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.metadata_remap', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK010.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               n_metadata=block.train.dset.meta['cat_meta'].n_meta, n_clusters=1000, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.05, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.0, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba741225-38e1-42a4-9a11-0c9cfad914dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()\n",
    "\n",
    "remap = torch.arange(block.train.dset.meta['cat_meta'].n_meta)%1000\n",
    "model.encoder.set_metadata_remap(remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2502a954-9dce-4bec-88ac-a3ad09c2f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e0b1c-8235-4608-82f0-dbedea461daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddb5d421-8b18-4a35-b3e9-997611ffe301",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8a991b6-a8a5-4901-af22-0694dda2d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10e68d4b-4c27-4656-8ce5-8abd64bed021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0260, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6da686-e2db-4210-b61f-ccda4ca0004d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK011`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77f28e38-a7bc-4068-9e64-976082e500ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder011(Encoder003):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config, \n",
    "        n_clusters:int,\n",
    "        n_metadata:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, num_metadata=n_clusters, **kwargs)\n",
    "        self.pretrained_meta_embeddings = nn.Embedding(n_clusters, config.dim)\n",
    "        self.register_buffer(\"metadata_remap\", torch.arange(n_metadata)%n_clusters, persistent=True)\n",
    "        self.post_init()\n",
    "\n",
    "    def set_metadata_remap(self, metadata_remap:torch.Tensor):\n",
    "        if metadata_remap.shape[0] != self.metadata_remap.shape[0]:\n",
    "            raise ValueError(f'Shape mismatch, `metadata_remap` should have {self.metadata_remap.shape[0]} elements.')\n",
    "        self.metadata_remap = metadata_remap\n",
    "\n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
    "            \n",
    "            if len(idx):\n",
    "                m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
    "                m_repr = F.normalize(self.meta_embeddings(self.metadata_remap[m_idx]) + self.pretrained_meta_embeddings(self.metadata_remap[m_idx]), dim=1)\n",
    "                \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
    "                meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "                \n",
    "                fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                data_fused_repr[idx] += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0a7c0db-6ba9-4dfb-b3e4-bec91fef19fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK011(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        n_clusters:int,\n",
    "        n_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder011(config, n_clusters=n_clusters, n_metadata=n_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_meta_embeddings(self):\n",
    "        self.encoder.init_meta_embeddings()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a6db9-9623-43bc-94bf-99c313e5ed9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d7a1791-ab3f-4c99-9682-38361dc93e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK011 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.metadata_remap', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK011.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               n_metadata=block.train.dset.meta['cat_meta'].n_meta, n_clusters=1000, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.05, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.0, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "904178fc-727e-4184-8c03-bc91ac00c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()\n",
    "\n",
    "remap = torch.arange(block.train.dset.meta['cat_meta'].n_meta)%1000\n",
    "model.encoder.set_metadata_remap(remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e56b9910-20ce-4cc7-8563-9feb2e18a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08d8096a-7e60-4740-9fa4-1285ebea49e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "944767cc-ffa8-46ef-881e-c2f011b07ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0252, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac89a74e-7d54-4f46-a33f-315bbf33ca4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK012`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6171fd60-03e8-4c37-b4f7-309bb0d4b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder012(Encoder):\n",
    "\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.meta_transform = RepresentationHead(config)\n",
    "        self.post_init()\n",
    "\n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
    "            \n",
    "            if len(idx):\n",
    "                m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
    "                m_repr = F.normalize(self.meta_transform(self.meta_embeddings(m_idx)), dim=1)\n",
    "                \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
    "                meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "                \n",
    "                fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                data_fused_repr[idx] += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4cab29c-16cb-4bdf-ad24-02a8da2c56e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK012(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder012(config, num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "        \n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f23bab3-29ae-4818-8c4c-04754ddda87c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e692da33-3b41-417c-852b-d9c3e12ea87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK012 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.meta_transform.layer_norm.bias', 'encoder.meta_transform.layer_norm.weight', 'encoder.meta_transform.projector.bias', 'encoder.meta_transform.projector.weight', 'encoder.meta_transform.transform.bias', 'encoder.meta_transform.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK012.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fc8eddd-e0a3-4efe-b8e5-ba75f6551c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.meta_transform.post_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef33d330-2180-4297-9382-403b7ecc2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_meta_embeddings(torch.zeros(656086, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2cd0a8f6-85ef-4900-b836-eea727465350",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6233e0ee-1281-4970-8e4b-58bd7f9d3ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9fea32b-7d15-4b6b-aae8-53b67119fc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', 'cat2data_data2ptr', 'data_input_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1918d73f-9ccc-40a7-9bd9-83dce60dd352",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8af4aeb7-09f9-466d-aff3-d01aefecb280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0260, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74e7a0-3283-4b4e-9b73-0aff71f471c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK013`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f16f62b-009f-4d70-a929-7efe2ec05b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder013(Encoder003):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.meta_distilbert = DistilBertModel(config)\n",
    "        self.post_init()\n",
    "\n",
    "    def meta_encode(self, input_ids:torch.Tensor, attention_mask:torch.Tensor, **kwargs):\n",
    "        o = self.meta_distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "        return Pooling.mean_pooling(o[0], attention_mask)\n",
    "\n",
    "    def init_meta_encoder(self):\n",
    "        sd_meta, sd_dr = self.meta_distilbert.state_dict(), self.distilbert.state_dict()\n",
    "        for k in sd_dr:\n",
    "            assert sd_meta[k].shape == sd_dr[k].shape\n",
    "            with torch.no_grad():\n",
    "                sd_meta[k].copy_(sd_dr[k])\n",
    "\n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            n_meta, bsz = m_args['data2ptr'].max(), len(m_args['data2ptr'])\n",
    "            assert torch.all(m_args['data2ptr'] == n_meta), f'All datapoints should have same number of metadata.'\n",
    "            \n",
    "            m_input_ids, m_attention_mask = m_args['input_ids'], m_args['attention_mask']\n",
    "            m_embed = self.meta_encode(input_ids=m_input_ids, attention_mask=m_attention_mask)\n",
    "            \n",
    "            m_idx = m_args['idx']\n",
    "            m_repr = F.normalize(self.meta_embeddings(m_idx) + m_embed + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
    "            \n",
    "            m_repr, m_repr_mask = m_repr.view(bsz, -1, self.config.dim), torch.ones((m_repr.shape[0],), device=m_repr.device, dtype=torch.bool).view(bsz, -1)\n",
    "            meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "            \n",
    "            fused_repr = self.cross_head(data_fused_repr, data_mask, m_repr, m_repr_mask)[0]\n",
    "            data_fused_repr += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cfecc54-1595-4e9a-8f1e-9d369b35d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK013(OAK008, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "    _keys_to_ignore_on_load_missing = [\"encoder.meta_distilbert\"]\n",
    "\n",
    "    @delegates(OAK008.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, num_metadata=num_metadata, resize_length=resize_length, **kwargs)\n",
    "        self.encoder = Encoder013(config, num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "\n",
    "    def init_meta_encoder(self):\n",
    "        self.encoder.init_meta_encoder()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d05f6-ffe9-4674-a1c3-5260da939e45",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c139c1b9-3cfc-49fa-b58e-9c13553ea78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK013 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight', 'label_embeddings.weight', 'label_remap']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK013.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000, \n",
    "                               n_labels=block.n_lbl, n_clusters=block.n_lbl//3,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "model.init_label_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc512c1e-5fbd-4ddc-8fb1-b059bea6d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()\n",
    "\n",
    "model.init_meta_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59645843-0aaf-44fe-96c5-4196cc2829ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "986e581e-91ab-46a7-a8a7-b5962a888638",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba055f66-dabf-4b54-984a-16cfcc0102aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9bea48d5-2079-483d-a1b6-0fe977aa0d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0149, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5115fb-8fd9-48a1-83d5-4db8cf07138a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8ee04ee4-b50d-46a3-9a40-1677006bdc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "56d6fdc4-70b9-4abc-b427-c22fe36934ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1795951242.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b.to(model.device))\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 1 at /tmp/ipykernel_26512/2049060262.py:45\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.encoder.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 2 at /tmp/ipykernel_26512/4122862164.py:106\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(61)forward()\n",
      "     59         **kwargs\n",
      "     60     ):  \n",
      "---> 61         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     62 \n",
      "     63         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(63)forward()\n",
      "     61         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     62 \n",
      "---> 63         if self.use_encoder_parallel:\n",
      "     64             encoder = XCDataParallel(module=self.encoder)\n",
      "     65         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(65)forward()\n",
      "     63         if self.use_encoder_parallel:\n",
      "     64             encoder = XCDataParallel(module=self.encoder)\n",
      "---> 65         else: encoder = self.encoder\n",
      "     66 \n",
      "     67         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(67)forward()\n",
      "     65         else: encoder = self.encoder\n",
      "     66 \n",
      "---> 67         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     68         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     69                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(68)forward()\n",
      "     66 \n",
      "     67         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 68         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     69                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     70 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lnk2data_attention_mask', 'lnk2data_input_ids', 'lnk2data_idx', 'lnk2data_data2ptr'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(69)forward()\n",
      "     67         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     68         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 69                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     70 \n",
      "     71         loss = None; lbl2data_o = EncoderOutput()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(68)forward()\n",
      "     66 \n",
      "     67         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 68         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     69                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     70 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(69)forward()\n",
      "     67         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     68         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 69                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     70 \n",
      "     71         loss = None; lbl2data_o = EncoderOutput()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(68)forward()\n",
      "     66 \n",
      "     67         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 68         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     69                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     70 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(115)forward()\n",
      "    113         **kwargs\n",
      "    114     ):  \n",
      "--> 115         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    116 \n",
      "    117         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(117)forward()\n",
      "    115         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    116 \n",
      "--> 117         if data_type is not None and data_type == \"meta\":\n",
      "    118             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    119         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutput(last_hidden_state=tensor([[[-0.6077, -1.4566, -1.2658,  ...,  0.4173,  0.4841, -0.4502],\n",
      "         [-0.6280, -0.1254, -0.2795,  ...,  0.7303,  0.4780, -0.8034],\n",
      "         [-0.5878,  0.2601, -0.8291,  ...,  0.7271, -0.0244, -0.1744],\n",
      "         [-0.3885, -0.0131, -0.3512,  ...,  0.8768, -0.2073, -0.3525],\n",
      "         [-0.2144, -1.0242, -1.2639,  ...,  1.1083,  0.2689,  0.1441]],\n",
      "\n",
      "        [[-0.0116, -0.6070, -1.0937,  ...,  0.4919, -0.6339,  0.3495],\n",
      "         [-0.4328, -0.5217, -0.7185,  ...,  0.3906, -0.9542,  0.9589],\n",
      "         [-0.6673, -0.8967, -1.2427,  ...,  0.3123, -0.9577, -0.1136],\n",
      "         [-0.2185,  0.0981, -0.4987,  ...,  0.7605, -0.7738,  0.0544],\n",
      "         [ 0.1080,  0.3637, -0.7733,  ...,  0.7831, -0.8321,  0.0020]],\n",
      "\n",
      "        [[-0.1806,  0.5675, -1.1267,  ...,  1.1764,  0.0713,  0.6914],\n",
      "         [ 0.0746,  0.4647, -1.5286,  ...,  0.7264,  0.2030,  0.5578],\n",
      "         [-0.2783,  0.2235, -0.8286,  ...,  0.4618,  0.0872, -0.2953],\n",
      "         [ 0.7958, -0.2424, -1.0187,  ...,  0.6092, -0.0145,  0.7918],\n",
      "         [ 0.6207,  0.0371, -0.9531,  ...,  0.8225, -0.6611,  0.1072]],\n",
      "\n",
      "        [[ 0.5336, -0.4709,  0.1039,  ...,  0.3853, -0.0933,  0.5370],\n",
      "         [ 1.0290,  0.8542,  0.0529,  ...,  0.4663,  0.4411,  0.5200],\n",
      "         [ 0.9370,  0.2671,  0.4589,  ...,  0.7556, -0.0404,  0.4426],\n",
      "         [ 0.8371, -0.3583,  0.2014,  ...,  0.7148,  0.2214,  0.3790],\n",
      "         [ 1.0329, -0.3276,  0.0614,  ...,  0.7897,  0.3368,  0.5574]],\n",
      "\n",
      "        [[-0.3118, -1.0130, -1.7808,  ...,  0.2968, -0.2475, -0.8826],\n",
      "         [ 0.3580, -0.0703, -0.8850,  ...,  0.1883,  0.1436, -0.2383],\n",
      "         [-0.5002,  0.0114, -1.2645,  ...,  0.7783, -0.3319, -0.9346],\n",
      "         [-0.4279, -0.4987, -1.3819,  ...,  0.4856, -0.0039, -0.7706],\n",
      "         [-0.2209, -0.5125, -1.2878,  ...,  0.6324,  0.1830, -0.4737]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    112         data_unnormalized:Optional[bool]=False,\n",
      "    113         **kwargs\n",
      "    114     ):  \n",
      "    115         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    116 \n",
      "--> 117         if data_type is not None and data_type == \"meta\":\n",
      "    118             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    119         else:\n",
      "    120             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    121 \n",
      "    122         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(120)forward()\n",
      "    118             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    119         else:\n",
      "--> 120             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    121 \n",
      "    122         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(122)forward()\n",
      "    120             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    121 \n",
      "--> 122         data_fused_repr = meta_repr = None\n",
      "    123         if data_aug_meta_prefix is not None:\n",
      "    124             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_repr.norm(dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(123)forward()\n",
      "    121 \n",
      "    122         data_fused_repr = meta_repr = None\n",
      "--> 123         if data_aug_meta_prefix is not None:\n",
      "    124             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    125             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(124)forward()\n",
      "    122         data_fused_repr = meta_repr = None\n",
      "    123         if data_aug_meta_prefix is not None:\n",
      "--> 124             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    125             if len(meta_kwargs):\n",
      "    126                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(125)forward()\n",
      "    123         if data_aug_meta_prefix is not None:\n",
      "    124             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "--> 125             if len(meta_kwargs):\n",
      "    126                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    127                                                                             torch.any(data_attention_mask, dim=1),\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(126)forward()\n",
      "    124             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    125             if len(meta_kwargs):\n",
      "--> 126                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    127                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    128                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(127)forward()\n",
      "    125             if len(meta_kwargs):\n",
      "    126                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "--> 127                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    128                                                                             meta_kwargs)\n",
      "    129                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(128)forward()\n",
      "    126                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    127                                                                             torch.any(data_attention_mask, dim=1),\n",
      "--> 128                                                                             meta_kwargs)\n",
      "    129                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    130 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(126)forward()\n",
      "    124             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    125             if len(meta_kwargs):\n",
      "--> 126                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    127                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    128                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_26512/3565704745.py(28)fuse_meta_into_embeddings()\n",
      "     26                 sd_meta[k].copy_(sd_dr[k])\n",
      "     27 \n",
      "---> 28     def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "     29         meta_repr = {}\n",
      "     30 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(29)fuse_meta_into_embeddings()\n",
      "     27 \n",
      "     28     def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "---> 29         meta_repr = {}\n",
      "     30 \n",
      "     31         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(31)fuse_meta_into_embeddings()\n",
      "     29         meta_repr = {}\n",
      "     30 \n",
      "---> 31         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     32         for m_key, m_args in meta_kwargs.items():\n",
      "     33             n_meta, bsz = m_args['data2ptr'].max(), len(m_args['data2ptr'])\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(32)fuse_meta_into_embeddings()\n",
      "     30 \n",
      "     31         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "---> 32         for m_key, m_args in meta_kwargs.items():\n",
      "     33             n_meta, bsz = m_args['data2ptr'].max(), len(m_args['data2ptr'])\n",
      "     34             assert torch.all(m_args['data2ptr'] == n_meta), f'All datapoints should have same number of metadata.'\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_fused_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(33)fuse_meta_into_embeddings()\n",
      "     31         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     32         for m_key, m_args in meta_kwargs.items():\n",
      "---> 33             n_meta, bsz = m_args['data2ptr'].max(), len(m_args['data2ptr'])\n",
      "     34             assert torch.all(m_args['data2ptr'] == n_meta), f'All datapoints should have same number of metadata.'\n",
      "     35 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(34)fuse_meta_into_embeddings()\n",
      "     32         for m_key, m_args in meta_kwargs.items():\n",
      "     33             n_meta, bsz = m_args['data2ptr'].max(), len(m_args['data2ptr'])\n",
      "---> 34             assert torch.all(m_args['data2ptr'] == n_meta), f'All datapoints should have same number of metadata.'\n",
      "     35 \n",
      "     36             m_input_ids, m_attention_mask = m_args['input_ids'], m_args['attention_mask']\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n_meta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  bsz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(36)fuse_meta_into_embeddings()\n",
      "     34             assert torch.all(m_args['data2ptr'] == n_meta), f'All datapoints should have same number of metadata.'\n",
      "     35 \n",
      "---> 36             m_input_ids, m_attention_mask = m_args['input_ids'], m_args['attention_mask']\n",
      "     37             m_embed = self.meta_encode(input_ids=m_input_ids, attention_mask=m_attention_mask)\n",
      "     38 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(37)fuse_meta_into_embeddings()\n",
      "     35 \n",
      "     36             m_input_ids, m_attention_mask = m_args['input_ids'], m_args['attention_mask']\n",
      "---> 37             m_embed = self.meta_encode(input_ids=m_input_ids, attention_mask=m_attention_mask)\n",
      "     38 \n",
      "     39             m_idx = m_args['idx']\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(39)fuse_meta_into_embeddings()\n",
      "     37             m_embed = self.meta_encode(input_ids=m_input_ids, attention_mask=m_attention_mask)\n",
      "     38 \n",
      "---> 39             m_idx = m_args['idx']\n",
      "     40             m_repr = F.normalize(self.meta_embeddings(m_idx) + m_embed + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "     41 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_embed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4711, -0.5405, -0.3613,  ...,  0.6627,  0.2056, -0.4132],\n",
      "        [-0.5355,  0.3508, -1.1401,  ..., -0.0078,  0.1995, -0.0930],\n",
      "        [-0.4559, -0.0452, -0.4907,  ...,  0.2223,  0.1730, -0.4363],\n",
      "        ...,\n",
      "        [-0.7420, -0.2882, -0.0634,  ...,  0.1905,  0.5780, -0.6984],\n",
      "        [-0.0296,  0.0637,  0.8700,  ..., -0.6256, -0.0730, -1.0056],\n",
      "        [-0.1513, -0.3573, -1.3101,  ...,  0.4211, -0.1453, -0.6851]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  embed.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'embed' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_embed.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(40)fuse_meta_into_embeddings()\n",
      "     38 \n",
      "     39             m_idx = m_args['idx']\n",
      "---> 40             m_repr = F.normalize(self.meta_embeddings(m_idx) + m_embed + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "     41 \n",
      "     42             m_repr, m_repr_mask = m_repr.view(bsz, -1, self.config.dim), torch.ones((m_repr.shape[0],), device=m_repr.device, dtype=torch.bool).view(bsz, -1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 72729, 161854, 161858, 120509, 306634, 487671, 102556,  68239,  54422,\n",
      "         79395, 174407,  72843,  84871,  84868,  84732])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.meta_embeddings(m_idx).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_embed.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.pretrained_meta_embeddings(m_idx).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(42)fuse_meta_into_embeddings()\n",
      "     40             m_repr = F.normalize(self.meta_embeddings(m_idx) + m_embed + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "     41 \n",
      "---> 42             m_repr, m_repr_mask = m_repr.view(bsz, -1, self.config.dim), torch.ones((m_repr.shape[0],), device=m_repr.device, dtype=torch.bool).view(bsz, -1)\n",
      "     43             meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "     44 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(43)fuse_meta_into_embeddings()\n",
      "     41 \n",
      "     42             m_repr, m_repr_mask = m_repr.view(bsz, -1, self.config.dim), torch.ones((m_repr.shape[0],), device=m_repr.device, dtype=torch.bool).view(bsz, -1)\n",
      "---> 43             meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "     44 \n",
      "     45             fused_repr = self.cross_head(data_fused_repr, data_mask, m_repr, m_repr_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr_mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr_mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(45)fuse_meta_into_embeddings()\n",
      "     43             meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "     44 \n",
      "---> 45             fused_repr = self.cross_head(data_fused_repr, data_mask, m_repr, m_repr_mask)[0]\n",
      "     46             data_fused_repr += fused_repr\n",
      "     47 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr_mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1696)__getattr__()\n",
      "   1694     # See full discussion on the problems with returning `Union` here\n",
      "   1695     # https://github.com/microsoft/pyright/issues/4213\n",
      "-> 1696     def __getattr__(self, name: str) -> Any:\n",
      "   1697         if '_parameters' in self.__dict__:\n",
      "   1698             _parameters = self.__dict__['_parameters']\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1697)__getattr__()\n",
      "   1695     # https://github.com/microsoft/pyright/issues/4213\n",
      "   1696     def __getattr__(self, name: str) -> Any:\n",
      "-> 1697         if '_parameters' in self.__dict__:\n",
      "   1698             _parameters = self.__dict__['_parameters']\n",
      "   1699             if name in _parameters:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "CrossAttentio..., bias=True)\n",
      ")\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1708)__getattr__()\n",
      "   1706             modules = self.__dict__['_modules']\n",
      "   1707             if name in modules:\n",
      "-> 1708                 return modules[name]\n",
      "   1709         raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
      "   1710 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1528)_wrapped_call_impl()\n",
      "   1526         return result\n",
      "   1527 \n",
      "-> 1528     def _wrapped_call_impl(self, *args, **kwargs):\n",
      "   1529         if self._compiled_call_impl is not None:\n",
      "   1530             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1529)_wrapped_call_impl()\n",
      "   1527 \n",
      "   1528     def _wrapped_call_impl(self, *args, **kwargs):\n",
      "-> 1529         if self._compiled_call_impl is not None:\n",
      "   1530             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1531         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1532)_wrapped_call_impl()\n",
      "   1530             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1531         else:\n",
      "-> 1532             return self._call_impl(*args, **kwargs)\n",
      "   1533 \n",
      "   1534     def _call_impl(self, *args, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1534)_call_impl()\n",
      "   1532             return self._call_impl(*args, **kwargs)\n",
      "   1533 \n",
      "-> 1534     def _call_impl(self, *args, **kwargs):\n",
      "   1535         forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1535)_call_impl()\n",
      "   1533 \n",
      "   1534     def _call_impl(self, *args, **kwargs):\n",
      "-> 1535         forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1537         # this function, and just call forward.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1538)_call_impl()\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1537         # this function, and just call forward.\n",
      "-> 1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1539)_call_impl()\n",
      "   1537         # this function, and just call forward.\n",
      "   1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "-> 1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1541             return forward_call(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1538)_call_impl()\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1537         # this function, and just call forward.\n",
      "-> 1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1539)_call_impl()\n",
      "   1537         # this function, and just call forward.\n",
      "   1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "-> 1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1541             return forward_call(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1538)_call_impl()\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1537         # this function, and just call forward.\n",
      "-> 1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1540)_call_impl()\n",
      "   1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "-> 1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1541             return forward_call(*args, **kwargs)\n",
      "   1542 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1538)_call_impl()\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1537         # this function, and just call forward.\n",
      "-> 1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1540)_call_impl()\n",
      "   1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "-> 1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1541             return forward_call(*args, **kwargs)\n",
      "   1542 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1538)_call_impl()\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1537         # this function, and just call forward.\n",
      "-> 1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1541)_call_impl()\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "-> 1541             return forward_call(*args, **kwargs)\n",
      "   1542 \n",
      "   1543         try:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_26512/1765836756.py(23)forward()\n",
      "     21         self.o.weight.data = torch.eye(self.o.out_features, self.o.in_features, dtype=self.o.weight.dtype)\n",
      "     22 \n",
      "---> 23     def forward(\n",
      "     24         self,\n",
      "     25         q: torch.Tensor,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(31)forward()\n",
      "     29         output_attentions:Optional[bool] = False,\n",
      "     30     ):\n",
      "---> 31         bs, q_len, dim = q.size()\n",
      "     32         v, k_len = k, k.size(1)\n",
      "     33 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  !q.size()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(32)forward()\n",
      "     30     ):\n",
      "     31         bs, q_len, dim = q.size()\n",
      "---> 32         v, k_len = k, k.size(1)\n",
      "     33 \n",
      "     34         h_dim = self.dim//self.n_h\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(34)forward()\n",
      "     32         v, k_len = k, k.size(1)\n",
      "     33 \n",
      "---> 34         h_dim = self.dim//self.n_h\n",
      "     35 \n",
      "     36         def shape(x: torch.Tensor): return x.view(bs, -1, self.n_h, h_dim).transpose(1, 2)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  k_len\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(36)forward()\n",
      "     34         h_dim = self.dim//self.n_h\n",
      "     35 \n",
      "---> 36         def shape(x: torch.Tensor): return x.view(bs, -1, self.n_h, h_dim).transpose(1, 2)\n",
      "     37 \n",
      "     38         def unshape(x: torch.Tensor): return x.transpose(1, 2).contiguous().view(bs, -1, self.n_h * h_dim)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  h_dim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(38)forward()\n",
      "     36         def shape(x: torch.Tensor): return x.view(bs, -1, self.n_h, h_dim).transpose(1, 2)\n",
      "     37 \n",
      "---> 38         def unshape(x: torch.Tensor): return x.transpose(1, 2).contiguous().view(bs, -1, self.n_h * h_dim)\n",
      "     39 \n",
      "     40         q = shape(self.q(q))  # (bs, n_h, q_len, h_dim)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(40)forward()\n",
      "     38         def unshape(x: torch.Tensor): return x.transpose(1, 2).contiguous().view(bs, -1, self.n_h * h_dim)\n",
      "     39 \n",
      "---> 40         q = shape(self.q(q))  # (bs, n_h, q_len, h_dim)\n",
      "     41         k = shape(self.k(k))  # (bs, n_h, k_len, h_dim)\n",
      "     42         v = shape(self.v(v))  # (bs, n_h, k_len, h_dim)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(41)forward()\n",
      "     39 \n",
      "     40         q = shape(self.q(q))  # (bs, n_h, q_len, h_dim)\n",
      "---> 41         k = shape(self.k(k))  # (bs, n_h, k_len, h_dim)\n",
      "     42         v = shape(self.v(v))  # (bs, n_h, k_len, h_dim)\n",
      "     43 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(42)forward()\n",
      "     40         q = shape(self.q(q))  # (bs, n_h, q_len, h_dim)\n",
      "     41         k = shape(self.k(k))  # (bs, n_h, k_len, h_dim)\n",
      "---> 42         v = shape(self.v(v))  # (bs, n_h, k_len, h_dim)\n",
      "     43 \n",
      "     44         q = q / math.sqrt(h_dim)  # (bs, n_h, q_len, h_dim)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(44)forward()\n",
      "     42         v = shape(self.v(v))  # (bs, n_h, k_len, h_dim)\n",
      "     43 \n",
      "---> 44         q = q / math.sqrt(h_dim)  # (bs, n_h, q_len, h_dim)\n",
      "     45         sc = torch.matmul(q, k.transpose(2, 3))  # (bs, n_h, q_len, k_len)\n",
      "     46 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  !q.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12, 1, 64])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  !k.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12, 3, 64])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(45)forward()\n",
      "     43 \n",
      "     44         q = q / math.sqrt(h_dim)  # (bs, n_h, q_len, h_dim)\n",
      "---> 45         sc = torch.matmul(q, k.transpose(2, 3))  # (bs, n_h, q_len, k_len)\n",
      "     46 \n",
      "     47         q_m, k_m = q_m.view(bs, 1, -1, 1).to(q.dtype), k_m.view(bs, 1, 1, -1).to(q.dtype)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  k.transpose(2, 3).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12, 64, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(47)forward()\n",
      "     45         sc = torch.matmul(q, k.transpose(2, 3))  # (bs, n_h, q_len, k_len)\n",
      "     46 \n",
      "---> 47         q_m, k_m = q_m.view(bs, 1, -1, 1).to(q.dtype), k_m.view(bs, 1, 1, -1).to(q.dtype)\n",
      "     48         mask = torch.matmul(q_m, k_m).expand_as(sc)  # (bs, n_h, q_len, k_len)\n",
      "     49 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  sc.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12, 1, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  sc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-4.1424e-04, -2.2880e-04, -6.0960e-05]],\n",
      "\n",
      "         [[ 9.9972e-04,  9.5448e-04,  7.1228e-04]],\n",
      "\n",
      "         [[ 2.2895e-03,  1.8841e-03,  1.4976e-04]],\n",
      "\n",
      "         [[-2.1307e-03, -5.1904e-04,  1.2063e-03]],\n",
      "\n",
      "         [[ 1.9698e-03,  6.5417e-04,  8.0679e-04]],\n",
      "\n",
      "         [[ 1.2304e-03,  1.1282e-03,  1.5732e-03]],\n",
      "\n",
      "         [[ 2.9919e-03,  1.0506e-03,  2.1831e-03]],\n",
      "\n",
      "         [[ 4.1416e-04,  1.0185e-03,  7.6501e-04]],\n",
      "\n",
      "         [[ 5.5429e-04,  4.4133e-03,  5.2506e-03]],\n",
      "\n",
      "         [[ 1.3871e-03,  9.2414e-04,  2.5209e-03]],\n",
      "\n",
      "         [[ 5.8925e-04,  2.4008e-04,  1.0212e-03]],\n",
      "\n",
      "         [[ 4.2999e-03,  1.7437e-03,  2.4098e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5860e-03,  4.0973e-03,  6.9158e-03]],\n",
      "\n",
      "         [[ 2.4058e-03,  7.0596e-03,  1.0392e-02]],\n",
      "\n",
      "         [[-9.3684e-04,  6.7379e-03,  8.7702e-03]],\n",
      "\n",
      "         [[ 2.2622e-04,  3.5357e-03,  4.1718e-03]],\n",
      "\n",
      "         [[ 1.9554e-03,  6.1795e-03,  7.3816e-03]],\n",
      "\n",
      "         [[ 9.0992e-04,  7.4287e-03,  7.7551e-03]],\n",
      "\n",
      "         [[ 2.3973e-03,  1.8775e-03,  4.6831e-03]],\n",
      "\n",
      "         [[ 1.1550e-03,  7.1889e-03,  7.7494e-03]],\n",
      "\n",
      "         [[ 3.6354e-03,  6.3996e-03,  8.8169e-03]],\n",
      "\n",
      "         [[ 3.5128e-03,  8.2675e-03,  1.0113e-02]],\n",
      "\n",
      "         [[ 1.0525e-03,  5.1585e-03,  7.5195e-03]],\n",
      "\n",
      "         [[ 3.0123e-03,  4.2046e-03,  6.3195e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2945e-03,  2.0315e-03,  2.9454e-03]],\n",
      "\n",
      "         [[ 2.6926e-03,  4.1044e-03,  3.6209e-03]],\n",
      "\n",
      "         [[ 4.7645e-03,  3.7491e-03,  3.2360e-03]],\n",
      "\n",
      "         [[-8.0766e-04,  9.3371e-04,  1.9642e-03]],\n",
      "\n",
      "         [[ 2.6646e-03,  3.0828e-03,  3.0210e-03]],\n",
      "\n",
      "         [[ 3.2716e-03,  4.3000e-03,  4.6769e-03]],\n",
      "\n",
      "         [[-6.0933e-04,  1.1313e-03, -2.5489e-04]],\n",
      "\n",
      "         [[-1.9189e-03,  2.4739e-03,  2.6375e-04]],\n",
      "\n",
      "         [[-8.8039e-04,  1.9959e-03, -2.5217e-04]],\n",
      "\n",
      "         [[ 6.9021e-04,  2.3552e-03,  2.5613e-03]],\n",
      "\n",
      "         [[ 7.5980e-04,  2.8816e-03, -4.6758e-04]],\n",
      "\n",
      "         [[ 1.4266e-03,  8.3523e-05,  1.9579e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.4452e-04,  6.9400e-04,  7.0185e-03]],\n",
      "\n",
      "         [[ 1.1683e-03,  1.2909e-03,  6.4856e-03]],\n",
      "\n",
      "         [[ 1.0291e-03,  2.1914e-03,  7.4622e-03]],\n",
      "\n",
      "         [[-7.9356e-04, -1.8946e-04,  6.1835e-03]],\n",
      "\n",
      "         [[ 1.1859e-03,  1.8674e-03,  7.1958e-03]],\n",
      "\n",
      "         [[-1.2733e-03, -1.0427e-04,  7.8673e-03]],\n",
      "\n",
      "         [[ 1.1575e-03,  5.9304e-04,  5.8172e-03]],\n",
      "\n",
      "         [[ 1.5397e-03,  1.0879e-03,  7.4142e-03]],\n",
      "\n",
      "         [[-2.5052e-04,  9.0672e-04,  6.3982e-03]],\n",
      "\n",
      "         [[ 8.8921e-04,  1.5753e-03,  5.5395e-03]],\n",
      "\n",
      "         [[ 6.1701e-04,  1.1551e-03,  1.1098e-02]],\n",
      "\n",
      "         [[ 1.2457e-03,  1.3912e-03,  7.9476e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6588e-04,  2.2767e-03,  9.7688e-03]],\n",
      "\n",
      "         [[ 2.2737e-03,  4.6024e-03,  1.2868e-02]],\n",
      "\n",
      "         [[-4.1286e-05,  7.9537e-04,  1.1015e-02]],\n",
      "\n",
      "         [[-7.5131e-04,  1.0838e-03,  7.6411e-03]],\n",
      "\n",
      "         [[ 8.1676e-04,  4.5228e-05,  1.0734e-02]],\n",
      "\n",
      "         [[ 3.7682e-03,  4.8315e-03,  1.0186e-02]],\n",
      "\n",
      "         [[ 2.4897e-03,  2.7121e-03,  8.4537e-03]],\n",
      "\n",
      "         [[ 1.9348e-04,  5.9002e-04,  6.1556e-03]],\n",
      "\n",
      "         [[ 2.6056e-03,  1.7783e-04,  9.7475e-03]],\n",
      "\n",
      "         [[ 4.5202e-03,  2.4541e-03,  7.7109e-03]],\n",
      "\n",
      "         [[ 7.3483e-04,  3.9726e-03,  9.1418e-03]],\n",
      "\n",
      "         [[ 2.2270e-03,  1.2492e-03,  1.0228e-02]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(48)forward()\n",
      "     46 \n",
      "     47         q_m, k_m = q_m.view(bs, 1, -1, 1).to(q.dtype), k_m.view(bs, 1, 1, -1).to(q.dtype)\n",
      "---> 48         mask = torch.matmul(q_m, k_m).expand_as(sc)  # (bs, n_h, q_len, k_len)\n",
      "     49 \n",
      "     50         sc = sc.masked_fill(mask == 0, torch.tensor(torch.finfo(sc.dtype).min))  # (bs, n_h, q_len, k_len)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q_m.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  k_m.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 1, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  sc.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12, 1, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(50)forward()\n",
      "     48         mask = torch.matmul(q_m, k_m).expand_as(sc)  # (bs, n_h, q_len, k_len)\n",
      "     49 \n",
      "---> 50         sc = sc.masked_fill(mask == 0, torch.tensor(torch.finfo(sc.dtype).min))  # (bs, n_h, q_len, k_len)\n",
      "     51 \n",
      "     52         w = nn.functional.softmax(sc, dim=-1)  # (bs, n_h, q_len, k_len)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12, 1, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     45         sc = torch.matmul(q, k.transpose(2, 3))  # (bs, n_h, q_len, k_len)\n",
      "     46 \n",
      "     47         q_m, k_m = q_m.view(bs, 1, -1, 1).to(q.dtype), k_m.view(bs, 1, 1, -1).to(q.dtype)\n",
      "     48         mask = torch.matmul(q_m, k_m).expand_as(sc)  # (bs, n_h, q_len, k_len)\n",
      "     49 \n",
      "---> 50         sc = sc.masked_fill(mask == 0, torch.tensor(torch.finfo(sc.dtype).min))  # (bs, n_h, q_len, k_len)\n",
      "     51 \n",
      "     52         w = nn.functional.softmax(sc, dim=-1)  # (bs, n_h, q_len, k_len)\n",
      "     53         w = self.dropout(w)  # (bs, n_h, q_len, k_len)\n",
      "     54 \n",
      "     55         o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  sc.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12, 1, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12, 1, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12, 1, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  mask.sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(180.)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  sc.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12, 1, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(52)forward()\n",
      "     50         sc = sc.masked_fill(mask == 0, torch.tensor(torch.finfo(sc.dtype).min))  # (bs, n_h, q_len, k_len)\n",
      "     51 \n",
      "---> 52         w = nn.functional.softmax(sc, dim=-1)  # (bs, n_h, q_len, k_len)\n",
      "     53         w = self.dropout(w)  # (bs, n_h, q_len, k_len)\n",
      "     54 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(53)forward()\n",
      "     51 \n",
      "     52         w = nn.functional.softmax(sc, dim=-1)  # (bs, n_h, q_len, k_len)\n",
      "---> 53         w = self.dropout(w)  # (bs, n_h, q_len, k_len)\n",
      "     54 \n",
      "     55         o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  (mask == 0).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  !w.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12, 1, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  !w.sum(dim=-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  !w.sum(dim=-1) == 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ True],\n",
      "         [False],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [ True]],\n",
      "\n",
      "        [[ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True]],\n",
      "\n",
      "        [[ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [ True],\n",
      "         [ True]],\n",
      "\n",
      "        [[False],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [False],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  !w.sum(dim=-1)-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000e+00],\n",
      "         [ 1.1921e-07],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [-1.1921e-07],\n",
      "         [-1.1921e-07],\n",
      "         [-5.9605e-08]],\n",
      "\n",
      "        [[-5.9605e-08],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 1.1921e-07],\n",
      "         [ 0.0000e+00],\n",
      "         [-5.9605e-08],\n",
      "         [ 0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [-5.9605e-08],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [-5.9605e-08],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 1.1921e-07],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00]],\n",
      "\n",
      "        [[-1.1921e-07],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [-5.9605e-08],\n",
      "         [ 1.1921e-07],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [ 0.0000e+00],\n",
      "         [-5.9605e-08]]], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  !w.sum(dim=-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]],\n",
      "\n",
      "        [[1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000],\n",
      "         [1.0000]]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  !(w.sum(dim=-1)-1).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.9802e-07, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     48         mask = torch.matmul(q_m, k_m).expand_as(sc)  # (bs, n_h, q_len, k_len)\n",
      "     49 \n",
      "     50         sc = sc.masked_fill(mask == 0, torch.tensor(torch.finfo(sc.dtype).min))  # (bs, n_h, q_len, k_len)\n",
      "     51 \n",
      "     52         w = nn.functional.softmax(sc, dim=-1)  # (bs, n_h, q_len, k_len)\n",
      "---> 53         w = self.dropout(w)  # (bs, n_h, q_len, k_len)\n",
      "     54 \n",
      "     55         o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
      "     56 \n",
      "     57         if output_attentions: return (o, w)\n",
      "     58         else: return (o,)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(55)forward()\n",
      "     53         w = self.dropout(w)  # (bs, n_h, q_len, k_len)\n",
      "     54 \n",
      "---> 55         o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
      "     56 \n",
      "     57         if output_attentions: return (o, w)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  !w.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12, 1, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  !v.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12, 3, 64])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(57)forward()\n",
      "     55         o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
      "     56 \n",
      "---> 57         if output_attentions: return (o, w)\n",
      "     58         else: return (o,)\n",
      "     59 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  !o.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1765836756.py(58)forward()\n",
      "     55         o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
      "     56 \n",
      "     57         if output_attentions: return (o, w)\n",
      "---> 58         else: return (o,)\n",
      "     59 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[[-0....iewBackward0>),)\n",
      "> /tmp/ipykernel_26512/1765836756.py(58)forward()\n",
      "     55         o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
      "     56 \n",
      "     57         if output_attentions: return (o, w)\n",
      "---> 58         else: return (o,)\n",
      "     59 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[[-0....iewBackward0>),)\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1541)_call_impl()\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "-> 1541             return forward_call(*args, **kwargs)\n",
      "   1542 \n",
      "   1543         try:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[[-0....iewBackward0>),)\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1532)_wrapped_call_impl()\n",
      "   1530             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1531         else:\n",
      "-> 1532             return self._call_impl(*args, **kwargs)\n",
      "   1533 \n",
      "   1534     def _call_impl(self, *args, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(46)fuse_meta_into_embeddings()\n",
      "     44 \n",
      "     45             fused_repr = self.cross_head(data_fused_repr, data_mask, m_repr, m_repr_mask)[0]\n",
      "---> 46             data_fused_repr += fused_repr\n",
      "     47 \n",
      "     48         return data_fused_repr.squeeze(), meta_repr\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_fused_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  fused_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(32)fuse_meta_into_embeddings()\n",
      "     30 \n",
      "     31         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "---> 32         for m_key, m_args in meta_kwargs.items():\n",
      "     33             n_meta, bsz = m_args['data2ptr'].max(), len(m_args['data2ptr'])\n",
      "     34             assert torch.all(m_args['data2ptr'] == n_meta), f'All datapoints should have same number of metadata.'\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/3565704745.py(48)fuse_meta_into_embeddings()\n",
      "     45             fused_repr = self.cross_head(data_fused_repr, data_mask, m_repr, m_repr_mask)[0]\n",
      "     46             data_fused_repr += fused_repr\n",
      "     47 \n",
      "---> 48         return data_fused_repr.squeeze(), meta_repr\n",
      "     49 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[-0.0...ezeBackward0>), {'lnk2data': tensor([[ 0.0...dexBackward0>)})\n",
      "> /tmp/ipykernel_26512/3565704745.py(48)fuse_meta_into_embeddings()\n",
      "     45             fused_repr = self.cross_head(data_fused_repr, data_mask, m_repr, m_repr_mask)[0]\n",
      "     46             data_fused_repr += fused_repr\n",
      "     47 \n",
      "---> 48         return data_fused_repr.squeeze(), meta_repr\n",
      "     49 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(129)forward()\n",
      "    127                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    128                                                                             meta_kwargs)\n",
      "--> 129                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    130 \n",
      "    131         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(131)forward()\n",
      "    129                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    130 \n",
      "--> 131         return EncoderOutput(\n",
      "    132             rep=data_repr,\n",
      "    133             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(132)forward()\n",
      "    130 \n",
      "    131         return EncoderOutput(\n",
      "--> 132             rep=data_repr,\n",
      "    133             fused_rep=data_fused_repr,\n",
      "    134             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(133)forward()\n",
      "    131         return EncoderOutput(\n",
      "    132             rep=data_repr,\n",
      "--> 133             fused_rep=data_fused_repr,\n",
      "    134             meta_repr=meta_repr,\n",
      "    135         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(134)forward()\n",
      "    132             rep=data_repr,\n",
      "    133             fused_rep=data_fused_repr,\n",
      "--> 134             meta_repr=meta_repr,\n",
      "    135         )\n",
      "    136 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(131)forward()\n",
      "    129                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    130 \n",
      "--> 131         return EncoderOutput(\n",
      "    132             rep=data_repr,\n",
      "    133             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...xBackward0>)})\n",
      "> /tmp/ipykernel_26512/4122862164.py(131)forward()\n",
      "    129                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    130 \n",
      "--> 131         return EncoderOutput(\n",
      "    132             rep=data_repr,\n",
      "    133             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(71)forward()\n",
      "     69                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     70 \n",
      "---> 71         loss = None; lbl2data_o = EncoderOutput()\n",
      "     72         if lbl2data_input_ids is not None:\n",
      "     73             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(72)forward()\n",
      "     70 \n",
      "     71         loss = None; lbl2data_o = EncoderOutput()\n",
      "---> 72         if lbl2data_input_ids is not None:\n",
      "     73             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(73)forward()\n",
      "     71         loss = None; lbl2data_o = EncoderOutput()\n",
      "     72         if lbl2data_input_ids is not None:\n",
      "---> 73             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(74)forward()\n",
      "     72         if lbl2data_input_ids is not None:\n",
      "     73             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "---> 74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "     76             lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(75)forward()\n",
      "     73             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "---> 75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "     76             lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
      "     77 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(74)forward()\n",
      "     72         if lbl2data_input_ids is not None:\n",
      "     73             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "---> 74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "     76             lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(75)forward()\n",
      "     73             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "---> 75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "     76             lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
      "     77 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(74)forward()\n",
      "     72         if lbl2data_input_ids is not None:\n",
      "     73             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "---> 74             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "     75                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "     76             lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(115)forward()\n",
      "    113         **kwargs\n",
      "    114     ):  \n",
      "--> 115         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    116 \n",
      "    117         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(117)forward()\n",
      "    115         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    116 \n",
      "--> 117         if data_type is not None and data_type == \"meta\":\n",
      "    118             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    119         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(120)forward()\n",
      "    118             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    119         else:\n",
      "--> 120             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    121 \n",
      "    122         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "o = func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "15412add-4193-4bcc-a158-493e855e62d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0149, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a4225-226b-47b4-9fb2-4b56fa6280ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK014`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "faf368ff-3a4c-4e8e-9c7c-1c7ac987f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder014(Encoder013):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        n_meta_clusters:int,\n",
    "        n_metadata:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, num_metadata=n_meta_clusters, **kwargs)\n",
    "        self.pretrained_meta_embeddings = nn.Embedding(n_meta_clusters, config.dim)\n",
    "        self.register_buffer(\"metadata_remap\", torch.arange(n_metadata)%n_meta_clusters, persistent=True)\n",
    "        self.post_init()\n",
    "\n",
    "    def set_metadata_remap(self, metadata_remap:torch.Tensor):\n",
    "        if metadata_remap.shape[0] != self.metadata_remap.shape[0]:\n",
    "            raise ValueError(f'Shape mismatch, `metadata_remap` should have {self.metadata_remap.shape[0]} elements.')\n",
    "        with torch.no_grad():\n",
    "            self.metadata_remap.copy_(metadata_remap)\n",
    "\n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            n_meta, bsz = m_args['data2ptr'].max(), len(m_args['data2ptr'])\n",
    "            assert torch.all(m_args['data2ptr'] == n_meta), f'All datapoints should have same number of metadata.'\n",
    "            \n",
    "            m_input_ids, m_attention_mask = m_args['input_ids'], m_args['attention_mask']\n",
    "            m_embed = self.meta_encode(input_ids=m_input_ids, attention_mask=m_attention_mask)\n",
    "            \n",
    "            m_idx = m_args['idx']\n",
    "            m_repr = F.normalize(self.meta_embeddings(self.metadata_remap[m_idx]) + m_embed + self.pretrained_meta_embeddings(self.metadata_remap[m_idx]), dim=1)\n",
    "            \n",
    "            m_repr, m_repr_mask = m_repr.view(bsz, -1, self.config.dim), torch.ones((m_repr.shape[0],), device=m_repr.device, dtype=torch.bool).view(bsz, -1)\n",
    "            meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "            \n",
    "            fused_repr = self.cross_head(data_fused_repr, data_mask, m_repr, m_repr_mask)[0]\n",
    "            data_fused_repr += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b2b890f3-6355-4791-a0de-3411a851c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK014(OAK013, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "    _keys_to_ignore_on_load_missing = [\"encoder.meta_distilbert\"]\n",
    "\n",
    "    @delegates(OAK013.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        n_metadata:int,\n",
    "        n_meta_clusters:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, num_metadata=n_metadata, resize_length=resize_length, **kwargs)\n",
    "        self.encoder = Encoder014(config, n_metadata=n_metadata, n_meta_clusters=n_meta_clusters, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca78c88-acb8-49a1-9ae2-25269f5de928",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f8c65b06-80f7-4b61-8bba-98f526f3a736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK014 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.metadata_remap', 'encoder.pretrained_meta_embeddings.weight', 'label_embeddings.weight', 'label_remap']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK014.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               n_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000, n_meta_clusters=block.train.dset.meta['lnk_meta'].n_meta//3,\n",
    "                               n_labels=block.n_lbl, n_clusters=block.n_lbl//3, \n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "model.init_label_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "31d91024-53e8-4d27-b893-6640152787cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()\n",
    "\n",
    "model.init_meta_encoder()\n",
    "\n",
    "remap = torch.arange(block.train.dset.meta['lnk_meta'].n_meta)%1000\n",
    "model.encoder.set_metadata_remap(remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec515c7-bbac-4e22-8ab9-6aa17bb287a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53a8cc5d-546c-4d11-a588-aaeeca1d972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ba74e69-d351-49f2-9e95-2a8826567a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a32dcf7-b17b-4a21-80ec-d06ac315725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4454517-8cb1-404b-9a71-291ea9e85361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0149, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627137a8-d899-48f4-9f74-60d7d9629518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "43e35249-9ce1-45d6-8244-a42ca5be15c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b15af2-f9c5-46a0-bc79-94bee931c981",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1795951242.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b.to(model.device))\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 3 at /tmp/ipykernel_26512/2049060262.py:45\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.encoder.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 4 at /tmp/ipykernel_26512/4122862164.py:106\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(61)forward()\n",
      "     59         **kwargs\n",
      "     60     ):  \n",
      "---> 61         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     62 \n",
      "     63         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(63)forward()\n",
      "     61         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     62 \n",
      "---> 63         if self.use_encoder_parallel:\n",
      "     64             encoder = XCDataParallel(module=self.encoder)\n",
      "     65         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(65)forward()\n",
      "     63         if self.use_encoder_parallel:\n",
      "     64             encoder = XCDataParallel(module=self.encoder)\n",
      "---> 65         else: encoder = self.encoder\n",
      "     66 \n",
      "     67         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(67)forward()\n",
      "     65         else: encoder = self.encoder\n",
      "     66 \n",
      "---> 67         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     68         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     69                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(68)forward()\n",
      "     66 \n",
      "     67         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 68         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     69                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     70 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(68)forward()\n",
      "     66 \n",
      "     67         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 68         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     69                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     70 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(69)forward()\n",
      "     67         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     68         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 69                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     70 \n",
      "     71         loss = None; lbl2data_o = EncoderOutput()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/2049060262.py(68)forward()\n",
      "     66 \n",
      "     67         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 68         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     69                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     70 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(115)forward()\n",
      "    113         **kwargs\n",
      "    114     ):  \n",
      "--> 115         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    116 \n",
      "    117         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(117)forward()\n",
      "    115         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    116 \n",
      "--> 117         if data_type is not None and data_type == \"meta\":\n",
      "    118             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    119         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(120)forward()\n",
      "    118             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    119         else:\n",
      "--> 120             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    121 \n",
      "    122         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(122)forward()\n",
      "    120             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    121 \n",
      "--> 122         data_fused_repr = meta_repr = None\n",
      "    123         if data_aug_meta_prefix is not None:\n",
      "    124             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(123)forward()\n",
      "    121 \n",
      "    122         data_fused_repr = meta_repr = None\n",
      "--> 123         if data_aug_meta_prefix is not None:\n",
      "    124             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    125             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(124)forward()\n",
      "    122         data_fused_repr = meta_repr = None\n",
      "    123         if data_aug_meta_prefix is not None:\n",
      "--> 124             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    125             if len(meta_kwargs):\n",
      "    126                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(125)forward()\n",
      "    123         if data_aug_meta_prefix is not None:\n",
      "    124             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "--> 125             if len(meta_kwargs):\n",
      "    126                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    127                                                                             torch.any(data_attention_mask, dim=1),\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(126)forward()\n",
      "    124             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    125             if len(meta_kwargs):\n",
      "--> 126                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    127                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    128                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(127)forward()\n",
      "    125             if len(meta_kwargs):\n",
      "    126                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "--> 127                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    128                                                                             meta_kwargs)\n",
      "    129                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(128)forward()\n",
      "    126                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    127                                                                             torch.any(data_attention_mask, dim=1),\n",
      "--> 128                                                                             meta_kwargs)\n",
      "    129                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    130 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/4122862164.py(126)forward()\n",
      "    124             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    125             if len(meta_kwargs):\n",
      "--> 126                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    127                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    128                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_26512/1735825316.py(22)fuse_meta_into_embeddings()\n",
      "     20             self.metadata_remap.copy_(metadata_remap)\n",
      "     21 \n",
      "---> 22     def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "     23         meta_repr = {}\n",
      "     24 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1735825316.py(23)fuse_meta_into_embeddings()\n",
      "     21 \n",
      "     22     def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "---> 23         meta_repr = {}\n",
      "     24 \n",
      "     25         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1735825316.py(25)fuse_meta_into_embeddings()\n",
      "     23         meta_repr = {}\n",
      "     24 \n",
      "---> 25         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     26         for m_key, m_args in meta_kwargs.items():\n",
      "     27             n_meta, bsz = m_args['data2ptr'].max(), len(m_args['data2ptr'])\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1735825316.py(26)fuse_meta_into_embeddings()\n",
      "     24 \n",
      "     25         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "---> 26         for m_key, m_args in meta_kwargs.items():\n",
      "     27             n_meta, bsz = m_args['data2ptr'].max(), len(m_args['data2ptr'])\n",
      "     28             assert torch.all(m_args['data2ptr'] == n_meta), f'All datapoints should have same number of metadata.'\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1735825316.py(27)fuse_meta_into_embeddings()\n",
      "     25         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     26         for m_key, m_args in meta_kwargs.items():\n",
      "---> 27             n_meta, bsz = m_args['data2ptr'].max(), len(m_args['data2ptr'])\n",
      "     28             assert torch.all(m_args['data2ptr'] == n_meta), f'All datapoints should have same number of metadata.'\n",
      "     29 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1735825316.py(28)fuse_meta_into_embeddings()\n",
      "     26         for m_key, m_args in meta_kwargs.items():\n",
      "     27             n_meta, bsz = m_args['data2ptr'].max(), len(m_args['data2ptr'])\n",
      "---> 28             assert torch.all(m_args['data2ptr'] == n_meta), f'All datapoints should have same number of metadata.'\n",
      "     29 \n",
      "     30             m_input_ids, m_attention_mask = m_args['input_ids'], m_args['attention_mask']\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1735825316.py(30)fuse_meta_into_embeddings()\n",
      "     28             assert torch.all(m_args['data2ptr'] == n_meta), f'All datapoints should have same number of metadata.'\n",
      "     29 \n",
      "---> 30             m_input_ids, m_attention_mask = m_args['input_ids'], m_args['attention_mask']\n",
      "     31             m_embed = self.meta_encode(input_ids=m_input_ids, attention_mask=m_attention_mask)\n",
      "     32 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1735825316.py(31)fuse_meta_into_embeddings()\n",
      "     29 \n",
      "     30             m_input_ids, m_attention_mask = m_args['input_ids'], m_args['attention_mask']\n",
      "---> 31             m_embed = self.meta_encode(input_ids=m_input_ids, attention_mask=m_attention_mask)\n",
      "     32 \n",
      "     33             m_idx = m_args['idx']\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_26512/1735825316.py(33)fuse_meta_into_embeddings()\n",
      "     31             m_embed = self.meta_encode(input_ids=m_input_ids, attention_mask=m_attention_mask)\n",
      "     32 \n",
      "---> 33             m_idx = m_args['idx']\n",
      "     34             m_repr = F.normalize(self.meta_embeddings(self.metadata_remap[m_idx]) + m_embed + self.pretrained_meta_embeddings(self.metadata_remap[m_idx]), dim=1)\n",
      "     35 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "o = func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367be2aa-95d1-4b64-9859-031cf533da24",
   "metadata": {},
   "source": [
    "## `OAK015`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d040f7d7-c2cc-4c39-adaa-86667c89cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK015(OAK003):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        neg2data_aug_meta_prefix:Optional[str]=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('neg2data_aug_meta_prefix')\n",
    "        self.rep_loss_fn = MultiTripletWithNegatives(margin=kwargs['margin'], n_negatives=kwargs['num_negatives'], \n",
    "                                                     tau=kwargs['tau'], apply_softmax=kwargs['apply_softmax'], \n",
    "                                                     reduce='mean')\n",
    "        \n",
    "    def compute_loss(self, data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, neg2data_repr, \n",
    "                     neg2data_data2ptr, neg2data_idx, plbl2data_data2ptr, plbl2data_idx, **kwargs):\n",
    "        return self.rep_loss_fn(data_repr, pos_targ=lbl2data_repr, n_pos=lbl2data_data2ptr, pos_idx=lbl2data_idx, \n",
    "                                neg_targ=neg2data_repr, n_neg=neg2data_data2ptr, neg_idx=neg2data_idx, \n",
    "                                n_ppos=plbl2data_data2ptr, ppos_idx=plbl2data_idx, **kwargs)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "\n",
    "        neg2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        neg2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        neg2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        neg2data_idx:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if (\n",
    "            lbl2data_input_ids is not None and \n",
    "            neg2data_input_ids is not None\n",
    "        ):\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "\n",
    "            neg2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('neg2data', self.neg2data_aug_meta_prefix, **kwargs)\n",
    "            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.neg2data_aug_meta_prefix, **neg2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
    "                                     neg2data_data2ptr, neg2data_idx, plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
    "            \n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
    "                                          neg2data_data2ptr, neg2data_idx, plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
    "                \n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, neg2data_o.rep, neg2data_data2ptr, neg2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "                \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc64a5-cebd-4301-80c4-aa6ae93c8606",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b0b9af8-cff8-43ec-b29d-d597dff84ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK015 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK015.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', margin=0.3, num_negatives=5, \n",
    "                               tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None,\n",
    "                               neg2data_aug_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False, normalize=True)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ac02eba1-0eb7-4328-b5c6-aae9915b6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb3d80-26d2-42f6-aad1-570fbb991e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57caf8dd-1133-4f20-9266-0f1b065fbb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2f0ac90b-b94a-4294-9fed-1f36b0bc0a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc8544-7d25-43a9-8c00-502598ceb4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a35e90ff-22f9-4944-9e62-127627894f98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e30d4a54-52b4-4224-ab5e-83aaeecfe48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1556, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5cc48-9a23-4523-ac69-10b89b4e234c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cd9a11be-54eb-4712-b45a-b6edc99f916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    o = model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "08de67b8-f18c-407c-97a8-465c17156fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/3721260802.py\u001b[0m(2)\u001b[0;36mfunc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 2 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m    \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(45)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     43 \u001b[0;31m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     44 \u001b[0;31m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m1\u001b[0;32m--> 45 \u001b[0;31m        \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     46 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     47 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_encoder_parallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(119)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    117 \u001b[0;31m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m2\u001b[0;32m-> 119 \u001b[0;31m        \u001b[0mdata_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    120 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    121 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"meta\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2221889608.py\u001b[0m(29)\u001b[0;36mfuse_meta_into_embeddings\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     27 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mfuse_meta_into_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_repr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_mask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m3\u001b[0;32m--> 29 \u001b[0;31m        \u001b[0mmeta_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     31 \u001b[0;31m        \u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_repr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(119)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    117 \u001b[0;31m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m2\u001b[0;32m-> 119 \u001b[0;31m        \u001b[0mdata_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    120 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    121 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"meta\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(135)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m                \u001b[0mdata_fused_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_fused\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        return EncoderOutput(\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m            \u001b[0mrep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m            \u001b[0mfused_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1750)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1748 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1749 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1750 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1751 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1752 \u001b[0;31m        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1739)\u001b[0;36m_wrapped_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1737 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1738 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1739 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1740 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1741 \u001b[0;31m    \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(64)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     62 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlbl2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     63 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 64 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     65 \u001b[0;31m            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderOutput(rep=tensor([[-0.0252,  0.0914, -0.0155,  ..., -0.0417,  0.0890, -0.0145],\n",
      "        [ 0.0107, -0.0238, -0.0349,  ...,  0.0151, -0.0291, -0.0294],\n",
      "        [-0.0068, -0.0017, -0.0149,  ...,  0.0273,  0.0346,  0.0232],\n",
      "        [-0.0244, -0.0302, -0.0259,  ...,  0.0584,  0.0058, -0.0318]],\n",
      "       grad_fn=<DivBackward0>), fused_rep=None, logits=None, fusion_weights=None, meta_repr=None)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(65)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     63 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 65 \u001b[0;31m            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(66)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     64 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     65 \u001b[0;31m            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m---> 66 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  neg2data_meta_kwargs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(65)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     63 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 65 \u001b[0;31m            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(66)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     64 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     65 \u001b[0;31m            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m---> 66 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(65)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     63 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 65 \u001b[0;31m            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(119)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    117 \u001b[0;31m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m2\u001b[0;32m-> 119 \u001b[0;31m        \u001b[0mdata_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    120 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    121 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"meta\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(135)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m                \u001b[0mdata_fused_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_fused\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        return EncoderOutput(\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m            \u001b[0mrep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m            \u001b[0mfused_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1750)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1748 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1749 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1750 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1751 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1752 \u001b[0;31m        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1739)\u001b[0;36m_wrapped_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1737 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1738 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1739 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1740 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1741 \u001b[0;31m    \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(68)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     66 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 68 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     69 \u001b[0;31m                                     \u001b[0mneg2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_o.rep.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(69)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m---> 69 \u001b[0;31m                                     \u001b[0mneg2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(68)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     66 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 68 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     69 \u001b[0;31m                                     \u001b[0mneg2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(69)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m---> 69 \u001b[0;31m                                     \u001b[0mneg2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(68)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     66 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 68 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     69 \u001b[0;31m                                     \u001b[0mneg2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(71)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     69 \u001b[0;31m                                     \u001b[0mneg2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 71 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     72 \u001b[0;31m                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     73 \u001b[0;31m                                          \u001b[0mneg2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0780, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(72)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     70 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 72 \u001b[0;31m                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     73 \u001b[0;31m                                          \u001b[0mneg2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(73)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     71 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     72 \u001b[0;31m                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m---> 73 \u001b[0;31m                                          \u001b[0mneg2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     75 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_calib_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(72)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     70 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 72 \u001b[0;31m                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     73 \u001b[0;31m                                          \u001b[0mneg2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(73)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     71 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     72 \u001b[0;31m                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m---> 73 \u001b[0;31m                                          \u001b[0mneg2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     75 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_calib_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(72)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     70 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 72 \u001b[0;31m                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     73 \u001b[0;31m                                          \u001b[0mneg2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(75)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     73 \u001b[0;31m                                          \u001b[0mneg2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 75 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_calib_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     76 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx,\n",
      "\u001b[0m\u001b[0;32m     77 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py\u001b[0m(81)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     79 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     80 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 81 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     82 \u001b[0;31m            \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused_rep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlbl2data_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlbl2data_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlbl2data_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     83 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c086ff8-cae9-430a-afbf-4271fa5afcea",
   "metadata": {},
   "source": [
    "## `OAK16`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7075471-76a3-4831-8ee2-f4353adaf890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK016(OAK003):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        neg2data_aug_meta_prefix:Optional[str]=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('neg2data_aug_meta_prefix')\n",
    "        self.rep_loss_fn = MarginMSEWithNegatives()\n",
    "        \n",
    "    def compute_loss(self, data_repr, lbl2data_repr, lbl2data_scores, neg2data_repr, neg2data_scores, **kwargs):\n",
    "        return self.rep_loss_fn(data_repr, lbl2data_repr, lbl2data_scores, neg2data_repr, neg2data_scores, **kwargs)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_scores:Optional[torch.Tensor]=None,\n",
    "\n",
    "        neg2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        neg2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        neg2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        neg2data_idx:Optional[torch.Tensor]=None,\n",
    "        neg2data_scores:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if (\n",
    "            lbl2data_input_ids is not None and \n",
    "            neg2data_input_ids is not None\n",
    "        ):\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "\n",
    "            neg2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('neg2data', self.neg2data_aug_meta_prefix, **kwargs)\n",
    "            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.neg2data_aug_meta_prefix, **neg2data_meta_kwargs)\n",
    "\n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
    "                                     neg2data_scores, **kwargs)\n",
    "            \n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
    "                                         neg2data_scores, **kwargs)\n",
    "                \n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, neg2data_o.rep, neg2data_data2ptr, neg2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "                \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4bed4-9547-4b7b-bf1d-2f5d7a7f7038",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d5c6c316-3693-4912-8605-f560fb015810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK016 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK016.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', margin=0.3, num_negatives=5, \n",
    "                               tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None,\n",
    "                               neg2data_aug_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False, normalize=True)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1682c427-eba9-445a-90b3-785da4d1e184",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(656086, 768))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a8ba9-2248-4974-8900-f99fc503613a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729c858-e3ec-47aa-834d-8ea1cac8e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1cfa660c-3610-4c3b-bc8d-c2deafc4763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75cc3a-0058-4591-9143-c39c339a88ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8f200fd0-0801-491d-983f-eaef0a325b8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c6ad9f1c-3eeb-4576-8508-9509c6e0946c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0051, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a7647-7fd2-466a-945d-06223206fc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c7ce52ed-4f4e-4bab-8769-cb90255b5329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    o = model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3ca203f5-c96d-49ca-87cd-5b5135b8227b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/3721260802.py\u001b[0m(2)\u001b[0;36mfunc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 2 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m    \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Type         Disp Enb   Where\n",
      "1   breakpoint   keep no    at /var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py:45\n",
      "\tbreakpoint already hit 3 times\n",
      "2   breakpoint   keep no    at /var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py:119\n",
      "\tbreakpoint already hit 8 times\n",
      "3   breakpoint   keep no    at /var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2221889608.py:29\n",
      "\tbreakpoint already hit 3 times\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  enable 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled breakpoint 1 at /var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1017695108.py:45\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  enable 2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled breakpoint 2 at /var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py:119\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  enable 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled breakpoint 3 at /var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2221889608.py:29\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(119)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    117 \u001b[0;31m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m2\u001b[0;32m-> 119 \u001b[0;31m        \u001b[0mdata_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    120 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    121 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"meta\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2221889608.py\u001b[0m(29)\u001b[0;36mfuse_meta_into_embeddings\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     27 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mfuse_meta_into_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_repr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_mask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m3\u001b[0;32m--> 29 \u001b[0;31m        \u001b[0mmeta_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     31 \u001b[0;31m        \u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_repr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[-0.0...ezeBackward0>), {'cat2data': tensor([[0., ...dexBackward0>)})\n",
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2221889608.py\u001b[0m(46)\u001b[0;36mfuse_meta_into_embeddings\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     43 \u001b[0;31m                \u001b[0mfused_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_repr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_repr_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     44 \u001b[0;31m                \u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfused_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     45 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 46 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     47 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(133)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    131 \u001b[0;31m                                                                            \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    132 \u001b[0;31m                                                                            \u001b[0mmeta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 133 \u001b[0;31m                \u001b[0mdata_fused_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_fused\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    135 \u001b[0;31m        return EncoderOutput(\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(135)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m                \u001b[0mdata_fused_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_fused\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        return EncoderOutput(\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m            \u001b[0mrep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m            \u001b[0mfused_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(136)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    134 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    135 \u001b[0;31m        return EncoderOutput(\n",
      "\u001b[0m\u001b[0;32m--> 136 \u001b[0;31m            \u001b[0mrep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m            \u001b[0mfused_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    138 \u001b[0;31m            \u001b[0mmeta_repr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(137)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    135 \u001b[0;31m        return EncoderOutput(\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m            \u001b[0mrep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 137 \u001b[0;31m            \u001b[0mfused_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    138 \u001b[0;31m            \u001b[0mmeta_repr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(138)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    136 \u001b[0;31m            \u001b[0mrep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m            \u001b[0mfused_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 138 \u001b[0;31m            \u001b[0mmeta_repr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    140 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(135)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m                \u001b[0mdata_fused_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_fused\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        return EncoderOutput(\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m            \u001b[0mrep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m            \u001b[0mfused_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...xBackward0>)})\n",
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(135)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m                \u001b[0mdata_fused_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_fused\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        return EncoderOutput(\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m            \u001b[0mrep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m            \u001b[0mfused_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...xBackward0>)})\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1750)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1748 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1749 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1750 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1751 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1752 \u001b[0;31m        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...xBackward0>)})\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1739)\u001b[0;36m_wrapped_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1737 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1738 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1739 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1740 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1741 \u001b[0;31m    \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(52)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     50 \u001b[0;31m                         \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdata_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     51 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 52 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlbl2data_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     53 \u001b[0;31m        if (\n",
      "\u001b[0m\u001b[0;32m     54 \u001b[0;31m            \u001b[0mlbl2data_input_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(54)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     52 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlbl2data_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     53 \u001b[0;31m        if (\n",
      "\u001b[0m\u001b[0;32m---> 54 \u001b[0;31m            \u001b[0mlbl2data_input_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     55 \u001b[0;31m            \u001b[0mneg2data_input_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     56 \u001b[0;31m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(55)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     53 \u001b[0;31m        if (\n",
      "\u001b[0m\u001b[0;32m     54 \u001b[0;31m            \u001b[0mlbl2data_input_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 55 \u001b[0;31m            \u001b[0mneg2data_input_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     56 \u001b[0;31m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     57 \u001b[0;31m            \u001b[0mlbl2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lbl2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(57)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     55 \u001b[0;31m            \u001b[0mneg2data_input_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     56 \u001b[0;31m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 57 \u001b[0;31m            \u001b[0mlbl2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lbl2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     58 \u001b[0;31m            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m     59 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlbl2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(58)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     56 \u001b[0;31m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     57 \u001b[0;31m            \u001b[0mlbl2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lbl2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 58 \u001b[0;31m            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m     59 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlbl2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     60 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(59)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     57 \u001b[0;31m            \u001b[0mlbl2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lbl2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     58 \u001b[0;31m            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m---> 59 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlbl2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     60 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     61 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(58)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     56 \u001b[0;31m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     57 \u001b[0;31m            \u001b[0mlbl2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lbl2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 58 \u001b[0;31m            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m     59 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlbl2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     60 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(59)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     57 \u001b[0;31m            \u001b[0mlbl2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lbl2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     58 \u001b[0;31m            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m---> 59 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlbl2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     60 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     61 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(58)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     56 \u001b[0;31m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     57 \u001b[0;31m            \u001b[0mlbl2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lbl2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 58 \u001b[0;31m            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m     59 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlbl2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     60 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(119)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    117 \u001b[0;31m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m2\u001b[0;32m-> 119 \u001b[0;31m        \u001b[0mdata_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    120 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    121 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"meta\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(135)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m                \u001b[0mdata_fused_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_fused\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        return EncoderOutput(\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m            \u001b[0mrep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m            \u001b[0mfused_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1750)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1748 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1749 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1750 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1751 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1752 \u001b[0;31m        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1739)\u001b[0;36m_wrapped_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1737 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1738 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1739 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1740 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1741 \u001b[0;31m    \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(61)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     59 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlbl2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     60 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 61 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     62 \u001b[0;31m            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m     63 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  neg2data_meta_kwargs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'neg2data_meta_kwargs' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(62)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     60 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     61 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 62 \u001b[0;31m            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m     63 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(63)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     61 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     62 \u001b[0;31m            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m---> 63 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     65 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(62)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     60 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     61 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 62 \u001b[0;31m            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m     63 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(63)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     61 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     62 \u001b[0;31m            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m---> 63 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     65 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(62)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     60 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     61 \u001b[0;31m            \u001b[0mneg2data_meta_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_feat_meta_aug_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg2data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 62 \u001b[0;31m            neg2data_o = encoder(data_input_ids=neg2data_input_ids, data_attention_mask=neg2data_attention_mask, \n",
      "\u001b[0m\u001b[0;32m     63 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(119)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    117 \u001b[0;31m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;31m2\u001b[0;32m-> 119 \u001b[0;31m        \u001b[0mdata_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    120 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    121 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"meta\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/1768784971.py\u001b[0m(135)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m                \u001b[0mdata_fused_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_fused\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        return EncoderOutput(\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m            \u001b[0mrep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m            \u001b[0mfused_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_fused_repr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1750)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1748 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1749 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1750 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1751 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1752 \u001b[0;31m        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1739)\u001b[0;36m_wrapped_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1737 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1738 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1739 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1740 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1741 \u001b[0;31m    \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(65)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     63 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 65 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m                                     \u001b[0mneg2data_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(66)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     65 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m---> 66 \u001b[0;31m                                     \u001b[0mneg2data_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(65)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     63 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 65 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m                                     \u001b[0mneg2data_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(66)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     65 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m---> 66 \u001b[0;31m                                     \u001b[0mneg2data_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(65)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     63 \u001b[0;31m                                 \u001b[0mdata_aug_meta_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg2data_aug_meta_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mneg2data_meta_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 65 \u001b[0;31m            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m                                     \u001b[0mneg2data_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(68)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     66 \u001b[0;31m                                     \u001b[0mneg2data_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 68 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     69 \u001b[0;31m                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m                                         \u001b[0mneg2data_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0026, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(69)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 69 \u001b[0;31m                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m                                         \u001b[0mneg2data_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(70)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     68 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     69 \u001b[0;31m                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m---> 70 \u001b[0;31m                                         \u001b[0mneg2data_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     72 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_calib_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(69)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 69 \u001b[0;31m                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m                                         \u001b[0mneg2data_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(70)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     68 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     69 \u001b[0;31m                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m---> 70 \u001b[0;31m                                         \u001b[0mneg2data_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     72 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_calib_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(69)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     67 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     68 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_query_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 69 \u001b[0;31m                loss += self.compute_loss(data_o.rep, lbl2data_o.rep, lbl2data_scores, neg2data_o.rep, \n",
      "\u001b[0m\u001b[0;32m     70 \u001b[0;31m                                         \u001b[0mneg2data_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(72)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     70 \u001b[0;31m                                         \u001b[0mneg2data_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 72 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_calib_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     73 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx,\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.use_calib_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.use_calib_loss = True\n",
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(73)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     71 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     72 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_calib_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 73 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx,\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     75 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, neg2data_o.rep, neg2data_data2ptr, neg2data_idx,\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(74)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     72 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_calib_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     73 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx,\n",
      "\u001b[0m\u001b[0;32m---> 74 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     75 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, neg2data_o.rep, neg2data_data2ptr, neg2data_idx,\n",
      "\u001b[0m\u001b[0;32m     76 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(73)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     71 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     72 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_calib_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 73 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx,\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     75 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, neg2data_o.rep, neg2data_data2ptr, neg2data_idx,\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suchith720/Projects/xcai/xcai/losses.py:23: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:55.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(75)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     73 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx,\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 75 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, neg2data_o.rep, neg2data_data2ptr, neg2data_idx,\n",
      "\u001b[0m\u001b[0;32m     76 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     77 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(76)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     74 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     75 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, neg2data_o.rep, neg2data_data2ptr, neg2data_idx,\n",
      "\u001b[0m\u001b[0;32m---> 76 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     77 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     78 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(75)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     73 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx,\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 75 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, neg2data_o.rep, neg2data_data2ptr, neg2data_idx,\n",
      "\u001b[0m\u001b[0;32m     76 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     77 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexError: index 34 is out of bounds for dimension 0 with size 34\n",
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(75)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     73 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx,\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 75 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, neg2data_o.rep, neg2data_data2ptr, neg2data_idx,\n",
      "\u001b[0m\u001b[0;32m     76 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     77 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/2665181823.py\u001b[0m(75)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     73 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep, lbl2data_data2ptr, lbl2data_idx,\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 75 \u001b[0;31m                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, neg2data_o.rep, neg2data_data2ptr, neg2data_idx,\n",
      "\u001b[0m\u001b[0;32m     76 \u001b[0;31m                                              \u001b[0mplbl2data_data2ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplbl2data_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     77 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexError: index 34 is out of bounds for dimension 0 with size 34\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1750)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1748 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1749 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1750 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1751 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1752 \u001b[0;31m        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1750)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1748 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1749 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1750 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1751 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1752 \u001b[0;31m        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexError: index 34 is out of bounds for dimension 0 with size 34\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1739)\u001b[0;36m_wrapped_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1737 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1738 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1739 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1740 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1741 \u001b[0;31m    \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/Users/suchith720/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py\u001b[0m(1739)\u001b[0;36m_wrapped_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1737 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1738 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1739 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1740 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1741 \u001b[0;31m    \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexError: index 34 is out of bounds for dimension 0 with size 34\n",
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/3721260802.py\u001b[0m(3)\u001b[0;36mfunc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 3 \u001b[0;31m    \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_22918/3721260802.py\u001b[0m(3)\u001b[0;36mfunc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 3 \u001b[0;31m    \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XCModelOutput(loss=tensor(0.0051, grad_fn=<AddBackward0>), logits=None, data_repr=tensor([[-0.0278, -0.0147, -0.0297,  ..., -0.0008,  0.0018, -0.0341],\n",
      "        [-0.0027, -0.0311, -0.0260,  ...,  0.0229, -0.0220, -0.0337],\n",
      "        [-0.0068, -0.0017, -0.0149,  ...,  0.0273,  0.0346,  0.0232],\n",
      "        [-0.0346, -0.0148, -0.0316,  ...,  0.0544,  0.0028, -0.0312]],\n",
      "       grad_fn=<DivBackward0>), data_fused_repr=tensor([[-0.0270, -0.0149, -0.0287,  ..., -0.0018,  0.0008, -0.0328],\n",
      "        [-0.0035, -0.0299, -0.0253,  ...,  0.0212, -0.0216, -0.0323],\n",
      "        [-0.0075, -0.0026, -0.0150,  ...,  0.0257,  0.0329,  0.0216],\n",
      "        [-0.0331, -0.0150, -0.0304,  ...,  0.0532,  0.0017, -0.0300]],\n",
      "       grad_fn=<DivBackward0>), lbl2data_repr=tensor([[-0.0252,  0.0914, -0.0155,  ..., -0.0417,  0.0890, -0.0145],\n",
      "        [ 0.0107, -0.0238, -0.0349,  ...,  0.0151, -0.0291, -0.0294],\n",
      "        [-0.0068, -0.0017, -0.0149,  ...,  0.0273,  0.0346,  0.0232],\n",
      "        [-0.0244, -0.0302, -0.0259,  ...,  0.0584,  0.0058, -0.0318]],\n",
      "       grad_fn=<DivBackward0>), lbl2data_fused_repr=None)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  o.loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0051, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 34 is out of bounds for dimension 0 with size 34",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[125], line 3\u001b[0m, in \u001b[0;36mfunc\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunc\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[0;32m----> 3\u001b[0m     o \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[112], line 75\u001b[0m, in \u001b[0;36mOAK016.forward\u001b[0;34m(self, data_input_ids, data_attention_mask, lbl2data_input_ids, lbl2data_attention_mask, lbl2data_data2ptr, lbl2data_idx, lbl2data_scores, neg2data_input_ids, neg2data_attention_mask, neg2data_data2ptr, neg2data_idx, neg2data_scores, plbl2data_data2ptr, plbl2data_idx, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_calib_loss:\n\u001b[1;32m     73\u001b[0m         loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalibration_loss(data_o\u001b[38;5;241m.\u001b[39mfused_rep, data_o\u001b[38;5;241m.\u001b[39mrep, lbl2data_o\u001b[38;5;241m.\u001b[39mrep, lbl2data_data2ptr, lbl2data_idx,\n\u001b[1;32m     74\u001b[0m                                       plbl2data_data2ptr,plbl2data_idx)\n\u001b[0;32m---> 75\u001b[0m         loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalibration_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfused_rep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg2data_o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg2data_data2ptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg2data_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mplbl2data_data2ptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mplbl2data_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m     79\u001b[0m     o \u001b[38;5;241m=\u001b[39m (data_o\u001b[38;5;241m.\u001b[39mlogits,data_o\u001b[38;5;241m.\u001b[39mrep,data_o\u001b[38;5;241m.\u001b[39mfused_rep,lbl2data_o\u001b[38;5;241m.\u001b[39mlogits,lbl2data_o\u001b[38;5;241m.\u001b[39mrep,lbl2data_o\u001b[38;5;241m.\u001b[39mfused_rep)\n",
      "Cell \u001b[0;32mIn[55], line 65\u001b[0m, in \u001b[0;36mOAK000.calibration_loss\u001b[0;34m(self, einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcalibration_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalib_loss_weight \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcab_loss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43meinp_repr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_repr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarg_repr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarg_ptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarg_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptarg_ptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptarg_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Projects/xcai/xcai/losses.py:141\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(cls, einp, inp, targ, n_inp2targ, inp2targ_idx, n_pinp2targ, pinp2targ_idx, margin, tau, n_negatives, apply_softmax, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m esc,sc \u001b[38;5;241m=\u001b[39m einp\u001b[38;5;129m@targ\u001b[39m\u001b[38;5;241m.\u001b[39mT,inp\u001b[38;5;129m@targ\u001b[39m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    140\u001b[0m _, idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munique(torch\u001b[38;5;241m.\u001b[39mcat([inp2targ_idx, pinp2targ_idx]), return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 141\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[43mget_sparse_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minp2targ_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_pinp2targ\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minp2targ_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    143\u001b[0m mul \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mpos \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    144\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu((sc\u001b[38;5;241m-\u001b[39mesc)\u001b[38;5;241m*\u001b[39mmul \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmargin)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 34 is out of bounds for dimension 0 with size 34"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "\u001b[0;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d19ac98-4b71-4351-a76e-91a182df09c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
