{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc296f6-a8d7-4a4c-b435-59340b5f9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816d57b5-40f1-4472-ad6f-ea014d90b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "027bee80-20cd-4003-925b-caa002001d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, numpy as np\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ed29e-8252-4ce5-9a4f-d89f26e4040c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcba962a-fd31-408d-bbb8-2cf8a94a7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.main import *\n",
    "from xcai.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c763df4d-0c1b-414d-9168-d8726571dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/suchith720/Projects/data/'\n",
    "\n",
    "config_key = \"data_meta\"\n",
    "config_dir = \"/Users/suchith720/Projects/mogicX/configs\"\n",
    "pkl_dir = f\"{data_dir}/processed/mogicX\"\n",
    "pkl_file = get_pkl_file(pkl_dir, 'wikiseealsotitles_data-oak-for-msmarco-with-hard-negatives-test_distilbert-base-uncased', \n",
    "                        True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd015316-7ba6-4b2e-8bfc-367e5c7a43e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = f\"{config_dir}/39_oak-for-msmarco-with-hard-negatives_test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa81e06c-d9fd-4e99-95e9-71d39fcb7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = build_block(pkl_file, config_file, True, config_key=config_key, only_test=False, main_oversample=True, \n",
    "                    meta_oversample={\"cat_meta\":False, \"lnk_meta\":True}, n_slbl_samples=5, \n",
    "                    n_sdata_meta_samples={\"cat_meta\":2, \"lnk_meta\":4}, do_build=False, \n",
    "                    train_meta_topk={\"lnk_meta\":10}, test_meta_topk={\"lnk_meta\":10}, return_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b252b-9583-48a7-811a-c6f25262e1d3",
   "metadata": {},
   "source": [
    "## `RLLossWeights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f04d2ae6-5cd7-4bbc-9691-bc567ddef801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_sparse_matrix(data_idx:torch.Tensor, n_data:torch.Tensor, scores:Optional[torch.Tensor]=None, \n",
    "                      size:Optional[Tuple]=None):\n",
    "    data_ptr = torch.cat([torch.zeros(1, device=n_data.device, dtype=n_data.dtype), n_data.cumsum(0)])\n",
    "    if scores is None: scores = torch.ones_like(data_idx)\n",
    "    if data_idx.shape != scores.shape: raise ValueError(f'`data_idx` and `scores` should have same shape.')\n",
    "    return (\n",
    "        torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n",
    "        if size is None else\n",
    "        torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device, size=size)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6abce-df20-4de6-8ab1-96cad6b12380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ea007bd-a98d-47b1-abab-8c22f8811ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RLLossWeights(torch.nn.Module):\n",
    "    def __init__(self, num_samples, std=0.1, lr=0.001, reward_func=None,\n",
    "                 collector=10, min=0.1, rest_init=0.1) -> None:\n",
    "        super().__init__()\n",
    "        init = np.ones(num_samples)\n",
    "        init[:] = rest_init\n",
    "        self.reward_func = reward_func\n",
    "        self.collector = collector\n",
    "        self.lr = lr\n",
    "        self.num_samples = num_samples\n",
    "        self.mu = torch.nn.Parameter(torch.Tensor(init))\n",
    "        self.std = torch.nn.Parameter(torch.Tensor(np.ones(num_samples)*std),\n",
    "                                      requires_grad=False)\n",
    "        self.dist = torch.distributions.normal.Normal(self.mu, self.std)\n",
    "        self.min = min\n",
    "        self.w = None\n",
    "        self.reset_metrics()\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        self.collect_size = 0\n",
    "        self.collect_value = 0\n",
    "        self.step_counter = 0\n",
    "\n",
    "    def sample(self, device=\"cpu\"):\n",
    "        if self.w is None:\n",
    "            self.w = self.clip(self.dist.sample())\n",
    "        return self.w.to(device)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.mu.grad = None\n",
    "        self.collect_size = 0\n",
    "        self.collect_value = 0\n",
    "        self.w = None\n",
    "\n",
    "    def collect(self, pred, gt):\n",
    "        size = pred.size(0)\n",
    "        rewd = self.reward_func(pred, gt)  # TODO\n",
    "        self.collect_value += rewd\n",
    "        self.collect_size += size\n",
    "        pass\n",
    "\n",
    "    def step(\n",
    "        self,\n",
    "        inp:torch.FloatTensor,\n",
    "        targ:torch.LongTensor, \n",
    "        n_inp2targ:torch.LongTensor,\n",
    "        inp2targ_idx:torch.LongTensor,\n",
    "        n_pinp2targ:torch.LongTensor,\n",
    "        pinp2targ_idx:torch.LongTensor\n",
    "    ):\n",
    "        pred = inp@targ.T\n",
    "        \n",
    "        _, idx = torch.unique(torch.cat([inp2targ_idx, pinp2targ_idx]), return_inverse=True)\n",
    "        gt = get_sparse_matrix(idx[len(inp2targ_idx):], n_pinp2targ, size=(len(n_pinp2targ), idx.max()+1)).to_dense()[:, idx[:len(inp2targ_idx)]]\n",
    "        \n",
    "        self.step_counter += 1\n",
    "        self.collect(pred, gt)\n",
    "        if self.step_counter % self.collector == 0:\n",
    "            loss = -self.dist.log_prob(self.w)*self.curr_reward\n",
    "            loss = torch.sum(loss).backward()\n",
    "            self.mu.data = self.mu - self.lr * self.mu.grad.data\n",
    "            self.dist.loc = self.clip(self.mu)\n",
    "            self.step_counter = 0\n",
    "            self.zero_grad()\n",
    "\n",
    "    def clip(self, vect):\n",
    "        return torch.clamp(vect, min=self.min)\n",
    "\n",
    "    @property\n",
    "    def curr_reward(self):\n",
    "        return self.collect_value/self.collect_size\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"{self.mu}\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "204a7c34-51e6-446a-baf5-9567ac1e2cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RLLossWeightsCumuluative(RLLossWeights):\n",
    "    def __init__(self, num_samples=1, std=0.01, lr=0.01, m=0.8,\n",
    "                 reward_func=None, collector=10, min=0.1, rest_init=0.1) -> None:\n",
    "        self.m = m\n",
    "        super().__init__(num_samples, std, lr, reward_func, collector, min, rest_init)\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        super().reset_metrics()\n",
    "        self.reward_prev = None\n",
    "        self.in_warmup = True\n",
    "\n",
    "    def step(\n",
    "        self,\n",
    "        inp:torch.FloatTensor,\n",
    "        targ:torch.LongTensor, \n",
    "        n_inp2targ:torch.LongTensor,\n",
    "        inp2targ_idx:torch.LongTensor,\n",
    "        n_pinp2targ:torch.LongTensor,\n",
    "        pinp2targ_idx:torch.LongTensor\n",
    "    ):\n",
    "        pred = inp@targ.T\n",
    "        \n",
    "        _, idx = torch.unique(torch.cat([inp2targ_idx, pinp2targ_idx]), return_inverse=True)\n",
    "        gt = get_sparse_matrix(idx[len(inp2targ_idx):], n_pinp2targ, size=(len(n_pinp2targ), idx.max()+1)).to_dense()[:, idx[:len(inp2targ_idx)]]\n",
    "    \n",
    "        self.step_counter += 1\n",
    "        self.collect(pred, gt)\n",
    "        \n",
    "        if self.step_counter % self.collector == 0:\n",
    "            if self.in_warmup:\n",
    "                self.in_warmup = False\n",
    "                self.reward_prev = self.curr_reward\n",
    "            else:\n",
    "                reward = self.curr_reward - self.reward_prev\n",
    "                loss = -self.dist.log_prob(self.w).sum()\n",
    "                loss.backward()\n",
    "                grad = self.mu.grad.data*reward\n",
    "                grad = torch.clip(torch.nan_to_num(grad), min=-1, max=1)\n",
    "                self.mu.data = self.mu - self.lr * grad\n",
    "            self.dist.loc = self.clip(self.mu)\n",
    "            self.step_counter = 0\n",
    "            self.reward_prev = (1-self.m)*self.curr_reward + \\\n",
    "                self.m*self.reward_prev\n",
    "            self.zero_grad()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030a5ebc-98d8-41f2-8c8a-5e5aa5b495ac",
   "metadata": {},
   "source": [
    "## Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0583b697-a27c-4ed2-a5a9-ca1cfb35d510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def AccMiniBatch(pred, gt):\n",
    "    gt = gt.to(pred.device)\n",
    "    indices = pred.topk(largest=True, dim=1, k=1)[1]\n",
    "    return torch.sum(gt.gather(1, indices)).item()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7ea05-9915-4cb6-8bed-2b139e7400ac",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba2edcb5-a5a7-42be-8ba6-c630bc694d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_w = RLLossWeightsCumuluative(num_samples=4, reward_func=AccMiniBatch, lr=0.01, collector=2, std=0.1, \n",
    "                                  min=0.1, rest_init=[1.0, 0.1, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b59d79bd-3cfa-404e-8880-ee627af783a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0408, 0.1624, 0.1000, 0.1000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = loss_w.sample(); ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ae1b0-e37f-450f-ad02-916f683086fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "277bdb6b-a31a-4713-9aec-68e3f84334c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT009 were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.dr_layer_norm.bias', 'encoder.dr_layer_norm.weight', 'encoder.dr_projector.bias', 'encoder.dr_projector.weight', 'encoder.dr_transform.bias', 'encoder.dr_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from xcai.models.PPP0XX import DBT009\n",
    "model = DBT009.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "batch = block.train.one_batch(10)\n",
    "o = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac803e-ed06-4f9e-8887-f128ed6dde40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed013548-f7f9-45d2-a686-5cfdf7e23507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/r_2wlyls39s3_q5g99w33dn80000gn/T/ipykernel_82347/212864468.py:10: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:55.)\n",
      "  torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device, size=size)\n"
     ]
    }
   ],
   "source": [
    "loss_w.step(o.data_repr, o.lbl2data_repr, batch['lbl2data_data2ptr'], batch['lbl2data_idx'], \n",
    "            batch['plbl2data_data2ptr'], batch['plbl2data_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bee876b-a7a5-4823-9547-277086fc766d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0408, 0.1624, 0.1000, 0.1000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_w.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f3e6a-6409-49c4-a139-6048b3bb69bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770e52d-4057-4a43-92b7-0b7af7739c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
