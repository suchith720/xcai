{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b84d227-6f70-4060-82c0-40648d681f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.sandwich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a33728-6828-4b79-a40e-4054c830d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8dcb50-00fe-4d0b-b2f2-fbb6b09049dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "290df3ff-0ce1-4791-ae32-c758f12d67e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, torch.nn as nn, torch.nn.functional as F, re\n",
    "from typing import Optional, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from transformers.utils.generic import ModelOutput\n",
    "from transformers import PretrainedConfig, DistilBertConfig, DistilBertPreTrainedModel, DistilBertModel\n",
    "from transformers.models.distilbert.modeling_distilbert import create_sinusoidal_embeddings, TransformerBlock\n",
    "\n",
    "from xcai.losses import *\n",
    "from xcai.learner import XCDataParallel\n",
    "from xcai.models.modeling_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef19d17-f0c4-40a9-9f5a-3b7d8eda0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from xcai.models.product_key import *\n",
    "from xcai.core import store_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76abb7-8560-490d-8cb5-a8ee46299b44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb535de-64ed-4430-8fcb-35eaead49eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08dd4c65-aaa1-44eb-9fb9-039d6807de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/scratch/scai/phd/aiz218323/outputs/mogicX/03_ngame-for-wikiseealsotitles'\n",
    "\n",
    "data_dir = '/home/scai/phd/aiz218323/scratch/datasets/benchmarks/'\n",
    "config_file = 'wikiseealsotitles'\n",
    "config_key = 'data_meta'\n",
    "\n",
    "mname = 'sentence-transformers/msmarco-distilbert-base-v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b9fe27-0065-4a54-a70a-f867a45c6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/scratch/scai/phd/aiz218323/datasets/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9867f45-61e8-466c-b015-afb4c68d1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = f'{pkl_dir}/mogicX/wikiseealsotitles_data-meta_distilbert-base-uncased_sxc.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55640a26-6348-4644-917d-f7779092b963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scai/phd/aiz218323/.local/lib/python3.10/site-packages/xclib-0.97-py3.10-linux-x86_64.egg/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n"
     ]
    }
   ],
   "source": [
    "block = build_block(pkl_file, config_file, True, config_key, data_dir=data_dir, n_sdata_meta_samples=3, do_build=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dc7d671-0dfb-4673-aff8-faa5b1f54ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2348fea-4b6f-4ea5-bc31-7f884cbf0ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_idx', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_data2ptr', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_data2ptr', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'pcat2lbl_idx', 'pcat2lbl_lbl2ptr', 'cat2lbl_idx', 'cat2lbl_lbl2ptr', 'cat2lbl_identifier', 'cat2lbl_input_text', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'cat2lbl_data2ptr', 'pcat2lbl_data2ptr'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7de80-5789-4ec6-a6d3-955f7780e960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ac7b776-b6a3-42c0-9efe-52121236b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel\n",
    "m = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d7f4996-a9fa-40be-9f1c-6feefc9d188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = m(input_ids=batch['data_input_ids'], attention_mask=batch['data_attention_mask'])\n",
    "o = Pooling.mean_pooling(o.last_hidden_state, batch['data_attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c2642-94d2-43bb-b9e1-42b07c851983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "152e63fd-6b47-4ff0-835d-f6e6b5b91f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1333, -0.0122, -0.4621,  ..., -0.2476,  0.0845,  0.1799],\n",
       "        [ 0.3242,  0.1735, -0.3537,  ...,  0.0098, -0.1589, -0.0305],\n",
       "        [ 0.1397,  0.1279, -0.5648,  ...,  0.0695,  0.0088,  0.1104],\n",
       "        ...,\n",
       "        [ 0.2267, -0.1360, -0.0137,  ...,  0.0121, -0.0757,  0.2140],\n",
       "        [ 0.3148,  0.0690, -0.1643,  ..., -0.0073, -0.0534, -0.1919],\n",
       "        [ 0.2646,  0.3013, -0.5160,  ..., -0.0020,  0.2130,  0.0120]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70605e74-1b00-4560-9a5e-fbb17b6f9bbb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33c722db-2fd8-4507-9720-be77e90bb0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Parameters:\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_data_aug_meta_prefix_for_encoder(prefix:str, **kwargs):\n",
    "        inputs = {}\n",
    "        args = [arg for arg in kwargs if prefix is not None and re.match(f'^{prefix}.*_(input_ids|attention_mask|data2ptr|idx)$', arg)]\n",
    "        for arg in args:\n",
    "            meta,param = arg.split('_', maxsplit=1)\n",
    "            inputs.setdefault(meta, {})[param] = kwargs[arg]\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_aug_meta_prefix_for_feature(feat:str, prefix:str, **kwargs):\n",
    "        keys = ['attention_mask', 'input_ids', 'idx']        \n",
    "        inputs = {f'{prefix}_{k}': kwargs[f'{prefix}_{k}'] for k in keys if f'{prefix}_{k}' in kwargs}\n",
    "        if prefix is not None and f'{prefix}_{feat}2ptr' in kwargs:\n",
    "            inputs.update({f'{prefix}_data2ptr': kwargs[f'{prefix}_{feat}2ptr']})\n",
    "        return inputs\n",
    "\n",
    "    @staticmethod\n",
    "    def from_aug_meta_prefix_for_loss(feat:str, prefix:str, **kwargs):\n",
    "        keys = [f'{prefix}_idx', f'p{prefix}_idx']\n",
    "        args = {k: kwargs[k] for k in keys if k in kwargs}\n",
    "        if prefix is not None and f'{prefix}_{feat}2ptr' in kwargs:\n",
    "            args.update({f'{prefix}_data2ptr': kwargs[f'{prefix}_{feat}2ptr']})\n",
    "        if prefix is not None and f'p{prefix}_{feat}2ptr' in kwargs:\n",
    "            args.update({f'p{prefix}_data2ptr': kwargs[f'p{prefix}_{feat}2ptr']})\n",
    "\n",
    "        inputs = {}\n",
    "        for arg in args:\n",
    "            meta,param = arg.split('_', maxsplit=1)\n",
    "            inputs.setdefault(meta, {})[param] = args[arg]\n",
    "        return inputs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df1a09-1d1e-4d57-af3e-37857d4792ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e746223-339d-44a7-8de0-7161636be755",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters.from_aug_meta_prefix_for_loss('lbl', 'cat2lbl', **batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "035419f7-01bf-4b51-88a6-d6adfcf38cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat2lbl': {'idx': tensor([ 67082,  79350, 101577,  71494, 169643,  68324, 135330, 125763,  82231,\n",
       "           86188, 155467,  28048, 148694,  93180,  85482, 138151, 102793,  84865,\n",
       "          439022, 439023,  91528,  74225, 141645, 289094, 170004, 488572,  56283,\n",
       "          129962,  99971, 174524, 490420,  72240, 127050, 126452, 170813, 474981,\n",
       "           46855, 217367, 179791, 402654, 105939, 130669,  81409,  74830,  70044,\n",
       "          121141,  62139, 121002,  54379,  68123,  74898, 166643, 166550,  75601,\n",
       "           68691,  61761,    656, 128580, 190220, 500130,  62668,  71775, 538327,\n",
       "          131647, 102522,  62594, 114572, 321592,  83631,  53106, 292602, 478961,\n",
       "           84872, 561039,  77674, 157101, 463424, 157434, 499332, 350836, 426850,\n",
       "           72514, 490081,  68235,  57133,   9952,  70022,  77811,  64823,  79370,\n",
       "          167418,  65653, 117839,  74213,  57745, 271915]),\n",
       "  'data2ptr': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " 'pcat2lbl': {'idx': tensor([ 27146,  67082,  72817,  87814,  88559,  88560, 101646, 130668, 299633,\n",
       "             656,  49684,  56026,  72991,  75604,  79350, 129019, 165107, 165108,\n",
       "           70154,  75304,  76961,  81434, 100127, 101577, 104146, 112817, 131262,\n",
       "          131264, 131265, 131284, 131288, 138567, 140781, 144686, 155398, 155399,\n",
       "          155400, 155401, 155402, 155403, 155404, 155405, 155406, 155407, 155408,\n",
       "          155409, 155410, 155411, 155412, 155413, 155414, 155415, 155416, 155417,\n",
       "          155418, 155419,   3056,  10463,  46859,  56287,  71468,  71494,  71495,\n",
       "           71496,  71497,  71498, 116138, 139060, 169643,  68324,  68326, 127769,\n",
       "           71497, 135330, 258077, 258101,  82475, 125763, 143625, 214384,    656,\n",
       "           28165,  82231, 138912,  53220,  86188, 174716, 174717, 155467,  28048,\n",
       "          148694,  27466,  72234,  93180,  85482, 161859, 161883, 272165, 138151,\n",
       "           79395, 102791, 102792, 102793, 102794,  84732,  84865,  84866,  84867,\n",
       "           84868,  84869,  84870,  84871,  84872,  84873,  84874,  84875,  84876,\n",
       "           84877,  84878,  84879,  84880,  84881, 439022, 439023, 161670, 435260,\n",
       "          439023,    656,  91528,  91529,  91530,  74225, 259765,  83239, 117808,\n",
       "          141642, 141643, 141644, 141645, 141646, 282628, 289094, 289095, 110921,\n",
       "          113592, 170004, 218588, 488572, 508118,  56283, 502239, 502773, 129961,\n",
       "          129962,  73238,  80103,  99971, 151909, 184098, 188309, 354599, 423863,\n",
       "          555039, 121618, 174523, 174524, 174525,  80129, 294502, 490420, 493245,\n",
       "           47085,  72240, 342971, 371773, 444784,  58873,  67166, 127050, 127053,\n",
       "          128784, 128785, 128786, 128787, 128788, 128789, 126452,  50423,  54304,\n",
       "           55903,  55905,  63794,  64711, 105823, 160065, 170812, 170813, 170814,\n",
       "          170815, 170816, 170817, 170818, 170819, 170820, 111060, 474981,  46854,\n",
       "           46855,  46862,  47512,  62555, 120363, 148837, 247978, 254289, 261731,\n",
       "          303902, 337301, 404822,  28168,  73842,  82234, 187578, 217367, 252997,\n",
       "          255284,  84773,  88956, 124867, 161606, 179316, 179319, 179409, 179778,\n",
       "          179786, 179791, 180406, 233429, 131594, 402654,   2809,  76655,  76656,\n",
       "           76657, 105939,  72673,  92821, 130669, 144003, 182160,  64527,  81409,\n",
       "          148105, 148106,   5926,  70044,  74825,  74826,  74827,  74828,  74829,\n",
       "           74830,  74831,  70044,  74829,  75622, 302326, 121141, 292267, 294546,\n",
       "          500149,  62139,  84336, 359886,  49591, 121001, 121002, 121003, 121004,\n",
       "          121005,  53615,  53634,  53636,  54379,  54414,  64740,  65856,  65991,\n",
       "           68964,  69078, 103693, 192360, 234490, 321498,  68123, 302731,  74897,\n",
       "           74898, 151217, 402654, 166643, 166644, 166645, 166550, 234696, 366245,\n",
       "          393514,  75601, 445093,  68691, 141863,  61513,  61761,    656, 177096,\n",
       "           77778, 128580, 190220, 229420, 375487, 292266, 500130,  62662,  62663,\n",
       "           62664,  62665,  62666,  62667,  62668,  71775, 538327, 131647,   4044,\n",
       "           53311,  64916,  71037,  77171,  80659,  80749,  80781,  81085, 101656,\n",
       "          101796, 101810, 101981, 102481, 102482, 102483, 102484, 102485, 102486,\n",
       "          102487, 102488, 102489, 102490, 102491, 102492, 102493, 102494, 102495,\n",
       "          102496, 102497, 102498, 102499, 102500, 102501, 102502, 102503, 102504,\n",
       "          102505, 102506, 102507, 102508, 102509, 102510, 102511, 102512, 102513,\n",
       "          102514, 102515, 102516, 102517, 102518, 102519, 102520, 102521, 102522,\n",
       "           62589,  62590,  62591,  62592,  62593,  62594,  62595,  62596,  24232,\n",
       "          114572,  68421, 148111, 248682, 321592, 420305,  46819,  63840,  83630,\n",
       "           83631, 309388,  53106,  69656,  77965,  72105,  74121, 125624, 201174,\n",
       "          292602, 495420, 478961,  60299,  84872, 117344, 132100, 138294, 138295,\n",
       "          144409, 144410, 144440, 144441, 144442, 144443, 144444, 144445, 144446,\n",
       "          144447, 144448, 144449,   7279,  11185,  11198,  11245,  11246,  25597,\n",
       "           78219,  78245,  78267, 143864, 190019, 257443, 532191, 561039, 561040,\n",
       "          561041, 561042, 584534, 584535,  70352,  77674,  87278, 145057, 167941,\n",
       "          170351, 184595, 184596, 184597, 184598, 184599,  68105,  68109,  68112,\n",
       "           68113,  79676,  84868,  84870,  84872,  84881, 100619, 100622, 100624,\n",
       "          157094, 157101, 157102, 161670, 178013, 178014, 178015, 463424, 157434,\n",
       "          157465, 339332, 124009, 188911, 498225, 499332, 499335, 157391, 350836,\n",
       "          426850,  72514, 130282, 130283, 395354, 490081,  68235, 426908,  57133,\n",
       "          153496,   9952,  82548, 165597,  70022, 111647, 167418,  69981,  77811,\n",
       "           82308, 141857, 141860,  62153,  64823,  71976,  79140,  79370,  91242,\n",
       "          131344, 131649, 147655, 147659, 147660, 147661, 147662, 147663, 147664,\n",
       "          147665, 167418,  65653, 117839, 318410,  74213, 137363,  50820,  53297,\n",
       "           57745,  70004,  48781, 169513, 271915]),\n",
       "  'data2ptr': tensor([ 9,  9, 38, 10,  3,  3,  4,  4,  0,  4,  4,  1,  1,  1,  3,  4,  1,  0,\n",
       "           5, 18,  2,  3,  4,  2,  7,  3,  3,  3,  3,  2,  9,  4,  4,  5, 10,  1,\n",
       "          17,  2, 13,  7, 12,  2,  0,  5,  5,  4,  9,  4,  4,  3,  6, 14,  2,  4,\n",
       "           3,  4,  2,  2,  2,  2,  2,  3,  2,  7,  1,  1,  1, 55,  8,  2,  5,  5,\n",
       "           3,  6,  1, 18, 19, 11, 19,  1,  3,  5,  2,  1,  3,  2,  2,  0,  2,  3,\n",
       "           3,  5,  2, 14,  1,  1,  2,  2,  4,  3])}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c0c820-ff1d-418d-9c7c-cd2ee4494020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "082f7adf-d3fb-41e8-afee-21095c7a3449",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31f0cdf3-583a-4cd9-9b45-5a970b5a2082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SandwichConfig(DistilBertConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_aug_meta_prefix:Optional[str] = None, \n",
    "        lbl2data_aug_meta_prefix:Optional[str] = None,\n",
    "\n",
    "        data_enrich:Optional[bool] = True,\n",
    "        lbl2data_enrich:Optional[bool] = True,\n",
    "        \n",
    "        num_batch_labels:Optional[int] = None,\n",
    "        batch_size:Optional[int] = None,\n",
    "        margin:Optional[float] = 0.3,\n",
    "        num_negatives:Optional[int] = 10,\n",
    "        tau:Optional[float] = 0.1,\n",
    "        apply_softmax:Optional[bool] = True,\n",
    "\n",
    "        use_calib_loss:Optional[float] = False,\n",
    "        calib_margin:Optional[float] = 0.05,\n",
    "        calib_num_negatives:Optional[int] = 10,\n",
    "        calib_tau:Optional[float] = 0.1,\n",
    "        calib_apply_softmax:Optional[bool] = False,\n",
    "        calib_loss_weight:Optional[float] = 0.1,\n",
    "        \n",
    "        use_query_loss:Optional[float] = True,\n",
    "        \n",
    "        use_meta_loss:Optional[bool] = False,\n",
    "        meta_loss_weight:Optional[float] = 0.1,\n",
    "        \n",
    "        use_encoder_parallel:Optional[bool] = True,\n",
    "        \n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.data_aug_meta_prefix = data_aug_meta_prefix\n",
    "        self.lbl2data_aug_meta_prefix = lbl2data_aug_meta_prefix\n",
    "\n",
    "        self.data_enrich = data_enrich\n",
    "        self.lbl2data_enrich = lbl2data_enrich\n",
    "\n",
    "        self.num_batch_labels = num_batch_labels\n",
    "        self.batch_size = batch_size\n",
    "        self.margin = margin\n",
    "        self.num_negatives = num_negatives\n",
    "        self.tau = tau\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        self.use_calib_loss = use_calib_loss\n",
    "        self.calib_loss_weight = calib_loss_weight\n",
    "        self.calib_margin = calib_margin\n",
    "        self.calib_num_negatives = calib_num_negatives\n",
    "        self.calib_tau = calib_tau\n",
    "        self.calib_apply_softmax = calib_apply_softmax\n",
    "        \n",
    "        self.use_query_loss = use_query_loss\n",
    "        \n",
    "        self.use_meta_loss = use_meta_loss\n",
    "        self.meta_loss_weight = meta_loss_weight\n",
    "\n",
    "        self.use_encoder_parallel = use_encoder_parallel\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9fe12c-5195-44b9-bcf6-504ad6da9a69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6373daca-347a-485c-b81e-5d74991875c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SandwichConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fafb3fe3-edd9-43ff-81bc-e92a1c6f164f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.meta_loss_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487dc644-2bfa-40dd-af8b-3fcafc949a14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Combiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d59f06d-f3aa-4cae-aff9-09fe682c3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrossCombinerBlock(TransformerBlock):\n",
    "\n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def post_init(self):\n",
    "        for module in self.modules(): self._init_weights(module)\n",
    "\n",
    "    def _initialize_weights(self, module: nn.Module):\n",
    "        for m in module.modules(): self._init_weights(m)\n",
    "\n",
    "    def _init_weights(self, module: nn.Module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.eye_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        m: torch.Tensor,\n",
    "        attn_mask: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        output_attentions: bool = False,\n",
    "    ) -> Tuple[torch.Tensor, ...]:\n",
    "        \n",
    "        # Cross-Attention\n",
    "        ca_output = self.attention(\n",
    "            query=x,\n",
    "            key=m,\n",
    "            value=m,\n",
    "            mask=attn_mask,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        if output_attentions:\n",
    "            ca_output, ca_weights = ca_output  # (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\n",
    "        else:  # To handle these `output_attentions` or `output_hidden_states` cases returning tuples\n",
    "            if type(ca_output) is not tuple:\n",
    "                raise TypeError(f\"ca_output must be a tuple but it is {type(ca_output)} type\")\n",
    "\n",
    "            ca_output = ca_output[0]\n",
    "        ca_output = self.sa_layer_norm(ca_output + x)  # (bs, seq_length, dim)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        ffn_output = self.ffn(ca_output)  # (bs, seq_length, dim)\n",
    "        ffn_output: torch.Tensor = self.output_layer_norm(ffn_output + ca_output)  # (bs, seq_length, dim)\n",
    "\n",
    "        output = (ffn_output,)\n",
    "        if output_attentions:\n",
    "            output = (ca_weights,) + output\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035eb983-a8f5-41ac-a053-90125ffa385d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## BaseEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4032f55d-88b8-40ff-bc6c-92868cd6e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class EncoderOutput(ModelOutput):\n",
    "    data_repr: Optional[torch.FloatTensor] = None\n",
    "    data_meta_repr: Optional[torch.FloatTensor] = None\n",
    "    enriched_data_repr: Optional[torch.FloatTensor] = None\n",
    "    meta_repr: Optional[torch.FloatTensor] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2393a39e-84a0-4328-93a2-67e845a995f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseEncoder(DistilBertPreTrainedModel):\n",
    "    \n",
    "    config_class= None\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig, \n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.meta_distilbert = DistilBertModel(config)\n",
    "        \n",
    "        self.query_head = RepresentationHead(config)\n",
    "        self.meta_query_head = RepresentationHead(config)\n",
    "        self.enriched_query_head = RepresentationHead(config)\n",
    "        \n",
    "        self.post_init()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_heads_to_identity(self):\n",
    "        self.query_head.post_init()\n",
    "        self.meta_query_head.post_init()\n",
    "        self.enriched_query_head.post_init()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_meta_distilbert(self):\n",
    "        sd, msd = self.distilbert.state_dict(), self.meta_distilbert.state_dict()\n",
    "        sd_keys, msd_keys = sd.keys(), msd.keys()\n",
    "        assert len(sd_keys) == len(msd_keys), f'mismatched keys: {len(sd_keys)} != {len(msd_keys)}'\n",
    "        for k in sd_keys:\n",
    "            assert sd[k].shape == msd[k].shape\n",
    "            msd[k].copy_(sd[k])\n",
    "\n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        return self.distilbert.get_position_embeddings()\n",
    "    \n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "        self.distilbert.resize_position_embeddings(new_num_position_embeddings)\n",
    "    \n",
    "    def encode(self, input_ids:torch.Tensor, attention_mask:torch.Tensor, **kwargs):\n",
    "        return self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def encode_meta(self, input_ids:torch.Tensor, attention_mask:torch.Tensor, **kwargs):\n",
    "        return self.meta_distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def encode_query(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.query_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "\n",
    "    def encode_meta_query(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.meta_query_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "\n",
    "    def encode_enriched_query(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.enriched_query_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "\n",
    "    def enrich_query_representation(self):\n",
    "        raise NotImplementedError(\"Override this method in a subclass.\")\n",
    "\n",
    "    def forward(self, data_input_ids: torch.Tensor, data_attention_mask: torch.Tensor, data_aug_meta_prefix: Optional[str]=None,\n",
    "                data_enrich: Optional[bool]=True, **kwargs):  \n",
    "        raise NotImplementedError(\"Override this method in a subclass.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b975a-9974-4e76-a832-0ac4633094e5",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "83ca2dcc-8f85-4127-b912-5d8d815bc19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder(BaseEncoder):\n",
    "    \n",
    "    config_class = SandwichConfig\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig, \n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.combiner_head = CrossCombinerBlock(config)\n",
    "        self.post_init()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_heads_to_identity(self):\n",
    "        self.combiner_head.post_init()\n",
    "        super().init_heads_to_identity()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_combiner_to_last_layer(self):\n",
    "        lsd, csd = self.distilbert.transformer.layer[-1].state_dict(), self.combiner_head.state_dict()\n",
    "        lsd_keys, csd_keys = lsd.keys(), csd.keys()\n",
    "        assert len(lsd_keys) == len(csd_keys), f'mismatched keys: {len(lsd_keys)} != {len(csd_keys)}'\n",
    "        for k in csd_keys:\n",
    "            assert csd[k].shape == lsd[k].shape\n",
    "            csd[k].copy_(lsd[k])\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_meta_distilbert(self):\n",
    "        super().init_meta_distilbert()\n",
    "\n",
    "    def enrich_query_representation(self, data_o:torch.Tensor, data_meta_o:torch.Tensor, data_attention_mask:torch.Tensor):\n",
    "        attn_mask = data_attention_mask.view(len(data_attention_mask), 1, 1, -1).bool()\n",
    "        fusion_o = self.combiner_head(x=data_o, m=data_meta_o, attn_mask=attn_mask)\n",
    "        enriched_data_repr = self.encode_enriched_query(fusion_o[0], data_attention_mask)\n",
    "        return enriched_data_repr\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_enrich: Optional[bool]=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        data_repr = self.encode_query(data_o[0], data_attention_mask)\n",
    "\n",
    "        data_meta_o = self.encode_meta(data_input_ids, data_attention_mask)\n",
    "        data_meta_repr = self.encode_meta_query(data_meta_o[0], data_attention_mask)\n",
    "        \n",
    "        meta_kwargs = Parameters.from_data_aug_meta_prefix_for_encoder(data_aug_meta_prefix, **kwargs)\n",
    "        meta_kwargs = meta_kwargs.get(data_aug_meta_prefix, None)\n",
    "\n",
    "        meta_repr = None\n",
    "        if meta_kwargs is not None and len(meta_kwargs['idx']):\n",
    "            meta_o = self.encode_meta(meta_kwargs['input_ids'], meta_kwargs['attention_mask'])\n",
    "            meta_repr = self.encode_meta_query(meta_o[0], meta_kwargs['attention_mask'])\n",
    "\n",
    "        enriched_data_repr = self.enrich_query_representation(data_o[0], data_meta_o[0], data_attention_mask) if data_enrich else None\n",
    "        \n",
    "        return EncoderOutput(\n",
    "            data_repr=data_repr,\n",
    "            data_meta_repr=data_meta_repr,\n",
    "            enriched_data_repr=enriched_data_repr,\n",
    "            meta_repr=enriched_data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af55be2-bd32-4db0-9dfd-c65f10dbf69c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "96ebd52b-436c-46e6-8ad3-3924738e1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SandwichConfig()\n",
    "m = Encoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "55a1c176-1373-4b32-8edc-e79e1ee817e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_idx', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_data2ptr', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_data2ptr', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'pcat2lbl_idx', 'pcat2lbl_lbl2ptr', 'cat2lbl_idx', 'cat2lbl_lbl2ptr', 'cat2lbl_identifier', 'cat2lbl_input_text', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'cat2lbl_data2ptr', 'pcat2lbl_data2ptr'])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "54afd1a2-4a9d-4f48-838a-b428cd7226d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_aug_meta_prefix='cat2data'\n",
    "output = m(**batch, data_aug_meta_prefix=data_aug_meta_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "be06da59-da28-43ea-bb10-c7b6309eb43e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderOutput(data_repr=tensor([[-0.0225,  0.0191, -0.0021,  ..., -0.0053, -0.0118,  0.0194],\n",
       "        [-0.0146, -0.0108, -0.0409,  ..., -0.0205, -0.0109,  0.0028],\n",
       "        [-0.0462, -0.0089, -0.0374,  ..., -0.0225, -0.0240, -0.0300],\n",
       "        ...,\n",
       "        [-0.0383, -0.0020, -0.0393,  ...,  0.0179, -0.0266,  0.0131],\n",
       "        [-0.0453, -0.0005,  0.0191,  ..., -0.0426,  0.0021,  0.0176],\n",
       "        [-0.0665,  0.0332, -0.0013,  ..., -0.0054, -0.0349,  0.0024]],\n",
       "       grad_fn=<DivBackward0>), data_meta_repr=tensor([[-0.0594,  0.0056, -0.0344,  ..., -0.0204,  0.0081,  0.0007],\n",
       "        [-0.0206, -0.0171, -0.0520,  ..., -0.0341,  0.0685,  0.0280],\n",
       "        [ 0.0005, -0.0642, -0.0187,  ..., -0.0258,  0.0917, -0.0041],\n",
       "        ...,\n",
       "        [-0.0019, -0.0299, -0.0214,  ..., -0.0219,  0.0619,  0.0317],\n",
       "        [-0.0137, -0.0348, -0.0467,  ..., -0.0402,  0.0678,  0.0130],\n",
       "        [-0.0162, -0.0277, -0.0211,  ..., -0.0462,  0.0306, -0.0103]],\n",
       "       grad_fn=<DivBackward0>), enriched_data_repr=tensor([[ 0.0470,  0.0437,  0.0096,  ..., -0.0027,  0.0329, -0.0598],\n",
       "        [ 0.0037,  0.0225, -0.0039,  ..., -0.0131,  0.0115, -0.0377],\n",
       "        [-0.0093,  0.0033, -0.0037,  ...,  0.0459,  0.0589, -0.0726],\n",
       "        ...,\n",
       "        [ 0.0187,  0.0310, -0.0346,  ...,  0.0145,  0.0261, -0.0349],\n",
       "        [ 0.0399,  0.0195, -0.0211,  ..., -0.0247,  0.0665, -0.0124],\n",
       "        [ 0.0101,  0.0102, -0.0294,  ...,  0.0019,  0.0223, -0.0617]],\n",
       "       grad_fn=<DivBackward0>), meta_repr=tensor([[ 0.0470,  0.0437,  0.0096,  ..., -0.0027,  0.0329, -0.0598],\n",
       "        [ 0.0037,  0.0225, -0.0039,  ..., -0.0131,  0.0115, -0.0377],\n",
       "        [-0.0093,  0.0033, -0.0037,  ...,  0.0459,  0.0589, -0.0726],\n",
       "        ...,\n",
       "        [ 0.0187,  0.0310, -0.0346,  ...,  0.0145,  0.0261, -0.0349],\n",
       "        [ 0.0399,  0.0195, -0.0211,  ..., -0.0247,  0.0665, -0.0124],\n",
       "        [ 0.0101,  0.0102, -0.0294,  ...,  0.0019,  0.0223, -0.0617]],\n",
       "       grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045dc821-df70-4d37-8961-86cdce86b4a3",
   "metadata": {},
   "source": [
    "## `SAW000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "70d26f79-06e1-4f0f-8010-5ab44fa286b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class SAWModelOutput(ModelOutput):\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    data_repr: Optional[torch.FloatTensor] = None\n",
    "    data_enriched_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_enriched_repr: Optional[torch.FloatTensor] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a2467815-5658-4ce0-a844-5c8542fcd09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SAW000(nn.Module):\n",
    "\n",
    "    config_class = SandwichConfig\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config: SandwichConfig,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.config, self.encoder = config, None\n",
    "        self.rep_loss_fn = MultiTriplet(margin=config.margin, n_negatives=config.num_negatives, tau=config.tau, \n",
    "                                        apply_softmax=config.apply_softmax, reduce='mean')\n",
    "        self.cab_loss_fn = Calibration(margin=config.calib_margin, tau=config.calib_tau, n_negatives=config.calib_num_negatives, \n",
    "                                       apply_softmax=config.calib_apply_softmax, reduce='mean')\n",
    "        \n",
    "    def init_heads_to_identity(self):\n",
    "        if self.encoder is None: raise ValueError('Encoder not initialized.')\n",
    "        self.encoder.init_heads_to_identity()\n",
    "\n",
    "    def init_combiner_to_last_layer(self):\n",
    "        if self.encoder is None: raise ValueError('Encoder not initialized.')\n",
    "        self.encoder.init_combiner_to_last_layer()\n",
    "\n",
    "    def init_meta_distilbert(self):\n",
    "        if self.encoder is None: raise ValueError('Encoder not initialized.')\n",
    "        self.encoder.init_meta_distilbert()\n",
    "        \n",
    "    def compute_loss(self, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.rep_loss_fn(inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "\n",
    "    def calibration_loss(self, einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.config.calib_loss_weight * self.cab_loss_fn(einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "\n",
    "    def compute_meta_loss(self, data_o, lbl2data_o, **kwargs):\n",
    "        loss = 0.0\n",
    "        meta_kwargs = Parameters.from_aug_meta_prefix_for_loss('data', self.config.data_aug_meta_prefix, **kwargs)\n",
    "        prefix = self.config.data_aug_meta_prefix\n",
    "        if meta_kwargs is not None and len(meta_kwargs[prefix]['idx']):\n",
    "            idx = torch.where(meta_kwargs[prefix]['data2ptr'] > 0)\n",
    "            loss += self.config.meta_loss_weight * self.compute_loss(data_o.data_meta_repr, \n",
    "                                                                     data_o.meta_repr,\n",
    "                                                                     meta_kwargs[prefix]['data2ptr'][idx],\n",
    "                                                                     meta_kwargs[prefix]['idx'],\n",
    "                                                                     meta_kwargs[f'p{prefix}']['data2ptr'][idx],\n",
    "                                                                     meta_kwargs[f'p{prefix}']['idx'])\n",
    "            \n",
    "        meta_kwargs = Parameters.from_aug_meta_prefix_for_loss('lbl', self.config.lbl2data_aug_meta_prefix, **kwargs)\n",
    "        prefix = self.config.lbl2data_aug_meta_prefix\n",
    "        if meta_kwargs is not None and len(meta_kwargs[prefix]['idx']):\n",
    "            idx = torch.where(meta_kwargs[prefix]['data2ptr'] > 0)\n",
    "            loss += self.config.meta_loss_weight * self.compute_loss(lbl2data_o.data_meta_repr, \n",
    "                                                                     lbl2data_o.meta_repr,\n",
    "                                                                     meta_kwargs[prefix]['data2ptr'][idx],\n",
    "                                                                     meta_kwargs[prefix]['idx'],\n",
    "                                                                     meta_kwargs[f'p{prefix}']['data2ptr'][idx],\n",
    "                                                                     meta_kwargs[f'p{prefix}']['idx'])\n",
    "        return loss\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ): \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.config.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_aug_meta_prefix_for_feature('data', self.config.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.config.data_aug_meta_prefix, data_enrich=self.config.data_enrich, **data_meta_kwargs)\n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_aug_meta_prefix_for_feature('lbl', self.config.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.config.lbl2data_aug_meta_prefix, data_enrich=self.config.lbl2data_enrich, **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.enriched_data_repr, lbl2data_o.enriched_data_repr,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.config.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.data_repr, lbl2data_o.data_repr,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.config.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.enriched_data_repr, data_o.data_repr, lbl2data_o.data_repr,\n",
    "                                              lbl2data_data2ptr,lbl2data_idx,plbl2data_data2ptr,plbl2data_idx)\n",
    "                loss += self.calibration_loss(data_o.enriched_data_repr, data_o.data_repr, lbl2data_o.enriched_data_repr,\n",
    "                                              lbl2data_data2ptr,lbl2data_idx, plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.config.use_meta_loss:\n",
    "                loss += self.compute_meta_loss(data_o, lbl2data_o, **kwargs)\n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.data_repr,data_o.enriched_data_repr,lbl2data_o.data_repr,lbl2data_o.enriched_data_repr)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        return SAWModelOutput(\n",
    "            loss=loss,\n",
    "            data_repr=data_o.data_repr,\n",
    "            data_enriched_repr=data_o.enriched_data_repr,\n",
    "            lbl2data_repr=lbl2data_o.data_repr,\n",
    "            lbl2data_enriched_repr=lbl2data_o.enriched_data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760aa441-82a7-4e20-98f7-b71bf4ad58e2",
   "metadata": {},
   "source": [
    "## `SAW001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d0dc5719-c811-41cb-ab03-991daff2ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SAW001(SAW000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.encoder = Encoder(config)\n",
    "        \n",
    "        self.post_init()\n",
    "        self.remap_post_init()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e0f21-d6d0-40d1-a3b4-a1f57cd68577",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "06dd341b-b4a7-416d-aca1-e7597a284a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SandwichConfig(\n",
    "    data_aug_meta_prefix='cat2data', \n",
    "    lbl2data_aug_meta_prefix='cat2lbl',\n",
    "\n",
    "    data_enrich=True,\n",
    "    lbl2data_enrich=True,\n",
    "\n",
    "    batch_size=100, \n",
    "    num_batch_labels=5000, \n",
    "    margin=0.3,\n",
    "    num_negatives=5,\n",
    "    tau=0.1,\n",
    "    apply_softmax=True,\n",
    "\n",
    "    use_calib_loss=True,\n",
    "    calib_loss_weight=0.1,\n",
    "    calib_margin=0.05,\n",
    "    calib_num_negatives=10,\n",
    "    calib_tau=0.1,\n",
    "    calib_apply_softmax=False,\n",
    "\n",
    "    use_query_loss=True,\n",
    "\n",
    "    use_meta_loss=False,\n",
    "    meta_loss_weight=0.1,\n",
    "    \n",
    "    use_encoder_parallel=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5c756da1-3064-4314-a9f6-a95e2e29c773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SAW001 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.combiner_head.attention.k_lin.bias', 'encoder.combiner_head.attention.k_lin.weight', 'encoder.combiner_head.attention.out_lin.bias', 'encoder.combiner_head.attention.out_lin.weight', 'encoder.combiner_head.attention.q_lin.bias', 'encoder.combiner_head.attention.q_lin.weight', 'encoder.combiner_head.attention.v_lin.bias', 'encoder.combiner_head.attention.v_lin.weight', 'encoder.combiner_head.ffn.lin1.bias', 'encoder.combiner_head.ffn.lin1.weight', 'encoder.combiner_head.ffn.lin2.bias', 'encoder.combiner_head.ffn.lin2.weight', 'encoder.combiner_head.output_layer_norm.bias', 'encoder.combiner_head.output_layer_norm.weight', 'encoder.combiner_head.sa_layer_norm.bias', 'encoder.combiner_head.sa_layer_norm.weight', 'encoder.enriched_query_head.layer_norm.bias', 'encoder.enriched_query_head.layer_norm.weight', 'encoder.enriched_query_head.projector.bias', 'encoder.enriched_query_head.projector.weight', 'encoder.enriched_query_head.transform.bias', 'encoder.enriched_query_head.transform.weight', 'encoder.meta_distilbert.embeddings.LayerNorm.bias', 'encoder.meta_distilbert.embeddings.LayerNorm.weight', 'encoder.meta_distilbert.embeddings.position_embeddings.weight', 'encoder.meta_distilbert.embeddings.word_embeddings.weight', 'encoder.meta_distilbert.transformer.layer.0.attention.k_lin.bias', 'encoder.meta_distilbert.transformer.layer.0.attention.k_lin.weight', 'encoder.meta_distilbert.transformer.layer.0.attention.out_lin.bias', 'encoder.meta_distilbert.transformer.layer.0.attention.out_lin.weight', 'encoder.meta_distilbert.transformer.layer.0.attention.q_lin.bias', 'encoder.meta_distilbert.transformer.layer.0.attention.q_lin.weight', 'encoder.meta_distilbert.transformer.layer.0.attention.v_lin.bias', 'encoder.meta_distilbert.transformer.layer.0.attention.v_lin.weight', 'encoder.meta_distilbert.transformer.layer.0.ffn.lin1.bias', 'encoder.meta_distilbert.transformer.layer.0.ffn.lin1.weight', 'encoder.meta_distilbert.transformer.layer.0.ffn.lin2.bias', 'encoder.meta_distilbert.transformer.layer.0.ffn.lin2.weight', 'encoder.meta_distilbert.transformer.layer.0.output_layer_norm.bias', 'encoder.meta_distilbert.transformer.layer.0.output_layer_norm.weight', 'encoder.meta_distilbert.transformer.layer.0.sa_layer_norm.bias', 'encoder.meta_distilbert.transformer.layer.0.sa_layer_norm.weight', 'encoder.meta_distilbert.transformer.layer.1.attention.k_lin.bias', 'encoder.meta_distilbert.transformer.layer.1.attention.k_lin.weight', 'encoder.meta_distilbert.transformer.layer.1.attention.out_lin.bias', 'encoder.meta_distilbert.transformer.layer.1.attention.out_lin.weight', 'encoder.meta_distilbert.transformer.layer.1.attention.q_lin.bias', 'encoder.meta_distilbert.transformer.layer.1.attention.q_lin.weight', 'encoder.meta_distilbert.transformer.layer.1.attention.v_lin.bias', 'encoder.meta_distilbert.transformer.layer.1.attention.v_lin.weight', 'encoder.meta_distilbert.transformer.layer.1.ffn.lin1.bias', 'encoder.meta_distilbert.transformer.layer.1.ffn.lin1.weight', 'encoder.meta_distilbert.transformer.layer.1.ffn.lin2.bias', 'encoder.meta_distilbert.transformer.layer.1.ffn.lin2.weight', 'encoder.meta_distilbert.transformer.layer.1.output_layer_norm.bias', 'encoder.meta_distilbert.transformer.layer.1.output_layer_norm.weight', 'encoder.meta_distilbert.transformer.layer.1.sa_layer_norm.bias', 'encoder.meta_distilbert.transformer.layer.1.sa_layer_norm.weight', 'encoder.meta_distilbert.transformer.layer.2.attention.k_lin.bias', 'encoder.meta_distilbert.transformer.layer.2.attention.k_lin.weight', 'encoder.meta_distilbert.transformer.layer.2.attention.out_lin.bias', 'encoder.meta_distilbert.transformer.layer.2.attention.out_lin.weight', 'encoder.meta_distilbert.transformer.layer.2.attention.q_lin.bias', 'encoder.meta_distilbert.transformer.layer.2.attention.q_lin.weight', 'encoder.meta_distilbert.transformer.layer.2.attention.v_lin.bias', 'encoder.meta_distilbert.transformer.layer.2.attention.v_lin.weight', 'encoder.meta_distilbert.transformer.layer.2.ffn.lin1.bias', 'encoder.meta_distilbert.transformer.layer.2.ffn.lin1.weight', 'encoder.meta_distilbert.transformer.layer.2.ffn.lin2.bias', 'encoder.meta_distilbert.transformer.layer.2.ffn.lin2.weight', 'encoder.meta_distilbert.transformer.layer.2.output_layer_norm.bias', 'encoder.meta_distilbert.transformer.layer.2.output_layer_norm.weight', 'encoder.meta_distilbert.transformer.layer.2.sa_layer_norm.bias', 'encoder.meta_distilbert.transformer.layer.2.sa_layer_norm.weight', 'encoder.meta_distilbert.transformer.layer.3.attention.k_lin.bias', 'encoder.meta_distilbert.transformer.layer.3.attention.k_lin.weight', 'encoder.meta_distilbert.transformer.layer.3.attention.out_lin.bias', 'encoder.meta_distilbert.transformer.layer.3.attention.out_lin.weight', 'encoder.meta_distilbert.transformer.layer.3.attention.q_lin.bias', 'encoder.meta_distilbert.transformer.layer.3.attention.q_lin.weight', 'encoder.meta_distilbert.transformer.layer.3.attention.v_lin.bias', 'encoder.meta_distilbert.transformer.layer.3.attention.v_lin.weight', 'encoder.meta_distilbert.transformer.layer.3.ffn.lin1.bias', 'encoder.meta_distilbert.transformer.layer.3.ffn.lin1.weight', 'encoder.meta_distilbert.transformer.layer.3.ffn.lin2.bias', 'encoder.meta_distilbert.transformer.layer.3.ffn.lin2.weight', 'encoder.meta_distilbert.transformer.layer.3.output_layer_norm.bias', 'encoder.meta_distilbert.transformer.layer.3.output_layer_norm.weight', 'encoder.meta_distilbert.transformer.layer.3.sa_layer_norm.bias', 'encoder.meta_distilbert.transformer.layer.3.sa_layer_norm.weight', 'encoder.meta_distilbert.transformer.layer.4.attention.k_lin.bias', 'encoder.meta_distilbert.transformer.layer.4.attention.k_lin.weight', 'encoder.meta_distilbert.transformer.layer.4.attention.out_lin.bias', 'encoder.meta_distilbert.transformer.layer.4.attention.out_lin.weight', 'encoder.meta_distilbert.transformer.layer.4.attention.q_lin.bias', 'encoder.meta_distilbert.transformer.layer.4.attention.q_lin.weight', 'encoder.meta_distilbert.transformer.layer.4.attention.v_lin.bias', 'encoder.meta_distilbert.transformer.layer.4.attention.v_lin.weight', 'encoder.meta_distilbert.transformer.layer.4.ffn.lin1.bias', 'encoder.meta_distilbert.transformer.layer.4.ffn.lin1.weight', 'encoder.meta_distilbert.transformer.layer.4.ffn.lin2.bias', 'encoder.meta_distilbert.transformer.layer.4.ffn.lin2.weight', 'encoder.meta_distilbert.transformer.layer.4.output_layer_norm.bias', 'encoder.meta_distilbert.transformer.layer.4.output_layer_norm.weight', 'encoder.meta_distilbert.transformer.layer.4.sa_layer_norm.bias', 'encoder.meta_distilbert.transformer.layer.4.sa_layer_norm.weight', 'encoder.meta_distilbert.transformer.layer.5.attention.k_lin.bias', 'encoder.meta_distilbert.transformer.layer.5.attention.k_lin.weight', 'encoder.meta_distilbert.transformer.layer.5.attention.out_lin.bias', 'encoder.meta_distilbert.transformer.layer.5.attention.out_lin.weight', 'encoder.meta_distilbert.transformer.layer.5.attention.q_lin.bias', 'encoder.meta_distilbert.transformer.layer.5.attention.q_lin.weight', 'encoder.meta_distilbert.transformer.layer.5.attention.v_lin.bias', 'encoder.meta_distilbert.transformer.layer.5.attention.v_lin.weight', 'encoder.meta_distilbert.transformer.layer.5.ffn.lin1.bias', 'encoder.meta_distilbert.transformer.layer.5.ffn.lin1.weight', 'encoder.meta_distilbert.transformer.layer.5.ffn.lin2.bias', 'encoder.meta_distilbert.transformer.layer.5.ffn.lin2.weight', 'encoder.meta_distilbert.transformer.layer.5.output_layer_norm.bias', 'encoder.meta_distilbert.transformer.layer.5.output_layer_norm.weight', 'encoder.meta_distilbert.transformer.layer.5.sa_layer_norm.bias', 'encoder.meta_distilbert.transformer.layer.5.sa_layer_norm.weight', 'encoder.meta_query_head.layer_norm.bias', 'encoder.meta_query_head.layer_norm.weight', 'encoder.meta_query_head.projector.bias', 'encoder.meta_query_head.projector.weight', 'encoder.meta_query_head.transform.bias', 'encoder.meta_query_head.transform.weight', 'encoder.query_head.layer_norm.bias', 'encoder.query_head.layer_norm.weight', 'encoder.query_head.projector.bias', 'encoder.query_head.projector.weight', 'encoder.query_head.transform.bias', 'encoder.query_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = SAW001.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e0834039-2ead-4a4e-82ce-27292001336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_heads_to_identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5e7be5c2-14bf-4539-8162-7b45f0e39313",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_combiner_to_last_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a9351b9d-088b-43c2-875d-545e9d3b7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_meta_distilbert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0c653176-5f81-43ee-93f8-6a0148834c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789115564/work/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "output = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd76c0-fb42-421a-82bf-35cf2b3791cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "e0ebacf1-113d-4f89-b73e-fad4e03d6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    b = prepare_batch(model, batch, m_args=['cat2data_idx', 'cat2data_data2ptr'])\n",
    "    o = model(**b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57a54b76-627a-412d-b571-4013f082ae9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAWModelOutput(loss=tensor(0.1293, grad_fn=<AddBackward0>), data_repr=tensor([[-3.0410e-02, -3.0241e-02, -3.2113e-02,  ..., -3.5623e-02,\n",
       "         -2.5720e-02,  7.6438e-02],\n",
       "        [-2.5134e-02,  1.2242e-02, -2.8343e-02,  ...,  7.1558e-02,\n",
       "         -2.2071e-02, -1.9431e-02],\n",
       "        [-2.2176e-02, -1.7220e-02, -2.3142e-02,  ...,  4.7774e-02,\n",
       "         -2.0947e-03, -1.5657e-02],\n",
       "        ...,\n",
       "        [-6.7133e-03, -2.3140e-02,  1.3361e-04,  ..., -1.4936e-02,\n",
       "         -9.2534e-03, -8.7000e-04],\n",
       "        [-2.4098e-02,  2.2817e-02,  3.1067e-02,  ..., -4.0922e-03,\n",
       "         -1.7239e-02, -3.6599e-03],\n",
       "        [ 2.4830e-02,  4.8248e-02, -2.4326e-03,  ...,  1.3954e-01,\n",
       "          4.4811e-02, -2.6876e-02]], grad_fn=<DivBackward0>), data_enriched_repr=tensor([[-2.0211e-02, -5.9858e-03, -2.2439e-02,  ..., -2.1754e-02,\n",
       "         -2.2301e-02,  7.6863e-02],\n",
       "        [-9.8610e-03, -2.1608e-02,  1.0650e-02,  ...,  3.6301e-02,\n",
       "         -2.0757e-02,  2.3284e-02],\n",
       "        [ 2.1760e-02, -2.2429e-02, -1.9076e-02,  ..., -1.0963e-02,\n",
       "         -2.1555e-02, -1.3106e-02],\n",
       "        ...,\n",
       "        [-1.9716e-02,  6.5463e-03,  1.2907e-01,  ..., -2.2265e-02,\n",
       "         -1.0874e-03, -2.2274e-02],\n",
       "        [ 1.4945e-02, -2.3425e-02, -4.2892e-05,  ..., -1.8428e-02,\n",
       "         -2.3038e-02, -2.2960e-02],\n",
       "        [ 8.9404e-02, -1.0834e-02, -5.9670e-04,  ...,  7.2791e-02,\n",
       "         -2.3324e-02, -1.6468e-02]], grad_fn=<DivBackward0>), lbl2data_repr=tensor([[-0.0038,  0.0010, -0.0195,  ..., -0.0004, -0.0062,  0.0739],\n",
       "        [-0.0251,  0.0122, -0.0283,  ...,  0.0716, -0.0221, -0.0194],\n",
       "        [ 0.0206,  0.0271,  0.0714,  ..., -0.0170, -0.0405,  0.0291],\n",
       "        ...,\n",
       "        [ 0.0233, -0.0006, -0.0239,  ..., -0.0326, -0.0185, -0.0222],\n",
       "        [-0.0202, -0.0052,  0.0049,  ..., -0.0035, -0.0326,  0.0111],\n",
       "        [-0.0307, -0.0106,  0.0028,  ...,  0.1134, -0.0230, -0.0274]],\n",
       "       grad_fn=<DivBackward0>), lbl2data_enriched_repr=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc0f676-7252-4751-92a5-a48e8dc1e8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
