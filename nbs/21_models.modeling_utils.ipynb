{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd48060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.modeling_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc4a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, re, inspect, pickle, os, torch.nn as nn, math\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Tuple, Mapping, Any, Union\n",
    "from transformers import (\n",
    "    PretrainedConfig,\n",
    "    DistilBertForMaskedLM,\n",
    "    DistilBertModel,\n",
    "    DistilBertPreTrainedModel,\n",
    ")\n",
    "from transformers.utils.generic import ModelOutput\n",
    "from transformers.activations import get_activation\n",
    "\n",
    "from fastcore.meta import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee9b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c00009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from xcai.block import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ede14",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc269b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/scai/phd/aiz218323/Projects/XC/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb671af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/xclib-0.97-py3.9-linux-x86_64.egg/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n"
     ]
    }
   ],
   "source": [
    "block = XCBlock.from_cfg(data_dir, 'data_metas', tfm='rm', tokenizer='distilbert-base-uncased', \n",
    "                         smp_features=[('lbl2data|cat2lbl2data',1,(1,3)), ('cat2data',1,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f3da90-d45a-40eb-bfeb-de65aa6cde4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c1d105-6978-44b6-a9c9-851220d03e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealso_data-meta_distilbert-base-uncased_rm_radga-cat.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843bd7a-d18c-4f44-bd4b-c56064ee937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'wb') as file: pickle.dump(block, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(5)\n",
    "for i,batch in enumerate(block.train.dl):\n",
    "    if i > 2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbdf322-d214-4cab-b424-be22ee84af83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'pcat2lbl_idx', 'pcat2lbl_lbl2data2ptr', 'pcat2lbl_data2ptr', 'cat2lbl_idx', 'cat2lbl_identifier', 'cat2lbl_input_text', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'cat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'cat2data_data2ptr', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'data_idx', 'hlk2lbl2data_idx', 'hlk2lbl2data_identifier', 'hlk2lbl2data_input_text', 'hlk2lbl2data_input_ids', 'hlk2lbl2data_attention_mask', 'hlk2lbl2data_data2ptr', 'hlk2lbl2data_plbl2data2ptr', 'hlk2data_idx', 'hlk2data_identifier', 'hlk2data_input_text', 'hlk2data_input_ids', 'hlk2data_attention_mask', 'hlk2data_data2ptr'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63666b5",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class XCModelOutput(ModelOutput):\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    logits: Optional[torch.FloatTensor] = None\n",
    "    data_repr: Optional[torch.FloatTensor] = None\n",
    "    data_fused_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_fused_repr: Optional[torch.FloatTensor] = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc40c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class EncoderOutput(ModelOutput):\n",
    "    rep: Optional[torch.FloatTensor] = None\n",
    "    fused_rep: Optional[torch.FloatTensor] = None\n",
    "    logits: Optional[torch.FloatTensor] = None\n",
    "    fusion_weights: Optional[torch.FloatTensor] = None\n",
    "    meta_repr: Optional[torch.FloatTensor] = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Pooling:\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_pooling(data_embeds:torch.FloatTensor, data_attention_mask:torch.LongTensor):\n",
    "        data_attention_mask = data_attention_mask.unsqueeze(2).expand(data_embeds.size()).float()\n",
    "        return torch.sum(data_embeds * data_attention_mask, 1) / torch.clamp(data_attention_mask.sum(1), min=1e-9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f97b11c",
   "metadata": {},
   "source": [
    "## CrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a92acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrossAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__()\n",
    "        self.config, self.n_h, self.dim = config, config.n_heads, config.dim\n",
    "        self.dropout = nn.Dropout(p=config.attention_dropout)\n",
    "\n",
    "        if self.dim % self.n_h != 0:\n",
    "            raise ValueError(f\"self.n_heads: {self.n_h} must divide self.dim: {self.dim} evenly.\")\n",
    "            \n",
    "        self.q = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.k = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.v = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.o = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "\n",
    "    def post_init(self):\n",
    "        self.q.weight.data = torch.eye(self.q.out_features, self.q.in_features, dtype=self.q.weight.dtype)\n",
    "        self.k.weight.data = torch.eye(self.k.out_features, self.k.in_features, dtype=self.k.weight.dtype)\n",
    "        self.v.weight.data = torch.eye(self.v.out_features, self.v.in_features, dtype=self.v.weight.dtype)\n",
    "        self.o.weight.data = torch.eye(self.o.out_features, self.o.in_features, dtype=self.o.weight.dtype)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        q: torch.Tensor,\n",
    "        q_m: torch.Tensor,\n",
    "        k: torch.Tensor, \n",
    "        k_m: torch.Tensor,\n",
    "        output_attentions:Optional[bool] = False,\n",
    "    ):\n",
    "        bs, q_len, dim = q.size()\n",
    "        v, k_len = k, k.size(1) \n",
    "\n",
    "        h_dim = self.dim//self.n_h\n",
    "\n",
    "        def shape(x: torch.Tensor): return x.view(bs, -1, self.n_h, h_dim).transpose(1, 2)\n",
    "\n",
    "        def unshape(x: torch.Tensor): return x.transpose(1, 2).contiguous().view(bs, -1, self.n_h * h_dim)\n",
    "\n",
    "        q = shape(self.q(q))  # (bs, n_h, q_len, h_dim)\n",
    "        k = shape(self.k(k))  # (bs, n_h, k_len, h_dim)\n",
    "        v = shape(self.v(v))  # (bs, n_h, k_len, h_dim)\n",
    "\n",
    "        q = q / math.sqrt(h_dim)  # (bs, n_h, q_len, h_dim)\n",
    "        sc = torch.matmul(q, k.transpose(2, 3))  # (bs, n_h, q_len, k_len)\n",
    "        \n",
    "        q_m, k_m = q_m.view(bs, 1, -1, 1).to(q.dtype), k_m.view(bs, 1, 1, -1).to(q.dtype)\n",
    "        mask = torch.matmul(q_m, k_m).expand_as(sc)  # (bs, n_h, q_len, k_len)\n",
    "        \n",
    "        sc = sc.masked_fill(mask == 0, torch.tensor(torch.finfo(sc.dtype).min))  # (bs, n_h, q_len, k_len)\n",
    "\n",
    "        w = nn.functional.softmax(sc, dim=-1)  # (bs, n_h, q_len, k_len)\n",
    "        w = self.dropout(w)  # (bs, n_h, q_len, k_len)\n",
    "\n",
    "        o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
    "        \n",
    "        if output_attentions: return (o, w)\n",
    "        else: return (o,)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258a231",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('distilbert-base-uncased')\n",
    "fuser = CrossAttention(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec047a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz, data_seq_len, n_meta, dim, dtype = 2, 3, 2, config.dim, torch.float32\n",
    "data, meta = torch.randn(bsz, data_seq_len, dim, dtype=dtype), torch.randn(bsz, n_meta, dim, dtype=dtype)\n",
    "data_mask = torch.randint(0, 2, size=(bsz,data_seq_len), dtype=dtype)\n",
    "meta_mask = torch.randint(0, 2, size=(bsz,n_meta), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = fuser(data, data_mask, meta, meta_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d426e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46f75c9",
   "metadata": {},
   "source": [
    "## Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e25a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RepresentationHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.transform = nn.Linear(config.dim, config.dim)\n",
    "        self.layer_norm = nn.LayerNorm(config.dim, eps=1e-12)\n",
    "        self.projector = nn.Linear(config.dim, config.dim)\n",
    "        self.activation = get_activation(config.activation)\n",
    "        \n",
    "        self.post_init()\n",
    "        \n",
    "    def post_init(self):\n",
    "        self.transform.weight.data = torch.eye(self.transform.out_features, self.transform.in_features, \n",
    "                                               dtype=self.transform.weight.dtype)\n",
    "        self.projector.weight.data = torch.eye(self.projector.out_features, self.projector.in_features, \n",
    "                                               dtype=self.projector.weight.dtype)\n",
    "        \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.transform(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.projector(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GenerationHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.transform = nn.Linear(config.dim, config.dim)\n",
    "        self.layer_norm = nn.LayerNorm(config.dim, eps=1e-12)\n",
    "        self.projector = nn.Linear(config.dim, config.vocab_size)\n",
    "        self.activation = get_activation(config.activation)\n",
    "        \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.transform(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.projector(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa14f380",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bd2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('distilbert-base-uncased')\n",
    "x = torch.randn(10, 20, config.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76321c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RepresentationHead(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ea52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = GenerationHead(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9224630",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ca951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Parameters:\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_meta_aug_prefix(prefix:str, **kwargs):\n",
    "        inputs = {}\n",
    "        args = [arg for arg in kwargs if prefix is not None and re.match(f'^{prefix}.*_(input_ids|attention_mask|data2ptr|meta_repr|idx)$', arg)]\n",
    "        for arg in args:\n",
    "            meta,param = arg.split('_', maxsplit=1)\n",
    "            inputs.setdefault(meta, {})[param] = kwargs[arg]\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_feat_meta_aug_prefix(feat:str, prefix:str, **kwargs):\n",
    "        keys = ['attention_mask', 'input_ids', 'meta_repr', 'idx']\n",
    "        \n",
    "        inputs = {f'{prefix}_{k}': kwargs[f'{prefix}_{k}'] for k in keys if f'{prefix}_{k}' in kwargs}\n",
    "        if prefix is not None and f'{prefix}_{feat}2ptr' in kwargs:\n",
    "            inputs.update({f'{prefix}_data2ptr': kwargs[f'{prefix}_{feat}2ptr']})\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_meta_pred_prefix(prefix:str, **kwargs):\n",
    "        inputs = {}\n",
    "        args = [arg for arg in kwargs if prefix is not None and re.match(f'^[p]?{prefix}.*', arg)]\n",
    "        for arg in args:\n",
    "            meta,param = arg.split('_', maxsplit=1)\n",
    "            if arg[0] == 'p': \n",
    "                inputs.setdefault(meta[1:], {})[f'p{param}'] = kwargs[arg]\n",
    "            else: \n",
    "                inputs.setdefault(meta, {})[param] = kwargs[arg]\n",
    "        return inputs\n",
    "\n",
    "    @staticmethod\n",
    "    def get_meta_loss_weights(lw:Union[float,List], n_meta:int):\n",
    "        if isinstance(lw, float):\n",
    "            lw = lw/n_meta if n_meta else None\n",
    "            return [lw] * n_meta\n",
    "        else:\n",
    "            if len(lw) != n_meta: raise ValueError(f'length of `lw` should be equal to number of metadata.')\n",
    "            return lw\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c76edd-7068-43c8-b661-5cbb185e788c",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2517ed38-5df8-40e5-8587-a09aca55fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(block.train.dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5429b9a1-8f1f-44b1-ba3f-e7c01e04b1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cat2lbl', 'cat2data'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Parameters.from_meta_aug_prefix('cat', **b); p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668bf4d9-4748-422b-a6a1-a0b502dcfcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cat2lbl_attention_mask', 'cat2lbl_input_ids', 'cat2lbl_idx', 'cat2lbl_data2ptr'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Parameters.from_feat_meta_aug_prefix('data', 'cat2lbl', **b); p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58af55d5-31aa-4b4a-8ea5-23e88d9770d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cat2lbl', 'cat2data'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Parameters.from_meta_pred_prefix('cat', **b); p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b4e7f-8d2e-4550-9a86-7c3002192951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
