{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa699db4-a4b7-430e-8aef-1944f185fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d402020-9db0-4fc9-97dc-301109edd3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a095b-e95c-4870-b0f7-9e772c387879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f01b50-cb84-4bfc-aa47-c0655db43642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, torch, scipy.sparse as sp, joblib, argparse\n",
    "from typing import Optional, Dict, Callable, Union\n",
    "\n",
    "from xcai.block import SXCBlock, XCBlock\n",
    "from xcai.core import get_best_model, load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2726e730-56ec-4dc4-9b68-18a7f824c81f",
   "metadata": {},
   "source": [
    "## `Arguement`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725be79-e4fc-418d-9798-61009ab95eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--build_block', action='store_true')\n",
    "    parser.add_argument('--use_pretrained', action='store_true')\n",
    "    \n",
    "    parser.add_argument('--do_train_inference', action='store_true')\n",
    "    parser.add_argument('--do_test_inference', action='store_true')\n",
    "    \n",
    "    parser.add_argument('--save_train_inference', action='store_true')\n",
    "    parser.add_argument('--save_test_inference', action='store_true')\n",
    "    \n",
    "    parser.add_argument('--save_representation', action='store_true')\n",
    "    \n",
    "    parser.add_argument('--use_sxc_sampler', action='store_true')\n",
    "    parser.add_argument('--only_test', action='store_true')\n",
    "\n",
    "    parser.add_argument('--pickle_dir', type=str, required=True)\n",
    "    \n",
    "    return parser.parse_args()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924b980-4c91-4070-bb48-63d85e510b87",
   "metadata": {},
   "source": [
    "## Build `block`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b5a44-cb8b-4339-bee8-3481d8269285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def build_block(pkl_file:str, config:Union[str,Dict], use_sxc:Optional[bool]=True, config_key:Optional[str]=None, \n",
    "                do_build:Optional[bool]=False, only_test:Optional[bool]=False, **kwargs):\n",
    "\n",
    "    if not os.path.exists(pkl_file): do_build = True\n",
    "\n",
    "    if do_build:\n",
    "        if isinstance(config, str) and os.path.exists(config): \n",
    "            config = load_config(config, config_key)\n",
    "            if only_test and 'train' in config['path']: del config['path']['train'] \n",
    "    \n",
    "        if use_sxc: \n",
    "            block = SXCBlock.from_cfg(config, padding=True, return_tensors='pt', **kwargs)\n",
    "        else: \n",
    "            block = XCBlock.from_cfg(config, transform_type='xcs', **kwargs)\n",
    "            \n",
    "        joblib.dump(block, pkl_file)\n",
    "    else:\n",
    "        block = joblib.load(pkl_file)\n",
    "\n",
    "    return block\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da69f1-9ff8-4f7f-b906-34950a2eb932",
   "metadata": {},
   "source": [
    "## Load `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05311055-f92b-4d0f-a258-427858530fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_model(output_dir:str, model_fn:Callable, model_args:Dict, init_fn:Callable, init_args:Optional[Dict]=dict(), \n",
    "               do_inference:Optional[bool]=False, use_pretrained:Optional[bool]=False):\n",
    "    if do_inference and not use_pretrained:\n",
    "        os.environ['WANDB_MODE'] = 'disabled'\n",
    "        model_args['mname'] = f'{output_dir}/{os.path.basename(get_best_model(output_dir))}'\n",
    "\n",
    "    model = model_fn(**model_args)\n",
    "    \n",
    "    if not do_inference or use_pretrained: \n",
    "        init_fn(model, **init_args)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28889520-f9ae-48d9-9d4c-af9a78a70b49",
   "metadata": {},
   "source": [
    "## `main` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f07db6-41b4-4f32-9baf-0d1fc66423e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_output(pred_idx:torch.Tensor, pred_ptr:torch.Tensor, pred_score:torch.Tensor, n_lbl:int, **kwargs):\n",
    "    n_data = pred_ptr.shape[0]\n",
    "    pred_ptr = torch.cat([torch.zeros((1,), dtype=torch.long), pred_ptr.cumsum(dim=0)])\n",
    "    pred = sp.csr_matrix((pred_score,pred_idx,pred_ptr), shape=(n_data, n_lbl))\n",
    "    return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1739a08-11b9-469e-b63d-c41f9952c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def main(learn, args, n_lbl:int):\n",
    "    do_infer = args.do_train_inference or args.do_test_inference or args.save_train_inference \\\n",
    "            or args.save_test_inference or args.save_representation\n",
    "    \n",
    "    if do_infer:\n",
    "        pred_dir = f'{learn.args.output_dir}/predictions'\n",
    "        os.makedirs(pred_dir, exist_ok=True)\n",
    "\n",
    "        if args.save_representation:\n",
    "            trn_repr, lbl_repr = learn.get_data_and_lbl_representation(learn.train_dataset)\n",
    "            tst_repr = learn._get_data_representation(learn.eval_dataset)\n",
    "\n",
    "            torch.save(trn_repr, f'{pred_dir}/train_repr.pth')\n",
    "            torch.save(tst_repr, f'{pred_dir}/test_repr.pth')\n",
    "            torch.save(lbl_repr, f'{pred_dir}/label_repr.pth')\n",
    "\n",
    "        if args.do_test_inference:\n",
    "            o = learn.predict(learn.eval_dataset)\n",
    "            print(o.metrics)\n",
    "\n",
    "            if args.save_test_inference:\n",
    "                with open(f'{pred_dir}/test_predictions.pkl', 'wb') as file:\n",
    "                    pickle.dump(o, file)\n",
    "\n",
    "                pred = get_output(o.pred_idx, o.pred_ptr, o.pred_score, n_lbl=n_lbl)\n",
    "                sp.save_npz(f'{pred_dir}/test_predictions.npz', pred)\n",
    "\n",
    "        if args.do_train_inference:\n",
    "            o = learn.predict(learn.train_dataset)\n",
    "            print(o.metrics)\n",
    "\n",
    "            if parse_args.save_train_inference:\n",
    "                with open(f'{pred_dir}/train_predictions.pkl', 'wb') as file:\n",
    "                    pickle.dump(o, file)\n",
    "\n",
    "                pred = get_output(o.pred_idx, o.pred_ptr, o.pred_score, n_lbl=n_lbl)\n",
    "                sp.save_npz(f'{pred_dir}/train_predictions.npz', pred)\n",
    "    else:\n",
    "        learn.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ad6dd-2e52-459e-b4ff-bdddc2cc33db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
