{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd48060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.oakX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d95873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2fc4a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import torch, re, inspect, pickle, os, torch.nn as nn, math\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Tuple, Mapping, Any, Union\n",
    "from transformers import (\n",
    "    PretrainedConfig,\n",
    "    DistilBertForMaskedLM,\n",
    "    DistilBertModel,\n",
    "    DistilBertPreTrainedModel,\n",
    ")\n",
    "from transformers.utils.generic import ModelOutput\n",
    "from transformers.activations import get_activation\n",
    "\n",
    "from fastcore.meta import *\n",
    "from fastcore.utils import *\n",
    "\n",
    "from xcai.losses import *\n",
    "from xcai.core import store_attr\n",
    "from xcai.learner import XCDataParallel\n",
    "from xcai.models.modeling_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee9b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c00009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from xcai.block import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ede14",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff9c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb671af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/xclib-0.97-py3.9-linux-x86_64.egg/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/scai/phd/aiz218323/Projects/XC/data/'\n",
    "\n",
    "block = XCBlock.from_cfg(data_dir, 'data_meta', transform_type='xcs', tokenizer='distilbert-base-uncased', \n",
    "                         sampling_features=[('lbl2data',1), ('cat2data',3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f3da90-d45a-40eb-bfeb-de65aa6cde4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04c1d105-6978-44b6-a9c9-851220d03e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealsotitles_data-meta_distilbert-base-uncased_xcs.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843bd7a-d18c-4f44-bd4b-c56064ee937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'wb') as file: pickle.dump(block, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b4c48b-178b-4136-a5c0-0009ddb84dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e9f4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "658cc0a9-b411-44f5-b675-3424c68bae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "block.collator.tfms.tfms[0].sampling_features = [('lbl2data',1), ('cat2data',3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c50e879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(5)\n",
    "for i,batch in enumerate(block.train.dl):\n",
    "    if i > 2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5f9f36e-bf56-4af0-8a38-89860721f191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'cat2data_data2ptr', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'data_idx', 'cat2lbl2data_idx', 'cat2lbl2data_identifier', 'cat2lbl2data_input_text', 'cat2lbl2data_input_ids', 'cat2lbl2data_attention_mask', 'cat2lbl2data_data2ptr', 'cat2lbl2data_lbl2data2ptr'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a8737b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5ed7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder(DistilBertPreTrainedModel):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig, \n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        \n",
    "        self.dr_head = RepresentationHead(config)\n",
    "        self.dr_fused_head = RepresentationHead(config)\n",
    "        self.meta_head = RepresentationHead(config)\n",
    "        self.cross_head = CrossAttention(config)\n",
    "\n",
    "        self.pretrained_meta_embeddings = nn.Embedding(num_metadata, config.dim)\n",
    "        \n",
    "        self.ones = torch.ones(resize_length, dtype=torch.long, device=self.device) if resize_length is not None else None\n",
    "        self.post_init()\n",
    "\n",
    "    def freeze_pretrained_meta_embeddings(self):\n",
    "        self.pretrained_meta_embeddings.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_pretrained_meta_embeddings(self):\n",
    "        self.pretrained_meta_embeddings.requires_grad_(True)\n",
    "\n",
    "    def set_pretrained_meta_embeddings(self, embed:torch.Tensor):\n",
    "        self.pretrained_meta_embeddings.weight.data = embed\n",
    "        \n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        return self.distilbert.get_position_embeddings()\n",
    "    \n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "        self.distilbert.resize_position_embeddings(new_num_position_embeddings)\n",
    "    \n",
    "    def encode(self, input_ids:torch.Tensor, attention_mask:torch.Tensor, **kwargs):\n",
    "        return self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    def dr(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.dr_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "\n",
    "    def dr_fused(self, embed:torch.Tensor):\n",
    "        embed = self.dr_fused_head(embed)\n",
    "        return F.normalize(embed, dim=1)\n",
    "\n",
    "    def meta(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.meta_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "    \n",
    "    def meta_unnormalized(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.meta_head(embed)\n",
    "        return Pooling.mean_pooling(embed, attention_mask)\n",
    "\n",
    "    def resize(self, idx:torch.Tensor, rep:torch.Tensor, num_inputs:torch.Tensor):\n",
    "        if torch.any(num_inputs == 0): raise ValueError(\"`num_inputs` should be non-zero positive integer.\")\n",
    "        bsz, total_num_inputs = num_inputs.shape[0], idx.shape[0]\n",
    "        \n",
    "        self.ones = self.ones.to(idx.device)\n",
    "        ones = (\n",
    "            torch.ones(total_num_inputs, dtype=torch.long, device=idx.device) \n",
    "            if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
    "        )\n",
    "        \n",
    "        max_num_inputs = num_inputs.max()\n",
    "        if (num_inputs == max_num_inputs).all():\n",
    "            return idx,rep,ones\n",
    "        \n",
    "        xnum_inputs = max_num_inputs-num_inputs+1\n",
    "        \n",
    "        inputs_ptr = num_inputs.cumsum(dim=0)-1\n",
    "        repeat_inputs = ones.scatter(0, inputs_ptr, xnum_inputs)\n",
    "        \n",
    "        resized_idx = idx.repeat_interleave(repeat_inputs, dim=0)\n",
    "        resized_rep = rep.repeat_interleave(repeat_inputs, dim=0)\n",
    "        \n",
    "        ignore_mask = ones.scatter(0, inputs_ptr, 0).repeat_interleave(repeat_inputs, dim=0).view(bsz, -1)\n",
    "        ignore_mask[:, -1] = 1; ignore_mask = ignore_mask.flatten()\n",
    "        \n",
    "        return resized_idx,resized_rep,ignore_mask\n",
    "        \n",
    "\n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
    "            \n",
    "            if len(idx):\n",
    "                m_idx,m_repr,m_repr_mask = self.resize(m_args['idx'], m_args['meta_repr'], m_args['data2ptr'][idx])\n",
    "                m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
    "                \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
    "                meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "                \n",
    "                fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                data_fused_repr[idx] += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_type:Optional[str]=None,\n",
    "        data_unnormalized:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        \n",
    "        if data_type is not None and data_type == \"meta\":\n",
    "            data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
    "        else: \n",
    "            data_repr = self.dr(data_o[0], data_attention_mask)\n",
    "        \n",
    "        data_fused_repr = meta_repr = None\n",
    "        if data_aug_meta_prefix is not None:\n",
    "            meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
    "            if len(meta_kwargs):\n",
    "                data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
    "                                                                            torch.any(data_attention_mask, dim=1), \n",
    "                                                                            meta_kwargs)\n",
    "                data_fused_repr = self.dr_fused(data_fused_repr)\n",
    "                \n",
    "        return EncoderOutput(\n",
    "            rep=data_repr,\n",
    "            fused_rep=data_fused_repr,\n",
    "            meta_repr=meta_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba618800-3966-4b2a-b887-96faa1cda5b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf51c610-41c8-4752-b2e6-5ac4cd5492ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK000(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, config,\n",
    "\n",
    "        num_metadata:int,\n",
    "\n",
    "        data_aug_meta_prefix:Optional[str]=None, \n",
    "        lbl2data_aug_meta_prefix:Optional[str]=None, \n",
    "\n",
    "        data_pred_meta_prefix:Optional[str]=None,\n",
    "        lbl2data_pred_meta_prefix:Optional[str]=None,\n",
    "        \n",
    "        num_batch_labels:Optional[int]=None, \n",
    "        batch_size:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        num_negatives:Optional[int]=5,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=True,\n",
    "\n",
    "        calib_margin:Optional[float]=0.3,\n",
    "        calib_num_negatives:Optional[int]=10,\n",
    "        calib_tau:Optional[float]=0.1,\n",
    "        calib_apply_softmax:Optional[bool]=False,\n",
    "        calib_loss_weight:Optional[float]=0.1,\n",
    "        use_calib_loss:Optional[float]=False,\n",
    "        \n",
    "        meta_loss_weight:Optional[Union[List,float]]=0.3,\n",
    "        \n",
    "        use_fusion_loss:Optional[bool]=False,\n",
    "        fusion_loss_weight:Optional[float]=0.15,\n",
    "\n",
    "        use_query_loss:Optional[float]=True,\n",
    "        \n",
    "        use_encoder_parallel:Optional[bool]=True,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        store_attr('meta_loss_weight,fusion_loss_weight,calib_loss_weight')\n",
    "        store_attr('data_pred_meta_prefix,lbl2data_pred_meta_prefix')\n",
    "        store_attr('data_aug_meta_prefix,lbl2data_aug_meta_prefix')\n",
    "        store_attr('use_fusion_loss,use_query_loss,use_calib_loss,use_encoder_parallel')\n",
    "\n",
    "        self.meta_embeddings = nn.Embedding(num_metadata, config.dim, sparse=True)\n",
    "        \n",
    "        self.rep_loss_fn = MultiTriplet(bsz=batch_size, tn_targ=num_batch_labels, margin=margin, n_negatives=num_negatives, \n",
    "                                        tau=tau, apply_softmax=apply_softmax, reduce='mean')\n",
    "        self.cab_loss_fn = Calibration(margin=calib_margin, tau=calib_tau, n_negatives=calib_num_negatives, \n",
    "                                       apply_softmax=calib_apply_softmax, reduce='mean')\n",
    "        self.encoder = None\n",
    "        \n",
    "        \n",
    "    def init_meta_embeddings(self):\n",
    "        self.meta_embeddings.weight.data = torch.zeros_like(self.meta_embeddings.weight.data)\n",
    "\n",
    "    def freeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(True)\n",
    "\n",
    "    def set_meta_embeddings(self, embed:torch.Tensor):\n",
    "        self.meta_embeddings.weight.data = embed\n",
    "\n",
    "    \n",
    "    def init_retrieval_head(self):\n",
    "        if self.encoder is None: raise ValueError('`self.encoder` is not initialized.')\n",
    "        self.encoder.dr_head.post_init()\n",
    "        self.encoder.meta_head.post_init()\n",
    "        self.encoder.dr_fused_head.post_init()\n",
    "\n",
    "    def init_cross_head(self):\n",
    "        if self.encoder is None: raise ValueError('`self.encoder` is not initialized.')\n",
    "        self.encoder.cross_head.post_init()\n",
    "        \n",
    "\n",
    "    def compute_loss(self, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.rep_loss_fn(inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "\n",
    "    def calibration_loss(self, einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.calib_loss_weight * self.cab_loss_fn(einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "    \n",
    "    def compute_meta_loss(self, data_repr, lbl2data_repr, **kwargs):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "            \n",
    "        data_meta_inputs = Parameters.from_meta_pred_prefix(self.data_pred_meta_prefix, **kwargs)\n",
    "        lbl2data_meta_inputs = Parameters.from_meta_pred_prefix(self.lbl2data_pred_meta_prefix, **kwargs)\n",
    "        meta_inputs = {**data_meta_inputs, **lbl2data_meta_inputs}\n",
    "\n",
    "        m_lw = Parameters.get_meta_loss_weights(self.meta_loss_weight, len(meta_inputs)) if len(meta_inputs) else []\n",
    "        \n",
    "        loss = 0.0\n",
    "        for inputs,lw in zip(meta_inputs.values(), m_lw):\n",
    "            if 'lbl2data2ptr' in inputs:\n",
    "                idx = torch.where(inputs['lbl2data2ptr'])[0]\n",
    "                if len(idx) > 0:\n",
    "                    inputs_o = encoder(data_input_ids=inputs['input_ids'], data_attention_mask=inputs['attention_mask'], \n",
    "                                       data_type=\"meta\")\n",
    "                    m_loss = self.rep_loss_fn(lbl2data_repr[idx], inputs_o.rep, inputs['lbl2data2ptr'][idx],\n",
    "                                              inputs['idx'], inputs['plbl2data2ptr'][idx], inputs['pidx'])\n",
    "                    loss += lw * m_loss\n",
    "\n",
    "            elif 'data2ptr' in inputs:\n",
    "                idx = torch.where(inputs['data2ptr'])[0]\n",
    "                if len(idx) > 0:\n",
    "                    inputs_o = encoder(data_input_ids=inputs['input_ids'], data_attention_mask=inputs['attention_mask'], \n",
    "                                       data_type=\"meta\")\n",
    "                    m_loss = self.rep_loss_fn(data_repr[idx], inputs_o.rep, inputs['data2ptr'][idx], inputs['idx'], \n",
    "                                              inputs['pdata2ptr'][idx], inputs['pidx'])\n",
    "                    loss += lw * m_loss       \n",
    "\n",
    "            else: raise ValueError('Invalid metadata input arguments.')\n",
    "        return loss\n",
    "\n",
    "    def compute_fusion_loss(self, data_repr, meta_repr:Dict, prefix:str, **kwargs):\n",
    "        meta_inputs = Parameters.from_meta_pred_prefix(prefix, **kwargs)\n",
    "        \n",
    "        loss = 0.0\n",
    "        if meta_repr is not None:\n",
    "            for key,input_repr in meta_repr.items():\n",
    "                inputs = meta_inputs[key]\n",
    "                if 'lbl2data2ptr' in inputs:\n",
    "                    idx = torch.where(inputs['lbl2data2ptr'])[0]\n",
    "                    if len(idx) > 0:\n",
    "                        m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['lbl2data2ptr'][idx],\n",
    "                                                  inputs['idx'], inputs['plbl2data2ptr'][idx], inputs['pidx'])\n",
    "                        loss += self.fusion_loss_weight * m_loss\n",
    "    \n",
    "                elif 'data2ptr' in inputs:\n",
    "                    idx = torch.where(inputs['data2ptr'])[0]\n",
    "                    if len(idx) > 0:\n",
    "                        m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['data2ptr'][idx], inputs['idx'], \n",
    "                                                  inputs['pdata2ptr'][idx], inputs['pidx'])\n",
    "                        loss += self.fusion_loss_weight * m_loss       \n",
    "    \n",
    "                else: raise ValueError('Invalid metadata input arguments.')\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def get_meta_representation(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "            \n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_unnormalized=True, data_type=\"meta\")\n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    def _get_encoder_meta_kwargs(self, feat:str, prefix:str, **kwargs):\n",
    "        meta_kwargs = Parameters.from_feat_meta_aug_prefix(feat, prefix, **kwargs)\n",
    "        if f'{prefix}_idx' in meta_kwargs:\n",
    "            m_idx = meta_kwargs[f'{prefix}_idx']\n",
    "            meta_kwargs[f'{prefix}_meta_repr'] = self.meta_embeddings(m_idx)\n",
    "        return meta_kwargs\n",
    "    \n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae7ddb-b7bb-4633-9238-c081ecd049ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c92804f4-bccf-4aa4-bf5e-8ab7cabf1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK001(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, num_metadata=num_metadata, **kwargs)\n",
    "        self.encoder = Encoder(config, num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b6bbef-d971-42d2-8c2b-63e2d8f91101",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86864591-7758-4b37-8702-fabfe8f872a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK001 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight', 'meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK001.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2d36d-4e8c-4827-b535-db7c509dd187",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(block.train.dset.meta['cat_meta'].n_meta, model.config.dim))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5e54c-df22-4186-8b2d-61371a17a985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d585ba-dd70-4988-90ff-2fbed155f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca4074-7bbd-4c10-aa36-3896a339fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7610c-12c9-4e76-a491-8b0de8747838",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7636803-c585-4577-b914-21addece4069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dcdfea-660c-4726-a9d4-03eef45e0c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3415984d-3419-4b98-9a43-59c2128fb81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0729, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d84627-0c4e-4e4f-8bd2-eee40fcf5d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083dc811-799f-4f59-8a5c-ef3afbd66c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0641a1d-693d-4ad0-ab31-d620231a7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680957d4-7bd2-46fa-b12f-4bb8a6f6b1db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3657616883.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b.to(model.device))\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.encoder.fuse_meta_into_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 3 at /tmp/ipykernel_20255/3568055818.py:89\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(90)fuse_meta_into_embeddings()\n",
      "     88 \n",
      "3    89     def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "---> 90         meta_repr = {}\n",
      "     91 \n",
      "     92         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(92)fuse_meta_into_embeddings()\n",
      "     90         meta_repr = {}\n",
      "     91 \n",
      "---> 92         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     93         for m_key, m_args in meta_kwargs.items():\n",
      "     94             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(93)fuse_meta_into_embeddings()\n",
      "     91 \n",
      "     92         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "---> 93         for m_key, m_args in meta_kwargs.items():\n",
      "     94             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     95             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(94)fuse_meta_into_embeddings()\n",
      "     92         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     93         for m_key, m_args in meta_kwargs.items():\n",
      "---> 94             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     95             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     96 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(95)fuse_meta_into_embeddings()\n",
      "     93         for m_key, m_args in meta_kwargs.items():\n",
      "     94             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "---> 95             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     96 \n",
      "     97             if len(idx):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(97)fuse_meta_into_embeddings()\n",
      "     95             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     96 \n",
      "---> 97             if len(idx):\n",
      "     98                 m_idx,m_repr,m_repr_mask = self.resize(m_args['idx'], m_args['meta_repr'], m_args['data2ptr'][idx])\n",
      "     99                 m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(98)fuse_meta_into_embeddings()\n",
      "     96 \n",
      "     97             if len(idx):\n",
      "---> 98                 m_idx,m_repr,m_repr_mask = self.resize(m_args['idx'], m_args['meta_repr'], m_args['data2ptr'][idx])\n",
      "     99                 m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "    100 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(99)fuse_meta_into_embeddings()\n",
      "     97             if len(idx):\n",
      "     98                 m_idx,m_repr,m_repr_mask = self.resize(m_args['idx'], m_args['meta_repr'], m_args['data2ptr'][idx])\n",
      "---> 99                 m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "    100 \n",
      "    101                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(101)fuse_meta_into_embeddings()\n",
      "     99                 m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "    100 \n",
      "--> 101                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "    102                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "    103 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  len(idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(102)fuse_meta_into_embeddings()\n",
      "    100 \n",
      "    101                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "--> 102                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "    103 \n",
      "    104                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(104)fuse_meta_into_embeddings()\n",
      "    102                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "    103 \n",
      "--> 104                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "    105                 data_fused_repr[idx] += fused_repr\n",
      "    106 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_fused_repr[idx].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(105)fuse_meta_into_embeddings()\n",
      "    103 \n",
      "    104                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "--> 105                 data_fused_repr[idx] += fused_repr\n",
      "    106 \n",
      "    107         return data_fused_repr.squeeze(), meta_repr\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(93)fuse_meta_into_embeddings()\n",
      "     91 \n",
      "     92         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "---> 93         for m_key, m_args in meta_kwargs.items():\n",
      "     94             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     95             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_20255/3568055818.py(107)fuse_meta_into_embeddings()\n",
      "    105                 data_fused_repr[idx] += fused_repr\n",
      "    106 \n",
      "--> 107         return data_fused_repr.squeeze(), meta_repr\n",
      "    108 \n",
      "    109 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[-0.0...ezeBackward0>), {'cat2data': tensor([[0., ...dexBackward0>)})\n",
      "> /tmp/ipykernel_20255/3568055818.py(107)fuse_meta_into_embeddings()\n",
      "    105                 data_fused_repr[idx] += fused_repr\n",
      "    106 \n",
      "--> 107         return data_fused_repr.squeeze(), meta_repr\n",
      "    108 \n",
      "    109 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XCModelOutput(loss=tensor(0.0737, device='cuda:0', grad_fn=<AddBackward0>), logits=None, data_repr=tensor([[-0.0346, -0.0148, -0.0316,  ...,  0.0544,  0.0028, -0.0312],\n",
       "        [-0.0225, -0.0189, -0.0329,  ...,  0.0344, -0.0342,  0.0102],\n",
       "        [ 0.0112,  0.0063, -0.0371,  ...,  0.0715, -0.0157,  0.0266],\n",
       "        [ 0.0698,  0.0139,  0.0030,  ...,  0.0345, -0.0052,  0.0286],\n",
       "        [-0.0170, -0.0224, -0.0301,  ...,  0.0244, -0.0210, -0.0329]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>), data_fused_repr=tensor([[-0.0331, -0.0150, -0.0304,  ...,  0.0532,  0.0017, -0.0300],\n",
       "        [-0.0219, -0.0186, -0.0314,  ...,  0.0326, -0.0325,  0.0088],\n",
       "        [ 0.0098,  0.0051, -0.0356,  ...,  0.0717, -0.0159,  0.0251],\n",
       "        [ 0.0695,  0.0125,  0.0019,  ...,  0.0329, -0.0060,  0.0270],\n",
       "        [-0.0171, -0.0221, -0.0292,  ...,  0.0229, -0.0208, -0.0317]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>), lbl2data_repr=tensor([[-0.0244, -0.0302, -0.0259,  ...,  0.0584,  0.0058, -0.0318],\n",
       "        [-0.0225, -0.0189, -0.0329,  ...,  0.0344, -0.0342,  0.0102],\n",
       "        [ 0.0061,  0.0408, -0.0347,  ...,  0.0263, -0.0338, -0.0048],\n",
       "        [ 0.0392,  0.0053,  0.0791,  ..., -0.0269, -0.0172,  0.0698],\n",
       "        [ 0.0358,  0.0146,  0.0086,  ...,  0.0373, -0.0104, -0.0009]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>), lbl2data_fused_repr=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f80b8-5c78-4f92-a1e2-74a5c996f286",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9064308f-6259-43fc-8c30-96972cf79483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK002(OAK001, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK001.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        n_labels:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.label_embeddings = nn.Embedding(n_labels, config.dim, sparse=True)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_label_embeddings(self):\n",
    "        self.label_embeddings.weight.data = torch.zeros_like(self.label_embeddings.weight.data)\n",
    "\n",
    "    def get_label_representation(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask)\n",
    "        data_o.rep = F.normalize(data_o.rep + self.label_embeddings(data_idx), dim=1)\n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(lbl2data_idx), dim=1)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae28e5a-4211-486a-8858-f847380a8102",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e19d3f3e-e599-49b2-9630-75f8f1092363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK002 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight', 'label_embeddings.weight', 'meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK002.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000, n_labels=block.n_lbl,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "model.init_label_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "029c620e-8962-4575-8dde-5eddca73b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(block.train.dset.meta['cat_meta'].n_meta, model.config.dim))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c67a086-d93b-4ab5-98ec-0f51b70a0277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f5c10eb-7302-441b-8bc3-463066367a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d591f8-58dc-4931-8884-b74cb26457b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4597145d-94bf-4ed2-b5de-01f78c843de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749b81d-2eac-4e86-8f28-3de67ea481c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f095489f-66c1-43ef-85ce-dee54f539d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc47d381-9e59-4a0e-8f3f-f2f4bce7128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a233321a-c4cc-4090-8e01-613821a1b294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3657616883.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b.to(model.device))\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 2 at /tmp/ipykernel_5633/3295374159.py:37\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3295374159.py(52)forward()\n",
      "     50         **kwargs\n",
      "     51     ):  \n",
      "---> 52         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     53 \n",
      "     54         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3295374159.py(54)forward()\n",
      "     52         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     53 \n",
      "---> 54         if self.use_encoder_parallel:\n",
      "     55             encoder = XCDataParallel(module=self.encoder)\n",
      "     56         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3295374159.py(56)forward()\n",
      "     54         if self.use_encoder_parallel:\n",
      "     55             encoder = XCDataParallel(module=self.encoder)\n",
      "---> 56         else: encoder = self.encoder\n",
      "     57 \n",
      "     58         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3295374159.py(58)forward()\n",
      "     56         else: encoder = self.encoder\n",
      "     57 \n",
      "---> 58         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     59         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     60                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_5633/799089617.py(159)_get_encoder_meta_kwargs()\n",
      "    157         )\n",
      "    158 \n",
      "--> 159     def _get_encoder_meta_kwargs(self, feat:str, prefix:str, **kwargs):\n",
      "    160         meta_kwargs = Parameters.from_feat_meta_aug_prefix(feat, prefix, **kwargs)\n",
      "    161         if f'{prefix}_idx' in meta_kwargs:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/799089617.py(160)_get_encoder_meta_kwargs()\n",
      "    158 \n",
      "    159     def _get_encoder_meta_kwargs(self, feat:str, prefix:str, **kwargs):\n",
      "--> 160         meta_kwargs = Parameters.from_feat_meta_aug_prefix(feat, prefix, **kwargs)\n",
      "    161         if f'{prefix}_idx' in meta_kwargs:\n",
      "    162             m_idx = meta_kwargs[f'{prefix}_idx']\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/799089617.py(161)_get_encoder_meta_kwargs()\n",
      "    159     def _get_encoder_meta_kwargs(self, feat:str, prefix:str, **kwargs):\n",
      "    160         meta_kwargs = Parameters.from_feat_meta_aug_prefix(feat, prefix, **kwargs)\n",
      "--> 161         if f'{prefix}_idx' in meta_kwargs:\n",
      "    162             m_idx = meta_kwargs[f'{prefix}_idx']\n",
      "    163             meta_kwargs[f'{prefix}_meta_repr'] = self.meta_embeddings(m_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/799089617.py(162)_get_encoder_meta_kwargs()\n",
      "    160         meta_kwargs = Parameters.from_feat_meta_aug_prefix(feat, prefix, **kwargs)\n",
      "    161         if f'{prefix}_idx' in meta_kwargs:\n",
      "--> 162             m_idx = meta_kwargs[f'{prefix}_idx']\n",
      "    163             meta_kwargs[f'{prefix}_meta_repr'] = self.meta_embeddings(m_idx)\n",
      "    164         return meta_kwargs\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/799089617.py(163)_get_encoder_meta_kwargs()\n",
      "    161         if f'{prefix}_idx' in meta_kwargs:\n",
      "    162             m_idx = meta_kwargs[f'{prefix}_idx']\n",
      "--> 163             meta_kwargs[f'{prefix}_meta_repr'] = self.meta_embeddings(m_idx)\n",
      "    164         return meta_kwargs\n",
      "    165 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cat2data_attention_mask', 'cat2data_input_ids', 'cat2data_idx', 'cat2data_data2ptr'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/799089617.py(164)_get_encoder_meta_kwargs()\n",
      "    162             m_idx = meta_kwargs[f'{prefix}_idx']\n",
      "    163             meta_kwargs[f'{prefix}_meta_repr'] = self.meta_embeddings(m_idx)\n",
      "--> 164         return meta_kwargs\n",
      "    165 \n",
      "    166 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_kwargs[f'{prefix}_meta_repr'].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "{'cat2data_attention_mask': tensor([[1, 1... 0, 0, 0, 0]]), 'cat2data_data2ptr': tensor([3, 1, 3, 3, 3]), 'cat2data_idx': tensor([16184...4875,  84866]), 'cat2data_input_ids': tensor([[  10...   0,     0]]), ...}\n",
      "> /tmp/ipykernel_5633/799089617.py(164)_get_encoder_meta_kwargs()\n",
      "    162             m_idx = meta_kwargs[f'{prefix}_idx']\n",
      "    163             meta_kwargs[f'{prefix}_meta_repr'] = self.meta_embeddings(m_idx)\n",
      "--> 164         return meta_kwargs\n",
      "    165 \n",
      "    166 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3295374159.py(59)forward()\n",
      "     57 \n",
      "     58         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 59         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     60                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     61 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3295374159.py(60)forward()\n",
      "     58         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     59         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 60                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     61 \n",
      "     62 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3295374159.py(59)forward()\n",
      "     57 \n",
      "     58         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 59         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     60                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     61 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3295374159.py(60)forward()\n",
      "     58         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     59         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 60                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     61 \n",
      "     62 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3295374159.py(59)forward()\n",
      "     57 \n",
      "     58         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 59         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     60                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     61 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1528)_wrapped_call_impl()\n",
      "   1526         return result\n",
      "   1527 \n",
      "-> 1528     def _wrapped_call_impl(self, *args, **kwargs):\n",
      "   1529         if self._compiled_call_impl is not None:\n",
      "   1530             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1529)_wrapped_call_impl()\n",
      "   1527 \n",
      "   1528     def _wrapped_call_impl(self, *args, **kwargs):\n",
      "-> 1529         if self._compiled_call_impl is not None:\n",
      "   1530             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1531         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1532)_wrapped_call_impl()\n",
      "   1530             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1531         else:\n",
      "-> 1532             return self._call_impl(*args, **kwargs)\n",
      "   1533 \n",
      "   1534     def _call_impl(self, *args, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1534)_call_impl()\n",
      "   1532             return self._call_impl(*args, **kwargs)\n",
      "   1533 \n",
      "-> 1534     def _call_impl(self, *args, **kwargs):\n",
      "   1535         forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1535)_call_impl()\n",
      "   1533 \n",
      "   1534     def _call_impl(self, *args, **kwargs):\n",
      "-> 1535         forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1537         # this function, and just call forward.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1538)_call_impl()\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1537         # this function, and just call forward.\n",
      "-> 1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1539)_call_impl()\n",
      "   1537         # this function, and just call forward.\n",
      "   1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "-> 1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1541             return forward_call(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1538)_call_impl()\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1537         # this function, and just call forward.\n",
      "-> 1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1539)_call_impl()\n",
      "   1537         # this function, and just call forward.\n",
      "   1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "-> 1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1541             return forward_call(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1538)_call_impl()\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1537         # this function, and just call forward.\n",
      "-> 1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1540)_call_impl()\n",
      "   1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "-> 1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1541             return forward_call(*args, **kwargs)\n",
      "   1542 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1538)_call_impl()\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1537         # this function, and just call forward.\n",
      "-> 1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1540)_call_impl()\n",
      "   1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "-> 1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1541             return forward_call(*args, **kwargs)\n",
      "   1542 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1538)_call_impl()\n",
      "   1536         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1537         # this function, and just call forward.\n",
      "-> 1538         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/torch/nn/modules/module.py(1541)_call_impl()\n",
      "   1539                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1540                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "-> 1541             return forward_call(*args, **kwargs)\n",
      "   1542 \n",
      "   1543         try:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_5633/3568055818.py(110)forward()\n",
      "    108 \n",
      "    109 \n",
      "--> 110     def forward(\n",
      "    111         self,\n",
      "    112         data_input_ids: torch.Tensor,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(119)forward()\n",
      "    117         **kwargs\n",
      "    118     ):  \n",
      "--> 119         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    120 \n",
      "    121         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(121)forward()\n",
      "    119         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    120 \n",
      "--> 121         if data_type is not None and data_type == \"meta\":\n",
      "    122             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    123         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(124)forward()\n",
      "    122             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    123         else:\n",
      "--> 124             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    125 \n",
      "    126         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(126)forward()\n",
      "    124             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    125 \n",
      "--> 126         data_fused_repr = meta_repr = None\n",
      "    127         if data_aug_meta_prefix is not None:\n",
      "    128             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(127)forward()\n",
      "    125 \n",
      "    126         data_fused_repr = meta_repr = None\n",
      "--> 127         if data_aug_meta_prefix is not None:\n",
      "    128             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    129             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(128)forward()\n",
      "    126         data_fused_repr = meta_repr = None\n",
      "    127         if data_aug_meta_prefix is not None:\n",
      "--> 128             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    129             if len(meta_kwargs):\n",
      "    130                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(129)forward()\n",
      "    127         if data_aug_meta_prefix is not None:\n",
      "    128             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "--> 129             if len(meta_kwargs):\n",
      "    130                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    131                                                                             torch.any(data_attention_mask, dim=1),\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> /tmp/ipykernel_5633/3568055818.py(130)forward()\n",
      "    128             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    129             if len(meta_kwargs):\n",
      "--> 130                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    131                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    132                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cat2data'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_kwargs['cat2data']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]), 'input_ids': tensor([[  101, 17332,  2683, 17228,  1999,  1996,  3009,  3400,   102,     0,\n",
      "             0,     0],\n",
      "        [  101,  2163,  1998,  6500,  2511,  1999,  3069,   102,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 13515, 17228,  1999,  1996,  3803,  3400,   102,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  4331,  1997, 13491,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  8055,  2163,  2510,  5073,  2730,  1999,  1996,  2137,  2942,\n",
      "          2162,   102],\n",
      "        [  101, 23109,  2012,  3146,  2110,  4528,   102,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2142,  2163,  2510,  2914,  9441,   102,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2163,  1998,  6500,  2511,  1999,  5497,   102,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  6941,  1997,  2710,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  7649,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  6500,  2104,  2510,  6139,   102,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  7726,  3032,  1998,  6500,   102,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  7726,  9814,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'idx': tensor([161847, 161863, 161853, 138151,  54425, 102551,  54422,  79395, 102793,\n",
      "        102791,  84879,  84875,  84866]), 'data2ptr': tensor([3, 1, 3, 3, 3]), 'meta_repr': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<EmbeddingBackward0>)}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_kwargs['cat2data'].keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['attention_mask', 'input_ids', 'idx', 'data2ptr', 'meta_repr'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(131)forward()\n",
      "    129             if len(meta_kwargs):\n",
      "    130                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "--> 131                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    132                                                                             meta_kwargs)\n",
      "    133                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(132)forward()\n",
      "    130                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    131                                                                             torch.any(data_attention_mask, dim=1),\n",
      "--> 132                                                                             meta_kwargs)\n",
      "    133                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    134 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(130)forward()\n",
      "    128             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    129             if len(meta_kwargs):\n",
      "--> 130                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    131                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    132                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_5633/3568055818.py(89)fuse_meta_into_embeddings()\n",
      "     87 \n",
      "     88 \n",
      "---> 89     def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "     90         meta_repr = {}\n",
      "     91 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(90)fuse_meta_into_embeddings()\n",
      "     88 \n",
      "     89     def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "---> 90         meta_repr = {}\n",
      "     91 \n",
      "     92         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(92)fuse_meta_into_embeddings()\n",
      "     90         meta_repr = {}\n",
      "     91 \n",
      "---> 92         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     93         for m_key, m_args in meta_kwargs.items():\n",
      "     94             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(93)fuse_meta_into_embeddings()\n",
      "     91 \n",
      "     92         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "---> 93         for m_key, m_args in meta_kwargs.items():\n",
      "     94             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     95             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(94)fuse_meta_into_embeddings()\n",
      "     92         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     93         for m_key, m_args in meta_kwargs.items():\n",
      "---> 94             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     95             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     96 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(95)fuse_meta_into_embeddings()\n",
      "     93         for m_key, m_args in meta_kwargs.items():\n",
      "     94             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "---> 95             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     96 \n",
      "     97             if len(idx):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(97)fuse_meta_into_embeddings()\n",
      "     95             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     96 \n",
      "---> 97             if len(idx):\n",
      "     98                 m_idx,m_repr,m_repr_mask = self.resize(m_args['idx'], m_args['meta_repr'], m_args['data2ptr'][idx])\n",
      "     99                 m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(98)fuse_meta_into_embeddings()\n",
      "     96 \n",
      "     97             if len(idx):\n",
      "---> 98                 m_idx,m_repr,m_repr_mask = self.resize(m_args['idx'], m_args['meta_repr'], m_args['data2ptr'][idx])\n",
      "     99                 m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "    100 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(99)fuse_meta_into_embeddings()\n",
      "     97             if len(idx):\n",
      "     98                 m_idx,m_repr,m_repr_mask = self.resize(m_args['idx'], m_args['meta_repr'], m_args['data2ptr'][idx])\n",
      "---> 99                 m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "    100 \n",
      "    101                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(101)fuse_meta_into_embeddings()\n",
      "     99                 m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "    100 \n",
      "--> 101                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "    102                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "    103 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(102)fuse_meta_into_embeddings()\n",
      "    100 \n",
      "    101                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "--> 102                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "    103 \n",
      "    104                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(104)fuse_meta_into_embeddings()\n",
      "    102                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "    103 \n",
      "--> 104                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "    105                 data_fused_repr[idx] += fused_repr\n",
      "    106 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(105)fuse_meta_into_embeddings()\n",
      "    103 \n",
      "    104                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "--> 105                 data_fused_repr[idx] += fused_repr\n",
      "    106 \n",
      "    107         return data_fused_repr.squeeze(), meta_repr\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(93)fuse_meta_into_embeddings()\n",
      "     91 \n",
      "     92         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "---> 93         for m_key, m_args in meta_kwargs.items():\n",
      "     94             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     95             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3568055818.py(107)fuse_meta_into_embeddings()\n",
      "    105                 data_fused_repr[idx] += fused_repr\n",
      "    106 \n",
      "--> 107         return data_fused_repr.squeeze(), meta_repr\n",
      "    108 \n",
      "    109 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[-0.0...ezeBackward0>), {'cat2data': tensor([[0., ...dexBackward0>)})\n",
      "> /tmp/ipykernel_5633/3568055818.py(107)fuse_meta_into_embeddings()\n",
      "    105                 data_fused_repr[idx] += fused_repr\n",
      "    106 \n",
      "--> 107         return data_fused_repr.squeeze(), meta_repr\n",
      "    108 \n",
      "    109 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_5633/3295374159.py(63)forward()\n",
      "     61 \n",
      "     62 \n",
      "---> 63         loss = None; lbl2data_o = EncoderOutput()\n",
      "     64         if lbl2data_input_ids is not None:\n",
      "     65             lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "o = func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e77cff15-2e99-4da3-a24e-c67a4d7da6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0202, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f32e1e-5f59-4b3d-ac54-819a2fbc6771",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "72eb188c-b2fc-4e01-84a2-ecbaf0f28db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK003(OAK001, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK001.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        n_labels:int,\n",
    "        n_clusters:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.label_embeddings = nn.Embedding(n_clusters, config.dim, sparse=True)\n",
    "        self.register_buffer(\"label_remap\", torch.arange(n_labels)%n_clusters, persistent=True)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_label_embeddings(self):\n",
    "        self.label_embeddings.weight.data = torch.zeros_like(self.label_embeddings.weight.data)\n",
    "\n",
    "    def set_label_embeddings(self, embed:torch.Tensor):\n",
    "        self.label_embeddings.weight.data = embed\n",
    "\n",
    "    def set_label_remap(self, label_remap:torch.Tensor):\n",
    "        if label_remap.shape[0] != self.label_remap.shape[0]:\n",
    "            raise ValueError(f'Shape mismatch, `label_remap` should have {self.label_remap.shape[0]} elements.')\n",
    "        self.label_remap = label_remap\n",
    "\n",
    "    def get_label_representation(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask)\n",
    "        data_o.rep = F.normalize(data_o.rep + self.label_embeddings(self.label_remap[data_idx]), dim=1)\n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2e7dc-71c6-4857-b0fb-fcd869baf67d",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d66ef7e-f5c8-4823-bdc4-99542aeb4d72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK003 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight', 'label_embeddings.weight', 'label_remap', 'meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK003.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000, \n",
    "                               n_labels=block.n_lbl, n_clusters=block.n_lbl//3,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "model.init_label_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a1dbed8-f942-4fb5-8754-cb6df533c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(block.train.dset.meta['cat_meta'].n_meta, model.config.dim))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a56d6e-b878-4e55-8e86-bbd0bba8c182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6aed62e-379e-4d6f-bc1d-63afc2382d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0742798-b05e-4bcb-a8fd-6efcbbea0751",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d7215e8-77b8-486c-8c3b-804e121ee03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab987e-7ac6-452b-a045-bed5a33efa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4ed2db1-6ee3-4a35-bc57-ab7961d67fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09d89967-a8a8-45e8-8636-1e438e88db6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0202, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b870501-6611-4840-9bce-aa64ed0ad6db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK004`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df87de38-dbed-48df-b09d-7789a7666518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK004(OAK001, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK001.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        n_labels:int,\n",
    "        n_clusters:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.label_embeddings = nn.Embedding(n_clusters, config.dim)\n",
    "        self.register_buffer(\"label_remap\", torch.arange(n_labels)%n_clusters, persistent=True)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_label_embeddings(self):\n",
    "        self.label_embeddings.weight.data = torch.zeros_like(self.label_embeddings.weight.data)\n",
    "\n",
    "    def set_label_embeddings(self, embed:torch.Tensor):\n",
    "        self.label_embeddings.weight.data = embed\n",
    "\n",
    "    def set_label_remap(self, label_remap:torch.Tensor):\n",
    "        if label_remap.shape[0] != self.label_remap.shape[0]:\n",
    "            raise ValueError(f'Shape mismatch, `label_remap` should have {self.label_remap.shape[0]} elements.')\n",
    "        self.label_remap = label_remap\n",
    "\n",
    "    def get_label_representation(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask)\n",
    "        data_o.rep = F.normalize(data_o.rep + self.label_embeddings(self.label_remap[data_idx]), dim=1)\n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca33e1bd-1e9f-4935-ad5e-7630ae2852b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "481ad336-eaaa-4891-9584-8712061a40ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK004 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight', 'label_embeddings.weight', 'label_remap', 'meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK004.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, resize_length=5000, \n",
    "                               n_labels=block.n_lbl, n_clusters=block.n_lbl//3,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "model.init_label_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec135539-32a9-4bda-9020-d54048844521",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(block.train.dset.meta['cat_meta'].n_meta, model.config.dim))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa4e047-b4fd-4452-83f4-3c554db4f0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68e62901-20bc-4619-8496-42682c9df909",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6140a-033a-4921-b1ef-10cd5786db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feddc1bd-e589-4ab0-932c-b5b713cb9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102233b8-2901-4479-91c7-3522fb248ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0c6c121-cb0f-4ae8-b9d7-e4088bc79d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc3d1b27-d0d3-412d-9c4b-6b7b7d2b974b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ed466-4d93-4253-b131-69843b13867c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
