{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd48060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.oakX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d95873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2fc4a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, re, inspect, pickle, os, torch.nn as nn, math\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Tuple, Mapping, Any, Union\n",
    "from transformers import (\n",
    "    PretrainedConfig,\n",
    "    DistilBertForMaskedLM,\n",
    "    DistilBertModel,\n",
    "    DistilBertPreTrainedModel,\n",
    ")\n",
    "from transformers.utils.generic import ModelOutput\n",
    "from transformers.activations import get_activation\n",
    "\n",
    "from fastcore.meta import *\n",
    "from fastcore.utils import *\n",
    "\n",
    "from xcai.losses import *\n",
    "from xcai.core import store_attr\n",
    "from xcai.learner import XCDataParallel\n",
    "from xcai.models.modeling_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee9b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c00009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from xcai.block import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff9c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ede14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb671af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/xclib-0.97-py3.9-linux-x86_64.egg/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/scai/phd/aiz218323/Projects/XC/data/'\n",
    "\n",
    "block = XCBlock.from_cfg(data_dir, 'data_lnk', transform_type='xcs', tokenizer='distilbert-base-uncased', \n",
    "                         sampling_features=[('lbl2data',1), ('lnk2data',3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ed19a-d454-47f8-857d-e8df71005511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04c1d105-6978-44b6-a9c9-851220d03e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealsotitles_data-lnk_distilbert-base-uncased_xcs.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f843bd7a-d18c-4f44-bd4b-c56064ee937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'wb') as file: pickle.dump(block, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b4c48b-178b-4136-a5c0-0009ddb84dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e9f4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "658cc0a9-b411-44f5-b675-3424c68bae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "block.collator.tfms.tfms[0].sampling_features = [('lbl2data',1), ('lnk2data',3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c50e879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(5)\n",
    "for i,batch in enumerate(block.train.dl):\n",
    "    if i > 2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f9f36e-bf56-4af0-8a38-89860721f191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_identifier', 'lnk2data_input_text', 'lnk2data_input_ids', 'lnk2data_attention_mask', 'lnk2data_data2ptr', 'lnk2lbl2data_idx', 'lnk2lbl2data_identifier', 'lnk2lbl2data_input_text', 'lnk2lbl2data_input_ids', 'lnk2lbl2data_attention_mask', 'lnk2lbl2data_data2ptr', 'lnk2lbl2data_lbl2data2ptr', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'data_idx'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a8737b",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5ed7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder(DistilBertPreTrainedModel):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig, \n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        \n",
    "        self.dr_head = RepresentationHead(config)\n",
    "        self.dr_fused_head = RepresentationHead(config)\n",
    "        self.meta_head = RepresentationHead(config)\n",
    "        self.cross_head = CrossAttention(config)\n",
    "\n",
    "        self.pretrained_meta_embeddings = nn.Embedding(num_metadata, config.dim, sparse=True)\n",
    "        \n",
    "        self.ones = torch.ones(resize_length, dtype=torch.long, device=self.device) if resize_length is not None else None\n",
    "        self.post_init()\n",
    "\n",
    "    def freeze_pretrained_meta_embeddings(self):\n",
    "        self.pretrained_meta_embeddings.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_pretrained_meta_embeddings(self):\n",
    "        self.pretrained_meta_embeddings.requires_grad_(True)\n",
    "\n",
    "    def set_pretrained_meta_embeddings(self, embed:torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            self.pretrained_meta_embeddings.weight.copy_(embed)\n",
    "        \n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        return self.distilbert.get_position_embeddings()\n",
    "    \n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "        self.distilbert.resize_position_embeddings(new_num_position_embeddings)\n",
    "    \n",
    "    def encode(self, input_ids:torch.Tensor, attention_mask:torch.Tensor, **kwargs):\n",
    "        return self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    def dr(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.dr_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "\n",
    "    def dr_fused(self, embed:torch.Tensor):\n",
    "        embed = self.dr_fused_head(embed)\n",
    "        return F.normalize(embed, dim=1)\n",
    "\n",
    "    def meta(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.meta_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "    \n",
    "    def meta_unnormalized(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.meta_head(embed)\n",
    "        return Pooling.mean_pooling(embed, attention_mask)\n",
    "\n",
    "    def resize(self, idx:torch.Tensor, rep:torch.Tensor, num_inputs:torch.Tensor):\n",
    "        if torch.any(num_inputs == 0): raise ValueError(\"`num_inputs` should be non-zero positive integer.\")\n",
    "        bsz, total_num_inputs = num_inputs.shape[0], idx.shape[0]\n",
    "        \n",
    "        self.ones = self.ones.to(idx.device)\n",
    "        ones = (\n",
    "            torch.ones(total_num_inputs, dtype=torch.long, device=idx.device) \n",
    "            if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
    "        )\n",
    "        \n",
    "        max_num_inputs = num_inputs.max()\n",
    "        if (num_inputs == max_num_inputs).all():\n",
    "            return idx,rep,ones\n",
    "        \n",
    "        xnum_inputs = max_num_inputs-num_inputs+1\n",
    "        \n",
    "        inputs_ptr = num_inputs.cumsum(dim=0)-1\n",
    "        repeat_inputs = ones.scatter(0, inputs_ptr, xnum_inputs)\n",
    "        \n",
    "        resized_idx = idx.repeat_interleave(repeat_inputs, dim=0)\n",
    "        resized_rep = rep.repeat_interleave(repeat_inputs, dim=0)\n",
    "        \n",
    "        ignore_mask = ones.scatter(0, inputs_ptr, 0).repeat_interleave(repeat_inputs, dim=0).view(bsz, -1)\n",
    "        ignore_mask[:, -1] = 1; ignore_mask = ignore_mask.flatten()\n",
    "        \n",
    "        return resized_idx,resized_rep,ignore_mask\n",
    "        \n",
    "\n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
    "            \n",
    "            if len(idx):\n",
    "                m_idx,m_repr,m_repr_mask = self.resize(m_args['idx'], m_args['meta_repr'], m_args['data2ptr'][idx])\n",
    "                m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
    "                \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
    "                meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "                \n",
    "                fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                data_fused_repr[idx] += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_type:Optional[str]=None,\n",
    "        data_unnormalized:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        \n",
    "        if data_type is not None and data_type == \"meta\":\n",
    "            data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
    "        else: \n",
    "            data_repr = self.dr(data_o[0], data_attention_mask)\n",
    "        \n",
    "        data_fused_repr = meta_repr = None\n",
    "        if data_aug_meta_prefix is not None:\n",
    "            meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
    "            if len(meta_kwargs):\n",
    "                data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
    "                                                                            torch.any(data_attention_mask, dim=1), \n",
    "                                                                            meta_kwargs)\n",
    "                data_fused_repr = self.dr_fused(data_fused_repr)\n",
    "                \n",
    "        return EncoderOutput(\n",
    "            rep=data_repr,\n",
    "            fused_rep=data_fused_repr,\n",
    "            meta_repr=meta_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba618800-3966-4b2a-b887-96faa1cda5b5",
   "metadata": {},
   "source": [
    "## `OAK000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bf51c610-41c8-4752-b2e6-5ac4cd5492ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK000(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, config,\n",
    "        \n",
    "        data_aug_meta_prefix:Optional[str]=None, \n",
    "        lbl2data_aug_meta_prefix:Optional[str]=None, \n",
    "\n",
    "        data_pred_meta_prefix:Optional[str]=None,\n",
    "        lbl2data_pred_meta_prefix:Optional[str]=None,\n",
    "        \n",
    "        num_batch_labels:Optional[int]=None, \n",
    "        batch_size:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        num_negatives:Optional[int]=5,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=True,\n",
    "\n",
    "        calib_margin:Optional[float]=0.3,\n",
    "        calib_num_negatives:Optional[int]=10,\n",
    "        calib_tau:Optional[float]=0.1,\n",
    "        calib_apply_softmax:Optional[bool]=False,\n",
    "        calib_loss_weight:Optional[float]=0.1,\n",
    "        use_calib_loss:Optional[float]=False,\n",
    "        \n",
    "        meta_loss_weight:Optional[Union[List,float]]=0.3,\n",
    "        \n",
    "        use_fusion_loss:Optional[bool]=False,\n",
    "        fusion_loss_weight:Optional[float]=0.15,\n",
    "\n",
    "        use_query_loss:Optional[float]=True,\n",
    "        \n",
    "        use_encoder_parallel:Optional[bool]=True,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        store_attr('meta_loss_weight,fusion_loss_weight,calib_loss_weight')\n",
    "        store_attr('data_pred_meta_prefix,lbl2data_pred_meta_prefix')\n",
    "        store_attr('data_aug_meta_prefix,lbl2data_aug_meta_prefix')\n",
    "        store_attr('use_fusion_loss,use_query_loss,use_calib_loss,use_encoder_parallel')\n",
    "        \n",
    "        self.rep_loss_fn = MultiTriplet(bsz=batch_size, tn_targ=num_batch_labels, margin=margin, n_negatives=num_negatives, \n",
    "                                        tau=tau, apply_softmax=apply_softmax, reduce='mean')\n",
    "        self.cab_loss_fn = Calibration(margin=calib_margin, tau=calib_tau, n_negatives=calib_num_negatives, \n",
    "                                       apply_softmax=calib_apply_softmax, reduce='mean')\n",
    "        self.encoder, self.meta_embeddings = None, None\n",
    "        \n",
    "    def init_meta_embeddings(self):\n",
    "        torch.nn.init.zeros_(self.meta_embeddings.weight)\n",
    "\n",
    "    def freeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(True)\n",
    "\n",
    "    def set_meta_embeddings(self, embed:torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            self.meta_embeddings.weight.copy_(embed)\n",
    "    \n",
    "    def init_retrieval_head(self):\n",
    "        if self.encoder is None: raise ValueError('`self.encoder` is not initialized.')\n",
    "        self.encoder.dr_head.post_init()\n",
    "        self.encoder.meta_head.post_init()\n",
    "        self.encoder.dr_fused_head.post_init()\n",
    "\n",
    "    def init_cross_head(self):\n",
    "        if self.encoder is None: raise ValueError('`self.encoder` is not initialized.')\n",
    "        self.encoder.cross_head.post_init()\n",
    "\n",
    "    def compute_loss(self, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.rep_loss_fn(inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "\n",
    "    def calibration_loss(self, einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.calib_loss_weight * self.cab_loss_fn(einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "    \n",
    "    def compute_meta_loss(self, data_repr, lbl2data_repr, **kwargs):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "            \n",
    "        data_meta_inputs = Parameters.from_meta_pred_prefix(self.data_pred_meta_prefix, **kwargs)\n",
    "        lbl2data_meta_inputs = Parameters.from_meta_pred_prefix(self.lbl2data_pred_meta_prefix, **kwargs)\n",
    "        meta_inputs = {**data_meta_inputs, **lbl2data_meta_inputs}\n",
    "\n",
    "        m_lw = Parameters.get_meta_loss_weights(self.meta_loss_weight, len(meta_inputs)) if len(meta_inputs) else []\n",
    "        \n",
    "        loss = 0.0\n",
    "        for inputs,lw in zip(meta_inputs.values(), m_lw):\n",
    "            if 'lbl2data2ptr' in inputs:\n",
    "                idx = torch.where(inputs['lbl2data2ptr'])[0]\n",
    "                if len(idx) > 0:\n",
    "                    inputs_o = encoder(data_input_ids=inputs['input_ids'], data_attention_mask=inputs['attention_mask'], \n",
    "                                       data_type=\"meta\")\n",
    "                    m_loss = self.rep_loss_fn(lbl2data_repr[idx], inputs_o.rep, inputs['lbl2data2ptr'][idx],\n",
    "                                              inputs['idx'], inputs['plbl2data2ptr'][idx], inputs['pidx'])\n",
    "                    loss += lw * m_loss\n",
    "\n",
    "            elif 'data2ptr' in inputs:\n",
    "                idx = torch.where(inputs['data2ptr'])[0]\n",
    "                if len(idx) > 0:\n",
    "                    inputs_o = encoder(data_input_ids=inputs['input_ids'], data_attention_mask=inputs['attention_mask'], \n",
    "                                       data_type=\"meta\")\n",
    "                    m_loss = self.rep_loss_fn(data_repr[idx], inputs_o.rep, inputs['data2ptr'][idx], inputs['idx'], \n",
    "                                              inputs['pdata2ptr'][idx], inputs['pidx'])\n",
    "                    loss += lw * m_loss       \n",
    "\n",
    "            else: raise ValueError('Invalid metadata input arguments.')\n",
    "        return loss\n",
    "\n",
    "    def compute_fusion_loss(self, data_repr, meta_repr:Dict, prefix:str, **kwargs):\n",
    "        meta_inputs = Parameters.from_meta_pred_prefix(prefix, **kwargs)\n",
    "        \n",
    "        loss = 0.0\n",
    "        if meta_repr is not None:\n",
    "            for key,input_repr in meta_repr.items():\n",
    "                inputs = meta_inputs[key]\n",
    "                if 'lbl2data2ptr' in inputs:\n",
    "                    idx = torch.where(inputs['lbl2data2ptr'])[0]\n",
    "                    if len(idx) > 0:\n",
    "                        m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['lbl2data2ptr'][idx],\n",
    "                                                  inputs['idx'], inputs['plbl2data2ptr'][idx], inputs['pidx'])\n",
    "                        loss += self.fusion_loss_weight * m_loss\n",
    "    \n",
    "                elif 'data2ptr' in inputs:\n",
    "                    idx = torch.where(inputs['data2ptr'])[0]\n",
    "                    if len(idx) > 0:\n",
    "                        m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['data2ptr'][idx], inputs['idx'], \n",
    "                                                  inputs['pdata2ptr'][idx], inputs['pidx'])\n",
    "                        loss += self.fusion_loss_weight * m_loss       \n",
    "    \n",
    "                else: raise ValueError('Invalid metadata input arguments.')\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def get_meta_representation(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "            \n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_unnormalized=True, data_type=\"meta\")\n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    def _get_encoder_meta_kwargs(self, feat:str, prefix:str, **kwargs):\n",
    "        meta_kwargs = Parameters.from_feat_meta_aug_prefix(feat, prefix, **kwargs)\n",
    "        return meta_kwargs\n",
    "    \n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae7ddb-b7bb-4633-9238-c081ecd049ef",
   "metadata": {},
   "source": [
    "## `OAK001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c92804f4-bccf-4aa4-bf5e-8ab7cabf1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK001(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.meta_embeddings = nn.Embedding(num_metadata, config.dim, sparse=True)\n",
    "        self.encoder = Encoder(config, num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def _get_encoder_meta_kwargs(self, feat:str, prefix:str, **kwargs):\n",
    "        meta_kwargs = Parameters.from_feat_meta_aug_prefix(feat, prefix, **kwargs)\n",
    "        if f'{prefix}_idx' in meta_kwargs:\n",
    "            m_idx = meta_kwargs[f'{prefix}_idx']\n",
    "            if len(m_idx): meta_kwargs[f'{prefix}_meta_repr'] = self.meta_embeddings(m_idx)\n",
    "        return meta_kwargs\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b6bbef-d971-42d2-8c2b-63e2d8f91101",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "86864591-7758-4b37-8702-fabfe8f872a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK001 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight', 'meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK001.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=10, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "58b2d36d-4e8c-4827-b535-db7c509dd187",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.ones(block.train.dset.meta['lnk_meta'].n_meta, model.config.dim))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5e54c-df22-4186-8b2d-61371a17a985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "18d585ba-dd70-4988-90ff-2fbed155f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4eca4074-7bbd-4c10-aa36-3896a339fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7610c-12c9-4e76-a491-8b0de8747838",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7636803-c585-4577-b914-21addece4069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "74dcdfea-660c-4726-a9d4-03eef45e0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3415984d-3419-4b98-9a43-59c2128fb81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0183, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d84627-0c4e-4e4f-8bd2-eee40fcf5d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083dc811-799f-4f59-8a5c-ef3afbd66c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c0641a1d-693d-4ad0-ab31-d620231a7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "680957d4-7bd2-46fa-b12f-4bb8a6f6b1db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/3657616883.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b.to(model.device))\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 1 at /tmp/ipykernel_36220/1449976710.py:158\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(173)forward()\n",
      "    171         **kwargs\n",
      "    172     ):  \n",
      "--> 173         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "    174 \n",
      "    175         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(175)forward()\n",
      "    173         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "    174 \n",
      "--> 175         if self.use_encoder_parallel:\n",
      "    176             encoder = XCDataParallel(module=self.encoder)\n",
      "    177         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(177)forward()\n",
      "    175         if self.use_encoder_parallel:\n",
      "    176             encoder = XCDataParallel(module=self.encoder)\n",
      "--> 177         else: encoder = self.encoder\n",
      "    178 \n",
      "    179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(179)forward()\n",
      "    177         else: encoder = self.encoder\n",
      "    178 \n",
      "--> 179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "    180         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "    181                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(180)forward()\n",
      "    178 \n",
      "    179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "--> 180         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "    181                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    182 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_meta_kwargs.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'dict' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lnk2data_attention_mask', 'lnk2data_input_ids', 'lnk2data_idx', 'lnk2data_data2ptr', 'lnk2data_meta_repr'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_meta_kwargs['lnk2data_data2ptr'].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_meta_kwargs['lnk2data_data2ptr']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 3, 3, 3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    175         if self.use_encoder_parallel:\n",
      "    176             encoder = XCDataParallel(module=self.encoder)\n",
      "    177         else: encoder = self.encoder\n",
      "    178 \n",
      "    179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "--> 180         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "    181                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    182 \n",
      "    183 \n",
      "    184         loss = None; lbl2data_o = EncoderOutput()\n",
      "    185         if lbl2data_input_ids is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b encoder.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 2 at /tmp/ipykernel_36220/179234550.py:111\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(181)forward()\n",
      "    179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "    180         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "--> 181                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    182 \n",
      "    183 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(180)forward()\n",
      "    178 \n",
      "    179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "--> 180         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "    181                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    182 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(181)forward()\n",
      "    179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "    180         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "--> 181                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    182 \n",
      "    183 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(180)forward()\n",
      "    178 \n",
      "    179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "--> 180         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "    181                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    182 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(120)forward()\n",
      "    118         **kwargs\n",
      "    119     ):  \n",
      "--> 120         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    121 \n",
      "    122         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(122)forward()\n",
      "    120         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    121 \n",
      "--> 122         if data_type is not None and data_type == \"meta\":\n",
      "    123             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    124         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_type\n",
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(125)forward()\n",
      "    123             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    124         else:\n",
      "--> 125             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    126 \n",
      "    127         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(127)forward()\n",
      "    125             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    126 \n",
      "--> 127         data_fused_repr = meta_repr = None\n",
      "    128         if data_aug_meta_prefix is not None:\n",
      "    129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(128)forward()\n",
      "    126 \n",
      "    127         data_fused_repr = meta_repr = None\n",
      "--> 128         if data_aug_meta_prefix is not None:\n",
      "    129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    130             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(129)forward()\n",
      "    127         data_fused_repr = meta_repr = None\n",
      "    128         if data_aug_meta_prefix is not None:\n",
      "--> 129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    130             if len(meta_kwargs):\n",
      "    131                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(130)forward()\n",
      "    128         if data_aug_meta_prefix is not None:\n",
      "    129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "--> 130             if len(meta_kwargs):\n",
      "    131                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    132                                                                             torch.any(data_attention_mask, dim=1),\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lnk2data'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_kwargs['lnk2data'].keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['attention_mask', 'input_ids', 'idx', 'data2ptr', 'meta_repr'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_kwargs['lnk2data']['meta_repr'].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(131)forward()\n",
      "    129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    130             if len(meta_kwargs):\n",
      "--> 131                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    132                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    133                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(132)forward()\n",
      "    130             if len(meta_kwargs):\n",
      "    131                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "--> 132                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    133                                                                             meta_kwargs)\n",
      "    134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(133)forward()\n",
      "    131                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    132                                                                             torch.any(data_attention_mask, dim=1),\n",
      "--> 133                                                                             meta_kwargs)\n",
      "    134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    135 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(131)forward()\n",
      "    129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    130             if len(meta_kwargs):\n",
      "--> 131                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    132                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    133                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_36220/179234550.py(90)fuse_meta_into_embeddings()\n",
      "     88 \n",
      "     89 \n",
      "---> 90     def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "     91         meta_repr = {}\n",
      "     92 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(91)fuse_meta_into_embeddings()\n",
      "     89 \n",
      "     90     def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "---> 91         meta_repr = {}\n",
      "     92 \n",
      "     93         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(93)fuse_meta_into_embeddings()\n",
      "     91         meta_repr = {}\n",
      "     92 \n",
      "---> 93         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     94         for m_key, m_args in meta_kwargs.items():\n",
      "     95             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(94)fuse_meta_into_embeddings()\n",
      "     92 \n",
      "     93         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "---> 94         for m_key, m_args in meta_kwargs.items():\n",
      "     95             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     96             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_fused_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(95)fuse_meta_into_embeddings()\n",
      "     93         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     94         for m_key, m_args in meta_kwargs.items():\n",
      "---> 95             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     96             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     97 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(96)fuse_meta_into_embeddings()\n",
      "     94         for m_key, m_args in meta_kwargs.items():\n",
      "     95             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "---> 96             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     97 \n",
      "     98             if len(idx):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(98)fuse_meta_into_embeddings()\n",
      "     96             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     97 \n",
      "---> 98             if len(idx):\n",
      "     99                 m_idx,m_repr,m_repr_mask = self.resize(m_args['idx'], m_args['meta_repr'], m_args['data2ptr'][idx])\n",
      "    100                 m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(99)fuse_meta_into_embeddings()\n",
      "     97 \n",
      "     98             if len(idx):\n",
      "---> 99                 m_idx,m_repr,m_repr_mask = self.resize(m_args['idx'], m_args['meta_repr'], m_args['data2ptr'][idx])\n",
      "    100                 m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "    101 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(100)fuse_meta_into_embeddings()\n",
      "     98             if len(idx):\n",
      "     99                 m_idx,m_repr,m_repr_mask = self.resize(m_args['idx'], m_args['meta_repr'], m_args['data2ptr'][idx])\n",
      "--> 100                 m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "    101 \n",
      "    102                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([117344, 161862, 161861, 487671, 309544, 129374, 102557, 102556,  54423,\n",
      "        559742,  79395, 102815,  84877,  84874,  84871], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(102)fuse_meta_into_embeddings()\n",
      "    100                 m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "    101 \n",
      "--> 102                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "    103                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "    104 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(103)fuse_meta_into_embeddings()\n",
      "    101 \n",
      "    102                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "--> 103                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "    104 \n",
      "    105                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(105)fuse_meta_into_embeddings()\n",
      "    103                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "    104 \n",
      "--> 105                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "    106                 data_fused_repr[idx] += fused_repr\n",
      "    107 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_fused_repr[idx].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_mask[idx].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361],\n",
      "         [0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361],\n",
      "         [0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361]],\n",
      "\n",
      "        [[0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361],\n",
      "         [0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361],\n",
      "         [0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361]],\n",
      "\n",
      "        [[0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361],\n",
      "         [0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361],\n",
      "         [0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361]],\n",
      "\n",
      "        [[0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361],\n",
      "         [0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361],\n",
      "         [0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361]],\n",
      "\n",
      "        [[0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361],\n",
      "         [0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361],\n",
      "         [0.0361, 0.0361, 0.0361,  ..., 0.0361, 0.0361, 0.0361]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100                 m_repr = F.normalize(m_repr + self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "    101 \n",
      "    102                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "    103                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "    104 \n",
      "--> 105                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "    106                 data_fused_repr[idx] += fused_repr\n",
      "    107 \n",
      "    108         return data_fused_repr.squeeze(), meta_repr\n",
      "    109 \n",
      "    110 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([117344, 161862, 161861, 487671, 309544, 129374, 102557, 102556,  54423,\n",
      "        559742,  79395, 102815,  84877,  84874,  84871], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_args['meta_repr']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.pretrained_meta_embeddings(m_idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(106)fuse_meta_into_embeddings()\n",
      "    104 \n",
      "    105                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "--> 106                 data_fused_repr[idx] += fused_repr\n",
      "    107 \n",
      "    108         return data_fused_repr.squeeze(), meta_repr\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(94)fuse_meta_into_embeddings()\n",
      "     92 \n",
      "     93         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "---> 94         for m_key, m_args in meta_kwargs.items():\n",
      "     95             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     96             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(108)fuse_meta_into_embeddings()\n",
      "    106                 data_fused_repr[idx] += fused_repr\n",
      "    107 \n",
      "--> 108         return data_fused_repr.squeeze(), meta_repr\n",
      "    109 \n",
      "    110 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[ 0.0...ezeBackward0>), {'lnk2data': tensor([[0.03...dexBackward0>)})\n",
      "> /tmp/ipykernel_36220/179234550.py(108)fuse_meta_into_embeddings()\n",
      "    106                 data_fused_repr[idx] += fused_repr\n",
      "    107 \n",
      "--> 108         return data_fused_repr.squeeze(), meta_repr\n",
      "    109 \n",
      "    110 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(134)forward()\n",
      "    132                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    133                                                                             meta_kwargs)\n",
      "--> 134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    135 \n",
      "    136         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(136)forward()\n",
      "    134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    135 \n",
      "--> 136         return EncoderOutput(\n",
      "    137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(137)forward()\n",
      "    135 \n",
      "    136         return EncoderOutput(\n",
      "--> 137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "    139             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(138)forward()\n",
      "    136         return EncoderOutput(\n",
      "    137             rep=data_repr,\n",
      "--> 138             fused_rep=data_fused_repr,\n",
      "    139             meta_repr=meta_repr,\n",
      "    140         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(139)forward()\n",
      "    137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "--> 139             meta_repr=meta_repr,\n",
      "    140         )\n",
      "    141 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(136)forward()\n",
      "    134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    135 \n",
      "--> 136         return EncoderOutput(\n",
      "    137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...xBackward0>)})\n",
      "> /tmp/ipykernel_36220/179234550.py(136)forward()\n",
      "    134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    135 \n",
      "--> 136         return EncoderOutput(\n",
      "    137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(184)forward()\n",
      "    182 \n",
      "    183 \n",
      "--> 184         loss = None; lbl2data_o = EncoderOutput()\n",
      "    185         if lbl2data_input_ids is not None:\n",
      "    186             lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(185)forward()\n",
      "    183 \n",
      "    184         loss = None; lbl2data_o = EncoderOutput()\n",
      "--> 185         if lbl2data_input_ids is not None:\n",
      "    186             lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    187             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(186)forward()\n",
      "    184         loss = None; lbl2data_o = EncoderOutput()\n",
      "    185         if lbl2data_input_ids is not None:\n",
      "--> 186             lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    187             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "    188                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(187)forward()\n",
      "    185         if lbl2data_input_ids is not None:\n",
      "    186             lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "--> 187             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "    188                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    189 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(188)forward()\n",
      "    186             lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    187             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "--> 188                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    189 \n",
      "    190             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(187)forward()\n",
      "    185         if lbl2data_input_ids is not None:\n",
      "    186             lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "--> 187             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "    188                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    189 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(188)forward()\n",
      "    186             lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    187             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "--> 188                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    189 \n",
      "    190             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(187)forward()\n",
      "    185         if lbl2data_input_ids is not None:\n",
      "    186             lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "--> 187             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "    188                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    189 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(120)forward()\n",
      "    118         **kwargs\n",
      "    119     ):  \n",
      "--> 120         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    121 \n",
      "    122         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XCModelOutput(loss=tensor(0.0183, device='cuda:0', grad_fn=<AddBackward0>), logits=None, data_repr=tensor([[-0.0346, -0.0148, -0.0316,  ...,  0.0544,  0.0028, -0.0312],\n",
       "        [-0.0225, -0.0189, -0.0329,  ...,  0.0344, -0.0342,  0.0102],\n",
       "        [ 0.0112,  0.0063, -0.0371,  ...,  0.0715, -0.0157,  0.0266],\n",
       "        [ 0.0698,  0.0139,  0.0030,  ...,  0.0345, -0.0052,  0.0286],\n",
       "        [-0.0170, -0.0224, -0.0301,  ...,  0.0244, -0.0210, -0.0329]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>), data_fused_repr=tensor([[-0.0332, -0.0150, -0.0304,  ...,  0.0533,  0.0018, -0.0301],\n",
       "        [-0.0219, -0.0187, -0.0315,  ...,  0.0327, -0.0326,  0.0088],\n",
       "        [ 0.0099,  0.0052, -0.0356,  ...,  0.0717, -0.0159,  0.0252],\n",
       "        [ 0.0695,  0.0125,  0.0020,  ...,  0.0330, -0.0059,  0.0271],\n",
       "        [-0.0171, -0.0221, -0.0292,  ...,  0.0230, -0.0208, -0.0318]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>), lbl2data_repr=tensor([[-0.0346, -0.0148, -0.0316,  ...,  0.0544,  0.0028, -0.0312],\n",
       "        [-0.0225, -0.0189, -0.0329,  ...,  0.0344, -0.0342,  0.0102],\n",
       "        [ 0.0061,  0.0408, -0.0347,  ...,  0.0263, -0.0338, -0.0048],\n",
       "        [ 0.0294, -0.0091,  0.0062,  ...,  0.0245,  0.0038, -0.0094],\n",
       "        [-0.0170, -0.0224, -0.0301,  ...,  0.0244, -0.0210, -0.0329]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>), lbl2data_fused_repr=None)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f80b8-5c78-4f92-a1e2-74a5c996f286",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9064308f-6259-43fc-8c30-96972cf79483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK002(OAK001, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK001.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        n_labels:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.label_embeddings = nn.Embedding(n_labels, config.dim, sparse=True)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_label_embeddings(self):\n",
    "        torch.nn.init.zeros_(self.label_embeddings.weight)\n",
    "\n",
    "    def get_label_representation(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask)\n",
    "        data_o.rep = F.normalize(data_o.rep + self.label_embeddings(data_idx), dim=1)\n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(lbl2data_idx), dim=1)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae28e5a-4211-486a-8858-f847380a8102",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e19d3f3e-e599-49b2-9630-75f8f1092363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK002 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight', 'label_embeddings.weight', 'meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK002.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000, n_labels=block.n_lbl,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "model.init_label_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "029c620e-8962-4575-8dde-5eddca73b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(block.train.dset.meta['lnk_meta'].n_meta, model.config.dim))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c67a086-d93b-4ab5-98ec-0f51b70a0277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f5c10eb-7302-441b-8bc3-463066367a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c5d591f8-58dc-4931-8884-b74cb26457b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4597145d-94bf-4ed2-b5de-01f78c843de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749b81d-2eac-4e86-8f28-3de67ea481c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f095489f-66c1-43ef-85ce-dee54f539d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc47d381-9e59-4a0e-8f3f-f2f4bce7128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a233321a-c4cc-4090-8e01-613821a1b294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e77cff15-2e99-4da3-a24e-c67a4d7da6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0213, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f32e1e-5f59-4b3d-ac54-819a2fbc6771",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "72eb188c-b2fc-4e01-84a2-ecbaf0f28db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK003(OAK001, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK001.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        n_labels:int,\n",
    "        n_clusters:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.label_embeddings = nn.Embedding(n_clusters, config.dim, sparse=True)\n",
    "        self.register_buffer(\"label_remap\", torch.arange(n_labels)%n_clusters, persistent=True)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_label_embeddings(self):\n",
    "        torch.nn.init.zeros_(self.label_embeddings.weight)\n",
    "\n",
    "    def set_label_embeddings(self, embed:torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            self.label_embeddings.weight.copy_(embed)\n",
    "\n",
    "    def set_label_remap(self, label_remap:torch.Tensor):\n",
    "        if label_remap.shape[0] != self.label_remap.shape[0]:\n",
    "            raise ValueError(f'Shape mismatch, `label_remap` should have {self.label_remap.shape[0]} elements.')\n",
    "        self.label_remap = label_remap\n",
    "\n",
    "    def get_label_representation(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask)\n",
    "        data_o.rep = F.normalize(data_o.rep + self.label_embeddings(self.label_remap[data_idx]), dim=1)\n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2e7dc-71c6-4857-b0fb-fcd869baf67d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d66ef7e-f5c8-4823-bdc4-99542aeb4d72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK003 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight', 'label_embeddings.weight', 'label_remap', 'meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK003.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000, \n",
    "                               n_labels=block.n_lbl, n_clusters=block.n_lbl//3,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "model.init_label_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8a1dbed8-f942-4fb5-8754-cb6df533c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(block.train.dset.meta['lnk_meta'].n_meta, model.config.dim))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a56d6e-b878-4e55-8e86-bbd0bba8c182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6aed62e-379e-4d6f-bc1d-63afc2382d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0742798-b05e-4bcb-a8fd-6efcbbea0751",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d7215e8-77b8-486c-8c3b-804e121ee03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab987e-7ac6-452b-a045-bed5a33efa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4ed2db1-6ee3-4a35-bc57-ab7961d67fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09d89967-a8a8-45e8-8636-1e438e88db6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0213, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b870501-6611-4840-9bce-aa64ed0ad6db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `OAK004`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df87de38-dbed-48df-b09d-7789a7666518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK004(OAK001, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK001.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        n_labels:int,\n",
    "        n_clusters:int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.label_embeddings = nn.Embedding(n_clusters, config.dim)\n",
    "        self.register_buffer(\"label_remap\", torch.arange(n_labels)%n_clusters, persistent=True)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def init_label_embeddings(self):\n",
    "        torch.nn.init.zeros_(self.label_embeddings.weight)\n",
    "\n",
    "    def set_label_embeddings(self, embed:torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            self.label_embeddings.weight.copy_(embed)\n",
    "\n",
    "    def set_label_remap(self, label_remap:torch.Tensor):\n",
    "        if label_remap.shape[0] != self.label_remap.shape[0]:\n",
    "            raise ValueError(f'Shape mismatch, `label_remap` should have {self.label_remap.shape[0]} elements.')\n",
    "        with torch.no_grad():\n",
    "            self.label_remap.copy_(label_remap)\n",
    "\n",
    "    def get_label_representation(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask)\n",
    "        data_o.rep = F.normalize(data_o.rep + self.label_embeddings(self.label_remap[data_idx]), dim=1)\n",
    "        return XCModelOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = self._get_encoder_meta_kwargs('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            lbl2data_o.rep = F.normalize(lbl2data_o.rep + self.label_embeddings(self.label_remap[lbl2data_idx]), dim=1)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca33e1bd-1e9f-4935-ad5e-7630ae2852b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "481ad336-eaaa-4891-9584-8712061a40ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK004 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight', 'label_embeddings.weight', 'label_remap', 'meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK004.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000, \n",
    "                               n_labels=block.n_lbl, n_clusters=block.n_lbl//3,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_meta_embeddings()\n",
    "model.init_label_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec135539-32a9-4bda-9020-d54048844521",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.zeros(block.train.dset.meta['lnk_meta'].n_meta, model.config.dim))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa4e047-b4fd-4452-83f4-3c554db4f0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "68e62901-20bc-4619-8496-42682c9df909",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6140a-033a-4921-b1ef-10cd5786db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feddc1bd-e589-4ab0-932c-b5b713cb9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102233b8-2901-4479-91c7-3522fb248ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c0c6c121-cb0f-4ae8-b9d7-e4088bc79d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc3d1b27-d0d3-412d-9c4b-6b7b7d2b974b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0213, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f0e59-376a-4f19-8e3a-0b6b08fc27e1",
   "metadata": {},
   "source": [
    "## `OAK005`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d50a4f65-a089-4151-a450-3d4cb98bfcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK005Encoder(Encoder):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "\n",
    "    def resize(self, idx:torch.Tensor, num_inputs:torch.Tensor):\n",
    "        if torch.any(num_inputs == 0): raise ValueError(\"`num_inputs` should be non-zero positive integer.\")\n",
    "        bsz, total_num_inputs = num_inputs.shape[0], idx.shape[0]\n",
    "        \n",
    "        self.ones = self.ones.to(idx.device)\n",
    "        ones = (\n",
    "            torch.ones(total_num_inputs, dtype=torch.long, device=idx.device) \n",
    "            if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
    "        )\n",
    "        \n",
    "        max_num_inputs = num_inputs.max()\n",
    "        if (num_inputs == max_num_inputs).all():\n",
    "            return idx,ones\n",
    "        \n",
    "        xnum_inputs = max_num_inputs-num_inputs+1\n",
    "        \n",
    "        inputs_ptr = num_inputs.cumsum(dim=0)-1\n",
    "        repeat_inputs = ones.scatter(0, inputs_ptr, xnum_inputs)\n",
    "        \n",
    "        resized_idx = idx.repeat_interleave(repeat_inputs, dim=0)\n",
    "        \n",
    "        ignore_mask = ones.scatter(0, inputs_ptr, 0).repeat_interleave(repeat_inputs, dim=0).view(bsz, -1)\n",
    "        ignore_mask[:, -1] = 1; ignore_mask = ignore_mask.flatten()\n",
    "        \n",
    "        return resized_idx,ignore_mask\n",
    "\n",
    "    def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
    "            \n",
    "            if len(idx):\n",
    "                m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
    "                m_repr = F.normalize(self.pretrained_meta_embeddings(m_idx), dim=1)\n",
    "                \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
    "                meta_repr[m_key] = m_repr[m_repr_mask]\n",
    "                \n",
    "                fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                data_fused_repr[idx] += fused_repr\n",
    "                \n",
    "        return data_fused_repr.squeeze(), meta_repr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "44a1c2e7-bdaf-4c7e-adeb-9b9d23387f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAK005(OAK000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(OAK000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = OAK005Encoder(config, num_metadata=num_metadata, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def _get_encoder_meta_kwargs(self, feat:str, prefix:str, **kwargs):\n",
    "        meta_kwargs = Parameters.from_feat_meta_aug_prefix(feat, prefix, **kwargs)\n",
    "        return meta_kwargs\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5670103a-6eab-4d4a-8a6b-c30de56fca7f",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "46a37d39-2453-490c-8901-3ed1608f45b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK005 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = OAK005.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=10, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=False,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.3, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0f8ce6fc-22a7-4249-9820-217a6fa27158",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.set_pretrained_meta_embeddings(torch.ones(block.train.dset.meta['lnk_meta'].n_meta, model.config.dim))\n",
    "model.encoder.freeze_pretrained_meta_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379d956-d5b0-4b4d-8cf6-b7834e708b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "772ddce6-0ad5-4e08-9f21-0a84a8d3bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8292d1d5-a269-4579-8786-7b4030fe2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', \n",
    "    'lnk2data_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56140d7-9bd3-4d34-ad3c-985ea7814112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8b3c8878-ff9b-4b53-af46-677e53e47084",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bc5111d9-b04d-404a-9dfa-d36eb26628cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0183, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2aa616-67f7-4e64-bb32-4c791c033e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "abec7537-bbeb-4b13-acc0-bdc103b35efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ab381e10-e68d-49d4-96e5-42e0f9e55d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/3657616883.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b.to(model.device))\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 3 at /tmp/ipykernel_36220/1449976710.py:158\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(173)forward()\n",
      "    171         **kwargs\n",
      "    172     ):  \n",
      "--> 173         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "    174 \n",
      "    175         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(175)forward()\n",
      "    173         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "    174 \n",
      "--> 175         if self.use_encoder_parallel:\n",
      "    176             encoder = XCDataParallel(module=self.encoder)\n",
      "    177         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(177)forward()\n",
      "    175         if self.use_encoder_parallel:\n",
      "    176             encoder = XCDataParallel(module=self.encoder)\n",
      "--> 177         else: encoder = self.encoder\n",
      "    178 \n",
      "    179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(179)forward()\n",
      "    177         else: encoder = self.encoder\n",
      "    178 \n",
      "--> 179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "    180         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "    181                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(180)forward()\n",
      "    178 \n",
      "    179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "--> 180         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "    181                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    182 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b encoder.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 4 at /tmp/ipykernel_36220/179234550.py:111\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(181)forward()\n",
      "    179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "    180         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "--> 181                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    182 \n",
      "    183 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(180)forward()\n",
      "    178 \n",
      "    179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "--> 180         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "    181                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    182 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(181)forward()\n",
      "    179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "    180         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "--> 181                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    182 \n",
      "    183 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(180)forward()\n",
      "    178 \n",
      "    179         data_meta_kwargs = self._get_encoder_meta_kwargs('data', self.data_aug_meta_prefix, **kwargs)\n",
      "--> 180         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "    181                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    182 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(120)forward()\n",
      "    118         **kwargs\n",
      "    119     ):  \n",
      "--> 120         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    121 \n",
      "    122         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(122)forward()\n",
      "    120         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    121 \n",
      "--> 122         if data_type is not None and data_type == \"meta\":\n",
      "    123             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    124         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(125)forward()\n",
      "    123             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    124         else:\n",
      "--> 125             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    126 \n",
      "    127         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(127)forward()\n",
      "    125             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    126 \n",
      "--> 127         data_fused_repr = meta_repr = None\n",
      "    128         if data_aug_meta_prefix is not None:\n",
      "    129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(128)forward()\n",
      "    126 \n",
      "    127         data_fused_repr = meta_repr = None\n",
      "--> 128         if data_aug_meta_prefix is not None:\n",
      "    129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    130             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(129)forward()\n",
      "    127         data_fused_repr = meta_repr = None\n",
      "    128         if data_aug_meta_prefix is not None:\n",
      "--> 129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    130             if len(meta_kwargs):\n",
      "    131                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(130)forward()\n",
      "    128         if data_aug_meta_prefix is not None:\n",
      "    129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "--> 130             if len(meta_kwargs):\n",
      "    131                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    132                                                                             torch.any(data_attention_mask, dim=1),\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lnk2data'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(131)forward()\n",
      "    129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    130             if len(meta_kwargs):\n",
      "--> 131                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    132                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    133                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(132)forward()\n",
      "    130             if len(meta_kwargs):\n",
      "    131                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "--> 132                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    133                                                                             meta_kwargs)\n",
      "    134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(133)forward()\n",
      "    131                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    132                                                                             torch.any(data_attention_mask, dim=1),\n",
      "--> 133                                                                             meta_kwargs)\n",
      "    134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    135 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(131)forward()\n",
      "    129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    130             if len(meta_kwargs):\n",
      "--> 131                 data_fused_repr, meta_repr = self.fuse_meta_into_embeddings(data_repr, \n",
      "    132                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    133                                                                             meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_36220/2023555771.py(37)fuse_meta_into_embeddings()\n",
      "     35         return resized_idx,ignore_mask\n",
      "     36 \n",
      "---> 37     def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "     38         meta_repr = {}\n",
      "     39 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(38)fuse_meta_into_embeddings()\n",
      "     36 \n",
      "     37     def fuse_meta_into_embeddings(self, data_repr:torch.Tensor, data_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "---> 38         meta_repr = {}\n",
      "     39 \n",
      "     40         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(40)fuse_meta_into_embeddings()\n",
      "     38         meta_repr = {}\n",
      "     39 \n",
      "---> 40         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     41         for m_key, m_args in meta_kwargs.items():\n",
      "     42             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(41)fuse_meta_into_embeddings()\n",
      "     39 \n",
      "     40         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "---> 41         for m_key, m_args in meta_kwargs.items():\n",
      "     42             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     43             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(42)fuse_meta_into_embeddings()\n",
      "     40         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "     41         for m_key, m_args in meta_kwargs.items():\n",
      "---> 42             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     43             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     44 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(43)fuse_meta_into_embeddings()\n",
      "     41         for m_key, m_args in meta_kwargs.items():\n",
      "     42             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "---> 43             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     44 \n",
      "     45             if len(idx):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(45)fuse_meta_into_embeddings()\n",
      "     43             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "     44 \n",
      "---> 45             if len(idx):\n",
      "     46                 m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
      "     47                 m_repr = F.normalize(self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(46)fuse_meta_into_embeddings()\n",
      "     44 \n",
      "     45             if len(idx):\n",
      "---> 46                 m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
      "     47                 m_repr = F.normalize(self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "     48 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(47)fuse_meta_into_embeddings()\n",
      "     45             if len(idx):\n",
      "     46                 m_idx,m_repr_mask = self.resize(m_args['idx'], m_args['data2ptr'][idx])\n",
      "---> 47                 m_repr = F.normalize(self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "     48 \n",
      "     49                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(49)fuse_meta_into_embeddings()\n",
      "     47                 m_repr = F.normalize(self.pretrained_meta_embeddings(m_idx), dim=1)\n",
      "     48 \n",
      "---> 49                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "     50                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "     51 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(50)fuse_meta_into_embeddings()\n",
      "     48 \n",
      "     49                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.bool().view(len(idx), -1)\n",
      "---> 50                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "     51 \n",
      "     52                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(52)fuse_meta_into_embeddings()\n",
      "     50                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "     51 \n",
      "---> 52                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "     53                 data_fused_repr[idx] += fused_repr\n",
      "     54 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(53)fuse_meta_into_embeddings()\n",
      "     51 \n",
      "     52                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "---> 53                 data_fused_repr[idx] += fused_repr\n",
      "     54 \n",
      "     55         return data_fused_repr.squeeze(), meta_repr\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(41)fuse_meta_into_embeddings()\n",
      "     39 \n",
      "     40         data_fused_repr, data_mask = data_repr.clone().view(-1, 1, self.config.dim), data_mask.view(-1, 1)\n",
      "---> 41         for m_key, m_args in meta_kwargs.items():\n",
      "     42             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     43             meta_repr[m_key] = torch.empty(0, self.config.dim).to(data_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/2023555771.py(55)fuse_meta_into_embeddings()\n",
      "     52                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "     53                 data_fused_repr[idx] += fused_repr\n",
      "     54 \n",
      "---> 55         return data_fused_repr.squeeze(), meta_repr\n",
      "     56 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[ 0.0...ezeBackward0>), {'lnk2data': tensor([[0.03...361, 0.0361]])})\n",
      "> /tmp/ipykernel_36220/2023555771.py(55)fuse_meta_into_embeddings()\n",
      "     52                 fused_repr = self.cross_head(data_fused_repr[idx], data_mask[idx], m_repr, m_repr_mask)[0]\n",
      "     53                 data_fused_repr[idx] += fused_repr\n",
      "     54 \n",
      "---> 55         return data_fused_repr.squeeze(), meta_repr\n",
      "     56 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(134)forward()\n",
      "    132                                                                             torch.any(data_attention_mask, dim=1),\n",
      "    133                                                                             meta_kwargs)\n",
      "--> 134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    135 \n",
      "    136         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(136)forward()\n",
      "    134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    135 \n",
      "--> 136         return EncoderOutput(\n",
      "    137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(137)forward()\n",
      "    135 \n",
      "    136         return EncoderOutput(\n",
      "--> 137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "    139             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(138)forward()\n",
      "    136         return EncoderOutput(\n",
      "    137             rep=data_repr,\n",
      "--> 138             fused_rep=data_fused_repr,\n",
      "    139             meta_repr=meta_repr,\n",
      "    140         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(139)forward()\n",
      "    137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "--> 139             meta_repr=meta_repr,\n",
      "    140         )\n",
      "    141 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(136)forward()\n",
      "    134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    135 \n",
      "--> 136         return EncoderOutput(\n",
      "    137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(120)forward()\n",
      "    118         **kwargs\n",
      "    119     ):  \n",
      "--> 120         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    121 \n",
      "    122         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(122)forward()\n",
      "    120         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    121 \n",
      "--> 122         if data_type is not None and data_type == \"meta\":\n",
      "    123             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    124         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(125)forward()\n",
      "    123             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    124         else:\n",
      "--> 125             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    126 \n",
      "    127         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(127)forward()\n",
      "    125             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    126 \n",
      "--> 127         data_fused_repr = meta_repr = None\n",
      "    128         if data_aug_meta_prefix is not None:\n",
      "    129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(128)forward()\n",
      "    126 \n",
      "    127         data_fused_repr = meta_repr = None\n",
      "--> 128         if data_aug_meta_prefix is not None:\n",
      "    129             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    130             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(136)forward()\n",
      "    134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    135 \n",
      "--> 136         return EncoderOutput(\n",
      "    137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(137)forward()\n",
      "    135 \n",
      "    136         return EncoderOutput(\n",
      "--> 137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "    139             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(138)forward()\n",
      "    136         return EncoderOutput(\n",
      "    137             rep=data_repr,\n",
      "--> 138             fused_rep=data_fused_repr,\n",
      "    139             meta_repr=meta_repr,\n",
      "    140         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(139)forward()\n",
      "    137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "--> 139             meta_repr=meta_repr,\n",
      "    140         )\n",
      "    141 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/179234550.py(136)forward()\n",
      "    134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    135 \n",
      "--> 136         return EncoderOutput(\n",
      "    137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> /tmp/ipykernel_36220/179234550.py(136)forward()\n",
      "    134                 data_fused_repr = self.dr_fused(data_fused_repr)\n",
      "    135 \n",
      "--> 136         return EncoderOutput(\n",
      "    137             rep=data_repr,\n",
      "    138             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(190)forward()\n",
      "    188                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    189 \n",
      "--> 190             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "    191                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "    192 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(191)forward()\n",
      "    189 \n",
      "    190             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "--> 191                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "    192 \n",
      "    193             if self.use_query_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(190)forward()\n",
      "    188                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    189 \n",
      "--> 190             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "    191                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "    192 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_36220/1449976710.py(193)forward()\n",
      "    191                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "    192 \n",
      "--> 193             if self.use_query_loss:\n",
      "    194                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "    195                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XCModelOutput(loss=tensor(0.0183, grad_fn=<AddBackward0>), logits=None, data_repr=tensor([[-0.0346, -0.0148, -0.0316,  ...,  0.0544,  0.0028, -0.0312],\n",
       "        [-0.0225, -0.0189, -0.0329,  ...,  0.0344, -0.0342,  0.0102],\n",
       "        [ 0.0112,  0.0063, -0.0371,  ...,  0.0715, -0.0157,  0.0266],\n",
       "        [ 0.0698,  0.0139,  0.0030,  ...,  0.0345, -0.0052,  0.0286],\n",
       "        [-0.0170, -0.0224, -0.0301,  ...,  0.0244, -0.0210, -0.0329]],\n",
       "       grad_fn=<DivBackward0>), data_fused_repr=tensor([[-0.0332, -0.0150, -0.0304,  ...,  0.0533,  0.0018, -0.0301],\n",
       "        [-0.0219, -0.0187, -0.0315,  ...,  0.0327, -0.0326,  0.0088],\n",
       "        [ 0.0099,  0.0052, -0.0356,  ...,  0.0717, -0.0159,  0.0252],\n",
       "        [ 0.0695,  0.0125,  0.0020,  ...,  0.0330, -0.0059,  0.0271],\n",
       "        [-0.0171, -0.0221, -0.0292,  ...,  0.0230, -0.0208, -0.0318]],\n",
       "       grad_fn=<DivBackward0>), lbl2data_repr=tensor([[-0.0346, -0.0148, -0.0316,  ...,  0.0544,  0.0028, -0.0312],\n",
       "        [-0.0225, -0.0189, -0.0329,  ...,  0.0344, -0.0342,  0.0102],\n",
       "        [ 0.0061,  0.0408, -0.0347,  ...,  0.0263, -0.0338, -0.0048],\n",
       "        [ 0.0294, -0.0091,  0.0062,  ...,  0.0245,  0.0038, -0.0094],\n",
       "        [-0.0170, -0.0224, -0.0301,  ...,  0.0244, -0.0210, -0.0329]],\n",
       "       grad_fn=<DivBackward0>), lbl2data_fused_repr=None)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8103fd-bf53-40d5-b0c1-ef7be732f309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
