{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b937d98-9beb-445c-bc68-c8d71a8c1ae0",
   "metadata": {},
   "source": [
    "# learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc714cf2-0372-49f6-a39c-24752a28145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4b498e-a0a3-4bdd-8741-ca516ddc64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0ac07c-66a4-40d0-a39b-e5220c20fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from enum import Enum\n",
    "from tqdm.auto import tqdm\n",
    "from scipy import sparse\n",
    "from packaging import version\n",
    "import torch, re, math, numpy as np, os, time, datasets, pickle, transformers\n",
    "from typing import Any, Tuple, Optional, Sequence, Union, Dict, List, NamedTuple\n",
    "from transformers import AutoTokenizer, BatchEncoding, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "import torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
    "\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.nn.parallel._functions import Scatter\n",
    "from torch.nn.parallel.scatter_gather import _is_namedtuple\n",
    "\n",
    "from xcai.core import *\n",
    "from xcai.data import *\n",
    "from xcai.sdata import *\n",
    "from xcai.representation.search import *\n",
    "from xcai.generation.trie import *\n",
    "from xcai.generation.generate import *\n",
    "from xcai.clustering.cluster import *\n",
    "from xcai.transform import PadFeatTfm\n",
    "from xcai.optimizers.oakX import MultipleOptimizer, MultipleScheduler\n",
    "\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "821000f3-31ca-44ed-a2a5-e060f900ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from transformers.trainer_pt_utils import (\n",
    "    find_batch_size, \n",
    "    nested_concat, nested_numpify, \n",
    "    IterableDatasetShard, \n",
    "    get_dataloader_sampler, \n",
    "    get_model_param_count,\n",
    "    LengthGroupedSampler\n",
    ")\n",
    "from transformers.trainer_utils import has_length, denumpify_detensorize, speed_metrics, TrainOutput, HPSearchBackend, seed_worker\n",
    "from transformers.trainer_callback import TrainerState, ExportableState\n",
    "from transformers.trainer import _is_peft_model\n",
    "from transformers.modeling_utils import unwrap_model\n",
    "from transformers.utils import is_sagemaker_mp_enabled, is_accelerate_available, is_torch_xla_available, logging, is_datasets_available\n",
    "from transformers.debug_utils import DebugOption, DebugUnderflowOverflow\n",
    "\n",
    "from transformers.integrations import hp_params\n",
    "from transformers.integrations.tpu import tpu_spmd_dataloader\n",
    "from transformers.integrations.deepspeed import deepspeed_init, deepspeed_load_checkpoint, is_deepspeed_available\n",
    "from transformers.trainer_utils import RemoveColumnsCollator\n",
    "\n",
    "if is_accelerate_available():\n",
    "    from accelerate import Accelerator, skip_first_batches\n",
    "    from accelerate import __version__ as accelerate_version\n",
    "    from accelerate.utils import (\n",
    "        DistributedDataParallelKwargs,\n",
    "        DistributedType,\n",
    "        GradientAccumulationPlugin,\n",
    "        load_fsdp_model,\n",
    "        load_fsdp_optimizer,\n",
    "        save_fsdp_model,\n",
    "        save_fsdp_optimizer,\n",
    "    )\n",
    "\n",
    "    DATA_SAMPLERS = [RandomSampler]\n",
    "    if version.parse(accelerate_version) > version.parse(\"0.23.0\"):\n",
    "        from accelerate.data_loader import SeedableRandomSampler\n",
    "\n",
    "        DATA_SAMPLERS += [SeedableRandomSampler]\n",
    "\n",
    "    if is_deepspeed_available():\n",
    "        from accelerate.utils import DeepSpeedSchedulerWrapper\n",
    "\n",
    "if is_accelerate_available(\"0.28.0\"):\n",
    "    from accelerate.utils import DataLoaderConfiguration\n",
    "\n",
    "TRAINING_ARGS_NAME = \"training_args.bin\"\n",
    "TRAINER_STATE_NAME = \"trainer_state.json\"\n",
    "OPTIMIZER_NAME = \"optimizer.pt\"\n",
    "OPTIMIZER_NAME_BIN = \"optimizer.bin\"\n",
    "SCHEDULER_NAME = \"scheduler.pt\"\n",
    "SCALER_NAME = \"scaler.pt\"\n",
    "FSDP_MODEL_NAME = \"pytorch_model_fsdp\"\n",
    "\n",
    "logger = logging.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a547561-f805-40c1-a6b2-d89e772ce149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b1b571-0043-4b86-acce-cb6cb0ef598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from xcai.block import *\n",
    "from xcai.models.PPP0XX import *\n",
    "from xcai.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6c73cc-d066-4c7f-a2b5-31003f38ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from xcai.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9985262",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efab5fa-1f75-44e8-b533-525d577f4209",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188e3a7-9458-456f-8a19-104fd139a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "block = XCBlock.from_cfg('/home/aiscuser/scratch/datasets', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca4d23b-4525-46bd-9a75-19ffca285235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "batch = block.train.one_batch(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e47e1ed-ad70-475f-a01f-cd9320705796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee43b109060489393f1b4531512f1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1c7e7b7f64465ea007044a1668c98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of BT0002 were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['loss_fn.o']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "m = BT0002.from_pretrained('bert-base-uncased', tn_targ=10_000, ig_tok=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf42c7-5471-4ff7-bc65-4020a5eb5f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95cdc4-ff76-4cd7-aa20-a54a03f7c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "b = prepare_batch(m, batch, m_args='lbl2data_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef492419-4e5a-4f08-bb1b-3ba3283703d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lbl2data_idx', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7a04d-81d7-402d-9a2d-b449b3acd3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "m = m.to('cuda')\n",
    "b = b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e64be93-2e54-4fbd-841b-c5d2828f5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "o = m(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5e531-8f3c-438e-ac10-b46c42e90093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.9452, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff8aa3-8d7a-4beb-8f0e-a8f2c82cbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets/'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealsotitles_data-cat-lnk_distilbert-base-uncased_xcs.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3638794-1429-44d7-9707-1d0e4bf54788",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d9190-682e-4017-954e-fad35c79ab13",
   "metadata": {},
   "source": [
    "## DataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b54c7fe-18b7-4502-a68d-5bbca3a75a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def scatter(inputs, target_gpus, chunk_sizes=None, dim=0):\n",
    "    def scatter_map(obj):\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return Scatter.apply(target_gpus, chunk_sizes, dim, obj)\n",
    "        if _is_namedtuple(obj):\n",
    "            return [type(obj)(*args) for args in zip(*map(scatter_map, obj))]\n",
    "        if isinstance(obj, tuple) and len(obj) > 0:\n",
    "            return list(zip(*map(scatter_map, obj)))\n",
    "        if isinstance(obj, list) and len(obj) > 0:\n",
    "            return [list(i) for i in zip(*map(scatter_map, obj))]\n",
    "        if isinstance(obj, dict) and len(obj) > 0:\n",
    "            return [type(obj)(i) for i in zip(*map(scatter_map, obj.items()))]\n",
    "        return [obj for _ in target_gpus] \n",
    "    try:\n",
    "        res = scatter_map(inputs)\n",
    "    finally:\n",
    "        scatter_map = None\n",
    "    return res\n",
    "    \n",
    "def scatter_kwargs(\n",
    "    inputs: Tuple[Any, ...],\n",
    "    kwargs: Optional[Dict[str, Any]],\n",
    "    target_gpus: Sequence[Union[int, torch.device]],\n",
    "    chunk_sizes: Optional[Sequence[int]]=None,\n",
    "    dim: int = 0,\n",
    ") -> Tuple[Tuple[Any, ...], Tuple[Dict[str, Any], ...]]:\n",
    "    scattered_inputs = scatter(inputs, target_gpus, chunk_sizes, dim) if inputs else []\n",
    "    scattered_kwargs = scatter(kwargs, target_gpus, chunk_sizes, dim) if kwargs else []\n",
    "    if len(scattered_inputs) < len(scattered_kwargs):\n",
    "        scattered_inputs.extend(() for _ in range(len(scattered_kwargs) - len(scattered_inputs)))\n",
    "    elif len(scattered_kwargs) < len(inputs):\n",
    "        scattered_kwargs.extend({} for _ in range(len(scattered_inputs) - len(scattered_kwargs)))\n",
    "    return scattered_inputs, scattered_kwargs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6420b5aa-6d09-47c1-809d-af19e02f800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCDataParallel(DataParallel):\n",
    "\n",
    "    @delegates(DataParallel.__init__)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def _get_feat_name(self, x:Optional[Dict[str, Any]]):\n",
    "        return list(set([k.split('_', maxsplit=1)[0] for k in x]))\n",
    "    \n",
    "    def _extract_feat(self, x:Optional[Dict[str, Any]], prefix:str):\n",
    "        return {k:v for k,v in x.items() if re.match(f'^{prefix}_(?!.*2ptr)', k) or re.match(f'^.*_{prefix}2ptr$', k)}\n",
    "\n",
    "    def scatter(\n",
    "        self,\n",
    "        inputs: Tuple[Any, ...],\n",
    "        kwargs: Optional[Dict[str, Any]],\n",
    "        device_ids: Sequence[Union[int, torch.device]],\n",
    "    ) ->Any:\n",
    "        if len(inputs): raise ValueError('`inputs` should be empty.')    \n",
    "        feat_name = self._get_feat_name(kwargs)\n",
    "        \n",
    "        data_feat = self._extract_feat(kwargs, 'data')\n",
    "        scattered_inputs, scattered_kwargs = scatter_kwargs(inputs, data_feat, device_ids, None, dim=self.dim)\n",
    "        feat_name.remove('data')\n",
    "        \n",
    "        for k in feat_name:\n",
    "            ptr_name = f'{k}_data2ptr'\n",
    "            if ptr_name in scattered_kwargs[0] and scattered_kwargs[0][ptr_name] is not None:\n",
    "                chunk_sz = [o[ptr_name].sum().item() for o in scattered_kwargs]\n",
    "                if len(chunk_sz) < len(device_ids): \n",
    "                    chunk_sz.extend([0 for _ in range(len(device_ids) - len(chunk_sz))])\n",
    "                \n",
    "                feat = self._extract_feat(kwargs, k)\n",
    "                _, o = scatter_kwargs(inputs, feat, device_ids, chunk_sz, dim=self.dim)\n",
    "                for p,q in zip(scattered_kwargs, o): p.update(q)\n",
    "                    \n",
    "        return tuple(scattered_inputs), tuple(scattered_kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553913e-875d-44c7-b58e-3b77ab8c4ae7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d9d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from transformers import AutoTokenizer, BatchEncoding\n",
    "\n",
    "tokz = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae19912",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/aiscuser/scratch/datasets'\n",
    "pkl_dir = f'{data_dir}/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ab4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{pkl_dir}/wikiseealso_data-metas_distilbert-base-uncased_rm_radga.pkl', 'rb') as file: \n",
    "    block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa4a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{pkl_dir}/wikiseealso_data-metas_distilbert-base-uncased_xcnlg_radga.pkl', 'rb') as file: \n",
    "    block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = block.train.one_batch(4)\n",
    "bb = BatchEncoding({k:v for k,v in b.items() if isinstance(v, torch.Tensor)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a78059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plbl2data_data2ptr :  torch.Size([4])\n",
      "lbl2data_data2ptr :  torch.Size([4])\n",
      "pcat2data_data2ptr :  torch.Size([4])\n",
      "cat2data_data2ptr :  torch.Size([4])\n",
      "pcat2lbl2data_data2ptr :  torch.Size([4])\n",
      "cat2lbl2data_data2ptr :  torch.Size([4])\n",
      "phlk2data_data2ptr :  torch.Size([4])\n",
      "hlk2data_data2ptr :  torch.Size([4])\n",
      "hlk2lbl2data_data2ptr :  torch.Size([4])\n",
      "hlk2lbl2data_plbl2data2ptr :  torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "for k,v in bb.items():\n",
    "    if 'ptr' in k: print(k, ': ', v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484462a0-4806-461a-957c-6ae5d1bd1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        for k,v in kwargs.items(): \n",
    "            if isinstance(v, torch.Tensor): print(k, ': ', v, ', ', v.device)\n",
    "        return kwargs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a9a39d-bff3-4588-9fd4-2899208a6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "m = XCDataParallel(module=MyModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85bff3f-e395-4486-9865-19d0f5bff763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plbl2data_data2ptrplbl2data_data2ptr :   :  tensor([2, 1], device='cuda:0')tensor([1, 2], device='cuda:1')  , ,   cuda:0cuda:1\n",
      "\n",
      "lbl2data_data2ptrlbl2data_data2ptr  : :   tensor([1, 2], device='cuda:1')tensor([2, 1], device='cuda:0') ,   , cuda:1 \n",
      "cuda:0pcat2data_data2ptr\n",
      " pcat2data_data2ptr:   : tensor([14,  6], device='cuda:1')  tensor([13,  6], device='cuda:0'),   cuda:1,  \n",
      "cat2data_data2ptrcuda:0\n",
      " : cat2data_data2ptr  :  tensor([1, 1], device='cuda:1') tensor([1, 1], device='cuda:0') , ,   cuda:0cuda:1\n",
      "\n",
      "pcat2lbl2data_data2ptrpcat2lbl2data_data2ptr :  :   tensor([4, 7], device='cuda:1')tensor([0, 4], device='cuda:0') ,   , cuda:0 \n",
      "cat2lbl2data_data2ptrcuda:1\n",
      " cat2lbl2data_data2ptr:   :  tensor([0, 1], device='cuda:0') tensor([1, 1], device='cuda:1'),   , cuda:0 \n",
      "cuda:1phlk2data_data2ptr\n",
      " phlk2data_data2ptr:   : tensor([16, 18], device='cuda:0')  , tensor([15, 40], device='cuda:1') cuda:0 \n",
      ", hlk2data_data2ptr  cuda:1: \n",
      "hlk2data_data2ptr  tensor([3, 3], device='cuda:0'):   , tensor([3, 3], device='cuda:1')  , cuda:0 \n",
      "cuda:1data_input_ids\n",
      " data_input_ids:   :  tensor([[ 101, 9808, 4270, 2314,  102,    0,    0],\n",
      "        [ 101, 4748, 3909, 4049,  102,    0,    0]], device='cuda:0') ,  cuda:0tensor([[  101,  2957, 14135,  1006,  2236,  1007,   102],\n",
      "        [  101,  9805,  3676,  2221,  1010,  2662,   102]], device='cuda:1')\n",
      " data_attention_mask,   : cuda:1\n",
      " data_attention_mask : tensor([[1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0]], device='cuda:0')  ,  cuda:0tensor([[1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1]], device='cuda:1')\n",
      "hlk2lbl2data_data2ptr  , :   cuda:1\n",
      "tensor([0, 5], device='cuda:0')hlk2lbl2data_data2ptr  : ,   cuda:0tensor([5, 9], device='cuda:1')\n",
      "cat2data_idx ,  :   cuda:1\n",
      "tensor([152298,  55068], device='cuda:0')cat2data_idx  , :   cuda:0\n",
      "cat2data_input_idstensor([ 54425, 104014], device='cuda:1')  : ,   cuda:1\n",
      "tensor([[  101,  5485,  1997, 18685,  2221,  1010,  5284,   102,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2309,  1011, 21235,  5245,  2121,  2948,   102,     0,     0,\n",
      "             0,     0]], device='cuda:0')cat2data_input_ids  , :   cuda:0\n",
      "cat2data_attention_mask : tensor([[  101,  8055,  2163,  2510,  5073,  2730,  1999,  1996,  2137,  2942,\n",
      "          2162,   102],\n",
      "        [  101,  7973, 17228,  1999,  2662,   102,     0,     0,     0,     0,\n",
      "             0,     0]], device='cuda:1')  ,  cuda:1tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]], device='cuda:0') \n",
      ", cat2data_attention_mask  cuda:0: \n",
      " cat2lbl2data_idx tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]], device='cuda:1'):   ,  tensor([273427], device='cuda:0')cuda:1 , \n",
      "cat2lbl2data_idx  cuda:0\n",
      ": cat2lbl2data_input_ids  tensor([490081, 104014], device='cuda:1'):   ,  tensor([[ 101, 7201, 1997, 2510, 2948,  102]], device='cuda:0') cuda:1\n",
      ", cat2lbl2data_input_ids cuda:0 : \n",
      "cat2lbl2data_attention_mask  : tensor([[  101,  7201,  1997, 11593,   102,     0],\n",
      "        [  101,  7973, 17228,  1999,  2662,   102]], device='cuda:1')  , tensor([[1, 1, 1, 1, 1, 1]], device='cuda:0')  cuda:1, \n",
      " cat2lbl2data_attention_maskcuda:0 \n",
      ":  pcat2lbl2data_idx : tensor([[1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1]], device='cuda:1')  , tensor([498200, 496349, 273427,  92979], device='cuda:0')  , cuda:1 cuda:0\n",
      "\n",
      "pcat2lbl2data_idxlbl2data_idx  :  :  tensor([395355, 107556, 395354, 490081, 547792, 545725, 355196, 153765,  98839,\n",
      "        104014, 119469], device='cuda:1')tensor([101316,  71037,  99923], device='cuda:0') ,   cuda:0, \n",
      " lbl2data_input_idscuda:1\n",
      " lbl2data_idx:   : tensor([[ 101, 2862, 1997, 5284, 5485,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [ 101, 2862, 1997, 5111, 5485,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [ 101, 2862, 1997, 2948, 1997, 1996, 2548, 3987, 2250, 2326,  102,    0,\n",
      "            0,    0]], device='cuda:0')  , tensor([  269, 55151, 55150], device='cuda:1') cuda:0 , \n",
      "lbl2data_attention_mask  cuda:1\n",
      ":  lbl2data_input_ids :  tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]], device='cuda:0') ,  tensor([[  101,  2862,  1997,  2137,  2942,  2162, 11593,  1006,  8055,  1007,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  9805,  3676,  2221,  1010,  2662,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2120,  4236,  1997,  3181,  3182, 26213,  1999,  9805,  3676,\n",
      "          2221,  1010,  2662,   102]], device='cuda:1')cuda:0\n",
      " pcat2data_idx,   : cuda:1 \n",
      "lbl2data_attention_mask : tensor([ 64717, 159252, 152298, 202322, 242932, 225043, 183785, 191189, 183855,\n",
      "        218989, 242907, 228216, 188424,  54866,  56102,  55068,  55069,  56101,\n",
      "         56100], device='cuda:0')  ,  cuda:0tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')\n",
      " , plbl2data_idx  : cuda:1\n",
      " pcat2data_idxtensor([ 71037, 101316,  99923], device='cuda:0')  :  ,  tensor([ 68276, 106638, 102346, 102550, 367802, 207931,  66312, 133998, 171930,\n",
      "         62824,  54423,  54425, 108939, 281131, 153767, 104014,  98839, 355196,\n",
      "        119469, 153765], device='cuda:1')cuda:0 \n",
      "hlk2lbl2data_plbl2data2ptr,   : cuda:1 \n",
      "plbl2data_idx : tensor([0, 0, 5], device='cuda:0')  ,  tensor([  269, 55150, 55151], device='cuda:1')cuda:0\n",
      " , phlk2data_idx  cuda:1:  \n",
      "hlk2lbl2data_plbl2data2ptr :  tensor([ 113865,    8637,   48624, 1397758,  794132,   13068,     254,   24213,\n",
      "         808587,  310460,  846531,  997655, 1221759,  916835, 1210975,  345267,\n",
      "          77253,   25418,  467468,    2667,  145886,  179309,  467472,   52621,\n",
      "         467465,  467466,    3004,  467473,    2736,  467471,  467464,  467470,\n",
      "         433167,  467469], device='cuda:0') , tensor([5, 4, 5], device='cuda:1')  cuda:0\n",
      ",  hlk2data_idxcuda:1 : \n",
      " phlk2data_idx tensor([ 48624, 794132,    254, 179309, 467472, 433167], device='cuda:0'):   ,  cuda:0\n",
      "tensor([   1571,  241461,    8805,    2582,   89844,  460143,    9824,     297,\n",
      "        1283293,   19288,  567212,   40308,    1464, 1282940,   14059,  948811,\n",
      "          61257,  517280,    4927,   15729,  304807,  243045,  815271,  716531,\n",
      "           7839,    8646,  441558,   20720,  147120,    2932, 2337137,  817356,\n",
      "          46779,   15335,   15675,  484300,  815267,     254,  834837, 1914233,\n",
      "          38369,  948613,  847391, 2455908,  438723,     147,  511595,  561003,\n",
      "          14452,    2894,     317,  836235,   39074,  511775,  403957],\n",
      "       device='cuda:1')hlk2data_input_ids ,  :   cuda:1\n",
      "hlk2data_idx :  tensor([[  101,  9808,  4270,  3842,   102,     0,     0,     0,     0],\n",
      "        [  101, 15237,  8071,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2142,  2163,   102,     0,     0,     0,     0,     0],\n",
      "        [  101, 28667, 11514,  3217, 18252,  3194,   102,     0,     0],\n",
      "        [  101, 11409,  2669,  3246,   102,     0,     0,     0,     0],\n",
      "        [  101, 24185,  4877, 22352, 17947,   102,     0,     0,     0]],\n",
      "       device='cuda:0') tensor([  19288, 1283293,    2582,    7839,    2894,  511595], device='cuda:1'),   cuda:0\n",
      "hlk2data_attention_mask,   : cuda:1 \n",
      "hlk2data_input_ids :  tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0]], device='cuda:0') ,  cuda:0\n",
      "tensor([[  101,  2236,  3738,  1999,  1996,  8055,  2163,  2390,   102],\n",
      "        [  101,  5900,  2110, 10211,   102,     0,     0,     0,     0],\n",
      "        [  101,  9991, 15049,  2808,   102,     0,     0,     0,     0],\n",
      "        [  101,  3534,  2051,  4224,   102,     0,     0,     0,     0],\n",
      "        [  101,  3009,  2653,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  4956,  7778,  2181,   102,     0,     0,     0,     0]],\n",
      "       device='cuda:1')hlk2lbl2data_idx  , :   cuda:1tensor([  40156,  527144, 1560778,  552110,  757054], device='cuda:0') \n",
      ", hlk2data_attention_mask  : cuda:0 \n",
      "hlk2lbl2data_input_ids : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0]], device='cuda:1')  ,  cuda:1\n",
      "tensor([[  101,  2061, 28400,  8939, 20720, 13714,  2358, 22134,  3334,   102],\n",
      "        [  101,  2460,  2828, 19681,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2632, 13959,  7464,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1054, 22394,  1011,  2465, 27636,   102,     0,     0,     0],\n",
      "        [  101, 20704,  3217, 23475,   102,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0')hlk2lbl2data_idx ,  :   cuda:0\n",
      "tensor([  13617, 1644592,   12853,  656719,   42218,  948160,     254,    7140,\n",
      "           2932,   46779,  441558, 1914233, 2337137, 2455908], device='cuda:1')hlk2lbl2data_attention_mask  ,  :  cuda:1\n",
      "hlk2lbl2data_input_ids : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]], device='cuda:0')  ,  cuda:0\n",
      "tensor([[  101,  2343,  1997,  1996,  8055,  2163,  1997,  2637,   102,     0],\n",
      "        [  101,  4557, 21863,  5420,  3044,   102,     0,     0,     0,     0],\n",
      "        [  101,  2390,  1997,  5900,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5340, 20082,  3483,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  3448,  6627,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2120,  4236,  1997,  3181,  3182, 26213,  1999,  2662,   102],\n",
      "        [  101,  2142,  2163,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2120,  4236,  1997,  3181,  3182,   102,     0,     0,     0],\n",
      "        [  101,  2662,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 11932,  3028,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 20287,  5063,  2653,   102,     0,     0,     0,     0,     0],\n",
      "        [  101, 25540,  2571, 26614,  2697,   102,     0,     0,     0,     0],\n",
      "        [  101,  9805,  3676,  1011, 10514, 12079,  6671,   102,     0,     0],\n",
      "        [  101,  9805,  3676,  2221,  3075,   102,     0,     0,     0,     0]],\n",
      "       device='cuda:1') ,  cuda:1\n",
      "hlk2lbl2data_attention_mask :  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]], device='cuda:1') ,  cuda:1\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "o = m(**bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49800f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all([torch.all(bb[k] == o[k].to('cpu')) for k in o.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d60df7f-8004-49ec-8cce-eb36a285c8e2",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c68a8a60-afdd-46a7-92f7-54e38080d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def __call__(self:RemoveColumnsCollator, features):\n",
    "    if isinstance(features, list):\n",
    "        features = [self._remove_columns(feature) for feature in features]\n",
    "    elif isinstance(features, dict) or isinstance(features, BatchEncoding):\n",
    "        features = self._remove_columns(features)\n",
    "    else:\n",
    "        raise ValueError(f'Invalid input type: {type(features)}')\n",
    "    return self.data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fee7b634-3ec5-4b5c-9d1f-75f32fa47fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCEvalLoopOutput(NamedTuple):\n",
    "    pred_idx: Union[np.ndarray, Tuple[np.ndarray]]\n",
    "    pred_ptr: Union[np.ndarray, Tuple[np.ndarray]]\n",
    "    pred_score: Union[np.ndarray, Tuple[np.ndarray]]\n",
    "    targ_idx: Optional[Union[np.ndarray, Tuple[np.ndarray]]]\n",
    "    targ_ptr: Optional[Union[np.ndarray, Tuple[np.ndarray]]]\n",
    "    gen_output: Optional[Dict]\n",
    "    repr_output: Optional[Dict]\n",
    "    metrics: Optional[Dict[str, float]]\n",
    "    num_samples: Optional[int]\n",
    "\n",
    "class XCPredictionOutput(NamedTuple):\n",
    "    pred_idx: Union[np.ndarray, Tuple[np.ndarray]]\n",
    "    pred_ptr: Union[np.ndarray, Tuple[np.ndarray]]\n",
    "    pred_score: Optional[Union[np.ndarray, Tuple[np.ndarray]]]\n",
    "    gen_output: Optional[Dict]\n",
    "    repr_output: Optional[Dict]\n",
    "    metrics: Optional[Dict[str, float]]\n",
    "    num_samples: Optional[int]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344f0926-8c47-420e-862b-750b2f19cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ParallelMode(Enum):\n",
    "    NOT_PARALLEL = \"not_parallel\"\n",
    "    NOT_DISTRIBUTED = \"not_distributed\"\n",
    "    DISTRIBUTED = \"distributed\"\n",
    "    SAGEMAKER_MODEL_PARALLEL = \"sagemaker_model_parallel\"\n",
    "    SAGEMAKER_DATA_PARALLEL = \"sagemaker_data_parallel\"\n",
    "    TPU = \"tpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8444fb71-7eb7-43c6-96ba-71759aa2b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCLearningArguments(Seq2SeqTrainingArguments):\n",
    "\n",
    "    @delegates(Seq2SeqTrainingArguments.__init__)\n",
    "    def __init__(self, \n",
    "                 use_encoder_parallel:Optional[bool]=False,\n",
    "                 generation_length_penalty:Optional[float]=1.0,\n",
    "                 generation_eos_token:Optional[int]=102,\n",
    "                 generation_num_beams:Optional[int]=5,\n",
    "                 generation_max_info:Optional[int]=None,\n",
    "                 representation_accumulation_steps:Optional[int]=None,\n",
    "                 \n",
    "                 output_representation_attribute:Optional[str]='data_repr',\n",
    "                 label_representation_attribute:Optional[str]='data_repr',\n",
    "                 representation_attribute:Optional[str]='data_repr',\n",
    "\n",
    "                 use_data_metadata_for_representation:Optional[bool]=False,\n",
    "                 \n",
    "                 representation_num_beams:Optional[int]=5,\n",
    "                 representation_search_type:Optional[str]='INDEX',\n",
    "                 index_space:Optional[str]='cosine', \n",
    "                 index_efc:Optional[int]=300, \n",
    "                 index_m:Optional[int]=100, \n",
    "                 index_efs:Optional[int]=300,\n",
    "                 index_num_threads:Optional[int]=84,\n",
    "                 use_cpu_for_searching:Optional[bool]=False,\n",
    "                 predict_with_generation:Optional[bool]=False,\n",
    "                 predict_with_representation:Optional[bool]=False,\n",
    "                 output_concatenation_weight:Optional[float]=1.0,\n",
    "                 group_by_cluster:Optional[bool]=False,\n",
    "                 num_clustering_warmup_epochs:Optional[int]=None,\n",
    "                 num_cluster_update_epochs:Optional[int]=1,\n",
    "                 num_cluster_size_update_epochs:Optional[int]=1,\n",
    "                 clustering_type:Optional[str]='EXPO',\n",
    "                 minimum_clusters:Optional[int]=3,\n",
    "                 maximum_clusters:Optional[int]=None,\n",
    "                 minimum_cluster_size:Optional[int]=1,\n",
    "                 maximum_cluster_size:Optional[int]=None,\n",
    "                 clustering_devices:Optional[List]=None,\n",
    "                 use_cpu_for_clustering:Optional[bool]=True,\n",
    "                 use_data_metadata_for_clustering:Optional[bool]=False,\n",
    "                 clustering_representation_attribute:Optional[str]='data_repr',\n",
    "                 \n",
    "                 target_indices_key:Optional[str]='lbl2data_idx',\n",
    "                 target_pointer_key:Optional[str]='lbl2data_data2ptr',\n",
    "                 \n",
    "                 data_aug_meta_name:Optional[str]=None,\n",
    "                 data_aug_prefix:Optional[str]=None,\n",
    "                 augmentation_num_beams:Optional[int]=3,\n",
    "                 predict_with_augmentation:Optional[bool]=False,\n",
    "                 use_augmentation_index_representation:Optional[bool]=False,\n",
    "                 metadata_representation_attribute:Optional[str]='data_repr',\n",
    "                 data_augmentation_attribute:Optional[str]='data_repr',\n",
    "                 data_meta_batch_size:Optional[int]=2048,\n",
    "\n",
    "                 augment_metadata:Optional[bool]=False,\n",
    "                 num_metadata_augment_epochs:Optional[int]=1,\n",
    "                 num_metadata_augment_warmup_epochs:Optional[int]=10,\n",
    "\n",
    "                 centroid_data_batch_size:Optional[int]=2048,\n",
    "                 centroid_data_attribute_representation:Optional[str]='data_repr',\n",
    "                 use_centroid_data_metadata:Optional[bool]=False,\n",
    "                 use_centroid_label_representation:Optional[bool]=False,\n",
    "\n",
    "                 use_teacher_lbl_representation:Optional[bool]=False,\n",
    "                 use_teacher_data_representation:Optional[bool]=False,\n",
    "                 \n",
    "                 use_distributional_representation:Optional[bool]=False,\n",
    "                 use_label_metadata:Optional[bool]=True,\n",
    "                 prune_metadata:Optional[bool]=False,\n",
    "                 num_metadata_prune_epochs:Optional[int]=1,\n",
    "                 metadata_prune_batch_size:Optional[int]=64,\n",
    "                 num_metadata_prune_warmup_epochs:Optional[int]=10,\n",
    "                 prune_metadata_names:Optional[List]=None,\n",
    "                 use_data_metadata_for_pruning:Optional[bool]=True,\n",
    "                 prune_metadata_threshold:Optional[float]=0.0,\n",
    "                 prune_metadata_topk:Optional[int]=None,\n",
    "\n",
    "                 free_parameter_warmup_steps:Optional[int]=0,\n",
    "                 free_parameter_lr_coefficient:[float]=1.0,\n",
    "\n",
    "                 mix_metadata:Optional[bool]=False,\n",
    "                 num_mix_metadata_epochs:Optional[int]=5,\n",
    "                 num_mix_metadata_warmup_epochs:Optional[int]=10,\n",
    "                 maximum_mix_metadata_epochs:Optional[int]=50,\n",
    "                 mix_metadata_name_1:Optional[str]=None,\n",
    "                 mix_metadata_name_2:Optional[str]=None,\n",
    "                 mix_metadata_k:Optional[int]=3,\n",
    "\n",
    "                 use_memory_aggressively:Optional[bool]=False,\n",
    "                 \n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        store_attr('output_representation_attribute,representation_attribute,label_representation_attribute')\n",
    "        store_attr('clustering_representation_attribute,use_data_metadata_for_clustering')\n",
    "        \n",
    "        store_attr('generation_num_beams,generation_length_penalty,generation_max_info,generation_eos_token')\n",
    "        store_attr('representation_accumulation_steps,representation_num_beams,representation_search_type')\n",
    "        store_attr('index_space,index_efc,index_m,index_efs,index_num_threads,use_cpu_for_searching')\n",
    "        store_attr('predict_with_generation,predict_with_representation,output_concatenation_weight')\n",
    "        store_attr('group_by_cluster,num_cluster_update_epochs,num_cluster_size_update_epochs,num_clustering_warmup_epochs')\n",
    "        store_attr('clustering_devices,clustering_type,maximum_cluster_size,use_cpu_for_clustering')\n",
    "        store_attr('target_indices_key,target_pointer_key')\n",
    "        store_attr('use_encoder_parallel')\n",
    "        store_attr('data_aug_meta_name,data_aug_prefix,augmentation_num_beams,predict_with_augmentation')\n",
    "        store_attr('use_augmentation_index_representation,metadata_representation_attribute,data_augmentation_attribute')\n",
    "        store_attr('use_distributional_representation')\n",
    "        store_attr('use_data_metadata_for_representation')\n",
    "        \n",
    "        store_attr('use_label_metadata,data_meta_batch_size,augment_metadata,num_metadata_augment_epochs,num_metadata_augment_warmup_epochs')\n",
    "        store_attr('use_centroid_data_metadata,use_centroid_label_representation,centroid_data_attribute_representation,centroid_data_batch_size')\n",
    "        store_attr('use_teacher_lbl_representation')\n",
    "        store_attr('use_teacher_data_representation')\n",
    "        \n",
    "        store_attr('prune_metadata,num_metadata_prune_epochs,num_metadata_prune_warmup_epochs,metadata_prune_batch_size,prune_metadata_names')\n",
    "        store_attr('use_data_metadata_for_pruning,prune_metadata_threshold,prune_metadata_topk')\n",
    "\n",
    "        store_attr('free_parameter_warmup_steps,free_parameter_lr_coefficient')\n",
    "\n",
    "        store_attr('mix_metadata,num_mix_metadata_epochs,num_mix_metadata_warmup_epochs,maximum_mix_metadata_epochs')\n",
    "        store_attr('mix_metadata_name_1,mix_metadata_name_2,mix_metadata_k')\n",
    "\n",
    "        store_attr('use_memory_aggressively')\n",
    "        self.minimum_clusters = max(1, minimum_clusters)\n",
    "        self.maximum_clusters = max(minimum_clusters, maximum_clusters) if maximum_clusters is not None else minimum_clusters\n",
    "        self.minimum_cluster_size = max(1, minimum_cluster_size)\n",
    "        \n",
    "        self.maximum_mix_metadata_epochs = min(maximum_mix_metadata_epochs, self.num_train_epochs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b036146-ad70-4c47-802c-763f1f2aaf45",
   "metadata": {},
   "source": [
    "### `XCLearner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b77b4bd-cd24-4b96-af56-474dfcbdcc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCLearner(Seq2SeqTrainer):\n",
    "\n",
    "    @delegates(Seq2SeqTrainer.__init__)\n",
    "    def __init__(self, \n",
    "                 trie:Optional[Trie]=None, \n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.tbs = TrieBeamSearch(trie, self.args.generation_eos_token, n_bm=self.args.generation_num_beams, \n",
    "                                  len_penalty=self.args.generation_length_penalty, max_info=self.args.generation_max_info, **kwargs)\n",
    "        self.idxs = (\n",
    "            BruteForceSearch(n_bm=self.args.representation_num_beams)\n",
    "            if self.args.representation_search_type == 'BRUTEFORCE' else\n",
    "            IndexSearch(space=self.args.index_space, efc=self.args.index_efc, m=self.args.index_m, \n",
    "                        efs=self.args.index_efs, n_bm=self.args.representation_num_beams, \n",
    "                        n_threads=self.args.index_num_threads) \n",
    "        )\n",
    "        self.aug_idxs = None\n",
    "\n",
    "    def _wrap_model(self, model, training=True, dataloader=None):\n",
    "        if unwrap_model(model) is not model:\n",
    "            return model\n",
    "\n",
    "        if self.args.n_gpu > 1:\n",
    "            if (hasattr(model, 'encoder') and isinstance(model.encoder, nn.DataParallel)) or self.args.use_encoder_parallel: return model\n",
    "            else: return XCDataParallel(module=model)\n",
    "        return model\n",
    "\n",
    "    def evaluate(self, eval_dataset:Optional[Dataset]=None, ignore_keys:Optional[List[str]]=None, \n",
    "             metric_key_prefix:str=\"eval\", **gen_kwargs):\n",
    "        gen_kwargs = gen_kwargs.copy()\n",
    "        if gen_kwargs.get(\"length_penalty\") is None and self.args.generation_length_penalty is not None:\n",
    "            gen_kwargs[\"length_penalty\"] = self.args.generation_length_penalty\n",
    "        if gen_kwargs.get(\"gen_num_beams\") is None and self.args.generation_num_beams is not None:\n",
    "            gen_kwargs[\"gen_num_beams\"] = self.args.generation_num_beams\n",
    "        if gen_kwargs.get(\"repr_num_beams\") is None and self.args.representation_num_beams is not None:\n",
    "            gen_kwargs[\"repr_num_beams\"] = self.args.representation_num_beams\n",
    "        if gen_kwargs.get(\"aug_num_beams\") is None and self.args.augmentation_num_beams is not None:\n",
    "            gen_kwargs[\"aug_num_beams\"] = self.args.augmentation_num_beams\n",
    "            \n",
    "        self.gather_function, self._gen_kwargs  = self.accelerator.gather, gen_kwargs\n",
    "        \n",
    "        return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
    "\n",
    "    def predict(self, test_dataset: Dataset, ignore_keys:Optional[List[str]]=None, \n",
    "            metric_key_prefix:str=\"test\", **gen_kwargs):\n",
    "        gen_kwargs = gen_kwargs.copy()\n",
    "        if gen_kwargs.get(\"length_penalty\") is None and self.args.generation_length_penalty is not None:\n",
    "            gen_kwargs[\"length_penalty\"] = self.args.generation_length_penalty\n",
    "        if gen_kwargs.get(\"gen_num_beams\") is None and self.args.generation_num_beams is not None:\n",
    "            gen_kwargs[\"gen_num_beams\"] = self.args.generation_num_beams\n",
    "        if gen_kwargs.get(\"repr_num_beams\") is None and self.args.representation_num_beams is not None:\n",
    "            gen_kwargs[\"repr_num_beams\"] = self.args.representation_num_beams\n",
    "        if gen_kwargs.get(\"aug_num_beams\") is None and self.args.augmentation_num_beams is not None:\n",
    "            gen_kwargs[\"aug_num_beams\"] = self.args.augmentation_num_beams\n",
    "    \n",
    "        self.gather_function, self._gen_kwargs = self.accelerator.gather, gen_kwargs\n",
    "        self._memory_tracker.start()\n",
    "    \n",
    "        test_dataloader = self.get_test_dataloader(test_dataset)\n",
    "        start_time = time.time()\n",
    "    \n",
    "        output = self.evaluation_loop(test_dataloader, description=\"Prediction\", ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
    "        total_batch_size = self.args.eval_batch_size * self.args.world_size\n",
    "        if f\"{metric_key_prefix}_jit_compilation_time\" in output.metrics:\n",
    "            start_time += output.metrics[f\"{metric_key_prefix}_jit_compilation_time\"]\n",
    "        output.metrics.update(\n",
    "            speed_metrics(metric_key_prefix,start_time,num_samples=output.num_samples,num_steps=math.ceil(output.num_samples / total_batch_size),)\n",
    "        )\n",
    "        self.control = self.callback_handler.on_predict(self.args, self.state, self.control, output.metrics)\n",
    "        self._memory_tracker.stop_and_update_metrics(output.metrics)\n",
    "        return XCPredictionOutput(pred_idx=output.pred_idx, pred_ptr=output.pred_ptr, pred_score=output.pred_score, \n",
    "                              gen_output=output.gen_output, repr_output=output.repr_output, metrics=output.metrics, \n",
    "                              num_samples=output.num_samples)\n",
    "    \n",
    "    def _gather_host_output(self, output, host_output):\n",
    "        if output is not None:\n",
    "            output = self.accelerator.pad_across_processes(output, dim=1, pad_index=-100)\n",
    "            output = self.gather_function((output))\n",
    "            return output if host_output is None else nested_concat(host_output, output, padding_index=-100)\n",
    "        else: return host_output\n",
    "\n",
    "    def _gather_all_output(self, host_output, all_output, to_cpu=True):\n",
    "        if host_output is not None:\n",
    "            if isinstance(host_output, torch.Tensor) and to_cpu: host_output = host_output.cpu()\n",
    "            return host_output if all_output is None else nested_concat(all_output, host_output, padding_index=-100)\n",
    "        else: return all_output\n",
    "\n",
    "    def create_optimizer_and_scheduler(self, num_training_steps: int):\n",
    "        if hasattr(self.model, 'meta_embeddings') and self.model.meta_embeddings.sparse:\n",
    "            NO_DECAY = ['bias', 'LayerNorm.weight']\n",
    "        \n",
    "            dense, sparse = [], []\n",
    "            for k, p in self.model.named_parameters():\n",
    "                if p.requires_grad:\n",
    "                    if \"meta_embeddings\" not in k: dense.append((k,p))\n",
    "                    else: sparse.append(p)\n",
    "        \n",
    "            params = [\n",
    "                {'params': [p for n, p in dense if not any(nd in n for nd in NO_DECAY)], 'weight_decay': 0.01},\n",
    "                {'params': [p for n, p in dense if any(nd in n for nd in NO_DECAY)], 'weight_decay': 0.0},\n",
    "            ]\n",
    "        \n",
    "            optimizer_list = [torch.optim.AdamW(params, **{'lr': self.args.learning_rate, 'eps': 1e-6}),\n",
    "                              torch.optim.SparseAdam(sparse, **{'lr': self.args.learning_rate * self.args.free_parameter_lr_coefficient, 'eps': 1e-6})]\n",
    "        \n",
    "            self.optimizer = MultipleOptimizer(optimizer_list)\n",
    "            scheduler_list = [transformers.get_linear_schedule_with_warmup(self.optimizer.optimizers[0], num_warmup_steps=self.args.warmup_steps,\n",
    "                                                                           num_training_steps=num_training_steps),\n",
    "                                transformers.get_cosine_schedule_with_warmup(self.optimizer.optimizers[1],\n",
    "                                                                             num_warmup_steps=self.args.free_parameter_warmup_steps,\n",
    "                                                                             num_training_steps=num_training_steps)]\n",
    "        \n",
    "            self.lr_scheduler = MultipleScheduler(scheduler_list)\n",
    "        else:\n",
    "            super().create_optimizer_and_scheduler(num_training_steps)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b506de6-d6bc-4e9d-a9df-85c673c12286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _get_dataset(self:XCLearner, dataset:Dataset, dset_type:str='lbl', use_metadata:Optional[bool]=False):\n",
    "    dset = get_attr(dataset, f'{dset_type}_dset')\n",
    "\n",
    "    data_aug_prefix = self.args.data_aug_meta_name if self.args.data_aug_prefix is None else self.args.data_aug_prefix\n",
    "    meta_name = f'{data_aug_prefix}_meta' if data_aug_prefix is not None else None\n",
    "    \n",
    "    if (\n",
    "        meta_name is not None and \n",
    "        dataset.meta is not None and \n",
    "        meta_name in dataset.meta and \n",
    "        use_metadata\n",
    "    ):    \n",
    "        meta_dset= dataset.meta[meta_name]\n",
    "        prefix,meta,meta_info  = meta_dset.prefix, get_attr(meta_dset, f'{dset_type}_meta'), meta_dset.meta_info\n",
    "\n",
    "        if dset_type == 'data':\n",
    "            metadata = type(meta_dset)(prefix=prefix, data_meta=meta, lbl_meta=sparse.csr_matrix((dataset.n_lbl, meta_dset.n_meta)), meta_info=meta_info)            \n",
    "        elif dset_type == 'lbl':\n",
    "            metadata = type(meta_dset)(prefix=prefix, data_meta=meta, lbl_meta=sparse.csr_matrix((dataset.n_data, meta_dset.n_meta)), meta_info=meta_info)\n",
    "        else: raise ValueError(f'Invalid `dset_type`, should be one of [\"data\", \"lbl\"].')\n",
    "\n",
    "        if isinstance(metadata, SMetaXCDataset):\n",
    "            metadata.n_data_meta_samples = meta_dset.n_data_meta_samples\n",
    "            metadata.n_sdata_meta_samples = meta_dset.n_sdata_meta_samples\n",
    "            metadata.meta_oversample = meta_dset.meta_oversample\n",
    "        elif isinstance(metadata, MetaXCDataset):\n",
    "            metadata.n_data_meta_samples = self.args.augmentation_num_beams\n",
    "        else: raise ValueError('Invalid meta dataset.')\n",
    "\n",
    "        meta_kwargs = {meta_name: metadata}\n",
    "        dset = type(dataset)(dset, **meta_kwargs)\n",
    "        \n",
    "    return dset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02cc228b-c71e-4f8f-a51b-3e495fc5337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _build_aug_index(self:XCLearner, dataset:Optional[Dataset]=None):\n",
    "    dataset = dataset if self.eval_dataset is None else self.eval_dataset\n",
    "    dataset = dataset if self.train_dataset is None else self.train_dataset\n",
    "    \n",
    "    meta_name = f'{self.args.data_aug_meta_name}_meta' if self.args.data_aug_meta_name is not None else None\n",
    "    if (\n",
    "        dataset is not None and \n",
    "        dataset.meta is not None and \n",
    "        meta_name is not None and \n",
    "        meta_name in dataset.meta\n",
    "    ):\n",
    "        self.aug_idxs = IndexSearch(space=self.args.index_space, efc=self.args.index_efc, m=self.args.index_m, \n",
    "                                    efs=self.args.index_efs, n_bm=self.args.augmentation_num_beams, \n",
    "                                    n_threads=self.args.index_num_threads)\n",
    "        \n",
    "        dset = type(dataset.data)(data_info=getattr(dataset.meta[meta_name], 'meta_info'))\n",
    "        dataloader = self.get_test_dataloader(dset)\n",
    "        rep = self.get_meta_representation(dataloader, to_cpu=isinstance(self.aug_idxs, IndexSearch))\n",
    "        self.aug_idxs.build(rep)\n",
    "\n",
    "@patch\n",
    "def _build_lbl_index(self:XCLearner, dataset:Optional[Dataset]=None):\n",
    "    dataset = self.eval_dataset if dataset is None or dataset.lbl_info is None else dataset\n",
    "    dataset = self.train_dataset if dataset is None or dataset.lbl_info is None else dataset\n",
    "    \n",
    "    if dataset is not None: \n",
    "        to_cpu = True if isinstance(self.idxs, IndexSearch) else self.args.use_cpu_for_searching\n",
    "        lbl_rep = self._get_lbl_representation(dataset, to_cpu=to_cpu)\n",
    "        self.idxs.build(lbl_rep)\n",
    "    else: raise ValueError('Failed to build `self.idxs`')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e5f5014-d15b-4419-b85c-bbbf6fe15346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _get_lbl_representation(self:XCLearner, dataset:Optional[Dataset]=None, to_cpu:Optional[bool]=False):\n",
    "    if dataset is not None:\n",
    "        if self.args.use_centroid_label_representation:\n",
    "            dataset = dataset if self.train_dataset else self.train_dataset\n",
    "            \n",
    "            if self.args.use_teacher_data_representation:\n",
    "                if not hasattr(self.model, 'm_teacher'): raise ValueError('Model does not contain `m_teacher`.')\n",
    "                data_rep = self.model.m_teacher.get_data_embeddings().data.cpu()\n",
    "            else:\n",
    "                dset = self._get_dataset(dataset, dset_type='data', use_metadata=self.args.use_centroid_data_metadata)\n",
    "                dataloader = self.get_test_dataloader(dset)\n",
    "                data_rep = self.get_representation(dataloader, representation_attribute=self.args.centroid_data_attribute_representation)\n",
    "            \n",
    "            lbl_data = dataset.data.data_lbl.T.tocsr()\n",
    "            \n",
    "            lbl_rep = None\n",
    "            for i in tqdm(range(0, lbl_data.shape[0], self.args.centroid_data_batch_size)):\n",
    "                data = lbl_data[i:i+self.args.centroid_data_batch_size]\n",
    "                rep = data@data_rep\n",
    "                rep = rep/data.getnnz(axis=1).reshape(-1, 1)\n",
    "                rep = (\n",
    "                    torch.tensor(rep, dtype=data_rep.dtype) \n",
    "                    if isinstance(self.idxs, IndexSearch) else \n",
    "                    torch.tensor(rep, device=self.model.device, dtype=data_rep.dtype)\n",
    "                )\n",
    "                lbl_rep = rep if lbl_rep is None else torch.cat([lbl_rep,rep], dim=0)\n",
    "                \n",
    "        elif self.args.use_teacher_lbl_representation:\n",
    "            if not hasattr(self.model, 'm_teacher'): raise ValueError('Model does not contain `m_teacher`.')\n",
    "            lbl_rep = self.model.m_teacher.get_lbl_embeddings().data\n",
    "        else:\n",
    "            dset = self._get_dataset(dataset, dset_type='lbl', use_metadata=self.args.use_label_metadata)\n",
    "            dataloader = self.get_test_dataloader(dset)\n",
    "            \n",
    "            if hasattr(self.model, 'get_label_representation'): lbl_rep = self.get_label_representation(dataloader, to_cpu=to_cpu)\n",
    "            else:lbl_rep = self.get_representation(dataloader, representation_attribute=self.args.label_representation_attribute, to_cpu=to_cpu)\n",
    "                \n",
    "        return lbl_rep\n",
    "    else: \n",
    "        raise ValueError('`dataset` is None, could not create label representation.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9414cf2d-53fe-4a2c-bbc1-c0a5d3e4ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_label_representation(self:XCLearner, dataloader: DataLoader, to_cpu:Optional[bool]=True):\n",
    "    data_host, all_data = None, None\n",
    "    \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        use_noise = self.model.disable_noise()\n",
    "    \n",
    "    for step, inputs in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        inputs = inputs.to(self.model.device)\n",
    "        with torch.no_grad(): data = getattr(self.model.get_label_representation(**inputs), self.args.label_representation_attribute)\n",
    "        data_host = self._gather_host_output(data, data_host)\n",
    "        if self.args.representation_accumulation_steps is not None and (step + 1) % self.args.representation_accumulation_steps == 0:\n",
    "            all_data, data_host = self._gather_all_output(data_host, all_data, to_cpu=to_cpu), None\n",
    "            \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        self.model.set_noise(use_noise)\n",
    "            \n",
    "    return self._gather_all_output(data_host, all_data, to_cpu=to_cpu)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e28f8f9-c2c1-4391-8ec9-d6ea44346107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def generation_output(\n",
    "    self:XCLearner,\n",
    "    model:nn.Module,\n",
    "    inputs:Dict[str, Union[torch.Tensor, Any]],\n",
    "    **kwargs\n",
    "):\n",
    "    inputs = self._prepare_inputs(inputs)\n",
    "    n_bm = kwargs.pop(\"gen_num_beams\") if \"gen_num_beams\" in kwargs and kwargs[\"gen_num_beams\"] is not None else self.args.generation_num_beams\n",
    "    len_penalty = kwargs.pop(\"length_penalty\") if \"length_penalty\" in kwargs and kwargs[\"length_penalty\"] is not None else self.args.generation_length_penalty\n",
    "    \n",
    "    with torch.no_grad(): o = self.tbs.proc(self.model, inputs.copy(), n_bm=n_bm, len_penalty=len_penalty)\n",
    "        \n",
    "    return {'pred_idx':o['info2seq2data_idx'], 'pred_score':o['info2seq2data_score'], 'pred_ptr':o['info2seq2data_data2ptr']}\n",
    "\n",
    "@patch\n",
    "def representation_output(\n",
    "    self:XCLearner,\n",
    "    model:nn.Module,\n",
    "    inputs:Dict[str, Union[torch.Tensor, Any]],\n",
    "    **kwargs\n",
    "):\n",
    "    inputs = self._prepare_inputs(inputs)\n",
    "    n_bm = kwargs.pop(\"repr_num_beams\") if \"repr_num_beams\" in kwargs and kwargs[\"repr_num_beams\"] is not None else self.args.representation_num_beams\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        o = model(**inputs)\n",
    "        if getattr(o, self.args.output_representation_attribute) is not None:\n",
    "            o = getattr(o, self.args.output_representation_attribute)\n",
    "        else:\n",
    "            o = getattr(o, self.args.representation_attribute)\n",
    "        if self.args.use_distributional_representation: o = o.exp()\n",
    "            \n",
    "    o = self.idxs.proc(o, n_bm=n_bm)\n",
    "        \n",
    "    return {'pred_idx':o['info2data_idx'], 'pred_score':o['info2data_score'], 'pred_ptr':o['info2data_data2ptr']}\n",
    "\n",
    "@patch\n",
    "def augmentation_output(\n",
    "    self:XCLearner,\n",
    "    model:nn.Module,\n",
    "    inputs:Dict[str, Union[torch.Tensor, Any]],\n",
    "    **kwargs\n",
    "):\n",
    "    if self.aug_idxs is None: \n",
    "        raise ValueError('Augmentation index `aug_idx` is not initialized.')\n",
    "        \n",
    "    inputs = self._prepare_inputs(inputs)\n",
    "    n_bm = kwargs.pop(\"aug_num_beams\") if \"aug_num_beams\" in kwargs and kwargs[\"aug_num_beams\"] is not None else self.args.augmentation_num_beams\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        inputs = {'data_input_ids':inputs['data_input_ids'], 'data_attention_mask':inputs['data_attention_mask']}\n",
    "        o = getattr(model(**inputs), self.args.data_augmentation_attribute)\n",
    "        if self.args.use_distributional_representation: o = o.exp()\n",
    "            \n",
    "    o = self.aug_idxs.proc(o, n_bm=n_bm)\n",
    "\n",
    "    \"\"\"\n",
    "    Preparing augmentation input\n",
    "    \"\"\"\n",
    "    meta_name = f'{self.args.data_aug_meta_name}_meta'\n",
    "    if (\n",
    "        meta_name is not None and \n",
    "        self.train_dataset.meta is not None and \n",
    "        meta_name in self.train_dataset.meta\n",
    "    ):    \n",
    "        meta_dset = self.train_dataset.meta[meta_name]\n",
    "        aug_info  = meta_dset.meta_info\n",
    "    else:\n",
    "        raise ValueError(f'Augmentation information not available.')\n",
    "            \n",
    "    pad_proc = PadFeatTfm(pad_tok=self.model.config.pad_token_id, prefix=\"meta\")\n",
    "    info = pad_proc({\n",
    "        'meta_input_ids':[aug_info['input_ids'][i] for i in o['info2data_idx']], \n",
    "        'meta_attention_mask':[aug_info['attention_mask'][i] for i in o['info2data_idx']],\n",
    "    })\n",
    "\n",
    "    data_aug_prefix = self.args.data_aug_meta_name if self.args.data_aug_prefix is None else self.args.data_aug_prefix\n",
    "    \n",
    "    if self.args.use_augmentation_index_representation:\n",
    "        rep = torch.tensor(self.aug_idxs.get_items(o['info2data_idx']))\n",
    "        return {\n",
    "            f'{data_aug_prefix}2data_idx':o['info2data_idx'],\n",
    "            f'{data_aug_prefix}2data_data2ptr': o['info2data_data2ptr'],\n",
    "            f'{data_aug_prefix}2data_meta_repr': rep,\n",
    "            f'{data_aug_prefix}2data_attention_mask': info['meta_attention_mask'],\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            f'{data_aug_prefix}2data_idx':o['info2data_idx'], \n",
    "            f'{data_aug_prefix}2data_data2ptr': o['info2data_data2ptr'],\n",
    "            f'{data_aug_prefix}2data_input_ids': info['meta_input_ids'], \n",
    "            f'{data_aug_prefix}2data_attention_mask': info['meta_attention_mask'],\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5967d99a-b531-4ff0-83a7-6808c0a8ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _perform_generation(self:XCLearner, model:nn.Module, predict_with_generation:Optional[bool]=None):\n",
    "    model = unwrap_model(model)\n",
    "    predict_with_generation = self.args.predict_with_generation if predict_with_generation is None else predict_with_generation\n",
    "    return getattr(model,'use_generation') if hasattr(model,'use_generation') else predict_with_generation\n",
    "\n",
    "@patch\n",
    "def _perform_representation(self:XCLearner, model:nn.Module, predict_with_representation:Optional[bool]=None):\n",
    "    model = unwrap_model(model)\n",
    "    predict_with_representation = self.args.predict_with_representation if predict_with_representation is None else predict_with_representation\n",
    "    return getattr(model,'use_representation') if hasattr(model,'use_representation') else predict_with_representation\n",
    "\n",
    "@patch\n",
    "def _perform_augmentation(self:XCLearner, model:nn.Module, predict_with_augmentation:Optional[bool]=None):\n",
    "    model = unwrap_model(model)\n",
    "    predict_with_augmentation = self.args.predict_with_augmentation if predict_with_augmentation is None else predict_with_augmentation\n",
    "    return getattr(model,'use_augmentation') if hasattr(model,'use_augmentation') else predict_with_augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6351dde7-b678-41d5-b710-005cb7db6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def resize_pred(cls:XCLearner, t, n_t):\n",
    "    max_n_t = n_t.max()\n",
    "    xn_t = max_n_t.max()-n_t+1\n",
    "    t_ptr = n_t.cumsum(dim=0)-1\n",
    "    r_t = torch.ones((len(t),), dtype=xn_t.dtype, device=xn_t.device).scatter(0, t_ptr, xn_t)\n",
    "    xt = t.repeat_interleave(r_t).view(len(n_t), -1)\n",
    "    return xt\n",
    "\n",
    "@patch\n",
    "def output_mask(cls:XCLearner, n_t, l):\n",
    "    max_n_t = n_t.max()\n",
    "    xn_t = max_n_t.max()-n_t+1\n",
    "    t_ptr = n_t.cumsum(dim=0)-1\n",
    "    mask_ptr = t_ptr+torch.arange(len(t_ptr), device=t_ptr.device)+1\n",
    "    mask = torch.ones((l+len(n_t),), dtype=mask_ptr.dtype, device=mask_ptr.device).scatter(0, mask_ptr, 0)\n",
    "    r_mask = torch.ones((l+len(n_t),), dtype=mask_ptr.dtype, device=mask_ptr.device).scatter(0, mask_ptr, xn_t-1)\n",
    "    mask = mask.repeat_interleave(r_mask).view(len(n_t), -1)\n",
    "    return mask\n",
    "\n",
    "@patch\n",
    "def resize_output(cls:XCLearner, pred_idx, pred_score, pred_ptr):\n",
    "    return cls.resize_pred(pred_idx, pred_ptr), cls.resize_pred(pred_score, pred_ptr), cls.output_mask(pred_ptr, len(pred_idx)), pred_ptr\n",
    "\n",
    "@patch\n",
    "def concatenate_output(cls:XCLearner, gen_o:Dict, repr_o:Dict):\n",
    "    gen_o['pred_score'] = torch.exp(gen_o['pred_score'])*cls.args.output_concatenation_weight\n",
    "    gen_o, repr_o = cls.resize_output(**gen_o), cls.resize_output(**repr_o)\n",
    "    pred_idx, pred_score, mask = [torch.hstack([gen_o[i], repr_o[i].cpu()]).flatten() for i in range(3)]\n",
    "    idx = torch.where(mask)[0]\n",
    "    return {\n",
    "        'pred_idx': pred_idx[idx],\n",
    "        'pred_score': pred_score[idx],\n",
    "        'pred_ptr': gen_o[3]+repr_o[3].cpu(),\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a98e5ae1-6971-416b-9b11-1e6234632c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def prediction_step(\n",
    "    self:XCLearner,\n",
    "    model: nn.Module,\n",
    "    inputs: Dict[str, Union[torch.Tensor, Any]],\n",
    "    prediction_loss_only: bool,\n",
    "    predict_with_generation: bool,\n",
    "    predict_with_representation: bool,\n",
    "    predict_with_augmentation:Optional[bool]=None,\n",
    "    ignore_keys: Optional[List[str]] = None,\n",
    "    **kwargs,\n",
    ") -> Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "    with torch.no_grad():\n",
    "        with self.compute_loss_context_manager(): outputs = model(**inputs)\n",
    "        if isinstance(outputs, dict):\n",
    "            loss = outputs[\"loss\"] if \"loss\" in outputs else None\n",
    "        else:\n",
    "            loss = outputs[0]\n",
    "        if loss is not None: loss = loss.mean().detach()            \n",
    "    prediction_loss_only = self.args.prediction_loss_only if prediction_loss_only is None else prediction_loss_only\n",
    "    if prediction_loss_only: return loss, {}\n",
    "    \n",
    "    if self._perform_augmentation(model, predict_with_augmentation): \n",
    "        aug_inputs = self.augmentation_output(model, inputs, **kwargs)\n",
    "        inputs.update(aug_inputs)\n",
    "        \n",
    "    output, gen_o, repr_o = None, None, None\n",
    "    if self._perform_generation(model, predict_with_generation): gen_o = self.generation_output(model, inputs, **kwargs)\n",
    "    if self._perform_representation(model, predict_with_representation): repr_o = self.representation_output(model, inputs, **kwargs)\n",
    "    \n",
    "    if gen_o is not None and repr_o is not None:\n",
    "        output = {f'{k}_gen':v for k,v in gen_o.items()}\n",
    "        output.update({f'{k}_repr':v for k,v in repr_o.items()})\n",
    "        output.update(self.concatenate_output(gen_o, repr_o))\n",
    "    else:\n",
    "        output = gen_o if repr_o is None else repr_o\n",
    "        \n",
    "    labels = {'targ_idx':inputs[self.args.target_indices_key], 'targ_ptr':inputs[self.args.target_pointer_key]} if self.args.target_indices_key in inputs else None\n",
    "    if labels is not None: output.update(labels)\n",
    "    \n",
    "    return loss, output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f189c5d7-a677-43e6-a78d-7485c07d9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def evaluation_loop(\n",
    "    self:XCLearner,\n",
    "    dataloader:DataLoader,\n",
    "    description:str,\n",
    "    prediction_loss_only:Optional[bool] = None,\n",
    "    predict_with_generation:Optional[bool]=None,\n",
    "    predict_with_representation:Optional[bool]=None,\n",
    "    ignore_keys:Optional[List[str]] = None,\n",
    "    metric_key_prefix:str=\"eval\",\n",
    ") -> XCEvalLoopOutput:\n",
    "    args = self.args\n",
    "    prediction_loss_only = prediction_loss_only if prediction_loss_only is not None else args.prediction_loss_only\n",
    "\n",
    "    \"\"\"\n",
    "    Disable random addition of noise\n",
    "    \"\"\"\n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        use_noise = self.model.disable_noise()\n",
    "\n",
    "    model = self._wrap_model(self.model, training=False, dataloader=dataloader)\n",
    "\n",
    "    if len(self.accelerator._models) == 0 and model is self.model:\n",
    "        model = self.accelerator.prepare(model) if self.is_deepspeed_enabled else self.accelerator.prepare_model(model, evaluation_mode=True)\n",
    "        if self.is_fsdp_enabled: self.model = model\n",
    "        if model is not self.model: self.model_wrapped = model\n",
    "        if self.is_deepspeed_enabled: self.deepspeed = self.model_wrapped\n",
    "\n",
    "    batch_size = self.args.eval_batch_size\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    self.callback_handler.eval_dataloader = dataloader\n",
    "    eval_dataset = getattr(dataloader, \"dataset\", None)\n",
    "    \n",
    "    if self._perform_representation(unwrap_model(model)) and not prediction_loss_only: \n",
    "        self._build_lbl_index(eval_dataset)\n",
    "            \n",
    "    if self._perform_augmentation(unwrap_model(model)) and not prediction_loss_only: \n",
    "        self._build_aug_index(eval_dataset)\n",
    "    \n",
    "    if args.past_index >= 0: self._past = None\n",
    "\n",
    "    losses_host, all_losses = None, None\n",
    "    host_output, all_output = {}, {}\n",
    "    \n",
    "    observed_num_examples = 0\n",
    "    for step, inputs in enumerate(dataloader):\n",
    "        observed_batch_size = find_batch_size(inputs)\n",
    "        if observed_batch_size is not None:\n",
    "            observed_num_examples += observed_batch_size\n",
    "            if batch_size is None: batch_size = observed_batch_size\n",
    "                \n",
    "        loss, output = self.prediction_step(model, inputs, prediction_loss_only, predict_with_generation, predict_with_representation, ignore_keys=ignore_keys)\n",
    "        \n",
    "        if loss is not None:\n",
    "            losses = self.gather_function((loss.repeat(batch_size)))\n",
    "            losses_host = losses if losses_host is None else nested_concat(losses_host, losses, padding_index=-100)\n",
    "        for k in output: host_output[k] = self._gather_host_output(output[k], host_output.get(k, None))\n",
    "            \n",
    "        self.control = self.callback_handler.on_prediction_step(args, self.state, self.control)\n",
    "        \n",
    "        if args.eval_accumulation_steps is not None and (step + 1) % args.eval_accumulation_steps == 0:\n",
    "            if losses_host is not None: all_losses = losses_host if all_losses is None else nested_concat(all_losses, losses, padding_index=-100)\n",
    "            for k in host_output: all_output[k], host_output[k] = self._gather_all_output(host_output[k], all_output.get(k, None)), None\n",
    "    \n",
    "    self.gather_function = self.accelerator.gather_for_metrics\n",
    "    if args.past_index and hasattr(self, \"_past\"): delattr(self, \"_past\")\n",
    "\n",
    "    if losses_host is not None: all_losses = losses_host if all_losses is None else nested_concat(all_losses, losses, padding_index=-100)\n",
    "    for k in host_output: all_output[k], host_output[k] = self._gather_all_output(host_output[k], all_output.get(k, None)), None\n",
    "        \n",
    "    if has_length(eval_dataset): num_samples = len(eval_dataset)\n",
    "    elif isinstance(eval_dataset, IterableDatasetShard) and getattr(eval_dataset, \"num_examples\", 0) > 0:\n",
    "        num_samples = eval_dataset.num_examples\n",
    "    else:\n",
    "        if has_length(dataloader): num_samples = self.num_examples(dataloader)\n",
    "        else: num_samples = observed_num_examples\n",
    "    if num_samples == 0 and observed_num_examples > 0: num_samples = observed_num_examples\n",
    "        \n",
    "    gen_output, repr_output = None, None\n",
    "    metric_input_keys = ['targ_idx', 'targ_ptr', 'pred_idx', 'pred_ptr', 'pred_score']\n",
    "    if 'pred_idx_gen' in all_output and all_output['pred_idx_gen'] is not None:\n",
    "        gen_output = {o:all_output[f'{o}_gen' if o.startswith('pred_') else o] for o in metric_input_keys}\n",
    "    if 'pred_idx_repr' in all_output and all_output['pred_idx_repr'] is not None:\n",
    "        repr_output = {o:all_output[f'{o}_repr' if o.startswith('pred_') else o] for o in metric_input_keys}\n",
    "    \n",
    "\n",
    "    if (self.compute_metrics is not None and \n",
    "        'targ_idx' in all_output and all_output['targ_idx'] is not None and \n",
    "        'pred_idx' in all_output and all_output['pred_idx'] is not None):\n",
    "        \n",
    "        metrics = self.compute_metrics(**{o:all_output[o] for o in metric_input_keys})\n",
    "        if gen_output is not None:\n",
    "            m = self.compute_metrics(**gen_output)\n",
    "            metrics.update({f'{k}_GEN':v for k,v in m.items()})\n",
    "        if repr_output is not None:\n",
    "            m = self.compute_metrics(**repr_output)\n",
    "            metrics.update({f'{k}_REPR':v for k,v in m.items()})      \n",
    "    else: metrics = {}\n",
    "        \n",
    "    metrics = denumpify_detensorize(metrics)\n",
    "\n",
    "    if all_losses is not None: metrics[f\"{metric_key_prefix}_loss\"] = all_losses.mean().item()\n",
    "    if hasattr(self, \"jit_compilation_time\"): metrics[f\"{metric_key_prefix}_jit_compilation_time\"] = self.jit_compilation_time\n",
    "        \n",
    "    for key in list(metrics.keys()):\n",
    "        if not key.startswith(f\"{metric_key_prefix}_\"): metrics[f\"{metric_key_prefix}_{key}\"] = metrics.pop(key)\n",
    "\n",
    "    \"\"\"\n",
    "    Set the noise addition state back\n",
    "    \"\"\"\n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        self.model.set_noise(use_noise)\n",
    "    \n",
    "    return XCEvalLoopOutput(pred_idx=all_output.get('pred_idx'), pred_ptr=all_output.get('pred_ptr'), \n",
    "                            pred_score=all_output.get('pred_score'),targ_idx=all_output.get('targ_idx'), \n",
    "                            targ_ptr=all_output.get('targ_ptr'), gen_output=gen_output, repr_output=repr_output,\n",
    "                            metrics=metrics, num_samples=num_samples)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d626f2e-22fa-4b44-82d9-af7d082cb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_meta_representation(self:XCLearner, dataloader: DataLoader, to_cpu:Optional[bool]=True):\n",
    "    data_host, all_data = None, None\n",
    "    \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        use_noise = self.model.disable_noise()\n",
    "    \n",
    "    for step, inputs in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        inputs = inputs.to(self.model.device)\n",
    "        with torch.no_grad(): data = getattr(self.model.get_meta_representation(**inputs), self.args.metadata_representation_attribute)\n",
    "        data_host = self._gather_host_output(data, data_host)\n",
    "        if self.args.representation_accumulation_steps is not None and (step + 1) % self.args.representation_accumulation_steps == 0:\n",
    "            all_data, data_host = self._gather_all_output(data_host, all_data, to_cpu=to_cpu), None\n",
    "            \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        self.model.set_noise(use_noise)\n",
    "            \n",
    "    return self._gather_all_output(data_host, all_data, to_cpu=to_cpu)\n",
    "\n",
    "@patch\n",
    "def get_representation(self:XCLearner, dataloader: DataLoader, representation_attribute:str, to_cpu:Optional[bool]=True):\n",
    "    data_host, all_data = None, None\n",
    "    \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        use_noise = self.model.disable_noise()\n",
    "    \n",
    "    for step, inputs in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        inputs = inputs.to(self.model.device)\n",
    "        with torch.no_grad(): data = getattr(self.model(**inputs), representation_attribute)\n",
    "        data_host = self._gather_host_output(data, data_host)\n",
    "        if self.args.representation_accumulation_steps is not None and (step + 1) % self.args.representation_accumulation_steps == 0:\n",
    "            all_data, data_host = self._gather_all_output(data_host, all_data, to_cpu=to_cpu), None\n",
    "            \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        self.model.set_noise(use_noise)\n",
    "            \n",
    "    return self._gather_all_output(data_host, all_data, to_cpu=to_cpu)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9ff3a6e-2fdd-4ca7-8673-6fcc4d5b41e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.optimizers.oakX import MultipleOptimizer, MultipleScheduler\n",
    "\n",
    "@patch\n",
    "def create_optimizer_and_scheduler(self:XCLearner, num_training_steps: int):\n",
    "    NO_DECAY = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "    dense, sparse = [], []\n",
    "    for k, p in model.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            if \"meta_embeddings\" not in k: dense.append((k,p))\n",
    "            else: sparse.append(p)\n",
    "\n",
    "    params = [\n",
    "        {'params': [p for n, p in dense if not any(nd in n for nd in NO_DECAY)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in dense if any(nd in n for nd in NO_DECAY)], 'weight_decay': 0.0},\n",
    "    ]\n",
    "\n",
    "    optimizer_list = [torch.optim.AdamW(params, **{'lr': self.args.learning_rate, 'eps': 1e-6}),\n",
    "                      torch.optim.SparseAdam(sparse, **{'lr': self.args.learning_rate * self.args.free_parameter_lr_coefficient, 'eps': 1e-6})]\n",
    "\n",
    "    self.optimizer = MultipleOptimizer(optimizer_list)\n",
    "    scheduler_list = [transformers.get_linear_schedule_with_warmup(self.optimizer.optimizers[0], num_warmup_steps=self.args.warmup_steps, num_training_steps=num_training_steps),\n",
    "                      transformers.get_cosine_schedule_with_warmup(self.optimizer.optimizers[1], num_warmup_steps=self.args.free_parameter_warmup_steps, num_training_steps=num_training_steps)]\n",
    "    \n",
    "    self.lr_scheduler = MultipleScheduler(scheduler_list)\n",
    "\n",
    "    super().create_optimizer_and_scheduler(num_training_steps)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ec06d-459a-4ba0-8b1d-74ff1d84a4ff",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "203b71a7-4ec2-47c5-a72d-77001b9c9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _get_train_sampler(self:XCLearner):\n",
    "    if self.train_dataset is None or not has_length(self.train_dataset):\n",
    "        return None\n",
    "        \n",
    "    if self.args.group_by_length:\n",
    "        if is_datasets_available() and isinstance(self.train_dataset, datasets.Dataset):\n",
    "            lengths = (\n",
    "                self.train_dataset[self.args.length_column_name]\n",
    "                if self.args.length_column_name in self.train_dataset.column_names\n",
    "                else None\n",
    "            )\n",
    "        else:\n",
    "            lengths = None\n",
    "        model_input_name = self.tokenizer.model_input_names[0] if self.tokenizer is not None else None\n",
    "        return LengthGroupedSampler(\n",
    "            self.args.train_batch_size * self.args.gradient_accumulation_steps,\n",
    "            dataset=self.train_dataset,\n",
    "            lengths=lengths,\n",
    "            model_input_name=model_input_name,\n",
    "        )\n",
    "\n",
    "    elif self.args.group_by_cluster:\n",
    "        return ClusterGroupedSampler(n=len(self.train_dataset))\n",
    "    else:\n",
    "        return RandomSampler(self.train_dataset)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "515cb389-f267-44a3-a65e-39b517b86660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_train_dataloader(self:XCLearner):\n",
    "    if self.train_dataset is None:\n",
    "        raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "\n",
    "    train_dataset = self.train_dataset\n",
    "    data_collator = self.data_collator\n",
    "    if is_datasets_available() and isinstance(train_dataset, datasets.Dataset):\n",
    "        train_dataset = self._remove_unused_columns(train_dataset, description=\"training\")\n",
    "    else:\n",
    "        data_collator = self._get_collator_with_removed_columns(data_collator, description=\"training\")\n",
    "\n",
    "    dataloader_params = {\n",
    "        \"batch_size\": self._train_batch_size,\n",
    "        \"collate_fn\": data_collator,\n",
    "        \"num_workers\": self.args.dataloader_num_workers,\n",
    "        \"pin_memory\": self.args.dataloader_pin_memory,\n",
    "        \"persistent_workers\": self.args.dataloader_persistent_workers,\n",
    "    }\n",
    "\n",
    "    if not isinstance(train_dataset, torch.utils.data.IterableDataset):\n",
    "        dataloader_params[\"sampler\"] = self._get_train_sampler()\n",
    "        dataloader_params[\"drop_last\"] = self.args.dataloader_drop_last\n",
    "        dataloader_params[\"worker_init_fn\"] = seed_worker\n",
    "        dataloader_params[\"prefetch_factor\"] = self.args.dataloader_prefetch_factor\n",
    "    \n",
    "    return DataLoader(train_dataset, **dataloader_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ffe7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _get_min_cluster_sz(self:XCLearner, epochs_trained:int, num_train_epochs:int):\n",
    "    \n",
    "    if self.args.num_clustering_warmup_epochs is not None:\n",
    "        if epochs_trained < self.args.num_clustering_warmup_epochs: return None\n",
    "        else: epochs_trained -= self.args.num_clustering_warmup_epochs\n",
    "    \n",
    "    if self.args.clustering_type == 'LINEAR':\n",
    "        if self.args.maximum_clusters is None: return self.train_dataset.n_data//self.args.minimum_clusters\n",
    "        else:\n",
    "            n_cluster = (self.args.maximum_clusters-self.args.minimum_clusters)/num_train_epochs*epochs_trained\n",
    "            return self.train_dataset.n_data//int(self.args.minimum_clusters+n_cluster)\n",
    "        \n",
    "    elif self.args.clustering_type == 'EXPO':\n",
    "        mult = 2**(epochs_trained//self.args.num_cluster_size_update_epochs)\n",
    "        cluster_sz = self.args.minimum_cluster_size*mult\n",
    "        cluster_sz = (\n",
    "            self.args.maximum_cluster_size \n",
    "            if self.args.maximum_cluster_size is not None and cluster_sz > self.args.maximum_cluster_size \n",
    "            else cluster_sz\n",
    "        )\n",
    "        return cluster_sz\n",
    "    \n",
    "    else: raise ValueError(f'Invalid `clustering_type`({self.args.clustering_type}).')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0a88f-67fb-4e00-9c10-8b3c32d5d85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447567d1-8fc1-4582-9673-34ff1c971048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _get_train_data_cluster(self:XCLearner, epochs_trained:int, num_train_epochs:int):\n",
    "    with torch.no_grad():\n",
    "        dataset = self._get_dataset(self.train_dataset, dset_type='data', use_metadata=self.args.use_data_metadata_for_clustering)\n",
    "        dataloader = self.get_test_dataloader(dataset)\n",
    "        data_repr = self.get_representation(dataloader, representation_attribute=self.args.clustering_representation_attribute, \n",
    "                                            to_cpu=self.args.use_cpu_for_clustering)\n",
    "        if self.args.use_distributional_representation: data_repr = data_repr.exp()\n",
    "            \n",
    "        cluster = BalancedClusters.proc(data_repr, self._get_min_cluster_sz(epochs_trained, num_train_epochs), \n",
    "                                        clustering_devices=self.args.clustering_devices)\n",
    "    return cluster\n",
    "\n",
    "@patch\n",
    "def update_dataloader_sampler(self:XCLearner, dataloader:DataLoader, epochs_trained:int, num_train_epochs:int):\n",
    "    if isinstance(dataloader.sampler, ClusterGroupedSampler):\n",
    "        self.model.train()\n",
    "        cluster = self._get_train_data_cluster(epochs_trained, num_train_epochs)\n",
    "        dataloader.sampler.set_cluster(cluster)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca40d6-b489-4225-ac4e-57369e4599be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def prune_metadata(self:XCLearner):\n",
    "    if self.train_dataset.meta is None: return\n",
    "\n",
    "    self.model.train()\n",
    "    with torch.no_grad():\n",
    "        data_dset = self._get_dataset(self.train_dataset, dset_type='data', use_metadata=self.args.use_data_metadata_for_pruning)\n",
    "        dataloader = self.get_test_dataloader(data_dset)\n",
    "        data_repr = self.get_representation(dataloader, representation_attribute=self.args.output_representation_attribute)\n",
    "    \n",
    "        lbl_dset = self._get_dataset(self.train_dataset, dset_type='lbl', use_metadata=self.args.use_label_metadata)\n",
    "        dataloader = self.get_test_dataloader(lbl_dset)\n",
    "        lbl_repr = self.get_representation(dataloader, representation_attribute=self.args.label_representation_attribute)\n",
    "    \n",
    "        prune_metadata_names = list(self.train_dataset.meta.keys()) if self.args.prune_metadata_names is None else self.args.prune_metadata_names\n",
    "        for m in self.args.prune_metadata_names:\n",
    "            if m not in self.train_dataset.meta: raise ValueError(f'Invalid metadata name: {m}')\n",
    "                \n",
    "            meta_dset = self.train_dataset.meta[m]\n",
    "            dataloader = self.get_test_dataloader(type(self.train_dataset.data)(data_info=meta_dset.meta_info))\n",
    "            meta_repr = self.get_representation(dataloader, representation_attribute=self.args.metadata_representation_attribute)\n",
    "            \n",
    "            meta_dset.prune_data_meta(data_repr, meta_repr, batch_size=self.args.metadata_prune_batch_size, \n",
    "                                      thresh=self.args.prune_metadata_threshold, topk=self.args.prune_metadata_topk)\n",
    "            meta_dset.prune_lbl_meta(lbl_repr, meta_repr, batch_size=self.args.metadata_prune_batch_size, \n",
    "                                     thresh=self.args.prune_metadata_threshold, topk=self.args.prune_metadata_topk)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e3557-89c8-487c-9517-461175c85216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_aug_data_meta(self:XCLearner, data_repr:torch.Tensor, batch_size:Optional[int]=64):\n",
    "    data_repr = F.normalize(data_repr, dim=1)\n",
    "    dl = DataLoader(data_repr, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    indices,num_items = None,None\n",
    "    for b in tqdm(dl, total=len(dl)): \n",
    "        o = self.aug_idxs.proc(b, n_bm=self.args.augmentation_num_beams)\n",
    "        indices = o['info2data_idx'] if indices is None else torch.hstack([indices,o['info2data_idx']])\n",
    "        num_items = o['info2data_data2ptr'] if num_items is None else torch.hstack([num_items,o['info2data_data2ptr']])\n",
    "    indptr = torch.concat([torch.tensor([0]), num_items.cumsum(dim=0)])\n",
    "    data = torch.ones((indices.shape[0],))\n",
    "    \n",
    "    data_meta = sparse.csr_matrix((data, indices, indptr), shape=(data_repr.shape[0], self.aug_idxs.index.element_count))\n",
    "    return data_meta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10416eb-4d26-4172-9d3c-e3920b0ba145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_augmentation_metadata(self:XCLearner):\n",
    "    self.model.train()\n",
    "    meta_name = f'{self.args.data_aug_meta_name}_meta' if self.args.data_aug_meta_name is not None else None\n",
    "    if (\n",
    "        self.train_dataset.meta is None or \n",
    "        meta_name is None or \n",
    "        meta_name not in self.train_dataset.meta\n",
    "    ): \n",
    "        return\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dataloader = self.get_test_dataloader(self.train_dataset.data_dset)\n",
    "        data_repr = self.get_representation(dataloader, representation_attribute=self.args.data_augmentation_attribute)\n",
    "        \n",
    "        self.aug_idxs = IndexSearch(space=self.args.index_space, efc=self.args.index_efc, m=self.args.index_m, \n",
    "                                    efs=self.args.index_efs, n_bm=self.args.augmentation_num_beams, \n",
    "                                    n_threads=self.args.index_num_threads)\n",
    "        \n",
    "        meta_info = getattr(self.train_dataset.meta[meta_name], 'meta_info')\n",
    "        dataloader = self.get_test_dataloader(type(self.train_dataset.data)(data_info=meta_info))\n",
    "        meta_repr = self.get_meta_representation(dataloader, to_cpu=isinstance(self.aug_idxs, IndexSearch))\n",
    "        self.aug_idxs.build(meta_repr)\n",
    "    \n",
    "        data_meta = self.get_aug_data_meta(data_repr, batch_size=self.args.data_meta_batch_size)\n",
    "        data_aug_prefix = self.args.data_aug_meta_name if self.args.data_aug_prefix is None else self.args.data_aug_prefix\n",
    "\n",
    "    meta_info = {\n",
    "        'identifier': meta_info['identifier'],\n",
    "        'input_text': meta_info['input_text'],\n",
    "        'meta_repr': meta_repr.tolist(),\n",
    "        'attention_mask': meta_info['attention_mask'],\n",
    "    }\n",
    "    \n",
    "    metadata = type(self.train_dataset.meta)(prefix=data_aug_prefix, data_meta=data_meta, lbl_meta=sparse.csr_matrix((self.train_dataset.n_lbl, meta_repr.shape[0])),\n",
    "                                             meta_info=meta_info)\n",
    "    meta_dset = self.train_dataset.meta[meta_name]\n",
    "    \n",
    "    if isinstance(metadata, SMetaXCDataset):\n",
    "        metadata.n_data_meta_samples = meta_dset.n_data_meta_samples\n",
    "        metadata.n_sdata_meta_samples = meta_dset.n_sdata_meta_samples\n",
    "        metadata.meta_oversample = meta_dset.meta_oversample\n",
    "    elif isinstance(metadata, MetaXCDataset):\n",
    "        metadata.n_data_meta_samples = self.args.augmentation_num_beams\n",
    "    else: raise ValueError('Invalid meta dataset.')\n",
    "            \n",
    "    self.train_dataset.meta[f'{data_aug_prefix}_meta'] = metadata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8006a3a-8ad7-4798-a866-0ec3f379d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _get_data_representation(self:XCLearner, dataset:Optional[Dataset]=None, to_cpu:Optional[bool]=True):\n",
    "    if dataset is not None:\n",
    "        dataset = self._get_dataset(dataset, dset_type='data', use_metadata=self.args.use_data_metadata_for_representation)\n",
    "        dataloader = self.get_test_dataloader(dataset)\n",
    "        data_rep = self.get_representation(dataloader, representation_attribute=self.args.output_representation_attribute, to_cpu=to_cpu)\n",
    "        return data_rep\n",
    "    else:\n",
    "        raise ValueError('`dataset` is None, could not create data representation.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf3dcc8-bb6f-4e58-b03d-29a33a781978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_data_and_lbl_representation(self:XCLearner, dataset:Optional[Dataset], to_cpu:Optional[bool]=True):\n",
    "    with torch.no_grad():\n",
    "        lbl_rep,data_rep = self._get_lbl_representation(dataset, to_cpu=to_cpu), self._get_data_representation(dataset, to_cpu=to_cpu)\n",
    "    return data_rep,lbl_rep\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43bf440-7e19-49a4-ab62-a74a2490cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def mix_metadata(self:XCLearner, epochs_trained:int):\n",
    "    if epochs_trained == self.args.maximum_mix_metadata_epochs: pct = 1\n",
    "    else: pct = (epochs_trained - self.args.num_mix_metadata_warmup_epochs)/(self.args.maximum_mix_metadata_epochs - self.args.num_mix_metadata_warmup_epochs)\n",
    "        \n",
    "    if pct < 0: raise ValueError(f'Mixing percentage cannot be negative: {pct:.2f}')\n",
    "    self.train_dataset.mix_meta_dataset(self.args.mix_metadata_name_1, self.args.mix_metadata_name_2, \n",
    "                                        pct=pct, k=self.args.mix_metadata_k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33907726-5248-4c73-84f1-ce900f119ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _validate_group_by_cluster(self:XCLearner):\n",
    "    if self.args.group_by_cluster and (not hasattr(self.model,'use_representation') or  not getattr(unwrap_model(self.model),'use_representation')):\n",
    "        raise ValueError('Cannot use `group_by_cluster` for models without `use_representation`.')\n",
    "        self.args.group_by_cluster = False\n",
    "\n",
    "@patch\n",
    "def _inner_training_loop(\n",
    "    self:XCLearner, batch_size=None, args=None, resume_from_checkpoint=None, trial=None, ignore_keys_for_eval=None\n",
    "):\n",
    "    self.accelerator.free_memory()\n",
    "    self._train_batch_size = batch_size\n",
    "    if self.args.auto_find_batch_size:\n",
    "        if self.state.train_batch_size != self._train_batch_size:\n",
    "            from accelerate.utils import release_memory\n",
    "\n",
    "            (self.model_wrapped,) = release_memory(self.model_wrapped)\n",
    "            self.model_wrapped = self.model\n",
    "\n",
    "            # Check for DeepSpeed *after* the intial pass and modify the config\n",
    "            if self.is_deepspeed_enabled:\n",
    "                # Temporarily unset `self.args.train_batch_size`\n",
    "                original_bs = self.args.per_device_train_batch_size\n",
    "                self.args.per_device_train_batch_size = self._train_batch_size // max(1, self.args.n_gpu)\n",
    "                self.propagate_args_to_deepspeed(True)\n",
    "                self.args.per_device_train_batch_size = original_bs\n",
    "        self.state.train_batch_size = self._train_batch_size\n",
    "    logger.debug(f\"Currently training with a batch size of: {self._train_batch_size}\")\n",
    "    \n",
    "    # Data loader and number of training steps\n",
    "    self._validate_group_by_cluster()\n",
    "    train_dataloader = self.get_train_dataloader()\n",
    "    \n",
    "    if self.is_fsdp_xla_v2_enabled:\n",
    "        train_dataloader = tpu_spmd_dataloader(train_dataloader)\n",
    "\n",
    "    # Setting up training control variables:\n",
    "    # number of training epochs: num_train_epochs\n",
    "    # number of training steps per epoch: num_update_steps_per_epoch\n",
    "    # total number of training steps to execute: max_steps\n",
    "    total_train_batch_size = self._train_batch_size * args.gradient_accumulation_steps * args.world_size\n",
    "\n",
    "    len_dataloader = None\n",
    "    num_train_tokens = None\n",
    "    if has_length(train_dataloader):\n",
    "        len_dataloader = len(train_dataloader)\n",
    "        num_update_steps_per_epoch = len_dataloader // args.gradient_accumulation_steps\n",
    "        num_update_steps_per_epoch = max(num_update_steps_per_epoch, 1)\n",
    "        num_examples = self.num_examples(train_dataloader)\n",
    "        if args.max_steps > 0:\n",
    "            max_steps = args.max_steps\n",
    "            num_train_epochs = args.max_steps // num_update_steps_per_epoch + int(\n",
    "                args.max_steps % num_update_steps_per_epoch > 0\n",
    "            )\n",
    "            # May be slightly incorrect if the last batch in the training dataloader has a smaller size but it's\n",
    "            # the best we can do.\n",
    "            num_train_samples = args.max_steps * total_train_batch_size\n",
    "            if args.include_tokens_per_second:\n",
    "                num_train_tokens = (\n",
    "                    self.num_tokens(train_dataloader, args.max_steps) * args.gradient_accumulation_steps\n",
    "                )\n",
    "        else:\n",
    "            max_steps = math.ceil(args.num_train_epochs * num_update_steps_per_epoch)\n",
    "            num_train_epochs = math.ceil(args.num_train_epochs)\n",
    "            num_train_samples = self.num_examples(train_dataloader) * args.num_train_epochs\n",
    "            if args.include_tokens_per_second:\n",
    "                num_train_tokens = self.num_tokens(train_dataloader) * args.num_train_epochs\n",
    "    elif args.max_steps > 0:  # Rely on max_steps when dataloader does not have a working size\n",
    "        max_steps = args.max_steps\n",
    "        # Setting a very large number of epochs so we go as many times as necessary over the iterator.\n",
    "        num_train_epochs = sys.maxsize\n",
    "        num_update_steps_per_epoch = max_steps\n",
    "        num_examples = total_train_batch_size * args.max_steps\n",
    "        num_train_samples = args.max_steps * total_train_batch_size\n",
    "        if args.include_tokens_per_second:\n",
    "            num_train_tokens = self.num_tokens(train_dataloader, args.max_steps) * args.gradient_accumulation_steps\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"args.max_steps must be set to a positive value if dataloader does not have a length, was\"\n",
    "            f\" {args.max_steps}\"\n",
    "        )\n",
    "\n",
    "    if DebugOption.UNDERFLOW_OVERFLOW in self.args.debug:\n",
    "        if self.args.n_gpu > 1:\n",
    "            # nn.DataParallel(model) replicates the model, creating new variables and module\n",
    "            # references registered here no longer work on other gpus, breaking the module\n",
    "            raise ValueError(\n",
    "                \"Currently --debug underflow_overflow is not supported under DP. Please use DDP\"\n",
    "                \" (torchrun or torch.distributed.launch (deprecated)).\"\n",
    "            )\n",
    "        else:\n",
    "            debug_overflow = DebugUnderflowOverflow(self.model)  # noqa\n",
    "\n",
    "    delay_optimizer_creation = is_sagemaker_mp_enabled() or self.is_fsdp_xla_enabled or self.is_fsdp_enabled\n",
    "\n",
    "    # We need to reset the scheduler, as its parameters may be different on subsequent calls\n",
    "    if self._created_lr_scheduler:\n",
    "        self.lr_scheduler = None\n",
    "        self._created_lr_scheduler = False\n",
    "\n",
    "    if self.is_deepspeed_enabled:\n",
    "        self.optimizer, self.lr_scheduler = deepspeed_init(self, num_training_steps=max_steps)\n",
    "\n",
    "    if not delay_optimizer_creation:\n",
    "        self.create_optimizer_and_scheduler(num_training_steps=max_steps)\n",
    "\n",
    "    self.state = TrainerState(\n",
    "            stateful_callbacks=[\n",
    "                cb for cb in self.callback_handler.callbacks + [self.control] if isinstance(cb, ExportableState)\n",
    "            ]\n",
    "        )\n",
    "    self.state.is_hyper_param_search = trial is not None\n",
    "    self.state.train_batch_size = self._train_batch_size\n",
    "\n",
    "    # Compute absolute values for logging, eval, and save if given as ratio\n",
    "    if args.logging_steps is not None:\n",
    "        if args.logging_steps < 1:\n",
    "            self.state.logging_steps = math.ceil(max_steps * args.logging_steps)\n",
    "        else:\n",
    "            self.state.logging_steps = args.logging_steps\n",
    "    if args.eval_steps is not None:\n",
    "        if args.eval_steps < 1:\n",
    "            self.state.eval_steps = math.ceil(max_steps * args.eval_steps)\n",
    "        else:\n",
    "            self.state.eval_steps = args.eval_steps\n",
    "    if args.save_steps is not None:\n",
    "        if args.save_steps < 1:\n",
    "            self.state.save_steps = math.ceil(max_steps * args.save_steps)\n",
    "        else:\n",
    "            self.state.save_steps = args.save_steps\n",
    "\n",
    "    # Activate gradient checkpointing if needed\n",
    "    if args.gradient_checkpointing:\n",
    "        if args.gradient_checkpointing_kwargs is None:\n",
    "            gradient_checkpointing_kwargs = {}\n",
    "        else:\n",
    "            gradient_checkpointing_kwargs = args.gradient_checkpointing_kwargs\n",
    "\n",
    "        self.model.gradient_checkpointing_enable(gradient_checkpointing_kwargs=gradient_checkpointing_kwargs)\n",
    "\n",
    "    model = self._wrap_model(self.model_wrapped)\n",
    "\n",
    "    # as the model is wrapped, don't use `accelerator.prepare`\n",
    "    # this is for unhandled cases such as\n",
    "    # FSDP-XLA, SageMaker MP/DP, DataParallel, IPEX\n",
    "    use_accelerator_prepare = True if model is self.model else False\n",
    "\n",
    "    if delay_optimizer_creation:\n",
    "        if use_accelerator_prepare:\n",
    "            self.model = self.accelerator.prepare(self.model)\n",
    "        self.create_optimizer_and_scheduler(num_training_steps=max_steps)\n",
    "\n",
    "    # prepare using `accelerator` prepare\n",
    "    if use_accelerator_prepare:\n",
    "        self.model.train()\n",
    "        if hasattr(self.lr_scheduler, \"step\"):\n",
    "            if self.use_apex:\n",
    "                model = self.accelerator.prepare(self.model)\n",
    "            else:\n",
    "                model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)\n",
    "        else:\n",
    "            # to handle cases wherein we pass \"DummyScheduler\" such as when it is specified in DeepSpeed config.\n",
    "            model, self.optimizer, self.lr_scheduler = self.accelerator.prepare(\n",
    "                self.model, self.optimizer, self.lr_scheduler\n",
    "            )\n",
    "\n",
    "    if self.is_fsdp_enabled:\n",
    "        self.model = self.model_wrapped = model\n",
    "\n",
    "    # for the rest of this function `model` is the outside model, whether it was wrapped or not\n",
    "    if model is not self.model:\n",
    "        self.model_wrapped = model\n",
    "\n",
    "    # backward compatibility\n",
    "    if self.is_deepspeed_enabled:\n",
    "        self.deepspeed = self.model_wrapped\n",
    "\n",
    "    # ckpt loading\n",
    "    if resume_from_checkpoint is not None:\n",
    "        if self.is_deepspeed_enabled:\n",
    "            deepspeed_load_checkpoint(\n",
    "                self.model_wrapped, resume_from_checkpoint, load_module_strict=not _is_peft_model(self.model)\n",
    "            )\n",
    "        elif is_sagemaker_mp_enabled() or self.is_fsdp_enabled:\n",
    "            self._load_from_checkpoint(resume_from_checkpoint, self.model_wrapped)\n",
    "\n",
    "    # Check if saved optimizer or scheduler states exist\n",
    "    self._load_optimizer_and_scheduler(resume_from_checkpoint)\n",
    "\n",
    "    # important: at this point:\n",
    "    # self.model         is the Transformers Model\n",
    "    # self.model_wrapped is DDP(Transformers Model), Deepspeed(Transformers Model),\n",
    "    # FSDP(Transformers Model), Dynamo Optimized Module(Transformers Model) etc.\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(f\"  Num examples = {num_examples:,}\")\n",
    "    logger.info(f\"  Num Epochs = {num_train_epochs:,}\")\n",
    "    logger.info(f\"  Instantaneous batch size per device = {self.args.per_device_train_batch_size:,}\")\n",
    "    if self.args.per_device_train_batch_size != self._train_batch_size:\n",
    "        logger.info(f\"  Training with DataParallel so batch size has been adjusted to: {self._train_batch_size:,}\")\n",
    "    logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_train_batch_size:,}\")\n",
    "    logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "    logger.info(f\"  Total optimization steps = {max_steps:,}\")\n",
    "    logger.info(f\"  Number of trainable parameters = {get_model_param_count(model, trainable_only=True):,}\")\n",
    "\n",
    "    self.state.epoch = 0\n",
    "    start_time = time.time()\n",
    "    epochs_trained = 0\n",
    "    steps_trained_in_current_epoch = 0\n",
    "    steps_trained_progress_bar = None\n",
    "\n",
    "    # Check if continuing training from a checkpoint\n",
    "    if resume_from_checkpoint is not None and os.path.isfile(\n",
    "        os.path.join(resume_from_checkpoint, TRAINER_STATE_NAME)\n",
    "    ):\n",
    "        self.state = TrainerState.load_from_json(os.path.join(resume_from_checkpoint, TRAINER_STATE_NAME))\n",
    "        epochs_trained = self.state.global_step // num_update_steps_per_epoch\n",
    "        if not args.ignore_data_skip:\n",
    "            steps_trained_in_current_epoch = self.state.global_step % (num_update_steps_per_epoch)\n",
    "            steps_trained_in_current_epoch *= args.gradient_accumulation_steps\n",
    "        else:\n",
    "            steps_trained_in_current_epoch = 0\n",
    "\n",
    "        logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
    "        logger.info(f\"  Continuing training from epoch {epochs_trained}\")\n",
    "        logger.info(f\"  Continuing training from global step {self.state.global_step}\")\n",
    "        if not args.ignore_data_skip:\n",
    "            logger.info(\n",
    "                f\"  Will skip the first {epochs_trained} epochs then the first\"\n",
    "                f\" {steps_trained_in_current_epoch} batches in the first epoch.\"\n",
    "            )\n",
    "\n",
    "    # Update the references\n",
    "    self.callback_handler.model = self.model\n",
    "    self.callback_handler.optimizer = self.optimizer\n",
    "    self.callback_handler.lr_scheduler = self.lr_scheduler\n",
    "    self.callback_handler.train_dataloader = train_dataloader\n",
    "    if self.hp_name is not None and self._trial is not None:\n",
    "        # use self._trial because the SigOpt/Optuna hpo only call `_hp_search_setup(trial)` instead of passing trial\n",
    "        # parameter to Train when using DDP.\n",
    "        self.state.trial_name = self.hp_name(self._trial)\n",
    "    if trial is not None:\n",
    "        assignments = trial.assignments if self.hp_search_backend == HPSearchBackend.SIGOPT else trial\n",
    "        self.state.trial_params = hp_params(assignments)\n",
    "    else:\n",
    "        self.state.trial_params = None\n",
    "    # This should be the same if the state has been saved but in case the training arguments changed, it's safer\n",
    "    # to set this after the load.\n",
    "    self.state.max_steps = max_steps\n",
    "    self.state.num_train_epochs = num_train_epochs\n",
    "    self.state.is_local_process_zero = self.is_local_process_zero()\n",
    "    self.state.is_world_process_zero = self.is_world_process_zero()\n",
    "\n",
    "    # tr_loss is a tensor to avoid synchronization of TPUs through .item()\n",
    "    tr_loss = torch.tensor(0.0).to(args.device)\n",
    "    # _total_loss_scalar is updated everytime .item() has to be called on tr_loss and stores the sum of all losses\n",
    "    self._total_loss_scalar = 0.0\n",
    "    self._globalstep_last_logged = self.state.global_step\n",
    "    model.zero_grad()\n",
    "    grad_norm: Optional[float] = None\n",
    "\n",
    "    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\n",
    "\n",
    "    # Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\n",
    "    if not args.ignore_data_skip:\n",
    "        for epoch in range(epochs_trained):\n",
    "            sampler = get_dataloader_sampler(train_dataloader)\n",
    "            sampler_kinds = [RandomSampler]\n",
    "            if version.parse(accelerate_version) > version.parse(\"0.23.0\"):\n",
    "                sampler_kinds.append(SeedableRandomSampler)\n",
    "            is_random_sampler = isinstance(sampler, tuple(sampler_kinds))\n",
    "            if not is_random_sampler:\n",
    "                # We just need to begin an iteration to create the randomization of the sampler.\n",
    "                for _ in train_dataloader:\n",
    "                    break\n",
    "            else:\n",
    "                # Otherwise we need to call the whooooole sampler cause there is some random operation added\n",
    "                # AT THE VERY END!\n",
    "                sampler = sampler if sampler is not None else []\n",
    "                _ = list(sampler)\n",
    "\n",
    "    total_batched_samples = 0\n",
    "    for epoch in range(epochs_trained, num_train_epochs):\n",
    "\n",
    "        if self.args.augment_metadata and (epoch % self.args.num_metadata_augment_epochs == 0 or epoch == self.args.num_metadata_augment_warmup_epochs) and epoch >= self.args.num_metadata_augment_warmup_epochs:\n",
    "            self.accelerator.free_memory()\n",
    "            self.get_augmentation_metadata()\n",
    "            self.accelerator.free_memory()\n",
    "            \n",
    "        if self.args.group_by_cluster and (epoch % self.args.num_cluster_update_epochs == 0 or epoch == self.args.num_clustering_warmup_epochs) and epoch >= self.args.num_clustering_warmup_epochs:\n",
    "            self.accelerator.free_memory()\n",
    "            self.update_dataloader_sampler(train_dataloader, epoch, num_train_epochs)\n",
    "            self.accelerator.free_memory()\n",
    "\n",
    "        if self.args.prune_metadata and (epoch % self.args.num_metadata_prune_epochs == 0 or epoch == self.args.num_metadata_prune_warmup_epochs) and epoch >= self.args.num_metadata_prune_warmup_epochs: \n",
    "            self.accelerator.free_memory()\n",
    "            self.prune_metadata()\n",
    "            self.accelerator.free_memory()\n",
    "\n",
    "        if self.args.mix_metadata and (epoch % self.args.num_mix_metadata_epochs == 0 or epoch == self.args.num_mix_metadata_warmup_epochs or epoch == self.args.maximum_mix_metadata_epochs) and epoch >= self.args.num_mix_metadata_warmup_epochs and epoch <= self.args.maximum_mix_metadata_epochs:\n",
    "            self.mix_metadata(epoch)\n",
    "\n",
    "        epoch_iterator = train_dataloader\n",
    "        if hasattr(epoch_iterator, \"set_epoch\"):\n",
    "            epoch_iterator.set_epoch(epoch)\n",
    "\n",
    "        # Reset the past mems state at the beginning of each epoch if necessary.\n",
    "        if args.past_index >= 0:\n",
    "            self._past = None\n",
    "\n",
    "        steps_in_epoch = (\n",
    "            len(epoch_iterator)\n",
    "            if len_dataloader is not None\n",
    "            else args.max_steps * args.gradient_accumulation_steps\n",
    "        )\n",
    "        self.control = self.callback_handler.on_epoch_begin(args, self.state, self.control)\n",
    "\n",
    "        if epoch == epochs_trained and resume_from_checkpoint is not None and steps_trained_in_current_epoch == 0:\n",
    "            self._load_rng_state(resume_from_checkpoint)\n",
    "\n",
    "        rng_to_sync = False\n",
    "        steps_skipped = 0\n",
    "        if steps_trained_in_current_epoch > 0:\n",
    "            epoch_iterator = skip_first_batches(epoch_iterator, steps_trained_in_current_epoch)\n",
    "            steps_skipped = steps_trained_in_current_epoch\n",
    "            steps_trained_in_current_epoch = 0\n",
    "            rng_to_sync = True\n",
    "\n",
    "        step = -1\n",
    "        for step, inputs in enumerate(epoch_iterator):\n",
    "            total_batched_samples += 1\n",
    "\n",
    "            if self.args.include_num_input_tokens_seen:\n",
    "                main_input_name = getattr(self.model, \"main_input_name\", \"input_ids\")\n",
    "                if main_input_name not in inputs:\n",
    "                    logger.warning(\n",
    "                        \"Tried to track the number of tokens seen, however the current model is \"\n",
    "                        \"not configured properly to know what item is the input. To fix this, add \"\n",
    "                        \"a `main_input_name` attribute to the model class you are using.\"\n",
    "                    )\n",
    "                else:\n",
    "                    self.state.num_input_tokens_seen += self.accelerator.gather(inputs[main_input_name]).numel()\n",
    "            if rng_to_sync:\n",
    "                self._load_rng_state(resume_from_checkpoint)\n",
    "                rng_to_sync = False\n",
    "\n",
    "            # Skip past any already trained steps if resuming training\n",
    "            if steps_trained_in_current_epoch > 0:\n",
    "                steps_trained_in_current_epoch -= 1\n",
    "                if steps_trained_progress_bar is not None:\n",
    "                    steps_trained_progress_bar.update(1)\n",
    "                if steps_trained_in_current_epoch == 0:\n",
    "                    self._load_rng_state(resume_from_checkpoint)\n",
    "                continue\n",
    "            elif steps_trained_progress_bar is not None:\n",
    "                steps_trained_progress_bar.close()\n",
    "                steps_trained_progress_bar = None\n",
    "\n",
    "            if step % args.gradient_accumulation_steps == 0:\n",
    "                self.control = self.callback_handler.on_step_begin(args, self.state, self.control)\n",
    "\n",
    "            with self.accelerator.accumulate(model):\n",
    "                tr_loss_step = self.training_step(model, inputs)\n",
    "\n",
    "            if (\n",
    "                args.logging_nan_inf_filter\n",
    "                and not is_torch_xla_available()\n",
    "                and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))\n",
    "            ):\n",
    "                # if loss is nan or inf simply add the average of previous logged losses\n",
    "                tr_loss += tr_loss / (1 + self.state.global_step - self._globalstep_last_logged)\n",
    "            else:\n",
    "                tr_loss += tr_loss_step\n",
    "\n",
    "            self.current_flos += float(self.floating_point_ops(inputs))\n",
    "\n",
    "            is_last_step_and_steps_less_than_grad_acc = (\n",
    "                steps_in_epoch <= args.gradient_accumulation_steps and (step + 1) == steps_in_epoch\n",
    "            )\n",
    "\n",
    "            if (\n",
    "                total_batched_samples % args.gradient_accumulation_steps == 0\n",
    "                or\n",
    "                # last step in epoch but step is always smaller than gradient_accumulation_steps\n",
    "                is_last_step_and_steps_less_than_grad_acc\n",
    "            ):\n",
    "                # the `or` condition of `is_last_step_and_steps_less_than_grad_acc` is not covered\n",
    "                # in accelerate. So, explicitly enable sync gradients to True in that case.\n",
    "                if is_last_step_and_steps_less_than_grad_acc:\n",
    "                    self.accelerator.gradient_state._set_sync_gradients(True)\n",
    "\n",
    "                # Gradient clipping\n",
    "                if args.max_grad_norm is not None and args.max_grad_norm > 0:\n",
    "                    # deepspeed does its own clipping\n",
    "\n",
    "                    if is_sagemaker_mp_enabled() and args.fp16:\n",
    "                        _grad_norm = self.optimizer.clip_master_grads(args.max_grad_norm)\n",
    "                    elif self.use_apex:\n",
    "                        # Revert to normal clipping otherwise, handling Apex or full precision\n",
    "                        _grad_norm = nn.utils.clip_grad_norm_(\n",
    "                            amp.master_params(self.optimizer),\n",
    "                            args.max_grad_norm,\n",
    "                        )\n",
    "                    else:\n",
    "                        _grad_norm = self.accelerator.clip_grad_norm_(\n",
    "                            model.parameters(),\n",
    "                            args.max_grad_norm,\n",
    "                        )\n",
    "\n",
    "                    if (\n",
    "                        is_accelerate_available()\n",
    "                        and self.accelerator.distributed_type == DistributedType.DEEPSPEED\n",
    "                    ):\n",
    "                        grad_norm = model.get_global_grad_norm()\n",
    "                    else:\n",
    "                        grad_norm = _grad_norm.item() if _grad_norm is not None else None\n",
    "\n",
    "                # Optimizer step\n",
    "                self.optimizer.step()\n",
    "                optimizer_was_run = not self.accelerator.optimizer_step_was_skipped\n",
    "                if optimizer_was_run:\n",
    "                    # Delay optimizer scheduling until metrics are generated\n",
    "                    if not isinstance(self.lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                        self.lr_scheduler.step()\n",
    "\n",
    "                model.zero_grad()\n",
    "                self.state.global_step += 1\n",
    "                self.state.epoch = epoch + (step + 1 + steps_skipped) / steps_in_epoch\n",
    "                self.control = self.callback_handler.on_step_end(args, self.state, self.control)\n",
    "\n",
    "                self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\n",
    "            else:\n",
    "                self.control = self.callback_handler.on_substep_end(args, self.state, self.control)\n",
    "\n",
    "            if self.control.should_epoch_stop or self.control.should_training_stop:\n",
    "                # PyTorch/XLA relies on the data loader to insert the mark_step for\n",
    "                # each step. Since we are breaking the loop early, we need to manually\n",
    "                # insert the mark_step here.\n",
    "                if is_torch_xla_available():\n",
    "                    xm.mark_step()\n",
    "                break\n",
    "\n",
    "            if self.args.use_memory_aggressively:\n",
    "                del inputs\n",
    "                self.accelerator.free_memory()\n",
    "                \n",
    "        if step < 0:\n",
    "            logger.warning(\n",
    "                \"There seems to be not a single sample in your epoch_iterator, stopping training at step\"\n",
    "                f\" {self.state.global_step}! This is expected if you're using an IterableDataset and set\"\n",
    "                f\" num_steps ({max_steps}) higher than the number of available samples.\"\n",
    "            )\n",
    "            self.control.should_training_stop = True\n",
    "\n",
    "        self.control = self.callback_handler.on_epoch_end(args, self.state, self.control)\n",
    "        self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\n",
    "\n",
    "        if DebugOption.TPU_METRICS_DEBUG in self.args.debug:\n",
    "            if is_torch_xla_available():\n",
    "                # tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\n",
    "                xm.master_print(met.metrics_report())\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    \"You enabled PyTorch/XLA debug metrics but you don't have a TPU \"\n",
    "                    \"configured. Check your training configuration if this is unexpected.\"\n",
    "                )\n",
    "        if self.control.should_training_stop:\n",
    "            break\n",
    "\n",
    "    if args.past_index and hasattr(self, \"_past\"):\n",
    "        # Clean the state at the end of training\n",
    "        delattr(self, \"_past\")\n",
    "\n",
    "    logger.info(\"\\n\\nTraining completed. Do not forget to share your model on huggingface.co/models =)\\n\\n\")\n",
    "    if args.load_best_model_at_end and self.state.best_model_checkpoint is not None:\n",
    "        # Wait for everyone to get here so we are sure the model has been saved by process 0.\n",
    "        if is_torch_xla_available():\n",
    "            xm.rendezvous(\"load_best_model_at_end\")\n",
    "        elif args.parallel_mode == ParallelMode.DISTRIBUTED:\n",
    "            dist.barrier()\n",
    "        elif is_sagemaker_mp_enabled():\n",
    "            smp.barrier()\n",
    "\n",
    "        self._load_best_model()\n",
    "\n",
    "    # add remaining tr_loss\n",
    "    self._total_loss_scalar += tr_loss.item()\n",
    "    train_loss = self._total_loss_scalar / self.state.global_step\n",
    "\n",
    "    metrics = speed_metrics(\n",
    "        \"train\",\n",
    "        start_time,\n",
    "        num_samples=num_train_samples,\n",
    "        num_steps=self.state.max_steps,\n",
    "        num_tokens=num_train_tokens,\n",
    "    )\n",
    "    self.store_flos()\n",
    "    metrics[\"total_flos\"] = self.state.total_flos\n",
    "    metrics[\"train_loss\"] = train_loss\n",
    "\n",
    "    self.is_in_train = False\n",
    "\n",
    "    self._memory_tracker.stop_and_update_metrics(metrics)\n",
    "\n",
    "    self.log(metrics)\n",
    "\n",
    "    run_dir = self._get_output_dir(trial)\n",
    "    checkpoints_sorted = self._sorted_checkpoints(use_mtime=False, output_dir=run_dir)\n",
    "\n",
    "    # Delete the last checkpoint when save_total_limit=1 if it's different from the best checkpoint and process allowed to save.\n",
    "    if self.args.should_save and self.state.best_model_checkpoint is not None and self.args.save_total_limit == 1:\n",
    "        for checkpoint in checkpoints_sorted:\n",
    "            if not os.path.samefile(checkpoint, self.state.best_model_checkpoint):\n",
    "                logger.info(f\"Deleting older checkpoint [{checkpoint}] due to args.save_total_limit\")\n",
    "                shutil.rmtree(checkpoint)\n",
    "\n",
    "    self.control = self.callback_handler.on_train_end(args, self.state, self.control)\n",
    "\n",
    "    # Wait for the checkpoint to be uploaded.\n",
    "    self._finish_current_push()\n",
    "\n",
    "    # After training we make sure to retrieve back the original forward pass method\n",
    "    # for the embedding layer by removing the forward post hook.\n",
    "    if self.neftune_noise_alpha is not None:\n",
    "        self._deactivate_neftune(self.model)\n",
    "\n",
    "    return TrainOutput(self.state.global_step, train_loss, metrics)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc27f85-b8d7-4147-9e19-2ea8f95f7d6d",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dad14e-12dd-4e8c-a16a-1da96ec96257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.models.PPP0XX import DBT021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90781b5d-e073-4e77-b102-cdf72a55c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d9b7ca-4600-4066-bfa4-a347724e9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = XCLearningArguments(\n",
    "    output_dir='/scratch/scai/phd/aiz218323/scratch/outputs/default/',\n",
    "    per_device_train_batch_size=800,\n",
    "    per_device_eval_batch_size=800,\n",
    "    num_train_epochs=50,\n",
    "    eval_steps=50,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='steps',\n",
    "    \n",
    "    representation_accumulation_steps=100,\n",
    "    representation_search_type='BRUTEFORCE',\n",
    "    output_representation_attribute='data_repr',\n",
    "    label_representation_attribute='data_repr',\n",
    "    metadata_representation_attribute='data_repr',\n",
    "    data_augmentation_attribute='data_repr',\n",
    "    representation_attribute='data_repr',\n",
    "    \n",
    "    group_by_cluster=False,\n",
    "    num_clustering_warmup_epochs=0,\n",
    "    num_cluster_update_epochs=2,\n",
    "    num_cluster_size_update_epochs=2,\n",
    "    use_data_metadata_for_clustering=True,\n",
    "    clustering_type='EXPO',\n",
    "    minimum_cluster_size=1,\n",
    "    maximum_cluster_size=4,\n",
    "\n",
    "    metric_for_best_model='P@1',\n",
    "    load_best_model_at_end=True,\n",
    "    target_indices_key='plbl2data_idx',\n",
    "    target_pointer_key='plbl2data_data2ptr',\n",
    "\n",
    "    use_distributional_representation=False,\n",
    "    use_encoder_parallel=True,\n",
    "    max_grad_norm=None, \n",
    "    fp16=True,\n",
    "\n",
    "    use_centroid_data_metadata=True,\n",
    "    use_centroid_label_representation=True,\n",
    "    centroid_data_attribute_representation='data_fused_repr',\n",
    "    centroid_data_batch_size=2048,\n",
    "\n",
    "    use_teacher_lbl_representation=False,\n",
    "    use_teacher_data_representation=False,\n",
    "\n",
    "    predict_with_augmentation=True,\n",
    "    use_augmentation_index_representation=True,\n",
    "    \n",
    "    label_names=['cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "                 'cat2lbl2data_idx', 'cat2lbl2data_input_ids', 'cat2lbl2data_attention_mask'],\n",
    "\n",
    "    prune_metadata=False,\n",
    "    num_metadata_prune_warmup_epochs=0,\n",
    "    num_metadata_prune_epochs=1,\n",
    "    metadata_prune_batch_size=2048,\n",
    "    prune_metadata_names=['cat_meta'],\n",
    "    use_data_metadata_for_pruning=False,\n",
    "    prune_metadata_threshold=0.0,\n",
    "    prune_metadata_topk=3,\n",
    "    \n",
    "    data_aug_meta_name='cat',\n",
    "    augmentation_num_beams=3,\n",
    "    data_aug_prefix='cat',\n",
    "    use_label_metadata=False,\n",
    "    \n",
    "    data_meta_batch_size=2048,\n",
    "    augment_metadata=False,\n",
    "    num_metadata_augment_warmup_epochs=0,\n",
    "    num_metadata_augment_epochs=5,\n",
    "\n",
    "    mix_metadata=True,\n",
    "    num_mix_metadata_epochs=1,\n",
    "    num_mix_metadata_warmup_epochs=1,\n",
    "    maximum_mix_metadata_epochs=3,\n",
    "    mix_metadata_name_1='cat',\n",
    "    mix_metadata_name_2='lnk',\n",
    "    mix_metadata_k=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0639d-feea-4369-86c4-64607b83e4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6243a0f3-dc7f-4839-bed5-2c6222e009fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT021 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.dr_layer_norm.bias', 'encoder.dr_layer_norm.weight', 'encoder.dr_projector.bias', 'encoder.dr_projector.weight', 'encoder.dr_transform.bias', 'encoder.dr_transform.weight', 'encoder.meta_layer_norm.bias', 'encoder.meta_layer_norm.weight', 'encoder.meta_projector.bias', 'encoder.meta_projector.weight', 'encoder.meta_transform.bias', 'encoder.meta_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()\n",
    "\n",
    "model = DBT021.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', tn_targ=1000, margin=0.3, \n",
    "                               tau=0.1, apply_softmax=True, n_negatives=10, m_lw=0.3, meta_prefix='cat', \n",
    "                               use_encoder_parallel=True, task_repr_type='tok', meta_repr_type='cls')\n",
    "model.init_dr_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530f470-b926-42ef-ad62-cfe62e2c3fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb74349",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset, valid_dset = block.train.dset.sample(n=100, seed=50), block.test.dset.sample(n=100, seed=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3405681-65e0-4cc7-9864-bfad7176763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset, valid_dset = block.train.dset, block.test.dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f5bd9b-3f60-4eaa-8d6d-ddc3e2e6fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PrecRecl(block.n_lbl, valid_dset.data.data_lbl_filterer, prop=block.train.dset.data.data_lbl, \n",
    "                  pk=5, rk=5, rep_pk=[1, 3, 5], rep_rk=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc998894-1a9f-4c12-8c75-2f4ff5758302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "learn = XCLearner(\n",
    "    model=model, \n",
    "    args=args,\n",
    "    data_collator=block.collator, \n",
    "    train_dataset=train_dset, \n",
    "    eval_dataset=valid_dset,\n",
    "    compute_metrics=metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c335a-f0fa-423c-baad-6dc4ec7ad020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5b65e-3c0f-4d99-b12f-dffc20c47e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e6114-a526-4648-927c-30aaacc88fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = learn.get_train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c245a5-c00d-41ff-9aa2-3ba1810b7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777137fe-1469-44ba-b2b2-e30533dadc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', 'cat2data_data2ptr', 'cat2lbl2data_idx', 'cat2lbl2data_input_ids', 'cat2lbl2data_attention_mask', 'cat2lbl2data_data2ptr', 'cat2lbl2data_lbl2data2ptr', 'data_input_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f22807-c779-4c9e-a17e-77efbfcd9429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1600]), torch.Size([7664]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['cat2data_data2ptr'].shape, batch['cat2data_idx'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ab8f1-5445-491d-a121-33e906b155b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 3,  ..., 2, 5, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['cat2data_data2ptr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95378273-e9cf-4500-874a-c9e5d206657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.train_dataset.meta.cat_meta.data_meta = sparse.csr_matrix((693082, 656086), dtype=np.float32)\n",
    "learn.train_dataset.meta.cat_meta._store_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3abf8f3-4184-486a-83bf-b04794137d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0748cb0-b875-4083-b781-87740e85db87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1600]), torch.Size([0]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['cat2data_data2ptr'].shape, batch['cat2data_idx'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b86cdc-c583-42a2-82f2-beaedc4f3d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['cat2data_data2ptr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d685d-4e2f-4019-a8c9-d59fcc015ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed11497-66c9-494c-8e62-a3b2c745da74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c6da9-08a8-4a85-8031-e8be9d410a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.args.use_teacher_data_representation = False\n",
    "learn.args.use_teacher_lbl_representation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb165c42-4d0f-4240-98e7-8b311c4e1896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return learn.predict(valid_dset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee22ad-2315-44ba-bece-c836a822309f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_33850/2962927837.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return learn.predict(valid_dset)\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b learn._build_lbl_index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 2 at /tmp/ipykernel_33850/1688291077.py:23\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_33850/1688291077.py(25)_build_lbl_index()\n",
      "2    23 @patch\n",
      "     24 def _build_lbl_index(self:XCLearner, dataset:Optional[Dataset]=None):\n",
      "---> 25     dataset = dataset if self.eval_dataset is None else self.eval_dataset\n",
      "     26     dataset = dataset if self.train_dataset is None else self.train_dataset\n",
      "     27 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_33850/1688291077.py(26)_build_lbl_index()\n",
      "     24 def _build_lbl_index(self:XCLearner, dataset:Optional[Dataset]=None):\n",
      "     25     dataset = dataset if self.eval_dataset is None else self.eval_dataset\n",
      "---> 26     dataset = dataset if self.train_dataset is None else self.train_dataset\n",
      "     27 \n",
      "     28     if dataset is not None: self._get_lbl_representation(dataset)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_33850/1688291077.py(28)_build_lbl_index()\n",
      "     26     dataset = dataset if self.train_dataset is None else self.train_dataset\n",
      "     27 \n",
      "---> 28     if dataset is not None: self._get_lbl_representation(dataset)\n",
      "     29     else: raise ValueError('Failed to build `self.idxs`')\n",
      "     30 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_33850/2047086755.py(2)_get_lbl_representation()\n",
      "      1 #| export\n",
      "----> 2 @patch\n",
      "      3 def _get_lbl_representation(self:XCLearner, dataset:Optional[Dataset]=None):\n",
      "      4 \n",
      "      5     if dataset is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_33850/2047086755.py(5)_get_lbl_representation()\n",
      "      3 def _get_lbl_representation(self:XCLearner, dataset:Optional[Dataset]=None):\n",
      "      4 \n",
      "----> 5     if dataset is not None:\n",
      "      6         if self.args.use_centroid_label_representation:\n",
      "      7             if self.args.use_teacher_data_representation:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_33850/2047086755.py(6)_get_lbl_representation()\n",
      "      4 \n",
      "      5     if dataset is not None:\n",
      "----> 6         if self.args.use_centroid_label_representation:\n",
      "      7             if self.args.use_teacher_data_representation:\n",
      "      8                 if not hasattr(self.model, 'm_teacher'): raise ValueError('Model does not contain `m_teacher`.')\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_33850/2047086755.py(7)_get_lbl_representation()\n",
      "      5     if dataset is not None:\n",
      "      6         if self.args.use_centroid_label_representation:\n",
      "----> 7             if self.args.use_teacher_data_representation:\n",
      "      8                 if not hasattr(self.model, 'm_teacher'): raise ValueError('Model does not contain `m_teacher`.')\n",
      "      9                 data_repr = self.model.m_teacher.get_data_embeddings().data.cpu()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_33850/2047086755.py(11)_get_lbl_representation()\n",
      "      9                 data_repr = self.model.m_teacher.get_data_embeddings().data.cpu()\n",
      "     10             else:\n",
      "---> 11                 dset = self._get_dataset(dataset, dset_type='data', use_metadata=self.args.use_centroid_data_metadata)\n",
      "     12                 dataloader = self.get_test_dataloader(dset)\n",
      "     13                 data_rep = self.get_representation(dataloader, representation_attribute=self.args.centroid_data_attribute_representation)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_33850/2047086755.py(12)_get_lbl_representation()\n",
      "     10             else:\n",
      "     11                 dset = self._get_dataset(dataset, dset_type='data', use_metadata=self.args.use_centroid_data_metadata)\n",
      "---> 12                 dataloader = self.get_test_dataloader(dset)\n",
      "     13                 data_rep = self.get_representation(dataloader, representation_attribute=self.args.centroid_data_attribute_representation)\n",
      "     14 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  len(dset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693082\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_33850/2047086755.py(13)_get_lbl_representation()\n",
      "     11                 dset = self._get_dataset(dataset, dset_type='data', use_metadata=self.args.use_centroid_data_metadata)\n",
      "     12                 dataloader = self.get_test_dataloader(dset)\n",
      "---> 13                 data_rep = self.get_representation(dataloader, representation_attribute=self.args.centroid_data_attribute_representation)\n",
      "     14 \n",
      "     15             lbl_data = self.train_dataset.data.data_lbl.T\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1cbc207015409e8ee928335e2f20b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "o = func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed154d48-6f84-43c3-8466-c74cdf24f823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08c36f-57ba-4f65-af80-5e03d67f61b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<693082x656086 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 3390902 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.train_dataset.meta.cat_meta.data_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6049e55-9aad-42ac-aa7f-33e07266fc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53220, 86188, 174716, 174717]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.train_dataset.meta.cat_meta.curr_data_meta[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab380e0b-fc85-4de0-b3c7-8539df376d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.args.prune_metadata_threshold=0.0\n",
    "learn.args.prune_metadata_topk=3\n",
    "\n",
    "learn.args.use_data_metadata_for_pruning = False\n",
    "learn.args.output_representation_attribute = 'data_repr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754510c-1052-445a-96c7-8a188cea240b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<693082x656086 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 3390902 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.train_dataset.meta.cat_meta.data_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb9a21-2164-4f3a-b544-5bd827ce224a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Agglutinative languages',\n",
       " 'Language families',\n",
       " 'Austroasiatic languages',\n",
       " 'Sino-Austronesian languages']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.train_dataset[10]['cat2data_input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a1a09-b680-4c85-b5d2-bb3d0e823c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd83429bbf34de5b8f4e2e26feb95c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b0b6b2d3294be6b0e16b60f7c01c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe1ebbddf604d479a193e255723c962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c372b652534975b64fc13b3db5ce61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1656 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab34b62a5fc24c279a3f9835850dba5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.prune_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f54d9-a0e0-4de8-9d67-55d037d62243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Agglutinative languages',\n",
       " 'Austroasiatic languages',\n",
       " 'Sino-Austronesian languages']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.train_dataset[10]['cat2data_input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1d412-f99d-4ccf-a7fd-c6745f45f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797476d-ac2a-4e58-9017-1230f5e0c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(chain(*learn.train_dataset.meta.cat_meta.curr_data_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605deb9b-683f-4897-bc2e-616574e886ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1681856"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0e86c-026a-4bee-83c7-7810a7a42676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0f2e5-e390-4a24-a125-6790f29360f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d567be2d4924e589b2af5ebd9d5acb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ceb30b6a394bcca7460e5222907dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfe48114515449089a4ab50dd404730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 14min 33s, sys: 1min 15s, total: 1h 15min 48s\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn.get_augmentation_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3edf8c-7616-4f12-b535-ad344d06a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    learn.prune_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172afc65-fb3a-4f68-b672-09d43851de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d807f7-6d7a-4e50-be2b-7d928e9c803c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b3eda2-50b5-4317-baa7-5d090b29e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Pdb; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e85d44-b2ec-46e3-9464-4dc1d71a6ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    Pdb().set_trace()\n",
    "    learn.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b65556-cfb4-4323-8821-aa8c29d4ff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32410/2062820902.py(3)func()\n",
      "      1 def func():\n",
      "      2     Pdb().set_trace()\n",
      "----> 3     learn.train()\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:38, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Model does not contain `m_teacher`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 3\u001b[0m, in \u001b[0;36mfunc\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m():\n\u001b[1;32m      2\u001b[0m     Pdb()\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 429\u001b[0m, in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:2412\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2410\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2412\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2413\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2415\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 43\u001b[0m, in \u001b[0;36mXCLearner.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     gen_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maug_num_beams\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugmentation_num_beams\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather, gen_kwargs\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer_seq2seq.py:166\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:3229\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3226\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3228\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3229\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3230\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3232\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3233\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3239\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "Cell \u001b[0;32mIn[24], line 38\u001b[0m, in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, predict_with_generation, predict_with_representation, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m     35\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(dataloader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_perform_representation(unwrap_model(model)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prediction_loss_only: \n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_lbl_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_perform_augmentation(unwrap_model(model)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prediction_loss_only: \n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_aug_index(eval_dataset)\n",
      "Cell \u001b[0;32mIn[17], line 30\u001b[0m, in \u001b[0;36m_build_lbl_index\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[1;32m     29\u001b[0m     to_cpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midxs, IndexSearch) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_cpu_for_searching\n\u001b[0;32m---> 30\u001b[0m     lbl_rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_lbl_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_cpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_cpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midxs\u001b[38;5;241m.\u001b[39mbuild(lbl_rep)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to build `self.idxs`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m, in \u001b[0;36m_get_lbl_representation\u001b[0;34m(self, dataset, to_cpu)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_centroid_label_representation:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_teacher_data_representation:\n\u001b[0;32m----> 7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm_teacher\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel does not contain `m_teacher`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m         data_rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mm_teacher\u001b[38;5;241m.\u001b[39mget_data_embeddings()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Model does not contain `m_teacher`."
     ]
    }
   ],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab196ed3-9b92-41c0-a392-dccba624d447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32410/3239534861.py(7)mix_metadata()\n",
      "      5     else: pct = (self.args.num_mix_metadata_warmup_epochs - epochs_trained)/(self.args.maximum_mix_metadata_epochs - epochs_trained)\n",
      "      6 \n",
      "----> 7     if pct < 0: raise ValueError(f'Mixing percentage cannot be negative: {pct:.2f}')\n",
      "      8     self.train_dataset.mix_meta_dataset(self.args.mix_metadata_name_1, self.args.mix_metadata_name_2, \n",
      "      9                                         pct=pct, k=self.args.mix_metadata_k)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  epochs_trained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.args.maximum_mix_metadata_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  (self.args.num_mix_metadata_warmup_epochs - epochs_trained)/(self.args.maximum_mix_metadata_epochs - epochs_trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.args.num_mix_metadata_warmup_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9079aa6-8389-4e65-993a-977686e2f0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed1c97-d679-4d7b-890d-0c21f4e80ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b369f0f-f0aa-4ba5-a311-e79ca5ff84b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:21: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='173300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    14/173300 00:09 < 37:32:17, 1.28 it/s, Epoch 0.00/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 318\u001b[0m, in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m    315\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    317\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m    319\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/data.py:293\u001b[0m, in \u001b[0;36mXCDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    292\u001b[0m         x\u001b[38;5;241m.\u001b[39mupdate(m\u001b[38;5;241m.\u001b[39mget_data_meta(idx))\n\u001b[0;32m--> 293\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl: x\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lbl_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlbl2data_idx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/fastcore/dispatch.py:120\u001b[0m, in \u001b[0;36mTypeDispatch.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/data.py:207\u001b[0m, in \u001b[0;36mMetaXCDataset.get_lbl_meta\u001b[0;34m(self, idxs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples: x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [[o[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(o))[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples]] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     x\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m:[[v[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m o] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/data.py:207\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples: x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [[o[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(o))[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples]] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     x\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m:[[v[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m o] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/data.py:207\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples: x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [[o[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(o))[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples]] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     x\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m:[[v[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m o] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/data.py:207\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples: x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [[o[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(o))[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples]] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     x\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m:[[\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m o] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5c3a15-d0af-4ff9-b925-6db26eaf8511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccdb0b-e563-4ace-9aab-5cd634dfd40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2037360939.py(61)predict()\n",
      "     59         #debug\n",
      "     60 \n",
      "---> 61         self.gather_function, self._gen_kwargs = self.accelerator.gather, gen_kwargs\n",
      "     62         self._memory_tracker.start()\n",
      "     63 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2037360939.py(62)predict()\n",
      "     60 \n",
      "     61         self.gather_function, self._gen_kwargs = self.accelerator.gather, gen_kwargs\n",
      "---> 62         self._memory_tracker.start()\n",
      "     63 \n",
      "     64         test_dataloader = self.get_test_dataloader(test_dataset)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2037360939.py(64)predict()\n",
      "     62         self._memory_tracker.start()\n",
      "     63 \n",
      "---> 64         test_dataloader = self.get_test_dataloader(test_dataset)\n",
      "     65         start_time = time.time()\n",
      "     66 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2037360939.py(65)predict()\n",
      "     63 \n",
      "     64         test_dataloader = self.get_test_dataloader(test_dataset)\n",
      "---> 65         start_time = time.time()\n",
      "     66 \n",
      "     67         output = self.evaluation_loop(test_dataloader, description=\"Prediction\", ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2037360939.py(67)predict()\n",
      "     65         start_time = time.time()\n",
      "     66 \n",
      "---> 67         output = self.evaluation_loop(test_dataloader, description=\"Prediction\", ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
      "     68         total_batch_size = self.args.eval_batch_size * self.args.world_size\n",
      "     69         if f\"{metric_key_prefix}_jit_compilation_time\" in output.metrics:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_17097/3130387093.py(2)evaluation_loop()\n",
      "      1 #| export\n",
      "----> 2 @patch\n",
      "      3 def evaluation_loop(\n",
      "      4     self:XCLearner,\n",
      "      5     dataloader:DataLoader,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(13)evaluation_loop()\n",
      "     11     metric_key_prefix:str=\"eval\",\n",
      "     12 ) -> XCEvalLoopOutput:\n",
      "---> 13     args = self.args\n",
      "     14     prediction_loss_only = prediction_loss_only if prediction_loss_only is not None else args.prediction_loss_only\n",
      "     15 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(14)evaluation_loop()\n",
      "     12 ) -> XCEvalLoopOutput:\n",
      "     13     args = self.args\n",
      "---> 14     prediction_loss_only = prediction_loss_only if prediction_loss_only is not None else args.prediction_loss_only\n",
      "     15 \n",
      "     16     \"\"\"\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(19)evaluation_loop()\n",
      "     17     Disable random addition of noise\n",
      "     18     \"\"\"\n",
      "---> 19     if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
      "     20         use_noise = self.model.disable_noise()\n",
      "     21 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(22)evaluation_loop()\n",
      "     20         use_noise = self.model.disable_noise()\n",
      "     21 \n",
      "---> 22     model = self._wrap_model(self.model, training=False, dataloader=dataloader)\n",
      "     23 \n",
      "     24     if len(self.accelerator._models) == 0 and model is self.model:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(24)evaluation_loop()\n",
      "     22     model = self._wrap_model(self.model, training=False, dataloader=dataloader)\n",
      "     23 \n",
      "---> 24     if len(self.accelerator._models) == 0 and model is self.model:\n",
      "     25         model = self.accelerator.prepare(model) if self.is_deepspeed_enabled else self.accelerator.prepare_model(model, evaluation_mode=True)\n",
      "     26         if self.is_fsdp_enabled: self.model = model\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(25)evaluation_loop()\n",
      "     23 \n",
      "     24     if len(self.accelerator._models) == 0 and model is self.model:\n",
      "---> 25         model = self.accelerator.prepare(model) if self.is_deepspeed_enabled else self.accelerator.prepare_model(model, evaluation_mode=True)\n",
      "     26         if self.is_fsdp_enabled: self.model = model\n",
      "     27         if model is not self.model: self.model_wrapped = model\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(26)evaluation_loop()\n",
      "     24     if len(self.accelerator._models) == 0 and model is self.model:\n",
      "     25         model = self.accelerator.prepare(model) if self.is_deepspeed_enabled else self.accelerator.prepare_model(model, evaluation_mode=True)\n",
      "---> 26         if self.is_fsdp_enabled: self.model = model\n",
      "     27         if model is not self.model: self.model_wrapped = model\n",
      "     28         if self.is_deepspeed_enabled: self.deepspeed = self.model_wrapped\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(27)evaluation_loop()\n",
      "     25         model = self.accelerator.prepare(model) if self.is_deepspeed_enabled else self.accelerator.prepare_model(model, evaluation_mode=True)\n",
      "     26         if self.is_fsdp_enabled: self.model = model\n",
      "---> 27         if model is not self.model: self.model_wrapped = model\n",
      "     28         if self.is_deepspeed_enabled: self.deepspeed = self.model_wrapped\n",
      "     29 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(28)evaluation_loop()\n",
      "     26         if self.is_fsdp_enabled: self.model = model\n",
      "     27         if model is not self.model: self.model_wrapped = model\n",
      "---> 28         if self.is_deepspeed_enabled: self.deepspeed = self.model_wrapped\n",
      "     29 \n",
      "     30     batch_size = self.args.eval_batch_size\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(30)evaluation_loop()\n",
      "     28         if self.is_deepspeed_enabled: self.deepspeed = self.model_wrapped\n",
      "     29 \n",
      "---> 30     batch_size = self.args.eval_batch_size\n",
      "     31 \n",
      "     32     model.eval()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(32)evaluation_loop()\n",
      "     30     batch_size = self.args.eval_batch_size\n",
      "     31 \n",
      "---> 32     model.eval()\n",
      "     33 \n",
      "     34     self.callback_handler.eval_dataloader = dataloader\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(34)evaluation_loop()\n",
      "     32     model.eval()\n",
      "     33 \n",
      "---> 34     self.callback_handler.eval_dataloader = dataloader\n",
      "     35     eval_dataset = getattr(dataloader, \"dataset\", None)\n",
      "     36 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(35)evaluation_loop()\n",
      "     33 \n",
      "     34     self.callback_handler.eval_dataloader = dataloader\n",
      "---> 35     eval_dataset = getattr(dataloader, \"dataset\", None)\n",
      "     36 \n",
      "     37     if self._perform_representation(unwrap_model(model)) and not prediction_loss_only:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(37)evaluation_loop()\n",
      "     35     eval_dataset = getattr(dataloader, \"dataset\", None)\n",
      "     36 \n",
      "---> 37     if self._perform_representation(unwrap_model(model)) and not prediction_loss_only:\n",
      "     38         self._build_lbl_index(eval_dataset)\n",
      "     39 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(38)evaluation_loop()\n",
      "     36 \n",
      "     37     if self._perform_representation(unwrap_model(model)) and not prediction_loss_only:\n",
      "---> 38         self._build_lbl_index(eval_dataset)\n",
      "     39 \n",
      "     40     if self._perform_augmentation(unwrap_model(model)) and not prediction_loss_only:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f385736d63c94df492385701d24a3cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(40)evaluation_loop()\n",
      "     38         self._build_lbl_index(eval_dataset)\n",
      "     39 \n",
      "---> 40     if self._perform_augmentation(unwrap_model(model)) and not prediction_loss_only:\n",
      "     41         self._build_aug_index(eval_dataset)\n",
      "     42 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(41)evaluation_loop()\n",
      "     39 \n",
      "     40     if self._perform_augmentation(unwrap_model(model)) and not prediction_loss_only:\n",
      "---> 41         self._build_aug_index(eval_dataset)\n",
      "     42 \n",
      "     43     if args.past_index >= 0: self._past = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_17097/3763747061.py(2)_build_aug_index()\n",
      "      1 #| export\n",
      "----> 2 @patch\n",
      "      3 def _build_aug_index(self:XCLearner, dataset:Optional[Dataset]=None):\n",
      "      4     dataset = dataset if self.eval_dataset is None else self.eval_dataset\n",
      "      5     dataset = dataset if self.train_dataset is None else self.train_dataset\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(4)_build_aug_index()\n",
      "      2 @patch\n",
      "      3 def _build_aug_index(self:XCLearner, dataset:Optional[Dataset]=None):\n",
      "----> 4     dataset = dataset if self.eval_dataset is None else self.eval_dataset\n",
      "      5     dataset = dataset if self.train_dataset is None else self.train_dataset\n",
      "      6 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(5)_build_aug_index()\n",
      "      3 def _build_aug_index(self:XCLearner, dataset:Optional[Dataset]=None):\n",
      "      4     dataset = dataset if self.eval_dataset is None else self.eval_dataset\n",
      "----> 5     dataset = dataset if self.train_dataset is None else self.train_dataset\n",
      "      6 \n",
      "      7     meta_name = f'{self.args.data_aug_meta_name}_meta' if self.args.data_aug_meta_name is not None else None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(7)_build_aug_index()\n",
      "      5     dataset = dataset if self.train_dataset is None else self.train_dataset\n",
      "      6 \n",
      "----> 7     meta_name = f'{self.args.data_aug_meta_name}_meta' if self.args.data_aug_meta_name is not None else None\n",
      "      8     if (\n",
      "      9         dataset is not None and\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(9)_build_aug_index()\n",
      "      7     meta_name = f'{self.args.data_aug_meta_name}_meta' if self.args.data_aug_meta_name is not None else None\n",
      "      8     if (\n",
      "----> 9         dataset is not None and\n",
      "     10         dataset.meta is not None and\n",
      "     11         meta_name is not None and\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(8)_build_aug_index()\n",
      "      6 \n",
      "      7     meta_name = f'{self.args.data_aug_meta_name}_meta' if self.args.data_aug_meta_name is not None else None\n",
      "----> 8     if (\n",
      "      9         dataset is not None and\n",
      "     10         dataset.meta is not None and\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(10)_build_aug_index()\n",
      "      8     if (\n",
      "      9         dataset is not None and\n",
      "---> 10         dataset.meta is not None and\n",
      "     11         meta_name is not None and\n",
      "     12         meta_name in dataset.meta\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(8)_build_aug_index()\n",
      "      6 \n",
      "      7     meta_name = f'{self.args.data_aug_meta_name}_meta' if self.args.data_aug_meta_name is not None else None\n",
      "----> 8     if (\n",
      "      9         dataset is not None and\n",
      "     10         dataset.meta is not None and\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(11)_build_aug_index()\n",
      "      9         dataset is not None and\n",
      "     10         dataset.meta is not None and\n",
      "---> 11         meta_name is not None and\n",
      "     12         meta_name in dataset.meta\n",
      "     13     ):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(8)_build_aug_index()\n",
      "      6 \n",
      "      7     meta_name = f'{self.args.data_aug_meta_name}_meta' if self.args.data_aug_meta_name is not None else None\n",
      "----> 8     if (\n",
      "      9         dataset is not None and\n",
      "     10         dataset.meta is not None and\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(12)_build_aug_index()\n",
      "     10         dataset.meta is not None and\n",
      "     11         meta_name is not None and\n",
      "---> 12         meta_name in dataset.meta\n",
      "     13     ):\n",
      "     14         self.aug_idxs = IndexSearch(space=self.args.index_space, efc=self.args.index_efc, m=self.args.index_m, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(8)_build_aug_index()\n",
      "      6 \n",
      "      7     meta_name = f'{self.args.data_aug_meta_name}_meta' if self.args.data_aug_meta_name is not None else None\n",
      "----> 8     if (\n",
      "      9         dataset is not None and\n",
      "     10         dataset.meta is not None and\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(14)_build_aug_index()\n",
      "     12         meta_name in dataset.meta\n",
      "     13     ):\n",
      "---> 14         self.aug_idxs = IndexSearch(space=self.args.index_space, efc=self.args.index_efc, m=self.args.index_m, \n",
      "     15                                     efs=self.args.index_efs, n_bm=self.args.augmentation_num_beams,\n",
      "     16                                     n_threads=self.args.index_num_threads)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(15)_build_aug_index()\n",
      "     13     ):\n",
      "     14         self.aug_idxs = IndexSearch(space=self.args.index_space, efc=self.args.index_efc, m=self.args.index_m, \n",
      "---> 15                                     efs=self.args.index_efs, n_bm=self.args.augmentation_num_beams,\n",
      "     16                                     n_threads=self.args.index_num_threads)\n",
      "     17 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(16)_build_aug_index()\n",
      "     14         self.aug_idxs = IndexSearch(space=self.args.index_space, efc=self.args.index_efc, m=self.args.index_m, \n",
      "     15                                     efs=self.args.index_efs, n_bm=self.args.augmentation_num_beams,\n",
      "---> 16                                     n_threads=self.args.index_num_threads)\n",
      "     17 \n",
      "     18         dset = MainXCDataset(getattr(dataset.meta[meta_name], 'meta_info'))\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(14)_build_aug_index()\n",
      "     12         meta_name in dataset.meta\n",
      "     13     ):\n",
      "---> 14         self.aug_idxs = IndexSearch(space=self.args.index_space, efc=self.args.index_efc, m=self.args.index_m, \n",
      "     15                                     efs=self.args.index_efs, n_bm=self.args.augmentation_num_beams,\n",
      "     16                                     n_threads=self.args.index_num_threads)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(18)_build_aug_index()\n",
      "     16                                     n_threads=self.args.index_num_threads)\n",
      "     17 \n",
      "---> 18         dset = MainXCDataset(getattr(dataset.meta[meta_name], 'meta_info'))\n",
      "     19         dataloader = self.get_test_dataloader(dset)\n",
      "     20         rep = self.get_meta_representation(dataloader, to_cpu=isinstance(self.aug_idxs, IndexSearch))\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(19)_build_aug_index()\n",
      "     17 \n",
      "     18         dset = MainXCDataset(getattr(dataset.meta[meta_name], 'meta_info'))\n",
      "---> 19         dataloader = self.get_test_dataloader(dset)\n",
      "     20         rep = self.get_meta_representation(dataloader, to_cpu=isinstance(self.aug_idxs, IndexSearch))\n",
      "     21         self.aug_idxs.build(rep)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(20)_build_aug_index()\n",
      "     18         dset = MainXCDataset(getattr(dataset.meta[meta_name], 'meta_info'))\n",
      "     19         dataloader = self.get_test_dataloader(dset)\n",
      "---> 20         rep = self.get_meta_representation(dataloader, to_cpu=isinstance(self.aug_idxs, IndexSearch))\n",
      "     21         self.aug_idxs.build(rep)\n",
      "     22 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77faebfd5ee497a8d5b1911747c2409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3763747061.py(21)_build_aug_index()\n",
      "     19         dataloader = self.get_test_dataloader(dset)\n",
      "     20         rep = self.get_meta_representation(dataloader, to_cpu=isinstance(self.aug_idxs, IndexSearch))\n",
      "---> 21         self.aug_idxs.build(rep)\n",
      "     22 \n",
      "     23 @patch\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  rep\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5328, -0.5598, -1.5582,  ...,  0.2927, -0.0323, -1.9101],\n",
      "        [ 0.9798,  1.1929,  0.7301,  ...,  0.0479, -0.2709, -0.7521],\n",
      "        [ 0.9411,  0.1891, -1.2752,  ..., -0.1096, -0.4901, -2.8935],\n",
      "        ...,\n",
      "        [ 1.3689,  0.1684,  0.0990,  ...,  0.5376,  0.8067, -1.1424],\n",
      "        [-0.4501,  0.5022,  0.4537,  ...,  0.6481,  2.1304,  0.8844],\n",
      "        [ 0.6426,  0.6652, -0.5456,  ...,  0.3794,  0.7022,  0.1856]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  torch.norm(rep, dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([23.6851, 23.1776, 23.8325,  ..., 24.5508, 24.1068, 22.8956])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> /tmp/ipykernel_17097/3763747061.py(21)_build_aug_index()\n",
      "     19         dataloader = self.get_test_dataloader(dset)\n",
      "     20         rep = self.get_meta_representation(dataloader, to_cpu=isinstance(self.aug_idxs, IndexSearch))\n",
      "---> 21         self.aug_idxs.build(rep)\n",
      "     22 \n",
      "     23 @patch\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(43)evaluation_loop()\n",
      "     41         self._build_aug_index(eval_dataset)\n",
      "     42 \n",
      "---> 43     if args.past_index >= 0: self._past = None\n",
      "     44 \n",
      "     45     losses_host, all_losses = None, None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(45)evaluation_loop()\n",
      "     43     if args.past_index >= 0: self._past = None\n",
      "     44 \n",
      "---> 45     losses_host, all_losses = None, None\n",
      "     46     host_output, all_output = {}, {}\n",
      "     47 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(46)evaluation_loop()\n",
      "     44 \n",
      "     45     losses_host, all_losses = None, None\n",
      "---> 46     host_output, all_output = {}, {}\n",
      "     47 \n",
      "     48     observed_num_examples = 0\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(48)evaluation_loop()\n",
      "     46     host_output, all_output = {}, {}\n",
      "     47 \n",
      "---> 48     observed_num_examples = 0\n",
      "     49     for step, inputs in enumerate(dataloader):\n",
      "     50         observed_batch_size = find_batch_size(inputs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(49)evaluation_loop()\n",
      "     47 \n",
      "     48     observed_num_examples = 0\n",
      "---> 49     for step, inputs in enumerate(dataloader):\n",
      "     50         observed_batch_size = find_batch_size(inputs)\n",
      "     51         if observed_batch_size is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(50)evaluation_loop()\n",
      "     48     observed_num_examples = 0\n",
      "     49     for step, inputs in enumerate(dataloader):\n",
      "---> 50         observed_batch_size = find_batch_size(inputs)\n",
      "     51         if observed_batch_size is not None:\n",
      "     52             observed_num_examples += observed_batch_size\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(51)evaluation_loop()\n",
      "     49     for step, inputs in enumerate(dataloader):\n",
      "     50         observed_batch_size = find_batch_size(inputs)\n",
      "---> 51         if observed_batch_size is not None:\n",
      "     52             observed_num_examples += observed_batch_size\n",
      "     53             if batch_size is None: batch_size = observed_batch_size\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(52)evaluation_loop()\n",
      "     50         observed_batch_size = find_batch_size(inputs)\n",
      "     51         if observed_batch_size is not None:\n",
      "---> 52             observed_num_examples += observed_batch_size\n",
      "     53             if batch_size is None: batch_size = observed_batch_size\n",
      "     54 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(53)evaluation_loop()\n",
      "     51         if observed_batch_size is not None:\n",
      "     52             observed_num_examples += observed_batch_size\n",
      "---> 53             if batch_size is None: batch_size = observed_batch_size\n",
      "     54 \n",
      "     55         loss, output = self.prediction_step(model, inputs, prediction_loss_only, predict_with_generation, predict_with_representation, ignore_keys=ignore_keys)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/3130387093.py(55)evaluation_loop()\n",
      "     53             if batch_size is None: batch_size = observed_batch_size\n",
      "     54 \n",
      "---> 55         loss, output = self.prediction_step(model, inputs, prediction_loss_only, predict_with_generation, predict_with_representation, ignore_keys=ignore_keys)\n",
      "     56 \n",
      "     57         if loss is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_17097/2932614700.py(2)prediction_step()\n",
      "      1 #| export\n",
      "----> 2 @patch\n",
      "      3 def prediction_step(\n",
      "      4     self:XCLearner,\n",
      "      5     model: nn.Module,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2932614700.py(14)prediction_step()\n",
      "     12     **kwargs,\n",
      "     13 ) -> Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
      "---> 14     with torch.no_grad():\n",
      "     15         with self.compute_loss_context_manager(): outputs = model(**inputs)\n",
      "     16         loss = (outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]).mean().detach()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2932614700.py(15)prediction_step()\n",
      "     13 ) -> Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
      "     14     with torch.no_grad():\n",
      "---> 15         with self.compute_loss_context_manager(): outputs = model(**inputs)\n",
      "     16         loss = (outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]).mean().detach()\n",
      "     17     prediction_loss_only = self.args.prediction_loss_only if prediction_loss_only is None else prediction_loss_only\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2932614700.py(16)prediction_step()\n",
      "     14     with torch.no_grad():\n",
      "     15         with self.compute_loss_context_manager(): outputs = model(**inputs)\n",
      "---> 16         loss = (outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]).mean().detach()\n",
      "     17     prediction_loss_only = self.args.prediction_loss_only if prediction_loss_only is None else prediction_loss_only\n",
      "     18     if prediction_loss_only: return loss, {}\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2932614700.py(17)prediction_step()\n",
      "     15         with self.compute_loss_context_manager(): outputs = model(**inputs)\n",
      "     16         loss = (outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]).mean().detach()\n",
      "---> 17     prediction_loss_only = self.args.prediction_loss_only if prediction_loss_only is None else prediction_loss_only\n",
      "     18     if prediction_loss_only: return loss, {}\n",
      "     19 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2932614700.py(18)prediction_step()\n",
      "     16         loss = (outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]).mean().detach()\n",
      "     17     prediction_loss_only = self.args.prediction_loss_only if prediction_loss_only is None else prediction_loss_only\n",
      "---> 18     if prediction_loss_only: return loss, {}\n",
      "     19 \n",
      "     20     if self._perform_augmentation(model, predict_with_augmentation):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2932614700.py(20)prediction_step()\n",
      "     18     if prediction_loss_only: return loss, {}\n",
      "     19 \n",
      "---> 20     if self._perform_augmentation(model, predict_with_augmentation):\n",
      "     21         aug_inputs = self.augmentation_output(model, inputs, **kwargs)\n",
      "     22         inputs.update(aug_inputs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2932614700.py(21)prediction_step()\n",
      "     19 \n",
      "     20     if self._perform_augmentation(model, predict_with_augmentation):\n",
      "---> 21         aug_inputs = self.augmentation_output(model, inputs, **kwargs)\n",
      "     22         inputs.update(aug_inputs)\n",
      "     23 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_17097/1871579336.py(39)augmentation_output()\n",
      "     37     return {'pred_idx':o['info2data_idx'], 'pred_score':o['info2data_score'], 'pred_ptr':o['info2data_data2ptr']}\n",
      "     38 \n",
      "---> 39 @patch\n",
      "     40 def augmentation_output(\n",
      "     41     self:XCLearner,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(46)augmentation_output()\n",
      "     44     **kwargs\n",
      "     45 ):\n",
      "---> 46     if self.aug_idxs is None:\n",
      "     47         raise ValueError('Augmentation index `aug_idx` is not initialized.')\n",
      "     48 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(49)augmentation_output()\n",
      "     47         raise ValueError('Augmentation index `aug_idx` is not initialized.')\n",
      "     48 \n",
      "---> 49     inputs = self._prepare_inputs(inputs)\n",
      "     50     n_bm = kwargs.pop(\"aug_num_beams\") if \"aug_num_beams\" in kwargs and kwargs[\"aug_num_beams\"] is not None else self.args.augmentation_num_beams\n",
      "     51 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(50)augmentation_output()\n",
      "     48 \n",
      "     49     inputs = self._prepare_inputs(inputs)\n",
      "---> 50     n_bm = kwargs.pop(\"aug_num_beams\") if \"aug_num_beams\" in kwargs and kwargs[\"aug_num_beams\"] is not None else self.args.augmentation_num_beams\n",
      "     51 \n",
      "     52     with torch.no_grad():\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(52)augmentation_output()\n",
      "     50     n_bm = kwargs.pop(\"aug_num_beams\") if \"aug_num_beams\" in kwargs and kwargs[\"aug_num_beams\"] is not None else self.args.augmentation_num_beams\n",
      "     51 \n",
      "---> 52     with torch.no_grad():\n",
      "     53         inputs = {'data_input_ids':inputs['data_input_ids'], 'data_attention_mask':inputs['data_attention_mask']}\n",
      "     54         o = getattr(model(**inputs), self.args.data_augmentation_attribute)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(53)augmentation_output()\n",
      "     51 \n",
      "     52     with torch.no_grad():\n",
      "---> 53         inputs = {'data_input_ids':inputs['data_input_ids'], 'data_attention_mask':inputs['data_attention_mask']}\n",
      "     54         o = getattr(model(**inputs), self.args.data_augmentation_attribute)\n",
      "     55         if self.args.use_distributional_representation: o = o.exp()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(54)augmentation_output()\n",
      "     52     with torch.no_grad():\n",
      "     53         inputs = {'data_input_ids':inputs['data_input_ids'], 'data_attention_mask':inputs['data_attention_mask']}\n",
      "---> 54         o = getattr(model(**inputs), self.args.data_augmentation_attribute)\n",
      "     55         if self.args.use_distributional_representation: o = o.exp()\n",
      "     56 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(55)augmentation_output()\n",
      "     53         inputs = {'data_input_ids':inputs['data_input_ids'], 'data_attention_mask':inputs['data_attention_mask']}\n",
      "     54         o = getattr(model(**inputs), self.args.data_augmentation_attribute)\n",
      "---> 55         if self.args.use_distributional_representation: o = o.exp()\n",
      "     56 \n",
      "     57     o = self.aug_idxs.proc(o, n_bm=n_bm)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(57)augmentation_output()\n",
      "     55         if self.args.use_distributional_representation: o = o.exp()\n",
      "     56 \n",
      "---> 57     o = self.aug_idxs.proc(o, n_bm=n_bm)\n",
      "     58 \n",
      "     59     \"\"\"\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(62)augmentation_output()\n",
      "     60     Preparing augmentation input\n",
      "     61     \"\"\"\n",
      "---> 62     meta_name = f'{self.args.data_aug_meta_name}_meta'\n",
      "     63     if (\n",
      "     64         meta_name is not None and\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(64)augmentation_output()\n",
      "     62     meta_name = f'{self.args.data_aug_meta_name}_meta'\n",
      "     63     if (\n",
      "---> 64         meta_name is not None and\n",
      "     65         self.train_dataset.meta is not None and\n",
      "     66         meta_name in self.train_dataset.meta\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(63)augmentation_output()\n",
      "     61     \"\"\"\n",
      "     62     meta_name = f'{self.args.data_aug_meta_name}_meta'\n",
      "---> 63     if (\n",
      "     64         meta_name is not None and\n",
      "     65         self.train_dataset.meta is not None and\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(65)augmentation_output()\n",
      "     63     if (\n",
      "     64         meta_name is not None and\n",
      "---> 65         self.train_dataset.meta is not None and\n",
      "     66         meta_name in self.train_dataset.meta\n",
      "     67     ):    \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(63)augmentation_output()\n",
      "     61     \"\"\"\n",
      "     62     meta_name = f'{self.args.data_aug_meta_name}_meta'\n",
      "---> 63     if (\n",
      "     64         meta_name is not None and\n",
      "     65         self.train_dataset.meta is not None and\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(66)augmentation_output()\n",
      "     64         meta_name is not None and\n",
      "     65         self.train_dataset.meta is not None and\n",
      "---> 66         meta_name in self.train_dataset.meta\n",
      "     67     ):    \n",
      "     68         meta_dset = self.train_dataset.meta[meta_name]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(63)augmentation_output()\n",
      "     61     \"\"\"\n",
      "     62     meta_name = f'{self.args.data_aug_meta_name}_meta'\n",
      "---> 63     if (\n",
      "     64         meta_name is not None and\n",
      "     65         self.train_dataset.meta is not None and\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(68)augmentation_output()\n",
      "     66         meta_name in self.train_dataset.meta\n",
      "     67     ):    \n",
      "---> 68         meta_dset = self.train_dataset.meta[meta_name]\n",
      "     69         aug_info  = meta_dset.meta_info\n",
      "     70     else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(69)augmentation_output()\n",
      "     67     ):    \n",
      "     68         meta_dset = self.train_dataset.meta[meta_name]\n",
      "---> 69         aug_info  = meta_dset.meta_info\n",
      "     70     else:\n",
      "     71         raise ValueError(f'Augmentation information not available.')\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(73)augmentation_output()\n",
      "     71         raise ValueError(f'Augmentation information not available.')\n",
      "     72 \n",
      "---> 73     pad_proc = PadFeatTfm(pad_tok=self.model.config.pad_token_id, prefix=\"meta\")\n",
      "     74     info = pad_proc({\n",
      "     75         'meta_input_ids':[aug_info['input_ids'][i] for i in o['info2data_idx']],\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(74)augmentation_output()\n",
      "     72 \n",
      "     73     pad_proc = PadFeatTfm(pad_tok=self.model.config.pad_token_id, prefix=\"meta\")\n",
      "---> 74     info = pad_proc({\n",
      "     75         'meta_input_ids':[aug_info['input_ids'][i] for i in o['info2data_idx']],\n",
      "     76         'meta_attention_mask':[aug_info['attention_mask'][i] for i in o['info2data_idx']],\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(75)augmentation_output()\n",
      "     73     pad_proc = PadFeatTfm(pad_tok=self.model.config.pad_token_id, prefix=\"meta\")\n",
      "     74     info = pad_proc({\n",
      "---> 75         'meta_input_ids':[aug_info['input_ids'][i] for i in o['info2data_idx']],\n",
      "     76         'meta_attention_mask':[aug_info['attention_mask'][i] for i in o['info2data_idx']],\n",
      "     77     })\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(76)augmentation_output()\n",
      "     74     info = pad_proc({\n",
      "     75         'meta_input_ids':[aug_info['input_ids'][i] for i in o['info2data_idx']],\n",
      "---> 76         'meta_attention_mask':[aug_info['attention_mask'][i] for i in o['info2data_idx']],\n",
      "     77     })\n",
      "     78 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(74)augmentation_output()\n",
      "     72 \n",
      "     73     pad_proc = PadFeatTfm(pad_tok=self.model.config.pad_token_id, prefix=\"meta\")\n",
      "---> 74     info = pad_proc({\n",
      "     75         'meta_input_ids':[aug_info['input_ids'][i] for i in o['info2data_idx']],\n",
      "     76         'meta_attention_mask':[aug_info['attention_mask'][i] for i in o['info2data_idx']],\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(79)augmentation_output()\n",
      "     77     })\n",
      "     78 \n",
      "---> 79     data_aug_prefix = self.args.data_aug_meta_name if self.args.data_aug_prefix is None else self.args.data_aug_prefix\n",
      "     80 \n",
      "     81     if self.args.use_augmentation_index_representation:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(81)augmentation_output()\n",
      "     79     data_aug_prefix = self.args.data_aug_meta_name if self.args.data_aug_prefix is None else self.args.data_aug_prefix\n",
      "     80 \n",
      "---> 81     if self.args.use_augmentation_index_representation:\n",
      "     82         rep = torch.tensor(self.aug_idxs.get_items(o['info2data_idx']))\n",
      "     83         return {\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(82)augmentation_output()\n",
      "     80 \n",
      "     81     if self.args.use_augmentation_index_representation:\n",
      "---> 82         rep = torch.tensor(self.aug_idxs.get_items(o['info2data_idx']))\n",
      "     83         return {\n",
      "     84             f'{data_aug_prefix}2data_idx':o['info2data_idx'],\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17097/1871579336.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rep = torch.tensor(self.aug_idxs.get_items(o['info2data_idx']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(84)augmentation_output()\n",
      "     82         rep = torch.tensor(self.aug_idxs.get_items(o['info2data_idx']))\n",
      "     83         return {\n",
      "---> 84             f'{data_aug_prefix}2data_idx':o['info2data_idx'],\n",
      "     85             f'{data_aug_prefix}2data_data2ptr': o['info2data_data2ptr'],\n",
      "     86             f'{data_aug_prefix}2data_meta_repr': rep,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  rep.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4800, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  torch.norm(rep, dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([22.9758, 23.8516, 23.5292,  ..., 23.0874, 23.2436, 24.1294])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(85)augmentation_output()\n",
      "     83         return {\n",
      "     84             f'{data_aug_prefix}2data_idx':o['info2data_idx'],\n",
      "---> 85             f'{data_aug_prefix}2data_data2ptr': o['info2data_data2ptr'],\n",
      "     86             f'{data_aug_prefix}2data_meta_repr': rep,\n",
      "     87             f'{data_aug_prefix}2data_attention_mask': info['meta_attention_mask'],\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(86)augmentation_output()\n",
      "     84             f'{data_aug_prefix}2data_idx':o['info2data_idx'],\n",
      "     85             f'{data_aug_prefix}2data_data2ptr': o['info2data_data2ptr'],\n",
      "---> 86             f'{data_aug_prefix}2data_meta_repr': rep,\n",
      "     87             f'{data_aug_prefix}2data_attention_mask': info['meta_attention_mask'],\n",
      "     88         }\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(87)augmentation_output()\n",
      "     85             f'{data_aug_prefix}2data_data2ptr': o['info2data_data2ptr'],\n",
      "     86             f'{data_aug_prefix}2data_meta_repr': rep,\n",
      "---> 87             f'{data_aug_prefix}2data_attention_mask': info['meta_attention_mask'],\n",
      "     88         }\n",
      "     89     else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(83)augmentation_output()\n",
      "     81     if self.args.use_augmentation_index_representation:\n",
      "     82         rep = torch.tensor(self.aug_idxs.get_items(o['info2data_idx']))\n",
      "---> 83         return {\n",
      "     84             f'{data_aug_prefix}2data_idx':o['info2data_idx'],\n",
      "     85             f'{data_aug_prefix}2data_data2ptr': o['info2data_data2ptr'],\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "{'aug2data_attention_mask': tensor([[1, 1....., 0, 0, 0]]), 'aug2data_data2ptr': tensor([3, 3,......, 3, 3, 3]), 'aug2data_idx': tensor([ 6919...1154,   2548]), 'aug2data_meta_repr': tensor([[-0.2...34, -0.5805]])}\n",
      "> /tmp/ipykernel_17097/1871579336.py(83)augmentation_output()\n",
      "     81     if self.args.use_augmentation_index_representation:\n",
      "     82         rep = torch.tensor(self.aug_idxs.get_items(o['info2data_idx']))\n",
      "---> 83         return {\n",
      "     84             f'{data_aug_prefix}2data_idx':o['info2data_idx'],\n",
      "     85             f'{data_aug_prefix}2data_data2ptr': o['info2data_data2ptr'],\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2932614700.py(22)prediction_step()\n",
      "     20     if self._perform_augmentation(model, predict_with_augmentation):\n",
      "     21         aug_inputs = self.augmentation_output(model, inputs, **kwargs)\n",
      "---> 22         inputs.update(aug_inputs)\n",
      "     23 \n",
      "     24     output, gen_o, repr_o = None, None, None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2932614700.py(24)prediction_step()\n",
      "     22         inputs.update(aug_inputs)\n",
      "     23 \n",
      "---> 24     output, gen_o, repr_o = None, None, None\n",
      "     25     if self._perform_generation(model, predict_with_generation): gen_o = self.generation_output(model, inputs, **kwargs)\n",
      "     26     if self._perform_representation(model, predict_with_representation): repr_o = self.representation_output(model, inputs, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2932614700.py(25)prediction_step()\n",
      "     23 \n",
      "     24     output, gen_o, repr_o = None, None, None\n",
      "---> 25     if self._perform_generation(model, predict_with_generation): gen_o = self.generation_output(model, inputs, **kwargs)\n",
      "     26     if self._perform_representation(model, predict_with_representation): repr_o = self.representation_output(model, inputs, **kwargs)\n",
      "     27 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2932614700.py(26)prediction_step()\n",
      "     24     output, gen_o, repr_o = None, None, None\n",
      "     25     if self._perform_generation(model, predict_with_generation): gen_o = self.generation_output(model, inputs, **kwargs)\n",
      "---> 26     if self._perform_representation(model, predict_with_representation): repr_o = self.representation_output(model, inputs, **kwargs)\n",
      "     27 \n",
      "     28     if gen_o is not None and repr_o is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_17097/2264972374.py(8)_perform_representation()\n",
      "      6     return getattr(model,'use_generation') if hasattr(model,'use_generation') else predict_with_generation\n",
      "      7 \n",
      "----> 8 @patch\n",
      "      9 def _perform_representation(self:XCLearner, model:nn.Module, predict_with_representation:Optional[bool]=None):\n",
      "     10     model = unwrap_model(model)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2264972374.py(10)_perform_representation()\n",
      "      8 @patch\n",
      "      9 def _perform_representation(self:XCLearner, model:nn.Module, predict_with_representation:Optional[bool]=None):\n",
      "---> 10     model = unwrap_model(model)\n",
      "     11     predict_with_representation = self.args.predict_with_representation if predict_with_representation is None else predict_with_representation\n",
      "     12     return getattr(model,'use_representation') if hasattr(model,'use_representation') else predict_with_representation\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2264972374.py(11)_perform_representation()\n",
      "      9 def _perform_representation(self:XCLearner, model:nn.Module, predict_with_representation:Optional[bool]=None):\n",
      "     10     model = unwrap_model(model)\n",
      "---> 11     predict_with_representation = self.args.predict_with_representation if predict_with_representation is None else predict_with_representation\n",
      "     12     return getattr(model,'use_representation') if hasattr(model,'use_representation') else predict_with_representation\n",
      "     13 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/2264972374.py(12)_perform_representation()\n",
      "     10     model = unwrap_model(model)\n",
      "     11     predict_with_representation = self.args.predict_with_representation if predict_with_representation is None else predict_with_representation\n",
      "---> 12     return getattr(model,'use_representation') if hasattr(model,'use_representation') else predict_with_representation\n",
      "     13 \n",
      "     14 @patch\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "True\n",
      "> /tmp/ipykernel_17097/2264972374.py(12)_perform_representation()\n",
      "     10     model = unwrap_model(model)\n",
      "     11     predict_with_representation = self.args.predict_with_representation if predict_with_representation is None else predict_with_representation\n",
      "---> 12     return getattr(model,'use_representation') if hasattr(model,'use_representation') else predict_with_representation\n",
      "     13 \n",
      "     14 @patch\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_17097/1871579336.py(17)representation_output()\n",
      "     15     return {'pred_idx':o['info2seq2data_idx'], 'pred_score':o['info2seq2data_score'], 'pred_ptr':o['info2seq2data_data2ptr']}\n",
      "     16 \n",
      "---> 17 @patch\n",
      "     18 def representation_output(\n",
      "     19     self:XCLearner,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(24)representation_output()\n",
      "     22     **kwargs\n",
      "     23 ):\n",
      "---> 24     inputs = self._prepare_inputs(inputs)\n",
      "     25     n_bm = kwargs.pop(\"repr_num_beams\") if \"repr_num_beams\" in kwargs and kwargs[\"repr_num_beams\"] is not None else self.args.representation_num_beams\n",
      "     26 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(25)representation_output()\n",
      "     23 ):\n",
      "     24     inputs = self._prepare_inputs(inputs)\n",
      "---> 25     n_bm = kwargs.pop(\"repr_num_beams\") if \"repr_num_beams\" in kwargs and kwargs[\"repr_num_beams\"] is not None else self.args.representation_num_beams\n",
      "     26 \n",
      "     27     with torch.no_grad():\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(27)representation_output()\n",
      "     25     n_bm = kwargs.pop(\"repr_num_beams\") if \"repr_num_beams\" in kwargs and kwargs[\"repr_num_beams\"] is not None else self.args.representation_num_beams\n",
      "     26 \n",
      "---> 27     with torch.no_grad():\n",
      "     28         o = model(**inputs)\n",
      "     29         if getattr(o, self.args.output_representation_attribute) is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_17097/1871579336.py(28)representation_output()\n",
      "     26 \n",
      "     27     with torch.no_grad():\n",
      "---> 28         o = model(**inputs)\n",
      "     29         if getattr(o, self.args.output_representation_attribute) is not None:\n",
      "     30             o = getattr(o, self.args.output_representation_attribute)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(280)keys()\n",
      "    278             self._encodings = state[\"encodings\"]\n",
      "    279 \n",
      "--> 280     def keys(self):\n",
      "    281         return self.data.keys()\n",
      "    282 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(281)keys()\n",
      "    279 \n",
      "    280     def keys(self):\n",
      "--> 281         return self.data.keys()\n",
      "    282 \n",
      "    283     def values(self):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "dict_keys(['p...ention_mask'])\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(281)keys()\n",
      "    279 \n",
      "    280     def keys(self):\n",
      "--> 281         return self.data.keys()\n",
      "    282 \n",
      "    283     def values(self):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([    4...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([5, 2,...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([    5...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([[  10...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([[1, 1...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([1, 1,...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([  202...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([13,  ...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([13,  ...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([31991...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([[  10...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([[1, 1...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([1, 1,...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([1, 1,...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([ 1937...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([39,  ...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([ 6820...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([[  10...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([[1, 1...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([1, 1,...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([[  10...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([[1, 1...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([ 6919...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([3, 3,...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([[-0.2...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(242)__getitem__()\n",
      "    240         return self._encodings is not None\n",
      "    241 \n",
      "--> 242     def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:\n",
      "    243         \"\"\"\n",
      "    244         If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(252)__getitem__()\n",
      "    250         with the constraint of slice.\n",
      "    251         \"\"\"\n",
      "--> 252         if isinstance(item, str):\n",
      "    253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([[1, 1...vice='cuda:0')\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py(253)__getitem__()\n",
      "    251         \"\"\"\n",
      "    252         if isinstance(item, str):\n",
      "--> 253             return self.data[item]\n",
      "    254         elif self._encodings is not None:\n",
      "    255             return self._encodings[item]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1507)_wrapped_call_impl()\n",
      "   1505         return result\n",
      "   1506 \n",
      "-> 1507     def _wrapped_call_impl(self, *args, **kwargs):\n",
      "   1508         if self._compiled_call_impl is not None:\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1508)_wrapped_call_impl()\n",
      "   1506 \n",
      "   1507     def _wrapped_call_impl(self, *args, **kwargs):\n",
      "-> 1508         if self._compiled_call_impl is not None:\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1510         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1511)_wrapped_call_impl()\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1510         else:\n",
      "-> 1511             return self._call_impl(*args, **kwargs)\n",
      "   1512 \n",
      "   1513     def _call_impl(self, *args, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1513)_call_impl()\n",
      "   1511             return self._call_impl(*args, **kwargs)\n",
      "   1512 \n",
      "-> 1513     def _call_impl(self, *args, **kwargs):\n",
      "   1514         forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1514)_call_impl()\n",
      "   1512 \n",
      "   1513     def _call_impl(self, *args, **kwargs):\n",
      "-> 1514         forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1516         # this function, and just call forward.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1517)_call_impl()\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1516         # this function, and just call forward.\n",
      "-> 1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1518)_call_impl()\n",
      "   1516         # this function, and just call forward.\n",
      "   1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "-> 1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1520             return forward_call(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1517)_call_impl()\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1516         # this function, and just call forward.\n",
      "-> 1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1518)_call_impl()\n",
      "   1516         # this function, and just call forward.\n",
      "   1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "-> 1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1520             return forward_call(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1517)_call_impl()\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1516         # this function, and just call forward.\n",
      "-> 1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1519)_call_impl()\n",
      "   1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "-> 1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1520             return forward_call(*args, **kwargs)\n",
      "   1521 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1517)_call_impl()\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1516         # this function, and just call forward.\n",
      "-> 1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1519)_call_impl()\n",
      "   1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "-> 1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1520             return forward_call(*args, **kwargs)\n",
      "   1521 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1517)_call_impl()\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1516         # this function, and just call forward.\n",
      "-> 1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1520)_call_impl()\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "-> 1520             return forward_call(*args, **kwargs)\n",
      "   1521 \n",
      "   1522         try:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/utils/operations.py(821)forward()\n",
      "    819     model_forward = ConvertOutputsToFp32(model_forward)\n",
      "    820 \n",
      "--> 821     def forward(*args, **kwargs):\n",
      "    822         return model_forward(*args, **kwargs)\n",
      "    823 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/utils/operations.py(822)forward()\n",
      "    820 \n",
      "    821     def forward(*args, **kwargs):\n",
      "--> 822         return model_forward(*args, **kwargs)\n",
      "    823 \n",
      "    824     # To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/utils/operations.py(809)__call__()\n",
      "    807         update_wrapper(self, model_forward)\n",
      "    808 \n",
      "--> 809     def __call__(self, *args, **kwargs):\n",
      "    810         return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "    811 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/utils/operations.py(810)__call__()\n",
      "    808 \n",
      "    809     def __call__(self, *args, **kwargs):\n",
      "--> 810         return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "    811 \n",
      "    812     def __getstate__(self):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/amp/autocast_mode.py(13)decorate_autocast()\n",
      "     11 \n",
      "     12 def autocast_decorator(autocast_instance, func):\n",
      "---> 13     @functools.wraps(func)\n",
      "     14     def decorate_autocast(*args, **kwargs):\n",
      "     15         with autocast_instance:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/amp/autocast_mode.py(15)decorate_autocast()\n",
      "     13     @functools.wraps(func)\n",
      "     14     def decorate_autocast(*args, **kwargs):\n",
      "---> 15         with autocast_instance:\n",
      "     16             return func(*args, **kwargs)\n",
      "     17 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/amp/autocast_mode.py(16)decorate_autocast()\n",
      "     14     def decorate_autocast(*args, **kwargs):\n",
      "     15         with autocast_instance:\n",
      "---> 16             return func(*args, **kwargs)\n",
      "     17 \n",
      "     18     decorate_autocast.__script_unsupported = \"@autocast() decorator is not supported in script mode\"  # type: ignore[attr-defined]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1198)forward()\n",
      "   1196         )\n",
      "   1197 \n",
      "-> 1198     def forward(\n",
      "   1199         self,\n",
      "   1200         data_input_ids:Optional[torch.Tensor]=None,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1213)forward()\n",
      "   1211         **kwargs\n",
      "   1212     ):  \n",
      "-> 1213         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "   1214 \n",
      "   1215         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1215)forward()\n",
      "   1213         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "   1214 \n",
      "-> 1215         if self.use_encoder_parallel:\n",
      "   1216             encoder = XCDataParallel(module=self.encoder)\n",
      "   1217         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1217)forward()\n",
      "   1215         if self.use_encoder_parallel:\n",
      "   1216             encoder = XCDataParallel(module=self.encoder)\n",
      "-> 1217         else: encoder = self.encoder\n",
      "   1218 \n",
      "   1219         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1219)forward()\n",
      "   1217         else: encoder = self.encoder\n",
      "   1218 \n",
      "-> 1219         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "   1220         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "   1221                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1220)forward()\n",
      "   1218 \n",
      "   1219         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "-> 1220         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "   1221                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "   1222 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['aug2data_attention_mask', 'aug2data_meta_repr', 'aug2data_data2ptr'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1221)forward()\n",
      "   1219         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "   1220         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "-> 1221                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "   1222 \n",
      "   1223 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1220)forward()\n",
      "   1218 \n",
      "   1219         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "-> 1220         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "   1221                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "   1222 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1221)forward()\n",
      "   1219         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "   1220         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "-> 1221                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "   1222 \n",
      "   1223 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1220)forward()\n",
      "   1218 \n",
      "   1219         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "-> 1220         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "   1221                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "   1222 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1507)_wrapped_call_impl()\n",
      "   1505         return result\n",
      "   1506 \n",
      "-> 1507     def _wrapped_call_impl(self, *args, **kwargs):\n",
      "   1508         if self._compiled_call_impl is not None:\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1508)_wrapped_call_impl()\n",
      "   1506 \n",
      "   1507     def _wrapped_call_impl(self, *args, **kwargs):\n",
      "-> 1508         if self._compiled_call_impl is not None:\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1510         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1511)_wrapped_call_impl()\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1510         else:\n",
      "-> 1511             return self._call_impl(*args, **kwargs)\n",
      "   1512 \n",
      "   1513     def _call_impl(self, *args, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1513)_call_impl()\n",
      "   1511             return self._call_impl(*args, **kwargs)\n",
      "   1512 \n",
      "-> 1513     def _call_impl(self, *args, **kwargs):\n",
      "   1514         forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1514)_call_impl()\n",
      "   1512 \n",
      "   1513     def _call_impl(self, *args, **kwargs):\n",
      "-> 1514         forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1516         # this function, and just call forward.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1517)_call_impl()\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1516         # this function, and just call forward.\n",
      "-> 1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1518)_call_impl()\n",
      "   1516         # this function, and just call forward.\n",
      "   1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "-> 1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1520             return forward_call(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1517)_call_impl()\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1516         # this function, and just call forward.\n",
      "-> 1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1518)_call_impl()\n",
      "   1516         # this function, and just call forward.\n",
      "   1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "-> 1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1520             return forward_call(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1517)_call_impl()\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1516         # this function, and just call forward.\n",
      "-> 1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1519)_call_impl()\n",
      "   1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "-> 1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1520             return forward_call(*args, **kwargs)\n",
      "   1521 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1517)_call_impl()\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1516         # this function, and just call forward.\n",
      "-> 1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1519)_call_impl()\n",
      "   1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "-> 1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "   1520             return forward_call(*args, **kwargs)\n",
      "   1521 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1517)_call_impl()\n",
      "   1515         # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "   1516         # this function, and just call forward.\n",
      "-> 1517         if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1520)_call_impl()\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "-> 1520             return forward_call(*args, **kwargs)\n",
      "   1521 \n",
      "   1522         try:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1050)forward()\n",
      "   1048 \n",
      "   1049 \n",
      "-> 1050     def forward(\n",
      "   1051         self,\n",
      "   1052         data_input_ids: torch.Tensor,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1059)forward()\n",
      "   1057         **kwargs\n",
      "   1058     ):\n",
      "-> 1059         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "   1060 \n",
      "   1061         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1061)forward()\n",
      "   1059         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "   1060 \n",
      "-> 1061         if data_type is not None and data_type == \"meta\":\n",
      "   1062             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "   1063         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1064)forward()\n",
      "   1062             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "   1063         else:\n",
      "-> 1064             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "   1065 \n",
      "   1066         data_fused_repr = data_fused_logits = fusion_weights = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1066)forward()\n",
      "   1064             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "   1065 \n",
      "-> 1066         data_fused_repr = data_fused_logits = fusion_weights = meta_repr = None\n",
      "   1067         if data_aug_meta_prefix is not None:\n",
      "   1068             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1067)forward()\n",
      "   1065 \n",
      "   1066         data_fused_repr = data_fused_logits = fusion_weights = meta_repr = None\n",
      "-> 1067         if data_aug_meta_prefix is not None:\n",
      "   1068             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "   1069             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1068)forward()\n",
      "   1066         data_fused_repr = data_fused_logits = fusion_weights = meta_repr = None\n",
      "   1067         if data_aug_meta_prefix is not None:\n",
      "-> 1068             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "   1069             if len(meta_kwargs):\n",
      "   1070                 data_fused_embed, fusion_weights, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1069)forward()\n",
      "   1067         if data_aug_meta_prefix is not None:\n",
      "   1068             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "-> 1069             if len(meta_kwargs):\n",
      "   1070                 data_fused_embed, fusion_weights, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "   1071                                                                                              data_attention_mask,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['aug2data'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1070)forward()\n",
      "   1068             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "   1069             if len(meta_kwargs):\n",
      "-> 1070                 data_fused_embed, fusion_weights, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "   1071                                                                                              data_attention_mask,\n",
      "   1072                                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1071)forward()\n",
      "   1069             if len(meta_kwargs):\n",
      "   1070                 data_fused_embed, fusion_weights, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "-> 1071                                                                                              data_attention_mask,\n",
      "   1072                                                                                              meta_kwargs)\n",
      "   1073                 data_fused_repr = self.fused_dr(data_fused_embed, data_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1072)forward()\n",
      "   1070                 data_fused_embed, fusion_weights, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "   1071                                                                                              data_attention_mask,\n",
      "-> 1072                                                                                              meta_kwargs)\n",
      "   1073                 data_fused_repr = self.fused_dr(data_fused_embed, data_attention_mask)\n",
      "   1074 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1070)forward()\n",
      "   1068             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "   1069             if len(meta_kwargs):\n",
      "-> 1070                 data_fused_embed, fusion_weights, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "   1071                                                                                              data_attention_mask,\n",
      "   1072                                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1017)fuse_meta_into_embeddings()\n",
      "   1015 \n",
      "   1016 \n",
      "-> 1017     def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "   1018         meta_repr, weights = {}, []\n",
      "   1019 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1018)fuse_meta_into_embeddings()\n",
      "   1016 \n",
      "   1017     def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "-> 1018         meta_repr, weights = {}, []\n",
      "   1019 \n",
      "   1020         for m_key, m_args in meta_kwargs.items():\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1020)fuse_meta_into_embeddings()\n",
      "   1018         meta_repr, weights = {}, []\n",
      "   1019 \n",
      "-> 1020         for m_key, m_args in meta_kwargs.items():\n",
      "   1021             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "   1022             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1021)fuse_meta_into_embeddings()\n",
      "   1019 \n",
      "   1020         for m_key, m_args in meta_kwargs.items():\n",
      "-> 1021             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "   1022             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "   1023 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1022)fuse_meta_into_embeddings()\n",
      "   1020         for m_key, m_args in meta_kwargs.items():\n",
      "   1021             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "-> 1022             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "   1023 \n",
      "   1024             if len(idx):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1024)fuse_meta_into_embeddings()\n",
      "   1022             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "   1023 \n",
      "-> 1024             if len(idx):\n",
      "   1025                 if not torch.all(m_args['data2ptr'][idx] == m_args['data2ptr'].max()):\n",
      "   1026                     raise ValueError(f'All datapoints should have same number of metadata.')\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1025)fuse_meta_into_embeddings()\n",
      "   1023 \n",
      "   1024             if len(idx):\n",
      "-> 1025                 if not torch.all(m_args['data2ptr'][idx] == m_args['data2ptr'].max()):\n",
      "   1026                     raise ValueError(f'All datapoints should have same number of metadata.')\n",
      "   1027 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1028)fuse_meta_into_embeddings()\n",
      "   1026                     raise ValueError(f'All datapoints should have same number of metadata.')\n",
      "   1027 \n",
      "-> 1028                 if 'meta_repr' in m_args:\n",
      "   1029                     m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
      "   1030                     m_repr_mask = m_repr_mask.bool()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1029)fuse_meta_into_embeddings()\n",
      "   1027 \n",
      "   1028                 if 'meta_repr' in m_args:\n",
      "-> 1029                     m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
      "   1030                     m_repr_mask = m_repr_mask.bool()\n",
      "   1031                 else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1030)fuse_meta_into_embeddings()\n",
      "   1028                 if 'meta_repr' in m_args:\n",
      "   1029                     m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
      "-> 1030                     m_repr_mask = m_repr_mask.bool()\n",
      "   1031                 else:\n",
      "   1032                     m_input_ids, m_attention_mask = m_args['input_ids'], m_args['attention_mask']\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4800, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.norm(dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([22.9758, 23.8516, 23.5292,  ..., 23.0874, 23.2436, 24.1294],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1038)fuse_meta_into_embeddings()\n",
      "   1036                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "   1037 \n",
      "-> 1038                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "   1039 \n",
      "   1040                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1040)fuse_meta_into_embeddings()\n",
      "   1038                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "   1039 \n",
      "-> 1040                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "   1041                 meta_repr[m_key] = F.normalize(meta_repr[m_key], dim=1)\n",
      "   1042 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1041)fuse_meta_into_embeddings()\n",
      "   1039 \n",
      "   1040                 meta_repr[m_key] = m_repr[m_repr_mask]\n",
      "-> 1041                 meta_repr[m_key] = F.normalize(meta_repr[m_key], dim=1)\n",
      "   1042 \n",
      "   1043                 fused_embed, w = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask, output_attentions"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=True)\n",
      "\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1043)fuse_meta_into_embeddings()\n",
      "   1041                 meta_repr[m_key] = F.normalize(meta_repr[m_key], dim=1)\n",
      "   1042 \n",
      "-> 1043                 fused_embed, w = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask, output_attentions=True)\n",
      "   1044                 embed[idx"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "] += self.cross_gate * fused_embed\n",
      "   1045                 weights.append(w)\n",
      "\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1044)fuse_meta_into_embeddings()\n",
      "   1042 \n",
      "   1043                 fused_embed, w = self.cross_head(embed[idx], attention_mask[idx], m_repr, "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_repr_mask, output_attentions=True)\n",
      "-> 1044                 embed[idx] += self.cross_gate * fused_embed\n",
      "   1045                 weights.append(w)\n",
      "   1046 \n",
      "\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1045)fuse_meta_into_embeddings()\n",
      "   1043                 fused_embed, w = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask, output_attentions=True)\n",
      "   1044                 embed[idx] "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+= self.cross_gate * fused_embed\n",
      "-> 1045                 weights.append(w)\n",
      "   1046 \n",
      "   1047         return embed, weights, meta_repr\n",
      "\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1020)fuse_meta_into_embeddings()\n",
      "   1018         meta_repr, weights = {}, []\n",
      "   1019 \n",
      "-> 1020         for m_key, m_args in meta_kwargs.items():\n",
      "   1021             idx = torch.where(m_args['data2ptr'] > 0)[0]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1022             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1047)fuse_meta_into_embeddings()\n",
      "   1045                 weights.append(w)\n",
      "   1046 \n",
      "-> 1047         return embed, weights, meta_repr\n",
      "   1048 \n",
      "   1049 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[[-0....vice='cuda:0'), [tensor([[[[0....vice='cuda:0')], {'aug2data': tensor([[-0.0...vice='cuda:0')})\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1047)fuse_meta_into_embeddings()\n",
      "   1045                 weights.append(w)\n",
      "   1046 \n",
      "-> 1047         return embed, weights, meta_repr\n",
      "   1048 \n",
      "   1049 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1073)forward()\n",
      "   1071                                                                                              data_attention_mask,\n",
      "   1072                                                                                              meta_kwargs)\n",
      "-> 1073                 data_fused_repr = self.fused_dr(data_fused_embed, data_attention_mask)\n",
      "   1074 \n",
      "   1075         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1075)forward()\n",
      "   1073                 data_fused_repr = self.fused_dr(data_fused_embed, data_attention_mask)\n",
      "   1074 \n",
      "-> 1075         return EncoderOutput(\n",
      "   1076             rep=data_repr,\n",
      "   1077             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1076)forward()\n",
      "   1074 \n",
      "   1075         return EncoderOutput(\n",
      "-> 1076             rep=data_repr,\n",
      "   1077             fused_rep=data_fused_repr,\n",
      "   1078             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1077)forward()\n",
      "   1075         return EncoderOutput(\n",
      "   1076             rep=data_repr,\n",
      "-> 1077             fused_rep=data_fused_repr,\n",
      "   1078             meta_repr=meta_repr,\n",
      "   1079         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1078)forward()\n",
      "   1076             rep=data_repr,\n",
      "   1077             fused_rep=data_fused_repr,\n",
      "-> 1078             meta_repr=meta_repr,\n",
      "   1079         )\n",
      "   1080 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1075)forward()\n",
      "   1073                 data_fused_repr = self.fused_dr(data_fused_embed, data_attention_mask)\n",
      "   1074 \n",
      "-> 1075         return EncoderOutput(\n",
      "   1076             rep=data_repr,\n",
      "   1077             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 49min 55s, sys: 1min 48s, total: 1h 51min 44s\n",
      "Wall time: 26min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "o = learn.predict(valid_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08055c58-a01d-446e-a7b8-916b5a44a3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.08889014273881912,\n",
       " 'test_P@1': 0.17256569867335156,\n",
       " 'test_P@3': 0.11264024636415412,\n",
       " 'test_P@5': 0.08082922569928175,\n",
       " 'test_N@1': 0.17256569862365723,\n",
       " 'test_N@3': 0.17039525508880615,\n",
       " 'test_N@5': 0.17370185256004333,\n",
       " 'test_PSP@1': 0.16356071325613564,\n",
       " 'test_PSP@3': 0.16702394838073903,\n",
       " 'test_PSP@5': 0.16916310160335513,\n",
       " 'test_PSN@1': 0.16356070339679718,\n",
       " 'test_PSN@3': 0.17378103733062744,\n",
       " 'test_PSN@5': 0.18096312880516052,\n",
       " 'test_R@5': 0.18238680984822833,\n",
       " 'test_runtime': 532.6447,\n",
       " 'test_samples_per_second': 333.271,\n",
       " 'test_steps_per_second': 0.208}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22faf4c2-6003-4504-a2e2-54505ca179f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03ed65-a635-4b24-8542-bb2c1b33109a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
