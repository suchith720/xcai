{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b937d98-9beb-445c-bc68-c8d71a8c1ae0",
   "metadata": {},
   "source": [
    "# learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc714cf2-0372-49f6-a39c-24752a28145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b498e-a0a3-4bdd-8741-ca516ddc64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ac07c-66a4-40d0-a39b-e5220c20fabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from tqdm.auto import tqdm\n",
    "from scipy import sparse\n",
    "from packaging import version\n",
    "import torch, re, math, numpy as np, os, time, datasets, pickle\n",
    "from typing import Any, Tuple, Optional, Sequence, Union, Dict, List, NamedTuple\n",
    "from transformers import AutoTokenizer, BatchEncoding, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
    "\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.nn.parallel._functions import Scatter\n",
    "from torch.nn.parallel.scatter_gather import _is_namedtuple\n",
    "\n",
    "from xcai.core import *\n",
    "from xcai.data import *\n",
    "from xcai.representation.search import *\n",
    "from xcai.generation.trie import *\n",
    "from xcai.generation.generate import *\n",
    "from xcai.clustering.cluster import *\n",
    "from xcai.transform import PadFeatTfm\n",
    "\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import *\n",
    "from fastcore.dispatch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821000f3-31ca-44ed-a2a5-e060f900ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from transformers.trainer_pt_utils import (\n",
    "    find_batch_size, \n",
    "    nested_concat, nested_numpify, \n",
    "    IterableDatasetShard, \n",
    "    get_dataloader_sampler, \n",
    "    get_model_param_count,\n",
    "    LengthGroupedSampler\n",
    ")\n",
    "from transformers.trainer_utils import has_length, denumpify_detensorize, speed_metrics, TrainOutput, HPSearchBackend, seed_worker\n",
    "from transformers.trainer_callback import TrainerState\n",
    "from transformers.trainer import _is_peft_model\n",
    "from transformers.modeling_utils import unwrap_model\n",
    "from transformers.utils import is_sagemaker_mp_enabled, is_accelerate_available, is_torch_tpu_available, logging, is_datasets_available\n",
    "from transformers.debug_utils import DebugOption, DebugUnderflowOverflow\n",
    "\n",
    "from transformers.integrations import hp_params\n",
    "from transformers.integrations.tpu import tpu_spmd_dataloader\n",
    "from transformers.integrations.deepspeed import deepspeed_init, deepspeed_load_checkpoint, is_deepspeed_available\n",
    "\n",
    "if is_accelerate_available():\n",
    "    from accelerate import Accelerator, skip_first_batches\n",
    "    from accelerate import __version__ as accelerate_version\n",
    "    from accelerate.utils import (\n",
    "        DistributedDataParallelKwargs,\n",
    "        DistributedType,\n",
    "        GradientAccumulationPlugin,\n",
    "        load_fsdp_model,\n",
    "        load_fsdp_optimizer,\n",
    "        save_fsdp_model,\n",
    "        save_fsdp_optimizer,\n",
    "    )\n",
    "\n",
    "    DATA_SAMPLERS = [RandomSampler]\n",
    "    if version.parse(accelerate_version) > version.parse(\"0.23.0\"):\n",
    "        from accelerate.data_loader import SeedableRandomSampler\n",
    "\n",
    "        DATA_SAMPLERS += [SeedableRandomSampler]\n",
    "\n",
    "    if is_deepspeed_available():\n",
    "        from accelerate.utils import DeepSpeedSchedulerWrapper\n",
    "\n",
    "if is_accelerate_available(\"0.28.0\"):\n",
    "    from accelerate.utils import DataLoaderConfiguration\n",
    "\n",
    "TRAINING_ARGS_NAME = \"training_args.bin\"\n",
    "TRAINER_STATE_NAME = \"trainer_state.json\"\n",
    "OPTIMIZER_NAME = \"optimizer.pt\"\n",
    "OPTIMIZER_NAME_BIN = \"optimizer.bin\"\n",
    "SCHEDULER_NAME = \"scheduler.pt\"\n",
    "SCALER_NAME = \"scaler.pt\"\n",
    "FSDP_MODEL_NAME = \"pytorch_model_fsdp\"\n",
    "\n",
    "logger = logging.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a547561-f805-40c1-a6b2-d89e772ce149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b1b571-0043-4b86-acce-cb6cb0ef598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from xcai.block import *\n",
    "from xcai.models.PPP0XX import *\n",
    "from xcai.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c73cc-d066-4c7f-a2b5-31003f38ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from xcai.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9985262",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efab5fa-1f75-44e8-b533-525d577f4209",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188e3a7-9458-456f-8a19-104fd139a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "block = XCBlock.from_cfg('/home/aiscuser/scratch/datasets', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca4d23b-4525-46bd-9a75-19ffca285235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "batch = block.train.one_batch(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e47e1ed-ad70-475f-a01f-cd9320705796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee43b109060489393f1b4531512f1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1c7e7b7f64465ea007044a1668c98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of BT0002 were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['loss_fn.o']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "m = BT0002.from_pretrained('bert-base-uncased', tn_targ=10_000, ig_tok=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf42c7-5471-4ff7-bc65-4020a5eb5f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95cdc4-ff76-4cd7-aa20-a54a03f7c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "b = prepare_batch(m, batch, m_args='lbl2data_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef492419-4e5a-4f08-bb1b-3ba3283703d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lbl2data_idx', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7a04d-81d7-402d-9a2d-b449b3acd3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "m = m.to('cuda')\n",
    "b = b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e64be93-2e54-4fbd-841b-c5d2828f5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "o = m(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5e531-8f3c-438e-ac10-b46c42e90093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.9452, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133a0cc-6ce3-4310-a2f4-5e936ac5ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealso_data-metas_distilbert-base-uncased_rm_radga-final.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7abf6df-1ee2-4105-9b48-7e66829e8cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealso_data-metas_distilbert-base-uncased_rm_radga-final-aug-hlk.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad44158-2094-4c74-8313-611d125a49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealso_data-meta_distilbert-base-uncased_rm_ramen-cat.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff8aa3-8d7a-4beb-8f0e-a8f2c82cbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealso_data-metas_distilbert-base-uncased_rm_radga-cat-final.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbee9ca-5a2c-4be0-882d-f7fffec78cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {pkl_dir}/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3638794-1429-44d7-9707-1d0e4bf54788",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e103c-4372-4f96-9c7b-b6707a4b5421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c7d9190-682e-4017-954e-fad35c79ab13",
   "metadata": {},
   "source": [
    "## DataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54c7fe-18b7-4502-a68d-5bbca3a75a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def scatter(inputs, target_gpus, chunk_sizes=None, dim=0):\n",
    "    def scatter_map(obj):\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return Scatter.apply(target_gpus, chunk_sizes, dim, obj)\n",
    "        if _is_namedtuple(obj):\n",
    "            return [type(obj)(*args) for args in zip(*map(scatter_map, obj))]\n",
    "        if isinstance(obj, tuple) and len(obj) > 0:\n",
    "            return list(zip(*map(scatter_map, obj)))\n",
    "        if isinstance(obj, list) and len(obj) > 0:\n",
    "            return [list(i) for i in zip(*map(scatter_map, obj))]\n",
    "        if isinstance(obj, dict) and len(obj) > 0:\n",
    "            return [type(obj)(i) for i in zip(*map(scatter_map, obj.items()))]\n",
    "        return [obj for _ in target_gpus] \n",
    "    try:\n",
    "        res = scatter_map(inputs)\n",
    "    finally:\n",
    "        scatter_map = None\n",
    "    return res\n",
    "    \n",
    "def scatter_kwargs(\n",
    "    inputs: Tuple[Any, ...],\n",
    "    kwargs: Optional[Dict[str, Any]],\n",
    "    target_gpus: Sequence[Union[int, torch.device]],\n",
    "    chunk_sizes: Optional[Sequence[int]]=None,\n",
    "    dim: int = 0,\n",
    ") -> Tuple[Tuple[Any, ...], Tuple[Dict[str, Any], ...]]:\n",
    "    scattered_inputs = scatter(inputs, target_gpus, chunk_sizes, dim) if inputs else []\n",
    "    scattered_kwargs = scatter(kwargs, target_gpus, chunk_sizes, dim) if kwargs else []\n",
    "    if len(scattered_inputs) < len(scattered_kwargs):\n",
    "        scattered_inputs.extend(() for _ in range(len(scattered_kwargs) - len(scattered_inputs)))\n",
    "    elif len(scattered_kwargs) < len(inputs):\n",
    "        scattered_kwargs.extend({} for _ in range(len(scattered_inputs) - len(scattered_kwargs)))\n",
    "    return scattered_inputs, scattered_kwargs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6420b5aa-6d09-47c1-809d-af19e02f800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCDataParallel(DataParallel):\n",
    "\n",
    "    @delegates(DataParallel.__init__)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def _get_feat_name(self, x:Optional[Dict[str, Any]]):\n",
    "        return list(set([k.split('_', maxsplit=1)[0] for k in x]))\n",
    "    \n",
    "    def _extract_feat(self, x:Optional[Dict[str, Any]], prefix:str):\n",
    "        return {k:v for k,v in x.items() if re.match(f'^{prefix}_(?!.*2ptr)', k) or re.match(f'^.*_{prefix}2ptr$', k)}\n",
    "\n",
    "    def scatter(\n",
    "        self,\n",
    "        inputs: Tuple[Any, ...],\n",
    "        kwargs: Optional[Dict[str, Any]],\n",
    "        device_ids: Sequence[Union[int, torch.device]],\n",
    "    ) ->Any:\n",
    "        if len(inputs): raise ValueError('`inputs` should be empty.')    \n",
    "        feat_name = self._get_feat_name(kwargs)\n",
    "        \n",
    "        data_feat = self._extract_feat(kwargs, 'data')\n",
    "        scattered_inputs, scattered_kwargs = scatter_kwargs(inputs, data_feat, device_ids, None, dim=self.dim)\n",
    "        feat_name.remove('data')\n",
    "        \n",
    "        for k in feat_name:\n",
    "            ptr_name = f'{k}_data2ptr'\n",
    "            if ptr_name in scattered_kwargs[0] and scattered_kwargs[0][ptr_name] is not None:\n",
    "                chunk_sz = [o[ptr_name].sum().item() for o in scattered_kwargs]\n",
    "                if len(chunk_sz) < len(device_ids): \n",
    "                    chunk_sz.extend([0 for _ in range(len(device_ids) - len(chunk_sz))])\n",
    "                \n",
    "                feat = self._extract_feat(kwargs, k)\n",
    "                _, o = scatter_kwargs(inputs, feat, device_ids, chunk_sz, dim=self.dim)\n",
    "                for p,q in zip(scattered_kwargs, o): p.update(q)\n",
    "                    \n",
    "        return tuple(scattered_inputs), tuple(scattered_kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553913e-875d-44c7-b58e-3b77ab8c4ae7",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d9d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from transformers import AutoTokenizer, BatchEncoding\n",
    "\n",
    "tokz = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae19912",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/aiscuser/scratch/datasets'\n",
    "pkl_dir = f'{data_dir}/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ab4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{pkl_dir}/wikiseealso_data-metas_distilbert-base-uncased_rm_radga.pkl', 'rb') as file: \n",
    "    block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa4a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{pkl_dir}/wikiseealso_data-metas_distilbert-base-uncased_xcnlg_radga.pkl', 'rb') as file: \n",
    "    block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = block.train.one_batch(4)\n",
    "bb = BatchEncoding({k:v for k,v in b.items() if isinstance(v, torch.Tensor)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a78059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plbl2data_data2ptr :  torch.Size([4])\n",
      "lbl2data_data2ptr :  torch.Size([4])\n",
      "pcat2data_data2ptr :  torch.Size([4])\n",
      "cat2data_data2ptr :  torch.Size([4])\n",
      "pcat2lbl2data_data2ptr :  torch.Size([4])\n",
      "cat2lbl2data_data2ptr :  torch.Size([4])\n",
      "phlk2data_data2ptr :  torch.Size([4])\n",
      "hlk2data_data2ptr :  torch.Size([4])\n",
      "hlk2lbl2data_data2ptr :  torch.Size([4])\n",
      "hlk2lbl2data_plbl2data2ptr :  torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "for k,v in bb.items():\n",
    "    if 'ptr' in k: print(k, ': ', v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484462a0-4806-461a-957c-6ae5d1bd1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        for k,v in kwargs.items(): \n",
    "            if isinstance(v, torch.Tensor): print(k, ': ', v, ', ', v.device)\n",
    "        return kwargs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a9a39d-bff3-4588-9fd4-2899208a6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "m = XCDataParallel(module=MyModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85bff3f-e395-4486-9865-19d0f5bff763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plbl2data_data2ptrplbl2data_data2ptr :   :  tensor([2, 1], device='cuda:0')tensor([1, 2], device='cuda:1')  , ,   cuda:0cuda:1\n",
      "\n",
      "lbl2data_data2ptrlbl2data_data2ptr  : :   tensor([1, 2], device='cuda:1')tensor([2, 1], device='cuda:0') ,   , cuda:1 \n",
      "cuda:0pcat2data_data2ptr\n",
      " pcat2data_data2ptr:   : tensor([14,  6], device='cuda:1')  tensor([13,  6], device='cuda:0'),   cuda:1,  \n",
      "cat2data_data2ptrcuda:0\n",
      " : cat2data_data2ptr  :  tensor([1, 1], device='cuda:1') tensor([1, 1], device='cuda:0') , ,   cuda:0cuda:1\n",
      "\n",
      "pcat2lbl2data_data2ptrpcat2lbl2data_data2ptr :  :   tensor([4, 7], device='cuda:1')tensor([0, 4], device='cuda:0') ,   , cuda:0 \n",
      "cat2lbl2data_data2ptrcuda:1\n",
      " cat2lbl2data_data2ptr:   :  tensor([0, 1], device='cuda:0') tensor([1, 1], device='cuda:1'),   , cuda:0 \n",
      "cuda:1phlk2data_data2ptr\n",
      " phlk2data_data2ptr:   : tensor([16, 18], device='cuda:0')  , tensor([15, 40], device='cuda:1') cuda:0 \n",
      ", hlk2data_data2ptr  cuda:1: \n",
      "hlk2data_data2ptr  tensor([3, 3], device='cuda:0'):   , tensor([3, 3], device='cuda:1')  , cuda:0 \n",
      "cuda:1data_input_ids\n",
      " data_input_ids:   :  tensor([[ 101, 9808, 4270, 2314,  102,    0,    0],\n",
      "        [ 101, 4748, 3909, 4049,  102,    0,    0]], device='cuda:0') ,  cuda:0tensor([[  101,  2957, 14135,  1006,  2236,  1007,   102],\n",
      "        [  101,  9805,  3676,  2221,  1010,  2662,   102]], device='cuda:1')\n",
      " data_attention_mask,   : cuda:1\n",
      " data_attention_mask : tensor([[1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0]], device='cuda:0')  ,  cuda:0tensor([[1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1]], device='cuda:1')\n",
      "hlk2lbl2data_data2ptr  , :   cuda:1\n",
      "tensor([0, 5], device='cuda:0')hlk2lbl2data_data2ptr  : ,   cuda:0tensor([5, 9], device='cuda:1')\n",
      "cat2data_idx ,  :   cuda:1\n",
      "tensor([152298,  55068], device='cuda:0')cat2data_idx  , :   cuda:0\n",
      "cat2data_input_idstensor([ 54425, 104014], device='cuda:1')  : ,   cuda:1\n",
      "tensor([[  101,  5485,  1997, 18685,  2221,  1010,  5284,   102,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2309,  1011, 21235,  5245,  2121,  2948,   102,     0,     0,\n",
      "             0,     0]], device='cuda:0')cat2data_input_ids  , :   cuda:0\n",
      "cat2data_attention_mask : tensor([[  101,  8055,  2163,  2510,  5073,  2730,  1999,  1996,  2137,  2942,\n",
      "          2162,   102],\n",
      "        [  101,  7973, 17228,  1999,  2662,   102,     0,     0,     0,     0,\n",
      "             0,     0]], device='cuda:1')  ,  cuda:1tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]], device='cuda:0') \n",
      ", cat2data_attention_mask  cuda:0: \n",
      " cat2lbl2data_idx tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]], device='cuda:1'):   ,  tensor([273427], device='cuda:0')cuda:1 , \n",
      "cat2lbl2data_idx  cuda:0\n",
      ": cat2lbl2data_input_ids  tensor([490081, 104014], device='cuda:1'):   ,  tensor([[ 101, 7201, 1997, 2510, 2948,  102]], device='cuda:0') cuda:1\n",
      ", cat2lbl2data_input_ids cuda:0 : \n",
      "cat2lbl2data_attention_mask  : tensor([[  101,  7201,  1997, 11593,   102,     0],\n",
      "        [  101,  7973, 17228,  1999,  2662,   102]], device='cuda:1')  , tensor([[1, 1, 1, 1, 1, 1]], device='cuda:0')  cuda:1, \n",
      " cat2lbl2data_attention_maskcuda:0 \n",
      ":  pcat2lbl2data_idx : tensor([[1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1]], device='cuda:1')  , tensor([498200, 496349, 273427,  92979], device='cuda:0')  , cuda:1 cuda:0\n",
      "\n",
      "pcat2lbl2data_idxlbl2data_idx  :  :  tensor([395355, 107556, 395354, 490081, 547792, 545725, 355196, 153765,  98839,\n",
      "        104014, 119469], device='cuda:1')tensor([101316,  71037,  99923], device='cuda:0') ,   cuda:0, \n",
      " lbl2data_input_idscuda:1\n",
      " lbl2data_idx:   : tensor([[ 101, 2862, 1997, 5284, 5485,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [ 101, 2862, 1997, 5111, 5485,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [ 101, 2862, 1997, 2948, 1997, 1996, 2548, 3987, 2250, 2326,  102,    0,\n",
      "            0,    0]], device='cuda:0')  , tensor([  269, 55151, 55150], device='cuda:1') cuda:0 , \n",
      "lbl2data_attention_mask  cuda:1\n",
      ":  lbl2data_input_ids :  tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]], device='cuda:0') ,  tensor([[  101,  2862,  1997,  2137,  2942,  2162, 11593,  1006,  8055,  1007,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  9805,  3676,  2221,  1010,  2662,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2120,  4236,  1997,  3181,  3182, 26213,  1999,  9805,  3676,\n",
      "          2221,  1010,  2662,   102]], device='cuda:1')cuda:0\n",
      " pcat2data_idx,   : cuda:1 \n",
      "lbl2data_attention_mask : tensor([ 64717, 159252, 152298, 202322, 242932, 225043, 183785, 191189, 183855,\n",
      "        218989, 242907, 228216, 188424,  54866,  56102,  55068,  55069,  56101,\n",
      "         56100], device='cuda:0')  ,  cuda:0tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:1')\n",
      " , plbl2data_idx  : cuda:1\n",
      " pcat2data_idxtensor([ 71037, 101316,  99923], device='cuda:0')  :  ,  tensor([ 68276, 106638, 102346, 102550, 367802, 207931,  66312, 133998, 171930,\n",
      "         62824,  54423,  54425, 108939, 281131, 153767, 104014,  98839, 355196,\n",
      "        119469, 153765], device='cuda:1')cuda:0 \n",
      "hlk2lbl2data_plbl2data2ptr,   : cuda:1 \n",
      "plbl2data_idx : tensor([0, 0, 5], device='cuda:0')  ,  tensor([  269, 55150, 55151], device='cuda:1')cuda:0\n",
      " , phlk2data_idx  cuda:1:  \n",
      "hlk2lbl2data_plbl2data2ptr :  tensor([ 113865,    8637,   48624, 1397758,  794132,   13068,     254,   24213,\n",
      "         808587,  310460,  846531,  997655, 1221759,  916835, 1210975,  345267,\n",
      "          77253,   25418,  467468,    2667,  145886,  179309,  467472,   52621,\n",
      "         467465,  467466,    3004,  467473,    2736,  467471,  467464,  467470,\n",
      "         433167,  467469], device='cuda:0') , tensor([5, 4, 5], device='cuda:1')  cuda:0\n",
      ",  hlk2data_idxcuda:1 : \n",
      " phlk2data_idx tensor([ 48624, 794132,    254, 179309, 467472, 433167], device='cuda:0'):   ,  cuda:0\n",
      "tensor([   1571,  241461,    8805,    2582,   89844,  460143,    9824,     297,\n",
      "        1283293,   19288,  567212,   40308,    1464, 1282940,   14059,  948811,\n",
      "          61257,  517280,    4927,   15729,  304807,  243045,  815271,  716531,\n",
      "           7839,    8646,  441558,   20720,  147120,    2932, 2337137,  817356,\n",
      "          46779,   15335,   15675,  484300,  815267,     254,  834837, 1914233,\n",
      "          38369,  948613,  847391, 2455908,  438723,     147,  511595,  561003,\n",
      "          14452,    2894,     317,  836235,   39074,  511775,  403957],\n",
      "       device='cuda:1')hlk2data_input_ids ,  :   cuda:1\n",
      "hlk2data_idx :  tensor([[  101,  9808,  4270,  3842,   102,     0,     0,     0,     0],\n",
      "        [  101, 15237,  8071,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2142,  2163,   102,     0,     0,     0,     0,     0],\n",
      "        [  101, 28667, 11514,  3217, 18252,  3194,   102,     0,     0],\n",
      "        [  101, 11409,  2669,  3246,   102,     0,     0,     0,     0],\n",
      "        [  101, 24185,  4877, 22352, 17947,   102,     0,     0,     0]],\n",
      "       device='cuda:0') tensor([  19288, 1283293,    2582,    7839,    2894,  511595], device='cuda:1'),   cuda:0\n",
      "hlk2data_attention_mask,   : cuda:1 \n",
      "hlk2data_input_ids :  tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0]], device='cuda:0') ,  cuda:0\n",
      "tensor([[  101,  2236,  3738,  1999,  1996,  8055,  2163,  2390,   102],\n",
      "        [  101,  5900,  2110, 10211,   102,     0,     0,     0,     0],\n",
      "        [  101,  9991, 15049,  2808,   102,     0,     0,     0,     0],\n",
      "        [  101,  3534,  2051,  4224,   102,     0,     0,     0,     0],\n",
      "        [  101,  3009,  2653,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  4956,  7778,  2181,   102,     0,     0,     0,     0]],\n",
      "       device='cuda:1')hlk2lbl2data_idx  , :   cuda:1tensor([  40156,  527144, 1560778,  552110,  757054], device='cuda:0') \n",
      ", hlk2data_attention_mask  : cuda:0 \n",
      "hlk2lbl2data_input_ids : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0]], device='cuda:1')  ,  cuda:1\n",
      "tensor([[  101,  2061, 28400,  8939, 20720, 13714,  2358, 22134,  3334,   102],\n",
      "        [  101,  2460,  2828, 19681,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2632, 13959,  7464,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1054, 22394,  1011,  2465, 27636,   102,     0,     0,     0],\n",
      "        [  101, 20704,  3217, 23475,   102,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0')hlk2lbl2data_idx ,  :   cuda:0\n",
      "tensor([  13617, 1644592,   12853,  656719,   42218,  948160,     254,    7140,\n",
      "           2932,   46779,  441558, 1914233, 2337137, 2455908], device='cuda:1')hlk2lbl2data_attention_mask  ,  :  cuda:1\n",
      "hlk2lbl2data_input_ids : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]], device='cuda:0')  ,  cuda:0\n",
      "tensor([[  101,  2343,  1997,  1996,  8055,  2163,  1997,  2637,   102,     0],\n",
      "        [  101,  4557, 21863,  5420,  3044,   102,     0,     0,     0,     0],\n",
      "        [  101,  2390,  1997,  5900,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5340, 20082,  3483,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  3448,  6627,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2120,  4236,  1997,  3181,  3182, 26213,  1999,  2662,   102],\n",
      "        [  101,  2142,  2163,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2120,  4236,  1997,  3181,  3182,   102,     0,     0,     0],\n",
      "        [  101,  2662,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 11932,  3028,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 20287,  5063,  2653,   102,     0,     0,     0,     0,     0],\n",
      "        [  101, 25540,  2571, 26614,  2697,   102,     0,     0,     0,     0],\n",
      "        [  101,  9805,  3676,  1011, 10514, 12079,  6671,   102,     0,     0],\n",
      "        [  101,  9805,  3676,  2221,  3075,   102,     0,     0,     0,     0]],\n",
      "       device='cuda:1') ,  cuda:1\n",
      "hlk2lbl2data_attention_mask :  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]], device='cuda:1') ,  cuda:1\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "o = m(**bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49800f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all([torch.all(bb[k] == o[k].to('cpu')) for k in o.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d60df7f-8004-49ec-8cce-eb36a285c8e2",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee7b634-3ec5-4b5c-9d1f-75f32fa47fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCEvalLoopOutput(NamedTuple):\n",
    "    pred_idx: Union[np.ndarray, Tuple[np.ndarray]]\n",
    "    pred_ptr: Union[np.ndarray, Tuple[np.ndarray]]\n",
    "    pred_score: Union[np.ndarray, Tuple[np.ndarray]]\n",
    "    targ_idx: Optional[Union[np.ndarray, Tuple[np.ndarray]]]\n",
    "    targ_ptr: Optional[Union[np.ndarray, Tuple[np.ndarray]]]\n",
    "    gen_output: Optional[Dict]\n",
    "    repr_output: Optional[Dict]\n",
    "    metrics: Optional[Dict[str, float]]\n",
    "    num_samples: Optional[int]\n",
    "\n",
    "class XCPredictionOutput(NamedTuple):\n",
    "    pred_idx: Union[np.ndarray, Tuple[np.ndarray]]\n",
    "    pred_ptr: Union[np.ndarray, Tuple[np.ndarray]]\n",
    "    pred_score: Optional[Union[np.ndarray, Tuple[np.ndarray]]]\n",
    "    gen_output: Optional[Dict]\n",
    "    repr_output: Optional[Dict]\n",
    "    metrics: Optional[Dict[str, float]]\n",
    "    num_samples: Optional[int]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8444fb71-7eb7-43c6-96ba-71759aa2b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCLearningArguments(Seq2SeqTrainingArguments):\n",
    "\n",
    "    @delegates(Seq2SeqTrainingArguments.__init__)\n",
    "    def __init__(self, \n",
    "                 use_encoder_parallel:Optional[bool]=False,\n",
    "                 generation_length_penalty:Optional[float]=1.0,\n",
    "                 generation_eos_token:Optional[int]=102,\n",
    "                 generation_num_beams:Optional[int]=5,\n",
    "                 generation_max_info:Optional[int]=None,\n",
    "                 representation_accumulation_steps:Optional[int]=None,\n",
    "                 \n",
    "                 output_representation_attribute:Optional[str]='data_repr',\n",
    "                 label_representation_attribute:Optional[str]='data_repr',\n",
    "                 \n",
    "                 representation_num_beams:Optional[int]=5,\n",
    "                 representation_search_type:Optional[str]='INDEX',\n",
    "                 index_space:Optional[str]='cosine', \n",
    "                 index_efc:Optional[int]=300, \n",
    "                 index_m:Optional[int]=100, \n",
    "                 index_efs:Optional[int]=300,\n",
    "                 index_num_threads:Optional[int]=84,\n",
    "                 predict_with_generation:Optional[bool]=False,\n",
    "                 predict_with_representation:Optional[bool]=False,\n",
    "                 output_concatenation_weight:Optional[float]=1.0,\n",
    "                 group_by_cluster:Optional[bool]=False,\n",
    "                 num_clustering_warmup_epochs:Optional[int]=None,\n",
    "                 num_cluster_update_epochs:Optional[int]=1,\n",
    "                 num_cluster_size_update_epochs:Optional[int]=1,\n",
    "                 clustering_type:Optional[str]='EXPO',\n",
    "                 minimum_clusters:Optional[int]=3,\n",
    "                 maximum_clusters:Optional[int]=None,\n",
    "                 minimum_cluster_size:Optional[int]=1,\n",
    "                 maximum_cluster_size:Optional[int]=None,\n",
    "                 clustering_devices:Optional[List]=None,\n",
    "                 use_data_metadata_for_clustering:Optional[bool]=False,\n",
    "                 \n",
    "                 target_indices_key:Optional[str]='lbl2data_idx',\n",
    "                 target_pointer_key:Optional[str]='lbl2data_data2ptr',\n",
    "                 \n",
    "                 data_aug_meta_name:Optional[str]=None,\n",
    "                 data_aug_prefix:Optional[str]=None,\n",
    "                 augmentation_num_beams:Optional[int]=3,\n",
    "                 predict_with_augmentation:Optional[bool]=False,\n",
    "                 use_augmentation_index_representation:Optional[bool]=False,\n",
    "                 metadata_representation_attribute:Optional[str]='data_repr',\n",
    "                 data_augmentation_attribute:Optional[str]='data_repr',\n",
    "                 data_meta_batch_size:Optional[int]=2048,\n",
    "\n",
    "                 augment_metadata:Optional[bool]=False,\n",
    "                 num_metadata_augment_epochs:Optional[int]=1,\n",
    "                 num_metadata_augment_warmup_epochs:Optional[int]=10,\n",
    "                 \n",
    "                 use_distributional_representation:Optional[bool]=False,\n",
    "                 use_label_metadata:Optional[bool]=True,\n",
    "                 prune_metadata:Optional[bool]=False,\n",
    "                 num_metadata_prune_epochs:Optional[int]=1,\n",
    "                 metadata_prune_batch_size:Optional[int]=64,\n",
    "                 num_metadata_prune_warmup_epochs:Optional[int]=10,\n",
    "                 prune_metadata_names:Optional[List]=None,\n",
    "                 use_data_metadata_for_pruning:Optional[bool]=True,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        store_attr('output_representation_attribute,label_representation_attribute,use_data_metadata_for_clustering')\n",
    "        \n",
    "        store_attr('generation_num_beams,generation_length_penalty,generation_max_info,generation_eos_token')\n",
    "        store_attr('representation_accumulation_steps,representation_num_beams,representation_search_type')\n",
    "        store_attr('index_space,index_efc,index_m,index_efs,index_num_threads')\n",
    "        store_attr('predict_with_generation,predict_with_representation,output_concatenation_weight')\n",
    "        store_attr('group_by_cluster,num_cluster_update_epochs,num_cluster_size_update_epochs,num_clustering_warmup_epochs')\n",
    "        store_attr('clustering_devices,clustering_type,maximum_cluster_size')\n",
    "        store_attr('target_indices_key,target_pointer_key')\n",
    "        store_attr('use_encoder_parallel')\n",
    "        store_attr('data_aug_meta_name,data_aug_prefix,augmentation_num_beams,predict_with_augmentation')\n",
    "        store_attr('use_augmentation_index_representation,metadata_representation_attribute,data_augmentation_attribute')\n",
    "        store_attr('use_distributional_representation')\n",
    "        \n",
    "        store_attr('use_label_metadata,data_meta_batch_size,augment_metadata,num_metadata_augment_epochs,num_metadata_augment_warmup_epochs')\n",
    "        \n",
    "        store_attr('prune_metadata,num_metadata_prune_epochs,num_metadata_prune_warmup_epochs,metadata_prune_batch_size,prune_metadata_names')\n",
    "        store_attr('use_data_metadata_for_pruning')\n",
    "        self.minimum_clusters = max(1, minimum_clusters)\n",
    "        self.maximum_clusters = max(minimum_clusters, maximum_clusters) if maximum_clusters is not None else minimum_clusters\n",
    "        self.minimum_cluster_size = max(1, minimum_cluster_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e0635-4bdc-4a00-9011-445ecdc0d838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b036146-ad70-4c47-802c-763f1f2aaf45",
   "metadata": {},
   "source": [
    "### `XCLearner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77b4bd-cd24-4b96-af56-474dfcbdcc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCLearner(Seq2SeqTrainer):\n",
    "\n",
    "    @delegates(Seq2SeqTrainer.__init__)\n",
    "    def __init__(self, \n",
    "                 trie:Optional[Trie]=None, \n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.tbs = TrieBeamSearch(trie, self.args.generation_eos_token, n_bm=self.args.generation_num_beams, \n",
    "                                  len_penalty=self.args.generation_length_penalty, max_info=self.args.generation_max_info, **kwargs)\n",
    "        self.idxs = (\n",
    "            BruteForceSearch(n_bm=self.args.representation_num_beams)\n",
    "            if self.args.representation_search_type == 'BRUTEFORCE' else\n",
    "            IndexSearch(space=self.args.index_space, efc=self.args.index_efc, m=self.args.index_m, \n",
    "                        efs=self.args.index_efs, n_bm=self.args.representation_num_beams, \n",
    "                        n_threads=self.args.index_num_threads) \n",
    "        )\n",
    "        self.aug_idxs = None\n",
    "\n",
    "    def _wrap_model(self, model, training=True, dataloader=None):\n",
    "        if unwrap_model(model) is not model:\n",
    "            return model\n",
    "\n",
    "        if self.args.n_gpu > 1:\n",
    "            if (hasattr(model, 'encoder') and isinstance(model.encoder, nn.DataParallel)) or self.args.use_encoder_parallel: return model\n",
    "            else: return XCDataParallel(module=model)\n",
    "        return model\n",
    "\n",
    "    def evaluate(self, eval_dataset:Optional[Dataset]=None, ignore_keys:Optional[List[str]]=None, \n",
    "             metric_key_prefix:str=\"eval\", **gen_kwargs):\n",
    "        gen_kwargs = gen_kwargs.copy()\n",
    "        if gen_kwargs.get(\"length_penalty\") is None and self.args.generation_length_penalty is not None:\n",
    "            gen_kwargs[\"length_penalty\"] = self.args.generation_length_penalty\n",
    "        if gen_kwargs.get(\"gen_num_beams\") is None and self.args.generation_num_beams is not None:\n",
    "            gen_kwargs[\"gen_num_beams\"] = self.args.generation_num_beams\n",
    "        if gen_kwargs.get(\"repr_num_beams\") is None and self.args.representation_num_beams is not None:\n",
    "            gen_kwargs[\"repr_num_beams\"] = self.args.representation_num_beams\n",
    "        if gen_kwargs.get(\"aug_num_beams\") is None and self.args.augmentation_num_beams is not None:\n",
    "            gen_kwargs[\"aug_num_beams\"] = self.args.augmentation_num_beams\n",
    "            \n",
    "        self.gather_function, self._gen_kwargs  = self.accelerator.gather, gen_kwargs\n",
    "        \n",
    "        return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
    "\n",
    "    def predict(self, test_dataset: Dataset, ignore_keys:Optional[List[str]]=None, \n",
    "            metric_key_prefix:str=\"test\", **gen_kwargs):\n",
    "        gen_kwargs = gen_kwargs.copy()\n",
    "        if gen_kwargs.get(\"length_penalty\") is None and self.args.generation_length_penalty is not None:\n",
    "            gen_kwargs[\"length_penalty\"] = self.args.generation_length_penalty\n",
    "        if gen_kwargs.get(\"gen_num_beams\") is None and self.args.generation_num_beams is not None:\n",
    "            gen_kwargs[\"gen_num_beams\"] = self.args.generation_num_beams\n",
    "        if gen_kwargs.get(\"repr_num_beams\") is None and self.args.representation_num_beams is not None:\n",
    "            gen_kwargs[\"repr_num_beams\"] = self.args.representation_num_beams\n",
    "        if gen_kwargs.get(\"aug_num_beams\") is None and self.args.augmentation_num_beams is not None:\n",
    "            gen_kwargs[\"aug_num_beams\"] = self.args.augmentation_num_beams\n",
    "    \n",
    "        self.gather_function, self._gen_kwargs = self.accelerator.gather, gen_kwargs\n",
    "        self._memory_tracker.start()\n",
    "    \n",
    "        test_dataloader = self.get_test_dataloader(test_dataset)\n",
    "        start_time = time.time()\n",
    "    \n",
    "        output = self.evaluation_loop(test_dataloader, description=\"Prediction\", ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
    "        total_batch_size = self.args.eval_batch_size * self.args.world_size\n",
    "        if f\"{metric_key_prefix}_jit_compilation_time\" in output.metrics:\n",
    "            start_time += output.metrics[f\"{metric_key_prefix}_jit_compilation_time\"]\n",
    "        output.metrics.update(\n",
    "            speed_metrics(metric_key_prefix,start_time,num_samples=output.num_samples,num_steps=math.ceil(output.num_samples / total_batch_size),)\n",
    "        )\n",
    "        self.control = self.callback_handler.on_predict(self.args, self.state, self.control, output.metrics)\n",
    "        self._memory_tracker.stop_and_update_metrics(output.metrics)\n",
    "        return XCPredictionOutput(pred_idx=output.pred_idx, pred_ptr=output.pred_ptr, pred_score=output.pred_score, \n",
    "                              gen_output=output.gen_output, repr_output=output.repr_output, metrics=output.metrics, \n",
    "                              num_samples=output.num_samples)\n",
    "    \n",
    "    def _gather_host_output(self, output, host_output):\n",
    "        if output is not None:\n",
    "            output = self.accelerator.pad_across_processes(output, dim=1, pad_index=-100)\n",
    "            output = self.gather_function((output))\n",
    "            return output if host_output is None else nested_concat(host_output, output, padding_index=-100)\n",
    "        else: return host_output\n",
    "\n",
    "    def _gather_all_output(self, host_output, all_output, to_cpu=True):\n",
    "        if host_output is not None:\n",
    "            if isinstance(host_output, torch.Tensor) and to_cpu: host_output = host_output.cpu()\n",
    "            return host_output if all_output is None else nested_concat(all_output, host_output, padding_index=-100)\n",
    "        else: return all_output\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b506de6-d6bc-4e9d-a9df-85c673c12286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _get_dataset(self:XCLearner, dataset:Dataset, dset_type:str='lbl', use_metadata:Optional[bool]=False):\n",
    "    dset = get_attr(dataset, f'{dset_type}_dset')\n",
    "\n",
    "    data_aug_prefix = self.args.data_aug_meta_name if self.args.data_aug_prefix is None else self.args.data_aug_prefix\n",
    "    meta_name = f'{data_aug_prefix}_meta' if data_aug_prefix is not None else None\n",
    "    \n",
    "    if (\n",
    "        meta_name is not None and \n",
    "        dataset.meta is not None and \n",
    "        meta_name in dataset.meta and \n",
    "        use_metadata\n",
    "    ):    \n",
    "        meta_dset= dataset.meta[meta_name]\n",
    "        prefix,meta,meta_info  = meta_dset.prefix, get_attr(meta_dset, f'{dset_type}_meta'), meta_dset.meta_info\n",
    "        if dset_type == 'data':\n",
    "            meta_kwargs = {meta_name: MetaXCDataset(prefix, meta, sparse.csr_matrix((dset.n_lbl, meta_dset.n_meta)), meta_info, \n",
    "                                                    n_data_meta_samples=self.args.augmentation_num_beams)}\n",
    "        elif dset_type == 'lbl':\n",
    "            meta_kwargs = {meta_name: MetaXCDataset(prefix, sparse.csr_matrix((dset.n_data, meta_dset.n_meta)), meta, meta_info, \n",
    "                                                    n_data_meta_samples=self.args.augmentation_num_beams)}\n",
    "        else: raise ValueError(f'Invalid `dset_type`, should be one of [\"data\", \"lbl\"].')\n",
    "            \n",
    "        dset = XCDataset(dset, **meta_kwargs)\n",
    "        \n",
    "    return dset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc228b-c71e-4f8f-a51b-3e495fc5337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _build_aug_index(self:XCLearner, dataset:Optional[Dataset]=None):\n",
    "    dataset = dataset if self.eval_dataset is None else self.eval_dataset\n",
    "    dataset = dataset if self.train_dataset is None else self.train_dataset\n",
    "    \n",
    "    meta_name = f'{self.args.data_aug_meta_name}_meta' if self.args.data_aug_meta_name is not None else None\n",
    "    if (\n",
    "        dataset is not None and \n",
    "        dataset.meta is not None and \n",
    "        meta_name is not None and \n",
    "        meta_name in dataset.meta\n",
    "    ):\n",
    "        self.aug_idxs = IndexSearch(space=self.args.index_space, efc=self.args.index_efc, m=self.args.index_m, \n",
    "                                    efs=self.args.index_efs, n_bm=self.args.augmentation_num_beams, \n",
    "                                    n_threads=self.args.index_num_threads)\n",
    "        \n",
    "        dset = MainXCDataset(getattr(dataset.meta[meta_name], 'meta_info'))\n",
    "        dataloader = self.get_test_dataloader(dset)\n",
    "        rep = self.get_meta_representation(dataloader, to_cpu=isinstance(self.aug_idxs, IndexSearch))\n",
    "        self.aug_idxs.build(rep)\n",
    "\n",
    "@patch\n",
    "def _build_lbl_index(self:XCLearner, dataset:Optional[Dataset]=None):\n",
    "    dataset = dataset if self.eval_dataset is None else self.eval_dataset\n",
    "    dataset = dataset if self.train_dataset is None else self.train_dataset\n",
    "    \n",
    "    if dataset is not None:\n",
    "        dset = self._get_dataset(dataset, dset_type='lbl', use_metadata=self.args.use_label_metadata)\n",
    "        dataloader = self.get_test_dataloader(dset)\n",
    "        rep = self.get_representation(dataloader, representation_attribute=self.args.label_representation_attribute, \n",
    "                                      to_cpu=isinstance(self.idxs, IndexSearch))\n",
    "        self.idxs.build(rep)\n",
    "        \n",
    "    else: raise ValueError('Failed to build `self.idxs`')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28f8f9-c2c1-4391-8ec9-d6ea44346107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def generation_output(\n",
    "    self:XCLearner,\n",
    "    model:nn.Module,\n",
    "    inputs:Dict[str, Union[torch.Tensor, Any]],\n",
    "    **kwargs\n",
    "):\n",
    "    inputs = self._prepare_inputs(inputs)\n",
    "    n_bm = kwargs.pop(\"gen_num_beams\") if \"gen_num_beams\" in kwargs and kwargs[\"gen_num_beams\"] is not None else self.args.generation_num_beams\n",
    "    len_penalty = kwargs.pop(\"length_penalty\") if \"length_penalty\" in kwargs and kwargs[\"length_penalty\"] is not None else self.args.generation_length_penalty\n",
    "    \n",
    "    with torch.no_grad(): o = self.tbs.proc(self.model, inputs.copy(), n_bm=n_bm, len_penalty=len_penalty)\n",
    "        \n",
    "    return {'pred_idx':o['info2seq2data_idx'], 'pred_score':o['info2seq2data_score'], 'pred_ptr':o['info2seq2data_data2ptr']}\n",
    "\n",
    "@patch\n",
    "def representation_output(\n",
    "    self:XCLearner,\n",
    "    model:nn.Module,\n",
    "    inputs:Dict[str, Union[torch.Tensor, Any]],\n",
    "    **kwargs\n",
    "):\n",
    "    inputs = self._prepare_inputs(inputs)\n",
    "    n_bm = kwargs.pop(\"repr_num_beams\") if \"repr_num_beams\" in kwargs and kwargs[\"repr_num_beams\"] is not None else self.args.representation_num_beams\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        o = getattr(model(**inputs), self.args.output_representation_attribute)\n",
    "        if self.args.use_distributional_representation: o = o.exp()\n",
    "            \n",
    "    o = self.idxs.proc(o, n_bm=n_bm)\n",
    "        \n",
    "    return {'pred_idx':o['info2data_idx'], 'pred_score':o['info2data_score'], 'pred_ptr':o['info2data_data2ptr']}\n",
    "\n",
    "@patch\n",
    "def augmentation_output(\n",
    "    self:XCLearner,\n",
    "    model:nn.Module,\n",
    "    inputs:Dict[str, Union[torch.Tensor, Any]],\n",
    "    **kwargs\n",
    "):\n",
    "    if self.aug_idxs is None: \n",
    "        raise ValueError('Augmentation index `aug_idx` is not initialized.')\n",
    "        \n",
    "    inputs = self._prepare_inputs(inputs)\n",
    "    n_bm = kwargs.pop(\"aug_num_beams\") if \"aug_num_beams\" in kwargs and kwargs[\"aug_num_beams\"] is not None else self.args.augmentation_num_beams\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        inputs = {'data_input_ids':inputs['data_input_ids'], 'data_attention_mask':inputs['data_attention_mask']}\n",
    "        o = getattr(model(**inputs), self.args.data_augmentation_attribute)\n",
    "        if self.args.use_distributional_representation: o = o.exp()\n",
    "            \n",
    "    o = self.aug_idxs.proc(o, n_bm=n_bm)\n",
    "\n",
    "    \"\"\"\n",
    "    Preparing augmentation input\n",
    "    \"\"\"\n",
    "    pad_proc = PadFeatTfm(pad_tok=self.model.config.pad_token_id, prefix=\"meta\")\n",
    "    info = pad_proc({\n",
    "        'meta_input_ids':[self.aug_info['input_ids'][i] for i in o['info2data_idx']], \n",
    "        'meta_attention_mask':[self.aug_info['attention_mask'][i] for i in o['info2data_idx']],\n",
    "    })\n",
    "\n",
    "    data_aug_prefix = self.args.data_aug_meta_name if self.args.data_aug_prefix is None else self.args.data_aug_prefix\n",
    "    \n",
    "    if self.args.use_augmentation_index_representation:\n",
    "        rep = torch.tensor(self.aug_idxs.index.get_items(o['info2data_idx']))\n",
    "        return {\n",
    "            f'{data_aug_prefix}2data_idx':o['info2data_idx'],\n",
    "            f'{data_aug_prefix}2data_data2ptr': o['info2data_data2ptr'],\n",
    "            f'{data_aug_prefix}2data_meta_repr': rep,\n",
    "            f'{data_aug_prefix}2data_attention_mask': aug_info['meta_attention_mask'],\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            f'{data_aug_prefix}2data_idx':o['info2data_idx'], \n",
    "            f'{data_aug_prefix}2data_data2ptr': o['info2data_data2ptr'],\n",
    "            f'{data_aug_prefix}2data_input_ids': info['meta_input_ids'], \n",
    "            f'{data_aug_prefix}2data_attention_mask': info['meta_attention_mask'],\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967d99a-b531-4ff0-83a7-6808c0a8ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _perform_generation(self:XCLearner, model:nn.Module, predict_with_generation:Optional[bool]=None):\n",
    "    model = unwrap_model(model)\n",
    "    predict_with_generation = self.args.predict_with_generation if predict_with_generation is None else predict_with_generation\n",
    "    return getattr(model,'use_generation') if hasattr(model,'use_generation') else predict_with_generation\n",
    "\n",
    "@patch\n",
    "def _perform_representation(self:XCLearner, model:nn.Module, predict_with_representation:Optional[bool]=None):\n",
    "    model = unwrap_model(model)\n",
    "    predict_with_representation = self.args.predict_with_representation if predict_with_representation is None else predict_with_representation\n",
    "    return getattr(model,'use_representation') if hasattr(model,'use_representation') else predict_with_representation\n",
    "\n",
    "@patch\n",
    "def _perform_augmentation(self:XCLearner, model:nn.Module, predict_with_augmentation:Optional[bool]=None):\n",
    "    model = unwrap_model(model)\n",
    "    predict_with_augmentation = self.args.predict_with_augmentation if predict_with_augmentation is None else predict_with_augmentation\n",
    "    return getattr(model,'use_augmentation') if hasattr(model,'use_augmentation') else predict_with_augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6351dde7-b678-41d5-b710-005cb7db6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def resize_pred(cls:XCLearner, t, n_t):\n",
    "    max_n_t = n_t.max()\n",
    "    xn_t = max_n_t.max()-n_t+1\n",
    "    t_ptr = n_t.cumsum(dim=0)-1\n",
    "    r_t = torch.ones((len(t),), dtype=xn_t.dtype, device=xn_t.device).scatter(0, t_ptr, xn_t)\n",
    "    xt = t.repeat_interleave(r_t).view(len(n_t), -1)\n",
    "    return xt\n",
    "\n",
    "@patch\n",
    "def output_mask(cls:XCLearner, n_t, l):\n",
    "    max_n_t = n_t.max()\n",
    "    xn_t = max_n_t.max()-n_t+1\n",
    "    t_ptr = n_t.cumsum(dim=0)-1\n",
    "    mask_ptr = t_ptr+torch.arange(len(t_ptr), device=t_ptr.device)+1\n",
    "    mask = torch.ones((l+len(n_t),), dtype=mask_ptr.dtype, device=mask_ptr.device).scatter(0, mask_ptr, 0)\n",
    "    r_mask = torch.ones((l+len(n_t),), dtype=mask_ptr.dtype, device=mask_ptr.device).scatter(0, mask_ptr, xn_t-1)\n",
    "    mask = mask.repeat_interleave(r_mask).view(len(n_t), -1)\n",
    "    return mask\n",
    "\n",
    "@patch\n",
    "def resize_output(cls:XCLearner, pred_idx, pred_score, pred_ptr):\n",
    "    return cls.resize_pred(pred_idx, pred_ptr), cls.resize_pred(pred_score, pred_ptr), cls.output_mask(pred_ptr, len(pred_idx)), pred_ptr\n",
    "\n",
    "@patch\n",
    "def concatenate_output(cls:XCLearner, gen_o:Dict, repr_o:Dict):\n",
    "    gen_o['pred_score'] = torch.exp(gen_o['pred_score'])*cls.args.output_concatenation_weight\n",
    "    gen_o, repr_o = cls.resize_output(**gen_o), cls.resize_output(**repr_o)\n",
    "    pred_idx, pred_score, mask = [torch.hstack([gen_o[i], repr_o[i].cpu()]).flatten() for i in range(3)]\n",
    "    idx = torch.where(mask)[0]\n",
    "    return {\n",
    "        'pred_idx': pred_idx[idx],\n",
    "        'pred_score': pred_score[idx],\n",
    "        'pred_ptr': gen_o[3]+repr_o[3].cpu(),\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e5ae1-6971-416b-9b11-1e6234632c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def prediction_step(\n",
    "    self:XCLearner,\n",
    "    model: nn.Module,\n",
    "    inputs: Dict[str, Union[torch.Tensor, Any]],\n",
    "    prediction_loss_only: bool,\n",
    "    predict_with_generation: bool,\n",
    "    predict_with_representation: bool,\n",
    "    predict_with_augmentation:Optional[bool]=None,\n",
    "    ignore_keys: Optional[List[str]] = None,\n",
    "    **kwargs,\n",
    ") -> Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "    with torch.no_grad():\n",
    "        with self.compute_loss_context_manager(): outputs = model(**inputs)\n",
    "        loss = (outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]).mean().detach()\n",
    "    prediction_loss_only = self.args.prediction_loss_only if prediction_loss_only is None else prediction_loss_only\n",
    "    if prediction_loss_only: return loss, {}\n",
    "    \n",
    "    if self._perform_augmentation(model, predict_with_augmentation): \n",
    "        aug_inputs = self.augmentation_output(model, inputs, **kwargs)\n",
    "        inputs.update(aug_inputs)\n",
    "        \n",
    "    output, gen_o, repr_o = None, None, None\n",
    "    if self._perform_generation(model, predict_with_generation): gen_o = self.generation_output(model, inputs, **kwargs)\n",
    "    if self._perform_representation(model, predict_with_representation): repr_o = self.representation_output(model, inputs, **kwargs)\n",
    "    \n",
    "    if gen_o is not None and repr_o is not None:\n",
    "        output = {f'{k}_gen':v for k,v in gen_o.items()}\n",
    "        output.update({f'{k}_repr':v for k,v in repr_o.items()})\n",
    "        output.update(self.concatenate_output(gen_o, repr_o))\n",
    "    else:\n",
    "        output = gen_o if repr_o is None else repr_o\n",
    "        \n",
    "    labels = {'targ_idx':inputs[self.args.target_indices_key], 'targ_ptr':inputs[self.args.target_pointer_key]} if self.args.target_indices_key in inputs else None\n",
    "    if labels is not None: output.update(labels)\n",
    "    \n",
    "    return loss, output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189c5d7-a677-43e6-a78d-7485c07d9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def evaluation_loop(\n",
    "    self:XCLearner,\n",
    "    dataloader:DataLoader,\n",
    "    description:str,\n",
    "    prediction_loss_only:Optional[bool] = None,\n",
    "    predict_with_generation:Optional[bool]=None,\n",
    "    predict_with_representation:Optional[bool]=None,\n",
    "    ignore_keys:Optional[List[str]] = None,\n",
    "    metric_key_prefix:str=\"eval\",\n",
    ") -> XCEvalLoopOutput:\n",
    "    args = self.args\n",
    "    prediction_loss_only = prediction_loss_only if prediction_loss_only is not None else args.prediction_loss_only\n",
    "\n",
    "    \"\"\"\n",
    "    Disable random addition of noise\n",
    "    \"\"\"\n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        use_noise = self.model.disable_noise()\n",
    "\n",
    "    model = self._wrap_model(self.model, training=False, dataloader=dataloader)\n",
    "\n",
    "    if len(self.accelerator._models) == 0 and model is self.model:\n",
    "        model = self.accelerator.prepare(model) if self.is_deepspeed_enabled else self.accelerator.prepare_model(model, evaluation_mode=True)\n",
    "        if self.is_fsdp_enabled: self.model = model\n",
    "        if model is not self.model: self.model_wrapped = model\n",
    "        if self.is_deepspeed_enabled: self.deepspeed = self.model_wrapped\n",
    "\n",
    "    batch_size = self.args.eval_batch_size\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    self.callback_handler.eval_dataloader = dataloader\n",
    "    eval_dataset = getattr(dataloader, \"dataset\", None)\n",
    "    \n",
    "    if self._perform_representation(unwrap_model(model)) and not prediction_loss_only: \n",
    "        self._build_lbl_index(eval_dataset)\n",
    "            \n",
    "    if self._perform_augmentation(unwrap_model(model)) and not prediction_loss_only: \n",
    "        self._build_aug_index(eval_dataset)\n",
    "    \n",
    "    if args.past_index >= 0: self._past = None\n",
    "\n",
    "    losses_host, all_losses = None, None\n",
    "    host_output, all_output = {}, {}\n",
    "    \n",
    "    observed_num_examples = 0\n",
    "    for step, inputs in enumerate(dataloader):\n",
    "        observed_batch_size = find_batch_size(inputs)\n",
    "        if observed_batch_size is not None:\n",
    "            observed_num_examples += observed_batch_size\n",
    "            if batch_size is None: batch_size = observed_batch_size\n",
    "                \n",
    "        loss, output = self.prediction_step(model, inputs, prediction_loss_only, predict_with_generation, predict_with_representation, ignore_keys=ignore_keys)\n",
    "        \n",
    "        if loss is not None:\n",
    "            losses = self.gather_function((loss.repeat(batch_size)))\n",
    "            losses_host = losses if losses_host is None else nested_concat(losses_host, losses, padding_index=-100)\n",
    "        for k in output: host_output[k] = self._gather_host_output(output[k], host_output.get(k, None))\n",
    "            \n",
    "        self.control = self.callback_handler.on_prediction_step(args, self.state, self.control)\n",
    "        \n",
    "        if args.eval_accumulation_steps is not None and (step + 1) % args.eval_accumulation_steps == 0:\n",
    "            if losses_host is not None: all_losses = losses_host if all_losses is None else nested_concat(all_losses, losses, padding_index=-100)\n",
    "            for k in host_output: all_output[k], host_output[k] = self._gather_all_output(host_output[k], all_output.get(k, None)), None\n",
    "    \n",
    "    self.gather_function = self.accelerator.gather_for_metrics\n",
    "    if args.past_index and hasattr(self, \"_past\"): delattr(self, \"_past\")\n",
    "\n",
    "    if losses_host is not None: all_losses = losses_host if all_losses is None else nested_concat(all_losses, losses, padding_index=-100)\n",
    "    for k in host_output: all_output[k], host_output[k] = self._gather_all_output(host_output[k], all_output.get(k, None)), None\n",
    "        \n",
    "    if has_length(eval_dataset): num_samples = len(eval_dataset)\n",
    "    elif isinstance(eval_dataset, IterableDatasetShard) and getattr(eval_dataset, \"num_examples\", 0) > 0:\n",
    "        num_samples = eval_dataset.num_examples\n",
    "    else:\n",
    "        if has_length(dataloader): num_samples = self.num_examples(dataloader)\n",
    "        else: num_samples = observed_num_examples\n",
    "    if num_samples == 0 and observed_num_examples > 0: num_samples = observed_num_examples\n",
    "        \n",
    "    gen_output, repr_output = None, None\n",
    "    metric_input_keys = ['targ_idx', 'targ_ptr', 'pred_idx', 'pred_ptr', 'pred_score']\n",
    "    if 'pred_idx_gen' in all_output and all_output['pred_idx_gen'] is not None:\n",
    "        gen_output = {o:all_output[f'{o}_gen' if o.startswith('pred_') else o] for o in metric_input_keys}\n",
    "    if 'pred_idx_repr' in all_output and all_output['pred_idx_repr'] is not None:\n",
    "        repr_output = {o:all_output[f'{o}_repr' if o.startswith('pred_') else o] for o in metric_input_keys}\n",
    "    \n",
    "\n",
    "    if (self.compute_metrics is not None and \n",
    "        'targ_idx' in all_output and all_output['targ_idx'] is not None and \n",
    "        'pred_idx' in all_output and all_output['pred_idx'] is not None):\n",
    "        \n",
    "        metrics = self.compute_metrics(**{o:all_output[o] for o in metric_input_keys})\n",
    "        if gen_output is not None:\n",
    "            m = self.compute_metrics(**gen_output)\n",
    "            metrics.update({f'{k}_GEN':v for k,v in m.items()})\n",
    "        if repr_output is not None:\n",
    "            m = self.compute_metrics(**repr_output)\n",
    "            metrics.update({f'{k}_REPR':v for k,v in m.items()})      \n",
    "    else: metrics = {}\n",
    "        \n",
    "    metrics = denumpify_detensorize(metrics)\n",
    "\n",
    "    if all_losses is not None: metrics[f\"{metric_key_prefix}_loss\"] = all_losses.mean().item()\n",
    "    if hasattr(self, \"jit_compilation_time\"): metrics[f\"{metric_key_prefix}_jit_compilation_time\"] = self.jit_compilation_time\n",
    "        \n",
    "    for key in list(metrics.keys()):\n",
    "        if not key.startswith(f\"{metric_key_prefix}_\"): metrics[f\"{metric_key_prefix}_{key}\"] = metrics.pop(key)\n",
    "\n",
    "    \"\"\"\n",
    "    Set the noise addition state back\n",
    "    \"\"\"\n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        self.model.set_noise(use_noise)\n",
    "    \n",
    "    return XCEvalLoopOutput(pred_idx=all_output.get('pred_idx'), pred_ptr=all_output.get('pred_ptr'), \n",
    "                            pred_score=all_output.get('pred_score'),targ_idx=all_output.get('targ_idx'), \n",
    "                            targ_ptr=all_output.get('targ_ptr'), gen_output=gen_output, repr_output=repr_output,\n",
    "                            metrics=metrics, num_samples=num_samples)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d626f2e-22fa-4b44-82d9-af7d082cb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_meta_representation(self:XCLearner, dataloader: DataLoader, to_cpu:Optional[bool]=True):\n",
    "    data_host, all_data = None, None\n",
    "    \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        use_noise = self.model.disable_noise()\n",
    "    \n",
    "    for step, inputs in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        inputs = inputs.to(self.model.device)\n",
    "        with torch.no_grad(): data = getattr(self.model.get_meta_representation(**inputs), self.args.metadata_representation_attribute)\n",
    "        data_host = self._gather_host_output(data, data_host)\n",
    "        if self.args.representation_accumulation_steps is not None and (step + 1) % self.args.representation_accumulation_steps == 0:\n",
    "            all_data, data_host = self._gather_all_output(data_host, all_data, to_cpu=to_cpu), None\n",
    "            \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        self.model.set_noise(use_noise)\n",
    "            \n",
    "    return self._gather_all_output(data_host, all_data, to_cpu=to_cpu)\n",
    "\n",
    "@patch\n",
    "def get_representation(self:XCLearner, dataloader: DataLoader, representation_attribute:str, to_cpu:Optional[bool]=True):\n",
    "    data_host, all_data = None, None\n",
    "    \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        use_noise = self.model.disable_noise()\n",
    "    \n",
    "    for step, inputs in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        inputs = inputs.to(self.model.device)\n",
    "        with torch.no_grad(): data = getattr(self.model(**inputs), representation_attribute)\n",
    "        data_host = self._gather_host_output(data, data_host)\n",
    "        if self.args.representation_accumulation_steps is not None and (step + 1) % self.args.representation_accumulation_steps == 0:\n",
    "            all_data, data_host = self._gather_all_output(data_host, all_data, to_cpu=to_cpu), None\n",
    "            \n",
    "    if hasattr(self.model, 'disable_noise') and callable(getattr(self.model, 'disable_noise')):\n",
    "        self.model.set_noise(use_noise)\n",
    "            \n",
    "    return self._gather_all_output(data_host, all_data, to_cpu=to_cpu)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ec06d-459a-4ba0-8b1d-74ff1d84a4ff",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b71a7-4ec2-47c5-a72d-77001b9c9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _get_train_sampler(self:XCLearner):\n",
    "    if self.train_dataset is None or not has_length(self.train_dataset):\n",
    "        return None\n",
    "        \n",
    "    if self.args.group_by_length:\n",
    "        if is_datasets_available() and isinstance(self.train_dataset, datasets.Dataset):\n",
    "            lengths = (\n",
    "                self.train_dataset[self.args.length_column_name]\n",
    "                if self.args.length_column_name in self.train_dataset.column_names\n",
    "                else None\n",
    "            )\n",
    "        else:\n",
    "            lengths = None\n",
    "        model_input_name = self.tokenizer.model_input_names[0] if self.tokenizer is not None else None\n",
    "        return LengthGroupedSampler(\n",
    "            self.args.train_batch_size * self.args.gradient_accumulation_steps,\n",
    "            dataset=self.train_dataset,\n",
    "            lengths=lengths,\n",
    "            model_input_name=model_input_name,\n",
    "        )\n",
    "\n",
    "    elif self.args.group_by_cluster:\n",
    "        return ClusterGroupedSampler(n=len(self.train_dataset))\n",
    "    else:\n",
    "        return RandomSampler(self.train_dataset)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515cb389-f267-44a3-a65e-39b517b86660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_train_dataloader(self:XCLearner):\n",
    "    if self.train_dataset is None:\n",
    "        raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "\n",
    "    train_dataset = self.train_dataset\n",
    "    data_collator = self.data_collator\n",
    "    if is_datasets_available() and isinstance(train_dataset, datasets.Dataset):\n",
    "        train_dataset = self._remove_unused_columns(train_dataset, description=\"training\")\n",
    "    else:\n",
    "        data_collator = self._get_collator_with_removed_columns(data_collator, description=\"training\")\n",
    "\n",
    "    dataloader_params = {\n",
    "        \"batch_size\": self._train_batch_size,\n",
    "        \"collate_fn\": data_collator,\n",
    "        \"num_workers\": self.args.dataloader_num_workers,\n",
    "        \"pin_memory\": self.args.dataloader_pin_memory,\n",
    "        \"persistent_workers\": self.args.dataloader_persistent_workers,\n",
    "    }\n",
    "\n",
    "    if not isinstance(train_dataset, torch.utils.data.IterableDataset):\n",
    "        dataloader_params[\"sampler\"] = self._get_train_sampler()\n",
    "        dataloader_params[\"drop_last\"] = self.args.dataloader_drop_last\n",
    "        dataloader_params[\"worker_init_fn\"] = seed_worker\n",
    "        dataloader_params[\"prefetch_factor\"] = self.args.dataloader_prefetch_factor\n",
    "    \n",
    "    return DataLoader(train_dataset, **dataloader_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _get_min_cluster_sz(self:XCLearner, epochs_trained:int, num_train_epochs:int):\n",
    "    \n",
    "    if self.args.num_clustering_warmup_epochs is not None:\n",
    "        if epochs_trained < self.args.num_clustering_warmup_epochs: return None\n",
    "        else: epochs_trained -= self.args.num_clustering_warmup_epochs\n",
    "    \n",
    "    if self.args.clustering_type == 'LINEAR':\n",
    "        if self.args.maximum_clusters is None: return self.train_dataset.n_data//self.args.minimum_clusters\n",
    "        else:\n",
    "            n_cluster = (self.args.maximum_clusters-self.args.minimum_clusters)/num_train_epochs*epochs_trained\n",
    "            return self.train_dataset.n_data//int(self.args.minimum_clusters+n_cluster)\n",
    "        \n",
    "    elif self.args.clustering_type == 'EXPO':\n",
    "        mult = 2**(epochs_trained//self.args.num_cluster_size_update_epochs)\n",
    "        cluster_sz = self.args.minimum_cluster_size*mult\n",
    "        cluster_sz = (\n",
    "            self.args.maximum_cluster_size \n",
    "            if self.args.maximum_cluster_size is not None and cluster_sz > self.args.maximum_cluster_size \n",
    "            else cluster_sz\n",
    "        )\n",
    "        return cluster_sz\n",
    "    \n",
    "    else: raise ValueError(f'Invalid `clustering_type`({self.args.clustering_type}).')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447567d1-8fc1-4582-9673-34ff1c971048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _get_train_data_cluster(self:XCLearner, epochs_trained:int, num_train_epochs:int):\n",
    "\n",
    "    dataset = self._get_dataset(self.train_dataset, dset_type='data', use_metadata=self.args.use_data_metadata_for_clustering)\n",
    "    dataloader = self.get_test_dataloader(dataset)\n",
    "    data_repr = self.get_representation(dataloader, representation_attribute=self.args.output_representation_attribute)\n",
    "    if self.args.use_distributional_representation: data_repr = data_repr.exp()\n",
    "        \n",
    "    cluster = BalancedClusters.proc(data_repr, self._get_min_cluster_sz(epochs_trained, num_train_epochs), clustering_devices=self.args.clustering_devices)\n",
    "    return cluster\n",
    "\n",
    "@patch\n",
    "def update_dataloader_sampler(self:XCLearner, dataloader:DataLoader, epochs_trained:int, num_train_epochs:int):\n",
    "    if isinstance(dataloader.sampler, ClusterGroupedSampler):\n",
    "        cluster = self._get_train_data_cluster(epochs_trained, num_train_epochs)\n",
    "        dataloader.sampler.set_cluster(cluster)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca40d6-b489-4225-ac4e-57369e4599be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def prune_metadata(self:XCLearner):\n",
    "    \n",
    "    if self.train_dataset.meta is None: return\n",
    "\n",
    "    data_dset = self._get_dataset(self.train_dataset, dset_type='data', use_metadata=self.args.use_data_metadata_for_pruning)\n",
    "    dataloader = self.get_test_dataloader(data_dset)\n",
    "    data_repr = self.get_representation(dataloader, representation_attribute=self.args.output_representation_attribute)\n",
    "\n",
    "    lbl_dset = self._get_dataset(self.train_dataset, dset_type='lbl', use_metadata=self.args.use_label_metadata)\n",
    "    dataloader = self.get_test_dataloader(lbl_dset)\n",
    "    lbl_repr = self.get_representation(dataloader, representation_attribute=self.args.label_representation_attribute)\n",
    "\n",
    "    prune_metadata_names = list(self.train_dataset.meta.keys()) if self.args.prune_metadata_names is None else self.args.prune_metadata_names\n",
    "    for m in self.args.prune_metadata_names:\n",
    "        if m not in self.train_dataset.meta: raise ValueError(f'Invalid metadata name: {m}')\n",
    "            \n",
    "        meta_dset = self.train_dataset.meta[m]\n",
    "        dataloader = self.get_test_dataloader(MainXCDataset(meta_dset.meta_info))\n",
    "        meta_repr = self.get_representation(dataloader, representation_attribute=self.args.metadata_representation_attribute)\n",
    "\n",
    "        meta_dset.prune_data_meta(data_repr, meta_repr, batch_size=self.args.metadata_prune_batch_size)\n",
    "        meta_dset.prune_lbl_meta(lbl_repr, meta_repr, batch_size=self.args.metadata_prune_batch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e3557-89c8-487c-9517-461175c85216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_aug_data_meta(self:XCLearner, data_repr:torch.Tensor, batch_size:Optional[int]=64):\n",
    "    data_repr = F.normalize(data_repr, dim=1)\n",
    "    dl = DataLoader(data_repr, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    indices,num_items = None,None\n",
    "    for b in tqdm(dl, total=len(dl)): \n",
    "        o = self.aug_idxs.proc(b, n_bm=self.args.augmentation_num_beams)\n",
    "        indices = o['info2data_idx'] if indices is None else torch.hstack([indices,o['info2data_idx']])\n",
    "        num_items = o['info2data_data2ptr'] if num_items is None else torch.hstack([num_items,o['info2data_data2ptr']])\n",
    "    indptr = torch.concat([torch.tensor([0]), num_items.cumsum(dim=0)])\n",
    "    data = torch.ones((indices.shape[0],))\n",
    "    \n",
    "    data_meta = sparse.csr_matrix((data, indices, indptr), shape=(data_repr.shape[0], self.aug_idxs.index.element_count))\n",
    "    return data_meta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10416eb-4d26-4172-9d3c-e3920b0ba145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_augmentation_metadata(self:XCLearner):\n",
    "    meta_name = f'{self.args.data_aug_meta_name}_meta' if self.args.data_aug_meta_name is not None else None\n",
    "    if (\n",
    "        self.train_dataset.meta is None or \n",
    "        meta_name is None or \n",
    "        meta_name not in self.train_dataset.meta\n",
    "    ): \n",
    "        return\n",
    "        \n",
    "    dataloader = self.get_test_dataloader(self.train_dataset.data_dset)\n",
    "    data_repr = self.get_representation(dataloader, representation_attribute=self.args.output_representation_attribute)\n",
    "    \n",
    "    self.aug_idxs = IndexSearch(space=self.args.index_space, efc=self.args.index_efc, m=self.args.index_m, \n",
    "                                efs=self.args.index_efs, n_bm=self.args.augmentation_num_beams, \n",
    "                                n_threads=self.args.index_num_threads)\n",
    "    \n",
    "    meta_info = getattr(self.train_dataset.meta[meta_name], 'meta_info')\n",
    "    dataloader = self.get_test_dataloader(MainXCDataset(meta_info))\n",
    "    meta_repr = self.get_meta_representation(dataloader, to_cpu=isinstance(self.aug_idxs, IndexSearch))\n",
    "    self.aug_idxs.build(meta_repr)\n",
    "\n",
    "    data_meta = self.get_aug_data_meta(data_repr, batch_size=self.args.data_meta_batch_size)\n",
    "    data_aug_prefix = self.args.data_aug_meta_name if self.args.data_aug_prefix is None else self.args.data_aug_prefix\n",
    "\n",
    "    meta_info = {\n",
    "        'identifier': meta_info['identifier'],\n",
    "        'input_text': meta_info['input_text'],\n",
    "        'meta_repr': meta_repr.tolist(),\n",
    "        'attention_mask': meta_info['attention_mask'],\n",
    "    }\n",
    "    \n",
    "    self.train_dataset.meta[f'{data_aug_prefix}_meta'] = MetaXCDataset(data_aug_prefix, data_meta, \n",
    "                                                                       sparse.csr_matrix((self.train_dataset.n_lbl, meta_repr.shape[0])), \n",
    "                                                                       meta_info,\n",
    "                                                                       n_data_meta_samples=self.args.augmentation_num_beams)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33907726-5248-4c73-84f1-ce900f119ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _validate_group_by_cluster(self:XCLearner):\n",
    "    if self.args.group_by_cluster and (not hasattr(self.model,'use_representation') or  not getattr(unwrap_model(self.model),'use_representation')):\n",
    "        raise ValueError('Cannot use `group_by_cluster` for models without `use_representation`.')\n",
    "        self.args.group_by_cluster = False\n",
    "\n",
    "@patch\n",
    "def _inner_training_loop(\n",
    "    self:XCLearner, batch_size=None, args=None, resume_from_checkpoint=None, trial=None, ignore_keys_for_eval=None\n",
    "):\n",
    "    self.accelerator.free_memory()\n",
    "    self._train_batch_size = batch_size\n",
    "    if self.args.auto_find_batch_size:\n",
    "        if self.state.train_batch_size != self._train_batch_size:\n",
    "            from accelerate.utils import release_memory\n",
    "\n",
    "            (self.model_wrapped,) = release_memory(self.model_wrapped)\n",
    "            self.model_wrapped = self.model\n",
    "\n",
    "            # Check for DeepSpeed *after* the intial pass and modify the config\n",
    "            if self.is_deepspeed_enabled:\n",
    "                # Temporarily unset `self.args.train_batch_size`\n",
    "                original_bs = self.args.per_device_train_batch_size\n",
    "                self.args.per_device_train_batch_size = self._train_batch_size // max(1, self.args.n_gpu)\n",
    "                self.propagate_args_to_deepspeed(True)\n",
    "                self.args.per_device_train_batch_size = original_bs\n",
    "        self.state.train_batch_size = self._train_batch_size\n",
    "    logger.debug(f\"Currently training with a batch size of: {self._train_batch_size}\")\n",
    "    \n",
    "    # Data loader and number of training steps\n",
    "    self._validate_group_by_cluster()\n",
    "    train_dataloader = self.get_train_dataloader()\n",
    "    \n",
    "    if self.is_fsdp_xla_v2_enabled:\n",
    "        train_dataloader = tpu_spmd_dataloader(train_dataloader)\n",
    "\n",
    "    # Setting up training control variables:\n",
    "    # number of training epochs: num_train_epochs\n",
    "    # number of training steps per epoch: num_update_steps_per_epoch\n",
    "    # total number of training steps to execute: max_steps\n",
    "    total_train_batch_size = self._train_batch_size * args.gradient_accumulation_steps * args.world_size\n",
    "\n",
    "    len_dataloader = None\n",
    "    num_train_tokens = None\n",
    "    if has_length(train_dataloader):\n",
    "        len_dataloader = len(train_dataloader)\n",
    "        num_update_steps_per_epoch = len_dataloader // args.gradient_accumulation_steps\n",
    "        num_update_steps_per_epoch = max(num_update_steps_per_epoch, 1)\n",
    "        num_examples = self.num_examples(train_dataloader)\n",
    "        if args.max_steps > 0:\n",
    "            max_steps = args.max_steps\n",
    "            num_train_epochs = args.max_steps // num_update_steps_per_epoch + int(\n",
    "                args.max_steps % num_update_steps_per_epoch > 0\n",
    "            )\n",
    "            # May be slightly incorrect if the last batch in the training dataloader has a smaller size but it's\n",
    "            # the best we can do.\n",
    "            num_train_samples = args.max_steps * total_train_batch_size\n",
    "            if args.include_tokens_per_second:\n",
    "                num_train_tokens = (\n",
    "                    self.num_tokens(train_dataloader, args.max_steps) * args.gradient_accumulation_steps\n",
    "                )\n",
    "        else:\n",
    "            max_steps = math.ceil(args.num_train_epochs * num_update_steps_per_epoch)\n",
    "            num_train_epochs = math.ceil(args.num_train_epochs)\n",
    "            num_train_samples = self.num_examples(train_dataloader) * args.num_train_epochs\n",
    "            if args.include_tokens_per_second:\n",
    "                num_train_tokens = self.num_tokens(train_dataloader) * args.num_train_epochs\n",
    "    elif args.max_steps > 0:  # Rely on max_steps when dataloader does not have a working size\n",
    "        max_steps = args.max_steps\n",
    "        # Setting a very large number of epochs so we go as many times as necessary over the iterator.\n",
    "        num_train_epochs = sys.maxsize\n",
    "        num_update_steps_per_epoch = max_steps\n",
    "        num_examples = total_train_batch_size * args.max_steps\n",
    "        num_train_samples = args.max_steps * total_train_batch_size\n",
    "        if args.include_tokens_per_second:\n",
    "            num_train_tokens = self.num_tokens(train_dataloader, args.max_steps) * args.gradient_accumulation_steps\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"args.max_steps must be set to a positive value if dataloader does not have a length, was\"\n",
    "            f\" {args.max_steps}\"\n",
    "        )\n",
    "\n",
    "    if DebugOption.UNDERFLOW_OVERFLOW in self.args.debug:\n",
    "        if self.args.n_gpu > 1:\n",
    "            # nn.DataParallel(model) replicates the model, creating new variables and module\n",
    "            # references registered here no longer work on other gpus, breaking the module\n",
    "            raise ValueError(\n",
    "                \"Currently --debug underflow_overflow is not supported under DP. Please use DDP\"\n",
    "                \" (torchrun or torch.distributed.launch (deprecated)).\"\n",
    "            )\n",
    "        else:\n",
    "            debug_overflow = DebugUnderflowOverflow(self.model)  # noqa\n",
    "\n",
    "    delay_optimizer_creation = is_sagemaker_mp_enabled() or self.is_fsdp_xla_enabled or self.is_fsdp_enabled\n",
    "\n",
    "    # We need to reset the scheduler, as its parameters may be different on subsequent calls\n",
    "    if self._created_lr_scheduler:\n",
    "        self.lr_scheduler = None\n",
    "        self._created_lr_scheduler = False\n",
    "\n",
    "    if self.is_deepspeed_enabled:\n",
    "        self.optimizer, self.lr_scheduler = deepspeed_init(self, num_training_steps=max_steps)\n",
    "\n",
    "    if not delay_optimizer_creation:\n",
    "        self.create_optimizer_and_scheduler(num_training_steps=max_steps)\n",
    "\n",
    "    self.state = TrainerState()\n",
    "    self.state.is_hyper_param_search = trial is not None\n",
    "    self.state.train_batch_size = self._train_batch_size\n",
    "\n",
    "    # Compute absolute values for logging, eval, and save if given as ratio\n",
    "    if args.logging_steps is not None:\n",
    "        if args.logging_steps < 1:\n",
    "            self.state.logging_steps = math.ceil(max_steps * args.logging_steps)\n",
    "        else:\n",
    "            self.state.logging_steps = args.logging_steps\n",
    "    if args.eval_steps is not None:\n",
    "        if args.eval_steps < 1:\n",
    "            self.state.eval_steps = math.ceil(max_steps * args.eval_steps)\n",
    "        else:\n",
    "            self.state.eval_steps = args.eval_steps\n",
    "    if args.save_steps is not None:\n",
    "        if args.save_steps < 1:\n",
    "            self.state.save_steps = math.ceil(max_steps * args.save_steps)\n",
    "        else:\n",
    "            self.state.save_steps = args.save_steps\n",
    "\n",
    "    # Activate gradient checkpointing if needed\n",
    "    if args.gradient_checkpointing:\n",
    "        if args.gradient_checkpointing_kwargs is None:\n",
    "            gradient_checkpointing_kwargs = {}\n",
    "        else:\n",
    "            gradient_checkpointing_kwargs = args.gradient_checkpointing_kwargs\n",
    "\n",
    "        self.model.gradient_checkpointing_enable(gradient_checkpointing_kwargs=gradient_checkpointing_kwargs)\n",
    "\n",
    "    model = self._wrap_model(self.model_wrapped)\n",
    "\n",
    "    # as the model is wrapped, don't use `accelerator.prepare`\n",
    "    # this is for unhandled cases such as\n",
    "    # FSDP-XLA, SageMaker MP/DP, DataParallel, IPEX\n",
    "    use_accelerator_prepare = True if model is self.model else False\n",
    "\n",
    "    if delay_optimizer_creation:\n",
    "        if use_accelerator_prepare:\n",
    "            self.model = self.accelerator.prepare(self.model)\n",
    "        self.create_optimizer_and_scheduler(num_training_steps=max_steps)\n",
    "\n",
    "    # prepare using `accelerator` prepare\n",
    "    if use_accelerator_prepare:\n",
    "        self.model.train()\n",
    "        if hasattr(self.lr_scheduler, \"step\"):\n",
    "            if self.use_apex:\n",
    "                model = self.accelerator.prepare(self.model)\n",
    "            else:\n",
    "                model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)\n",
    "        else:\n",
    "            # to handle cases wherein we pass \"DummyScheduler\" such as when it is specified in DeepSpeed config.\n",
    "            model, self.optimizer, self.lr_scheduler = self.accelerator.prepare(\n",
    "                self.model, self.optimizer, self.lr_scheduler\n",
    "            )\n",
    "\n",
    "    if self.is_fsdp_enabled:\n",
    "        self.model = self.model_wrapped = model\n",
    "\n",
    "    # for the rest of this function `model` is the outside model, whether it was wrapped or not\n",
    "    if model is not self.model:\n",
    "        self.model_wrapped = model\n",
    "\n",
    "    # backward compatibility\n",
    "    if self.is_deepspeed_enabled:\n",
    "        self.deepspeed = self.model_wrapped\n",
    "\n",
    "    # ckpt loading\n",
    "    if resume_from_checkpoint is not None:\n",
    "        if self.is_deepspeed_enabled:\n",
    "            deepspeed_load_checkpoint(\n",
    "                self.model_wrapped, resume_from_checkpoint, load_module_strict=not _is_peft_model(self.model)\n",
    "            )\n",
    "        elif is_sagemaker_mp_enabled() or self.is_fsdp_enabled:\n",
    "            self._load_from_checkpoint(resume_from_checkpoint, self.model_wrapped)\n",
    "\n",
    "    # Check if saved optimizer or scheduler states exist\n",
    "    self._load_optimizer_and_scheduler(resume_from_checkpoint)\n",
    "\n",
    "    # important: at this point:\n",
    "    # self.model         is the Transformers Model\n",
    "    # self.model_wrapped is DDP(Transformers Model), Deepspeed(Transformers Model),\n",
    "    # FSDP(Transformers Model), Dynamo Optimized Module(Transformers Model) etc.\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(f\"  Num examples = {num_examples:,}\")\n",
    "    logger.info(f\"  Num Epochs = {num_train_epochs:,}\")\n",
    "    logger.info(f\"  Instantaneous batch size per device = {self.args.per_device_train_batch_size:,}\")\n",
    "    if self.args.per_device_train_batch_size != self._train_batch_size:\n",
    "        logger.info(f\"  Training with DataParallel so batch size has been adjusted to: {self._train_batch_size:,}\")\n",
    "    logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_train_batch_size:,}\")\n",
    "    logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "    logger.info(f\"  Total optimization steps = {max_steps:,}\")\n",
    "    logger.info(f\"  Number of trainable parameters = {get_model_param_count(model, trainable_only=True):,}\")\n",
    "\n",
    "    self.state.epoch = 0\n",
    "    start_time = time.time()\n",
    "    epochs_trained = 0\n",
    "    steps_trained_in_current_epoch = 0\n",
    "    steps_trained_progress_bar = None\n",
    "\n",
    "    # Check if continuing training from a checkpoint\n",
    "    if resume_from_checkpoint is not None and os.path.isfile(\n",
    "        os.path.join(resume_from_checkpoint, TRAINER_STATE_NAME)\n",
    "    ):\n",
    "        self.state = TrainerState.load_from_json(os.path.join(resume_from_checkpoint, TRAINER_STATE_NAME))\n",
    "        epochs_trained = self.state.global_step // num_update_steps_per_epoch\n",
    "        if not args.ignore_data_skip:\n",
    "            steps_trained_in_current_epoch = self.state.global_step % (num_update_steps_per_epoch)\n",
    "            steps_trained_in_current_epoch *= args.gradient_accumulation_steps\n",
    "        else:\n",
    "            steps_trained_in_current_epoch = 0\n",
    "\n",
    "        logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
    "        logger.info(f\"  Continuing training from epoch {epochs_trained}\")\n",
    "        logger.info(f\"  Continuing training from global step {self.state.global_step}\")\n",
    "        if not args.ignore_data_skip:\n",
    "            logger.info(\n",
    "                f\"  Will skip the first {epochs_trained} epochs then the first\"\n",
    "                f\" {steps_trained_in_current_epoch} batches in the first epoch.\"\n",
    "            )\n",
    "\n",
    "    # Update the references\n",
    "    self.callback_handler.model = self.model\n",
    "    self.callback_handler.optimizer = self.optimizer\n",
    "    self.callback_handler.lr_scheduler = self.lr_scheduler\n",
    "    self.callback_handler.train_dataloader = train_dataloader\n",
    "    if self.hp_name is not None and self._trial is not None:\n",
    "        # use self._trial because the SigOpt/Optuna hpo only call `_hp_search_setup(trial)` instead of passing trial\n",
    "        # parameter to Train when using DDP.\n",
    "        self.state.trial_name = self.hp_name(self._trial)\n",
    "    if trial is not None:\n",
    "        assignments = trial.assignments if self.hp_search_backend == HPSearchBackend.SIGOPT else trial\n",
    "        self.state.trial_params = hp_params(assignments)\n",
    "    else:\n",
    "        self.state.trial_params = None\n",
    "    # This should be the same if the state has been saved but in case the training arguments changed, it's safer\n",
    "    # to set this after the load.\n",
    "    self.state.max_steps = max_steps\n",
    "    self.state.num_train_epochs = num_train_epochs\n",
    "    self.state.is_local_process_zero = self.is_local_process_zero()\n",
    "    self.state.is_world_process_zero = self.is_world_process_zero()\n",
    "\n",
    "    # tr_loss is a tensor to avoid synchronization of TPUs through .item()\n",
    "    tr_loss = torch.tensor(0.0).to(args.device)\n",
    "    # _total_loss_scalar is updated everytime .item() has to be called on tr_loss and stores the sum of all losses\n",
    "    self._total_loss_scalar = 0.0\n",
    "    self._globalstep_last_logged = self.state.global_step\n",
    "    model.zero_grad()\n",
    "    grad_norm: Optional[float] = None\n",
    "\n",
    "    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\n",
    "\n",
    "    # Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\n",
    "    if not args.ignore_data_skip:\n",
    "        for epoch in range(epochs_trained):\n",
    "            sampler = get_dataloader_sampler(train_dataloader)\n",
    "            sampler_kinds = [RandomSampler]\n",
    "            if version.parse(accelerate_version) > version.parse(\"0.23.0\"):\n",
    "                sampler_kinds.append(SeedableRandomSampler)\n",
    "            is_random_sampler = isinstance(sampler, tuple(sampler_kinds))\n",
    "            if not is_random_sampler:\n",
    "                # We just need to begin an iteration to create the randomization of the sampler.\n",
    "                for _ in train_dataloader:\n",
    "                    break\n",
    "            else:\n",
    "                # Otherwise we need to call the whooooole sampler cause there is some random operation added\n",
    "                # AT THE VERY END!\n",
    "                sampler = sampler if sampler is not None else []\n",
    "                _ = list(sampler)\n",
    "\n",
    "    total_batched_samples = 0\n",
    "    for epoch in range(epochs_trained, num_train_epochs):\n",
    "        \n",
    "        if self.args.group_by_cluster and (epoch % self.args.num_cluster_update_epochs == 0 or epoch == self.args.num_clustering_warmup_epochs) and epoch >= self.args.num_clustering_warmup_epochs:\n",
    "            self.update_dataloader_sampler(train_dataloader, epoch, num_train_epochs)\n",
    "\n",
    "        if self.args.prune_metadata and (epoch % self.args.num_metadata_prune_epochs == 0 or epoch == self.args.num_metadata_prune_warmup_epochs) and epoch >= self.args.num_metadata_prune_warmup_epochs: \n",
    "            self.prune_metadata()\n",
    "\n",
    "        if self.args.augment_metadata and (epoch % self.args.num_metadata_augment_epochs == 0 or epoch == self.args.num_metadata_augment_warmup_epochs) and epoch >= self.args.num_metadata_augment_warmup_epochs:\n",
    "            self.get_augmentation_metadata()\n",
    "        \n",
    "        epoch_iterator = train_dataloader\n",
    "        if hasattr(epoch_iterator, \"set_epoch\"):\n",
    "            epoch_iterator.set_epoch(epoch)\n",
    "\n",
    "        # Reset the past mems state at the beginning of each epoch if necessary.\n",
    "        if args.past_index >= 0:\n",
    "            self._past = None\n",
    "\n",
    "        steps_in_epoch = (\n",
    "            len(epoch_iterator)\n",
    "            if len_dataloader is not None\n",
    "            else args.max_steps * args.gradient_accumulation_steps\n",
    "        )\n",
    "        self.control = self.callback_handler.on_epoch_begin(args, self.state, self.control)\n",
    "\n",
    "        if epoch == epochs_trained and resume_from_checkpoint is not None and steps_trained_in_current_epoch == 0:\n",
    "            self._load_rng_state(resume_from_checkpoint)\n",
    "\n",
    "        rng_to_sync = False\n",
    "        steps_skipped = 0\n",
    "        if steps_trained_in_current_epoch > 0:\n",
    "            epoch_iterator = skip_first_batches(epoch_iterator, steps_trained_in_current_epoch)\n",
    "            steps_skipped = steps_trained_in_current_epoch\n",
    "            steps_trained_in_current_epoch = 0\n",
    "            rng_to_sync = True\n",
    "\n",
    "        step = -1\n",
    "        for step, inputs in enumerate(epoch_iterator):\n",
    "            total_batched_samples += 1\n",
    "\n",
    "            if self.args.include_num_input_tokens_seen:\n",
    "                main_input_name = getattr(self.model, \"main_input_name\", \"input_ids\")\n",
    "                if main_input_name not in inputs:\n",
    "                    logger.warning(\n",
    "                        \"Tried to track the number of tokens seen, however the current model is \"\n",
    "                        \"not configured properly to know what item is the input. To fix this, add \"\n",
    "                        \"a `main_input_name` attribute to the model class you are using.\"\n",
    "                    )\n",
    "                else:\n",
    "                    self.state.num_input_tokens_seen += self.accelerator.gather(inputs[main_input_name]).numel()\n",
    "            if rng_to_sync:\n",
    "                self._load_rng_state(resume_from_checkpoint)\n",
    "                rng_to_sync = False\n",
    "\n",
    "            # Skip past any already trained steps if resuming training\n",
    "            if steps_trained_in_current_epoch > 0:\n",
    "                steps_trained_in_current_epoch -= 1\n",
    "                if steps_trained_progress_bar is not None:\n",
    "                    steps_trained_progress_bar.update(1)\n",
    "                if steps_trained_in_current_epoch == 0:\n",
    "                    self._load_rng_state(resume_from_checkpoint)\n",
    "                continue\n",
    "            elif steps_trained_progress_bar is not None:\n",
    "                steps_trained_progress_bar.close()\n",
    "                steps_trained_progress_bar = None\n",
    "\n",
    "            if step % args.gradient_accumulation_steps == 0:\n",
    "                self.control = self.callback_handler.on_step_begin(args, self.state, self.control)\n",
    "\n",
    "            with self.accelerator.accumulate(model):\n",
    "                tr_loss_step = self.training_step(model, inputs)\n",
    "\n",
    "            if (\n",
    "                args.logging_nan_inf_filter\n",
    "                and not is_torch_tpu_available()\n",
    "                and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))\n",
    "            ):\n",
    "                # if loss is nan or inf simply add the average of previous logged losses\n",
    "                tr_loss += tr_loss / (1 + self.state.global_step - self._globalstep_last_logged)\n",
    "            else:\n",
    "                tr_loss += tr_loss_step\n",
    "\n",
    "            self.current_flos += float(self.floating_point_ops(inputs))\n",
    "\n",
    "            is_last_step_and_steps_less_than_grad_acc = (\n",
    "                steps_in_epoch <= args.gradient_accumulation_steps and (step + 1) == steps_in_epoch\n",
    "            )\n",
    "\n",
    "            if (\n",
    "                total_batched_samples % args.gradient_accumulation_steps == 0\n",
    "                or\n",
    "                # last step in epoch but step is always smaller than gradient_accumulation_steps\n",
    "                is_last_step_and_steps_less_than_grad_acc\n",
    "            ):\n",
    "                # the `or` condition of `is_last_step_and_steps_less_than_grad_acc` is not covered\n",
    "                # in accelerate. So, explicitly enable sync gradients to True in that case.\n",
    "                if is_last_step_and_steps_less_than_grad_acc:\n",
    "                    self.accelerator.gradient_state._set_sync_gradients(True)\n",
    "\n",
    "                # Gradient clipping\n",
    "                if args.max_grad_norm is not None and args.max_grad_norm > 0:\n",
    "                    # deepspeed does its own clipping\n",
    "\n",
    "                    if is_sagemaker_mp_enabled() and args.fp16:\n",
    "                        _grad_norm = self.optimizer.clip_master_grads(args.max_grad_norm)\n",
    "                    elif self.use_apex:\n",
    "                        # Revert to normal clipping otherwise, handling Apex or full precision\n",
    "                        _grad_norm = nn.utils.clip_grad_norm_(\n",
    "                            amp.master_params(self.optimizer),\n",
    "                            args.max_grad_norm,\n",
    "                        )\n",
    "                    else:\n",
    "                        _grad_norm = self.accelerator.clip_grad_norm_(\n",
    "                            model.parameters(),\n",
    "                            args.max_grad_norm,\n",
    "                        )\n",
    "\n",
    "                    if (\n",
    "                        is_accelerate_available()\n",
    "                        and self.accelerator.distributed_type == DistributedType.DEEPSPEED\n",
    "                    ):\n",
    "                        grad_norm = model.get_global_grad_norm()\n",
    "                    else:\n",
    "                        grad_norm = _grad_norm.item() if _grad_norm is not None else None\n",
    "\n",
    "                # Optimizer step\n",
    "                self.optimizer.step()\n",
    "                optimizer_was_run = not self.accelerator.optimizer_step_was_skipped\n",
    "                if optimizer_was_run:\n",
    "                    # Delay optimizer scheduling until metrics are generated\n",
    "                    if not isinstance(self.lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                        self.lr_scheduler.step()\n",
    "\n",
    "                model.zero_grad()\n",
    "                self.state.global_step += 1\n",
    "                self.state.epoch = epoch + (step + 1 + steps_skipped) / steps_in_epoch\n",
    "                self.control = self.callback_handler.on_step_end(args, self.state, self.control)\n",
    "\n",
    "                self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\n",
    "            else:\n",
    "                self.control = self.callback_handler.on_substep_end(args, self.state, self.control)\n",
    "\n",
    "            if self.control.should_epoch_stop or self.control.should_training_stop:\n",
    "                # PyTorch/XLA relies on the data loader to insert the mark_step for\n",
    "                # each step. Since we are breaking the loop early, we need to manually\n",
    "                # insert the mark_step here.\n",
    "                if is_torch_tpu_available():\n",
    "                    xm.mark_step()\n",
    "                break\n",
    "        if step < 0:\n",
    "            logger.warning(\n",
    "                \"There seems to be not a single sample in your epoch_iterator, stopping training at step\"\n",
    "                f\" {self.state.global_step}! This is expected if you're using an IterableDataset and set\"\n",
    "                f\" num_steps ({max_steps}) higher than the number of available samples.\"\n",
    "            )\n",
    "            self.control.should_training_stop = True\n",
    "\n",
    "        self.control = self.callback_handler.on_epoch_end(args, self.state, self.control)\n",
    "        self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\n",
    "\n",
    "        if DebugOption.TPU_METRICS_DEBUG in self.args.debug:\n",
    "            if is_torch_tpu_available():\n",
    "                # tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\n",
    "                xm.master_print(met.metrics_report())\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    \"You enabled PyTorch/XLA debug metrics but you don't have a TPU \"\n",
    "                    \"configured. Check your training configuration if this is unexpected.\"\n",
    "                )\n",
    "        if self.control.should_training_stop:\n",
    "            break\n",
    "\n",
    "    if args.past_index and hasattr(self, \"_past\"):\n",
    "        # Clean the state at the end of training\n",
    "        delattr(self, \"_past\")\n",
    "\n",
    "    logger.info(\"\\n\\nTraining completed. Do not forget to share your model on huggingface.co/models =)\\n\\n\")\n",
    "    if args.load_best_model_at_end and self.state.best_model_checkpoint is not None:\n",
    "        # Wait for everyone to get here so we are sure the model has been saved by process 0.\n",
    "        if is_torch_tpu_available():\n",
    "            xm.rendezvous(\"load_best_model_at_end\")\n",
    "        elif args.parallel_mode == ParallelMode.DISTRIBUTED:\n",
    "            dist.barrier()\n",
    "        elif is_sagemaker_mp_enabled():\n",
    "            smp.barrier()\n",
    "\n",
    "        self._load_best_model()\n",
    "\n",
    "    # add remaining tr_loss\n",
    "    self._total_loss_scalar += tr_loss.item()\n",
    "    train_loss = self._total_loss_scalar / self.state.global_step\n",
    "\n",
    "    metrics = speed_metrics(\n",
    "        \"train\",\n",
    "        start_time,\n",
    "        num_samples=num_train_samples,\n",
    "        num_steps=self.state.max_steps,\n",
    "        num_tokens=num_train_tokens,\n",
    "    )\n",
    "    self.store_flos()\n",
    "    metrics[\"total_flos\"] = self.state.total_flos\n",
    "    metrics[\"train_loss\"] = train_loss\n",
    "\n",
    "    self.is_in_train = False\n",
    "\n",
    "    self._memory_tracker.stop_and_update_metrics(metrics)\n",
    "\n",
    "    self.log(metrics)\n",
    "\n",
    "    run_dir = self._get_output_dir(trial)\n",
    "    checkpoints_sorted = self._sorted_checkpoints(use_mtime=False, output_dir=run_dir)\n",
    "\n",
    "    # Delete the last checkpoint when save_total_limit=1 if it's different from the best checkpoint and process allowed to save.\n",
    "    if self.args.should_save and self.state.best_model_checkpoint is not None and self.args.save_total_limit == 1:\n",
    "        for checkpoint in checkpoints_sorted:\n",
    "            if not os.path.samefile(checkpoint, self.state.best_model_checkpoint):\n",
    "                logger.info(f\"Deleting older checkpoint [{checkpoint}] due to args.save_total_limit\")\n",
    "                shutil.rmtree(checkpoint)\n",
    "\n",
    "    self.control = self.callback_handler.on_train_end(args, self.state, self.control)\n",
    "\n",
    "    # Wait for the checkpoint to be uploaded.\n",
    "    self._finish_current_push()\n",
    "\n",
    "    # After training we make sure to retrieve back the original forward pass method\n",
    "    # for the embedding layer by removing the forward post hook.\n",
    "    if self.neftune_noise_alpha is not None:\n",
    "        self._deactivate_neftune(self.model)\n",
    "\n",
    "    return TrainOutput(self.state.global_step, train_loss, metrics)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc27f85-b8d7-4147-9e19-2ea8f95f7d6d",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dad14e-12dd-4e8c-a16a-1da96ec96257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.models.radga import RAD002\n",
    "from xcai.models.PPP0XX import DBT021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90781b5d-e073-4e77-b102-cdf72a55c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'disabled'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d9b7ca-4600-4066-bfa4-a347724e9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = XCLearningArguments(\n",
    "    output_dir='/scratch/scai/phd/aiz218323/scratch/outputs/default/',\n",
    "    per_device_train_batch_size=10,\n",
    "    per_device_eval_batch_size=10,\n",
    "    num_train_epochs=50,\n",
    "    eval_steps=50,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='steps',\n",
    "    \n",
    "    representation_accumulation_steps=100,\n",
    "    representation_search_type='BRUTEFORCE',\n",
    "    output_representation_attribute='data_repr',\n",
    "    label_representation_attribute='data_repr',\n",
    "    metadata_representation_attribute='data_repr',\n",
    "    data_augmentation_attribute='data_repr',\n",
    "    \n",
    "    group_by_cluster=True,\n",
    "    num_clustering_warmup_epochs=0,\n",
    "    num_cluster_update_epochs=2,\n",
    "    num_cluster_size_update_epochs=2,\n",
    "    use_data_metadata_for_clustering=True,\n",
    "    clustering_type='EXPO',\n",
    "    minimum_cluster_size=1,\n",
    "    maximum_cluster_size=4,\n",
    "\n",
    "    use_distributional_representation=False,\n",
    "    use_encoder_parallel=True,\n",
    "    max_grad_norm=None, \n",
    "    fp16=True,\n",
    "\n",
    "    predict_with_augmentation=False,\n",
    "    use_augmentation_index_representation=True,\n",
    "    \n",
    "    label_names=['cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', 'aug2data_idx', 'aug2data_meta_repr', 'aug2data_attention_mask'],\n",
    "\n",
    "    prune_metadata=False,\n",
    "    num_metadata_prune_warmup_epochs=0,\n",
    "    num_metadata_prune_epochs=1,\n",
    "    metadata_prune_batch_size=2048,\n",
    "    prune_metadata_names=['cat_meta'],\n",
    "    use_data_metadata_for_pruning=True,\n",
    "\n",
    "    data_aug_meta_name='cat',\n",
    "    augmentation_num_beams=3,\n",
    "    data_aug_prefix='aug',\n",
    "    use_label_metadata=False,\n",
    "    \n",
    "    data_meta_batch_size=2048,\n",
    "    augment_metadata=True,\n",
    "    num_metadata_augment_warmup_epochs=0,\n",
    "    num_metadata_augment_epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6243a0f3-dc7f-4839-bed5-2c6222e009fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT021 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.dr_layer_norm.bias', 'encoder.dr_layer_norm.weight', 'encoder.dr_projector.bias', 'encoder.dr_projector.weight', 'encoder.dr_transform.bias', 'encoder.dr_transform.weight', 'encoder.meta_layer_norm.bias', 'encoder.meta_layer_norm.weight', 'encoder.meta_projector.bias', 'encoder.meta_projector.weight', 'encoder.meta_transform.bias', 'encoder.meta_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()\n",
    "\n",
    "model = DBT021.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', tn_targ=1000, margin=0.3, \n",
    "                               tau=0.1, apply_softmax=True, n_negatives=10, m_lw=0.3, meta_prefix='cat', \n",
    "                               use_encoder_parallel=True, task_repr_type='tok', meta_repr_type='cls')\n",
    "model.init_dr_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e98fe-3f9e-42ee-9d14-404fe9555533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RAD002 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bsz = max(args.per_device_train_batch_size, args.per_device_eval_batch_size)*torch.cuda.device_count()\n",
    "\n",
    "model = RAD002.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', num_batch_labels=5000, batch_size=bsz,\n",
    "                               margin=0.3, num_negatives=10, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='hlk2data', lbl2data_aug_meta_prefix='hlk2lbl', \n",
    "                               resize_length=5000,\n",
    "                               \n",
    "                               meta_loss_weight=0.3, pred_meta_prefix='cat', \n",
    "                               \n",
    "                               fusion_loss_weight=0.05, use_fusion_loss=True, use_noise=True, use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10552f66-756a-4da3-9880-4c97e7488d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.models.radga import RAD003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c1d38-0347-471f-8339-3acd18c63d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RAD003 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.fused_dr_head.layer_norm.bias', 'encoder.fused_dr_head.layer_norm.weight', 'encoder.fused_dr_head.projector.bias', 'encoder.fused_dr_head.projector.weight', 'encoder.fused_dr_head.transform.bias', 'encoder.fused_dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RAD003.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', num_batch_labels=5000, batch_size=100,\n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               calib_margin=0.3, calib_num_negatives=5, calib_tau=0.1, calib_apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='aug2data', lbl2data_aug_meta_prefix='aug2lbl', \n",
    "                               meta_loss_weight=0.3, pred_meta_prefix='cat', \n",
    "                               use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b4b300-50b2-40b4-b29d-40b6d578d50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb74349",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset, valid_dset = block.train.dset.sample(n=1000, seed=50), block.test.dset.sample(n=1000, seed=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3405681-65e0-4cc7-9864-bfad7176763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset, valid_dset = block.train.dset, block.test.dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f5bd9b-3f60-4eaa-8d6d-ddc3e2e6fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PrecRecl(block.n_lbl, valid_dset.data.data_lbl_filterer, prop=block.train.dset.data.data_lbl, \n",
    "                  pk=5, rk=5, rep_pk=[1, 3, 5], rep_rk=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc998894-1a9f-4c12-8c75-2f4ff5758302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "learn = XCLearner(\n",
    "    model=model, \n",
    "    args=args,\n",
    "    data_collator=block.collator, \n",
    "    train_dataset=train_dset, \n",
    "    eval_dataset=valid_dset,\n",
    "    compute_metrics=metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3edf8c-7616-4f12-b535-ad344d06a792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb9a21-2164-4f3a-b544-5bd827ce224a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Living people',\n",
       " 'American male golfers',\n",
       " '1943 births',\n",
       " 'PGA Tour Champions golfers',\n",
       " \"Wake Forest Demon Deacons men's golfers\",\n",
       " 'Golfers from Pennsylvania',\n",
       " 'People from Bryn Mawr, Pennsylvania']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.train_dataset[8]['cat2data_input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a1a09-b680-4c85-b5d2-bb3d0e823c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38c3a9d6f744e568af25116eb6b26f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73dcc3a26f74e05819745c46b47b976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47191e929dcf4d79a39866a5f1e1ced4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb5d2cdfc7545ea917ea2b8c14f8f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4920bbefbe1f4e22bdfd20d2a5b13d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.prune_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f54d9-a0e0-4de8-9d67-55d037d62243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['American male golfers',\n",
       " 'PGA Tour Champions golfers',\n",
       " \"Wake Forest Demon Deacons men's golfers\",\n",
       " 'Golfers from Pennsylvania']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.train_dataset[8]['cat2data_input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db52911-2940-4ccb-821c-64415838129b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0f2e5-e390-4a24-a125-6790f29360f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff68016760914d1f8ee5ccf369ef806b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28f690cae7c4780bc3ad5a8f0dce631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32805 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e053b1d84d495dba709cb07e4c02e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 4min 17s, sys: 2min, total: 1h 6min 17s\n",
      "Wall time: 9min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn.get_augmentation_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f99d4c-6aa9-49cc-911c-f598b3a49c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897daf41-1577-4e2e-986f-fa67ead1bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(learn.get_train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40872a8c-8704-4e86-94bc-32c0de9c942d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plbl2data_idx\n",
      "plbl2data_data2ptr\n",
      "lbl2data_idx\n",
      "lbl2data_input_ids\n",
      "lbl2data_attention_mask\n",
      "lbl2data_data2ptr\n",
      "pcat2data_idx\n",
      "pcat2data_data2ptr\n",
      "cat2data_idx\n",
      "cat2data_input_ids\n",
      "cat2data_attention_mask\n",
      "cat2data_data2ptr\n",
      "data_input_ids\n",
      "data_attention_mask\n",
      "aug2data_idx\n",
      "aug2data_meta_repr\n",
      "aug2data_data2ptr\n"
     ]
    }
   ],
   "source": [
    "for k in b.keys(): print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b3eda2-50b5-4317-baa7-5d090b29e51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5662b3-c309-4d98-b153-2a3cf128e185",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'attention_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py:1215\u001b[0m, in \u001b[0;36mRAD003.forward\u001b[0;34m(self, data_input_ids, data_attention_mask, lbl2data_data2ptr, lbl2data_idx, lbl2data_input_ids, lbl2data_attention_mask, plbl2data_data2ptr, plbl2data_idx, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: encoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\n\u001b[1;32m   1214\u001b[0m data_meta_kwargs \u001b[38;5;241m=\u001b[39m Parameters\u001b[38;5;241m.\u001b[39mfrom_feat_meta_aug_prefix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_aug_meta_prefix, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1215\u001b[0m data_o \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdata_aug_meta_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_aug_meta_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_meta_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1219\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m; lbl2data_o \u001b[38;5;241m=\u001b[39m EncoderOutput()\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lbl2data_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py:1070\u001b[0m, in \u001b[0;36mEncoder003.forward\u001b[0;34m(self, data_input_ids, data_attention_mask, data_aug_meta_prefix, data_type, data_unnormalized, **kwargs)\u001b[0m\n\u001b[1;32m   1068\u001b[0m     meta_kwargs \u001b[38;5;241m=\u001b[39m Parameters\u001b[38;5;241m.\u001b[39mfrom_meta_aug_prefix(data_aug_meta_prefix, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(meta_kwargs):\n\u001b[0;32m-> 1070\u001b[0m         data_fused_embed, fusion_weights, meta_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuse_meta_into_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_o\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[43mdata_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[43mmeta_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1073\u001b[0m         data_fused_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfused_dr_head(data_fused_embed, data_attention_mask)\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m EncoderOutput(\n\u001b[1;32m   1076\u001b[0m     rep\u001b[38;5;241m=\u001b[39mdata_repr,\n\u001b[1;32m   1077\u001b[0m     fused_rep\u001b[38;5;241m=\u001b[39mdata_fused_repr,\n\u001b[1;32m   1078\u001b[0m     meta_repr\u001b[38;5;241m=\u001b[39mmeta_repr,\n\u001b[1;32m   1079\u001b[0m )\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py:1028\u001b[0m, in \u001b[0;36mEncoder003.fuse_meta_into_embeddings\u001b[0;34m(self, embed, attention_mask, meta_kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll datapoints should have same number of metadata.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta_repr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m m_args:\n\u001b[0;32m-> 1028\u001b[0m     m_repr,m_repr_mask \u001b[38;5;241m=\u001b[39m m_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta_repr\u001b[39m\u001b[38;5;124m'\u001b[39m],torch\u001b[38;5;241m.\u001b[39many(\u001b[43mm_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1029\u001b[0m     m_repr,m_repr_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize(m_repr, m_repr_mask, m_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata2ptr\u001b[39m\u001b[38;5;124m'\u001b[39m][idx])\n\u001b[1;32m   1030\u001b[0m     m_repr_mask \u001b[38;5;241m=\u001b[39m m_repr_mask\u001b[38;5;241m.\u001b[39mbool()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'attention_mask'"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f47c1-dc88-4a9b-9993-bb82770ed323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155170b3-12f2-4d88-bfeb-cfe39d17c081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b369f0f-f0aa-4ba5-a311-e79ca5ff84b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:21: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='173300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    14/173300 00:09 < 37:32:17, 1.28 it/s, Epoch 0.00/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 318\u001b[0m, in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m    315\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    317\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m    319\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/data.py:293\u001b[0m, in \u001b[0;36mXCDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    292\u001b[0m         x\u001b[38;5;241m.\u001b[39mupdate(m\u001b[38;5;241m.\u001b[39mget_data_meta(idx))\n\u001b[0;32m--> 293\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl: x\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lbl_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlbl2data_idx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg_2/lib/python3.9/site-packages/fastcore/dispatch.py:120\u001b[0m, in \u001b[0;36mTypeDispatch.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/data.py:207\u001b[0m, in \u001b[0;36mMetaXCDataset.get_lbl_meta\u001b[0;34m(self, idxs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples: x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [[o[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(o))[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples]] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     x\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m:[[v[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m o] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/data.py:207\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples: x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [[o[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(o))[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples]] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     x\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m:[[v[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m o] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/data.py:207\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples: x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [[o[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(o))[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples]] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     x\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m:[[v[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m o] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/scratch/scai/phd/aiz218323/Projects/xcai/xcai/data.py:207\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples: x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [[o[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(o))[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_lbl_meta_samples]] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     x\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m:[[\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m o] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_info\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78bda65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccdb0b-e563-4ace-9aab-5cd634dfd40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = learn.predict(learn.eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c40ed3-6a16-47ab-b6ad-4dc832cfeca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
