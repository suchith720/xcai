{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3319d-0ed2-4620-881b-815e24d2acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp generation.generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a749a72-0d6a-4775-b43b-9bcfe479c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c3605-6356-42af-bc53-ba6ae80df222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf9a3eb-4d6c-45f5-a9ef-7792b867ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, math\n",
    "from torch.multiprocessing import Pool\n",
    "import torch.nn.functional as F\n",
    "from itertools import chain\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Optional, Sequence, Any, Dict, List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from fastcore.utils import *\n",
    "from fastcore.dispatch import *\n",
    "from fastcore.meta import *\n",
    "from fastcore.parallel import *\n",
    "\n",
    "from xcai.core import *\n",
    "from xcai.transform import *\n",
    "from xcai.generation.trie import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba7615-60f1-4de9-99c8-d41e9c8616c0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc5232-b266-4e29-bf8c-ab49625bd3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import numpy as np\n",
    "from xcai.block import *\n",
    "from xcai.models.MMM00X import BT0002\n",
    "from xcai.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110eab55-9fa2-4e5c-9b9a-46383e7f2182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "block = XCBlock.from_cfg('train', tokz='bert-base-cased')\n",
    "b, n_lbl = block.train.one_batch(), block.n_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48add0d6-cb8c-4640-b20f-219e4f049022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "fname = '/home/scai/phd/aiz218323/Projects/XC_NLG/code/models/bert-base-cased_RB33-NAR-3+8-2_(mapped)LF-WikiSeeAlsoTitles-320K/checkpoint-242000'\n",
    "m = BT0002.from_pretrained(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c58c02-d0b0-4148-90c6-d5baac3428fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "o = m(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61703fd8-3556-4c51-8fd1-470f74432ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 13, 28996]), 312330)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "o.logits.shape, len(block.lbl_info['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff642e5-c1b4-484b-a3e9-2c6e8caebf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1401e110b94d40a08f1d4ca9bbb9a814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "toks = block.lbl_info['input_ids']\n",
    "info = [[i] for i in range(len(toks))]\n",
    "t = Trie.from_list(toks, info, max_info=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bbe353-1d4b-43a5-8f9b-bcb88f5459c6",
   "metadata": {},
   "source": [
    "## Trie Pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b173dc-e2be-492b-9f26-b22e6eca2bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TriePtr:\n",
    "\n",
    "    def __init__(self, trie, max_info:Optional[int]=None):\n",
    "        store_attr('trie,max_info')\n",
    "        self.ptr, self.hyp = trie.root, [trie.root.tok]\n",
    "\n",
    "    @property\n",
    "    def tokens(self):\n",
    "        return list(self.ptr.nxt_toks.keys())\n",
    "\n",
    "    def next(self, val:int):\n",
    "        if val not in self.tokens: raise ValueError(f'`{val}` not a valid next token.')\n",
    "        self.ptr = self.ptr.nxt_toks[val]\n",
    "        self.hyp.append(val)\n",
    "\n",
    "    def suffixes(self):\n",
    "        o = []\n",
    "        Trie._search(self.ptr, self.hyp, o, self.max_info)\n",
    "        return sorted(o, key=lambda x: x.cnt, reverse=True)\n",
    "\n",
    "    @property\n",
    "    def is_end(self):\n",
    "        return self.ptr.is_end\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        info = list(self.ptr.info) if self.max_info is None else list(self.ptr.info)[:self.max_info]\n",
    "        return TrieOutput(self.hyp, self.ptr.cnt, info)\n",
    "\n",
    "    def copy(self):\n",
    "        t = TriePtr(self.trie, self.max_info)\n",
    "        t.ptr,t.hyp = self.ptr,self.hyp.copy()\n",
    "        return t\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133c7130-0157-4581-9319-57878aa324a6",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7398f89c-3fe3-49e9-aeca-b267bcf3b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TriePtr(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6e1947-1682-425d-8916-18515f1b62a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a93bc7-601d-4934-88c3-9bee9b1b977f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.is_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f7da3-2870-4a86-be22-8f3d40605598",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.next(102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe2261-4b76-474e-a902-da94dab2ea19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TrieOutput(s=[101, 200, 100, 222, 102], cnt=1, info=None)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.suffixes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd7dde-2dcf-4f39-b8b1-c91501f93b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrieOutput(s=[101, 200, 100, 222, 102], cnt=1, info=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c133622-f26b-455e-b866-dd54cd582d2f",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178aaf98-d3ef-4282-a0cf-550f3af7b2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TriePtr(t)\n",
    "l = [tp.copy(), tp.copy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa84d96f-804e-4306-a05b-472cce0e27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l[0].next(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36dbb60-d75e-41c2-baec-c0ea1bf99b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([102], [100, 200, 300])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0].tokens, l[1].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e3228-bf03-45c6-a9b9-4bee895ec30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 100], [101])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0].hyp, l[1].hyp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c840673-98c0-4ff3-a1d0-c48c4c3749c8",
   "metadata": {},
   "source": [
    "## Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6cf6c-99ad-4bef-bfac-898326ff2a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Hypothesis:\n",
    "\n",
    "    def __init__(self, n_bm:int, len_penalty:Optional[float]=1.0):\n",
    "        store_attr('n_bm,len_penalty')\n",
    "        self.worst_sc, self.beams = 1e9, []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.beams)\n",
    "\n",
    "    def add(self, hyp, sum_logits:float, gen_len:Optional[int]=None):\n",
    "        if gen_len is not None: sc = sum_logits/gen_len**self.len_penalty\n",
    "        else: sc = sum_logits/len(hyp.s)**self.len_penalty\n",
    "\n",
    "        if len(self) < self.n_bm or sc > self.worst_sc:\n",
    "            self.beams.append((sc, hyp))\n",
    "            if len(self) > self.n_bm:\n",
    "                nxt_sc = sorted([(s,i) for i,(s,_) in enumerate(self.beams)])\n",
    "                del self.beams[nxt_sc[0][1]]\n",
    "                self.worst_sc = nxt_sc[1][0]\n",
    "            else: self.worst_sc = min(sc, self.worst_sc)\n",
    "\n",
    "    def is_done(self, best_sc:float, cur_len:int):\n",
    "        if len(self) < self.n_bm: return False\n",
    "        high_sc = best_sc/cur_len**self.len_penalty\n",
    "        return self.worst_sc >= high_sc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e299bd13-a2ae-4598-a239-c355bd8cd839",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496764c2-df2f-499f-a2ea-29b575677607",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = Hypothesis(5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c50bd90-0323-452c-9239-56529c284c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91d668-ce3c-411a-9574-363016ac78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp.add(TrieOutput([1, 3, 6, 11, 12, 14], 2, [2, 5]), sum_logits=-1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0f668-9571-4fe1-ba0b-f9c3e72857bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.75, TrieOutput(s=[1, 2, 3, 4], cnt=2, info=[0, 1, 2])),\n",
       " (-0.6, TrieOutput(s=[1, 3, 6, 11], cnt=2, info=[2, 5])),\n",
       " (-0.6, TrieOutput(s=[1, 3, 6, 11], cnt=2, info=[2, 5])),\n",
       " (-0.5366563145999494, TrieOutput(s=[1, 3, 6, 11, 12], cnt=2, info=[2, 5])),\n",
       " (-0.48989794855663565,\n",
       "  TrieOutput(s=[1, 3, 6, 11, 12, 14], cnt=2, info=[2, 5]))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp.beams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039739cc-950c-411c-9b42-03af0e659380",
   "metadata": {},
   "source": [
    "## Trie Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c8822c-3ec9-4c65-b4af-6f241596e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TrieBeam:\n",
    "\n",
    "    def __init__(self, trie:Trie, n_bm:Optional[int]=5, max_bm:Optional[int]=None, len_penalty:Optional[float]=1.0, \n",
    "                 max_info:Optional[int]=None):\n",
    "        store_attr('trie,n_bm,len_penalty,max_info')\n",
    "        self.max_bm, self.hyp = max_bm if max_bm is None else max(max_bm, 2*n_bm), None\n",
    "\n",
    "    def valid(self, ptr:List, sc:torch.FloatTensor):\n",
    "        v_tok, v_sc, v_idx = [], [], []\n",
    "        for i,(p,s) in enumerate(zip(ptr,sc)):\n",
    "            toks = p.tokens\n",
    "            v_tok.extend(toks)\n",
    "            v_sc.extend(s[toks].tolist())\n",
    "            v_idx.extend([i for _ in range(len(toks))])\n",
    "        return v_tok, v_sc, v_idx\n",
    "\n",
    "    def topk(self, ptr:List, tok:List, sc:List, idx:List):\n",
    "        top_sc, top_i = (\n",
    "            torch.topk(torch.tensor(sc), 2*self.n_bm, dim=0) \n",
    "            if len(sc) > 2*self.n_bm else torch.sort(torch.tensor(sc), dim=0, descending=True)\n",
    "        )\n",
    "        top_sc = top_sc.tolist()\n",
    "        top_idx, top_tok = list(zip(*[(idx[i],tok[i]) for i in top_i]))\n",
    "        top_ptr = [ptr[i].copy() for i in top_idx]\n",
    "        for p,t in zip(top_ptr, top_tok): p.next(t)\n",
    "        return top_ptr, top_sc\n",
    "\n",
    "    def next(self, ptr:List, sc:List):\n",
    "        nxt_ptr, nxt_sc = [], []\n",
    "        for i,(p,s) in enumerate(zip(ptr, sc)):\n",
    "            if p.is_end: self.hyp.add(p.value, s)\n",
    "            else: nxt_ptr.append(p);nxt_sc.append(s)\n",
    "        nxt_ptr,nxt_sc = nxt_ptr[:self.n_bm],torch.tensor(nxt_sc[:self.n_bm]).unsqueeze(1)\n",
    "        return nxt_ptr, nxt_sc\n",
    "\n",
    "    def finalize(self, ptr:List, sc:List):\n",
    "        if len(self.hyp) < self.n_bm:\n",
    "            nh = int(math.ceil((self.max_bm-len(self.hyp))/len(ptr))) if self.max_bm is not None and len(ptr) else None\n",
    "            for p,s in zip(ptr, sc):\n",
    "                hyps = p.suffixes() if nh is None else p.suffixes()[:nh]\n",
    "                for o in hyps: self.hyp.add(o, s)\n",
    "        if len(self.hyp) < self.n_bm: raise ValueError(f'`len(self.hyp)`({len(self.hyp)}) < `n_bm`({self.n_bm})')\n",
    "        seq_sc, seq_ids, info, n_info = list(map(list, zip(*[(sc,hyp.s,hyp.info,len(hyp.info)) for sc,hyp in self.hyp.beams])))\n",
    "        return {\n",
    "            'seq2data_data2ptr':[self.n_bm],\n",
    "            'seq2data_score':seq_sc, \n",
    "            'seq2data_output_ids':seq_ids, \n",
    "            'info2seq2data_idx':list(chain(*info)),\n",
    "            'info2seq2data_seq2ptr':n_info,\n",
    "            'info2seq2data_data2ptr':[sum(n_info)],\n",
    "        }\n",
    "        \n",
    "    def proc(self, logits:torch.FloatTensor, n_bm:Optional[int]=None, max_bm:Optional[int]=None, len_penalty:Optional[float]=None, \n",
    "             max_info:Optional[int]=None):\n",
    "        store_attr('n_bm,len_penalty,max_info', is_none=False)\n",
    "        if max_bm is not None: self.max_bm = max(max_bm, 2*self.n_bm)\n",
    "        \n",
    "        self.hyp = Hypothesis(self.n_bm, self.len_penalty)\n",
    "        sc = torch.full((self.n_bm,1), -1e9); sc[0,0] = 0\n",
    "        ptr = [TriePtr(self.trie,self.max_info) for _ in range(2*self.n_bm)]\n",
    "        \n",
    "        cur_len,seq_len = 1,logits.shape[0]\n",
    "        while True:\n",
    "            sc = logits[cur_len:cur_len+1].expand(sc.shape[0],-1) + sc\n",
    "            v_tok, v_sc, v_idx = self.valid(ptr, sc)\n",
    "            top_ptr, top_sc = self.topk(ptr, v_tok, v_sc, v_idx)\n",
    "            ptr, sc = self.next(top_ptr, top_sc)\n",
    "            cur_len += 1\n",
    "            \n",
    "            if cur_len >= seq_len or len(ptr) == 0 or self.hyp.is_done(sc.max().item(), cur_len):\n",
    "                break\n",
    "        return self.finalize(ptr, sc.squeeze(1).tolist())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ea52e-2fca-454c-b140-d6715c462031",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020ab6f2-6345-4cba-90fc-c311420a6cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "tb = TrieBeam(t, n_bm=5, len_penalty=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f9e874-3ffe-4898-afd0-7f2d2f3fd1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "i = F.log_softmax(o.logits, dim=-1)\n",
    "r = tb.proc(i[0], len_penalty=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761aad8a-3231-45f6-8486-0719f74d18fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seq2data_data2ptr': [5],\n",
       " 'seq2data_score': [-0.0007121877170385026,\n",
       "  -0.000994869279160678,\n",
       "  -0.0009977314937062937,\n",
       "  -0.0010254948953590068,\n",
       "  -0.0006374765653163195],\n",
       " 'seq2data_output_ids': [[101, 5619, 1104, 11765, 1107, 1726, 102],\n",
       "  [101, 5619, 1104, 11765, 1107, 12247, 102],\n",
       "  [101, 5619, 1104, 11765, 1107, 7217, 102],\n",
       "  [101, 5619, 1104, 11765, 1107, 3900, 102],\n",
       "  [101, 5619, 1104, 11765, 1107, 4471, 6722, 102]],\n",
       " 'info2seq2data_idx': [150667, 297701, 208470, 276666, 278542],\n",
       " 'info2seq2data_seq2ptr': [1, 1, 1, 1, 1],\n",
       " 'info2seq2data_data2ptr': [5]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8703eb59-7481-4e7b-8792-580b32f42a22",
   "metadata": {},
   "source": [
    "## TrieBeamSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4979a6-1c6c-48b6-9778-2fe97d492a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "PARAM = {\n",
    "    'pad_tok': 0,\n",
    "    'pad_side': 'right',\n",
    "    'drop': True,\n",
    "    'ret_t': True,\n",
    "    'in_place': True,\n",
    "    'collapse': True,\n",
    "    'device': 'cpu',\n",
    "    'n_bm': 5,\n",
    "    'len_penalty': 1.2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8b40ea-9213-4d3d-91c1-d490b793765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def tbs_proc(x): return x[0].proc(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231b300-667e-45a4-91f7-0f21cacaeb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TrieBeamSearch:\n",
    "\n",
    "    @delegates(XCPadOutputTfm.__init__)\n",
    "    def __init__(self, trie:Trie, n_bm:int=5, max_bm:Optional[int]=None, len_penalty:Optional[float]=1.0, max_info:Optional[int]=None,\n",
    "                 n_threads=3, **kwargs):\n",
    "        store_attr('trie,n_bm,max_bm,len_penalty,max_info,n_threads')\n",
    "        self.tfm = XCPadOutputTfm(**kwargs)\n",
    "        \n",
    "    def proc(self, model, inputs:Dict, n_bm:int=None, max_bm:Optional[int]=None, len_penalty:Optional[float]=None, \n",
    "             max_info:Optional[int]=None):\n",
    "        store_attr('n_bm,max_bm,len_penalty,max_info', is_none=False)\n",
    "        logits, attention_mask = F.log_softmax(model(**inputs).logits, dim=-1).cpu(), inputs['data_attention_mask'].bool().cpu()\n",
    "        hyps = [TrieBeam(self.trie, self.n_bm, self.max_bm, self.len_penalty, self.max_info) for _ in range(logits.shape[0])]\n",
    "        outputs = [h.proc(l[a]) for h,l,a in zip(hyps, logits, attention_mask)]\n",
    "        outputs = self.tfm({k:list(chain(*[o[k] for o in outputs])) for k in outputs[0]})\n",
    "        outputs['info2seq2data_score'] = torch.repeat_interleave(outputs['seq2data_score'], outputs['info2seq2data_seq2ptr'], dim=0)\n",
    "        return outputs\n",
    "\n",
    "    def proc_parallel(self, model, inputs:Dict, n_bm:int=None, max_bm:Optional[int]=None, len_penalty:Optional[float]=None, \n",
    "                      max_info:Optional[int]=None, n_threads=None):\n",
    "        store_attr('n_bm,max_bm,len_penalty,max_info,n_threads', is_none=False)\n",
    "        logits = F.log_softmax(model(**inputs).logits, dim=-1).cpu().share_memory_()\n",
    "        attention_mask = inputs['data_attention_mask'].bool().cpu().share_memory_()\n",
    "        hyps = [TrieBeam(self.trie, self.n_bm, self.max_bm, self.len_penalty, self.max_info) for _ in range(logits.shape[0])]\n",
    "        \n",
    "        with torch.no_grad(), Pool(processes=n_threads) as pool: outputs = list(pool.map(tbs_proc, list(zip(hyps, logits, attention_mask))))\n",
    "        \n",
    "        outputs = self.tfm({k:list(chain(*[o[k] for o in outputs])) for k in outputs[0]})\n",
    "        outputs['info2seq2data_score'] = torch.repeat_interleave(outputs['seq2data_score'], outputs['info2seq2data_seq2ptr'], dim=0)\n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e692f-850e-42de-b609-c2881526d3d6",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6c3e0-f136-4f73-a1b7-ebe9fcc268ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "tbs = TrieBeamSearch(t, n_bm=20, max_bm=20, len_penalty=1, max_info=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be3a691-d166-48e5-a7f0-d6e4006ea66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "bsz = 64\n",
    "b = block.train.one_batch(bsz)\n",
    "b = prepare_batch(m, b, m_args=['lbl2data_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad43881-27e0-4d0e-b4d5-36a12ad7f1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lbl2data_idx', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74385099-4553-4577-8ffd-673283e0c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "m, b = m.to('cuda'), b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c077f-fee2-465a-8588-1fc3de89efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "r = tbs.proc(m, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb25504-e00c-43de-b797-2e3a31488b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['info2seq2data_idx', 'info2seq2data_seq2ptr', 'info2seq2data_data2ptr', 'seq2data_data2ptr', 'seq2data_score', 'seq2data_output_ids', 'info2seq2data_score'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b1d9d-7881-4782-a646-0c455b5320f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.info2seq2data_data2ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c5b8f-9762-45a8-8c50-40639a664d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/scai/phd/aiz218323/scratch/anaconda3/envs/xc_nlg/lib/python3.9/weakref.py\", line 106, in remove\n",
      "    def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mtbs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[89], line 22\u001b[0m, in \u001b[0;36mTrieBeamSearch.proc_parallel\u001b[0;34m(self, model, inputs, n_bm, len_penalty, n_threads)\u001b[0m\n\u001b[1;32m     19\u001b[0m logits \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mshare_memory_()\n\u001b[1;32m     20\u001b[0m hyps \u001b[38;5;241m=\u001b[39m [TrieBeam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrie, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_bm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlen_penalty) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), Pool(processes\u001b[38;5;241m=\u001b[39mn_threads) \u001b[38;5;28;01mas\u001b[39;00m pool: outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtbs_proc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhyps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtfm({k:\u001b[38;5;28mlist\u001b[39m(chain(\u001b[38;5;241m*\u001b[39m[o[k] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m outputs])) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]})\n\u001b[1;32m     25\u001b[0m outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfo2seq2data_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrepeat_interleave(outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq2data_score\u001b[39m\u001b[38;5;124m'\u001b[39m], outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfo2seq2data_seq2ptr\u001b[39m\u001b[38;5;124m'\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/scratch/anaconda3/envs/xc_nlg/lib/python3.9/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scratch/anaconda3/envs/xc_nlg/lib/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/scratch/anaconda3/envs/xc_nlg/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scratch/anaconda3/envs/xc_nlg/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/scratch/anaconda3/envs/xc_nlg/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "r = tbs.proc_parallel(m, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dd5b0d-2ccb-48a1-b82e-7b8cf4d61810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info2seq2data_idx torch.Size([2040])\n",
      "info2seq2data_seq2ptr torch.Size([320])\n",
      "info2seq2data_data2ptr torch.Size([64])\n",
      "seq2data_data2ptr torch.Size([64])\n",
      "seq2data_score torch.Size([320])\n",
      "seq2data_output_ids torch.Size([320, 17])\n",
      "info2seq2data_score torch.Size([2040])\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "for k,v in r.items(): print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488a4f1-1b41-4472-9513-5cbf3bf94943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "output = {}\n",
    "output['targ_idx'] = b['lbl2data_idx'].cpu()\n",
    "output['targ_ptr'] = b['lbl2data_data2ptr'].cpu()\n",
    "\n",
    "output['pred_idx'] = r['info2seq2data_idx'].cpu()\n",
    "output['pred_score'] = r['info2seq2data_score'].cpu()\n",
    "output['pred_ptr'] = r['info2seq2data_data2ptr'].cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a78727-9da9-487e-a356-a9150903b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "metric = PrecRecl(n_lbl, prop=block.train.dset.data.data_lbl, pk=5, rk=5, rep_pk=[1, 3, 5], rep_rk=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec4827b-865e-4c60-b1a7-97c20db01d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P@1': 0.5,\n",
       " 'P@3': 0.26562500000000006,\n",
       " 'P@5': 0.18437499999999998,\n",
       " 'N@1': 0.5,\n",
       " 'N@3': 0.51767075,\n",
       " 'N@5': 0.5278427,\n",
       " 'PSP@1': 0.42532231190544867,\n",
       " 'PSP@3': 0.44209107351860044,\n",
       " 'PSP@5': 0.46167468811559276,\n",
       " 'PSN@1': 0.42532232,\n",
       " 'PSN@3': 0.47837257,\n",
       " 'PSN@5': 0.5009967,\n",
       " 'R@5': 0.5492559523809524}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "metric(**output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16be828-f065-403b-b0e6-1c7a0992f99d",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0667c72-f8ac-45cf-990b-6d6ab27f1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "filterer = np.loadtxt('/home/scai/phd/aiz218323/Projects/XC_NLG/data/(mapped)LF-WikiSeeAlsoTitles-320K/filter_labels_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4becac-0e02-4326-966e-83c4910403c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "tbs = TrieBeamSearch(t, n_bm=5, len_penalty=1.5)\n",
    "metric = PrecRecl(n_lbl, filterer, prop=block.train.dset.data.data_lbl, pk=5, rk=5, rep_pk=[1, 3, 5], rep_rk=[5])\n",
    "\n",
    "block.test.bsz = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834ba59-1342-4f7d-80d2-3f0a792fc4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def get_xo(inp, targ):\n",
    "    return {\n",
    "        'targ_idx':inp['lbl2data_idx'],\n",
    "        'targ_ptr':inp['lbl2data_data2ptr'],\n",
    "        'pred_idx':targ['info2seq2data_idx'],\n",
    "        'pred_score':targ['info2seq2data_score'],\n",
    "        'pred_ptr':targ['info2seq2data_data2ptr'],\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db846309-cfca-4faf-bfd7-bca3611a37b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "m = m.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc6421-6c9e-4907-b215-4af775901940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4826dcb4a447d4819844e4e2af4aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1776 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "metric.reset()\n",
    "\n",
    "for b in tqdm(block.test.dl, total=len(block.test.dl)):\n",
    "    b = prepare_batch(m, b).to('cuda')\n",
    "    r = tbs.proc(m, b)\n",
    "    o = get_xo(b, r)\n",
    "    metric.accumulate(**o)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac9b726-5289-4386-86af-2e3721d23c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P@1': 0.15198715601498464,\n",
       " 'P@3': 0.09240721441383382,\n",
       " 'P@5': 0.06510323071290847,\n",
       " 'N@1': 0.15198715,\n",
       " 'N@3': 0.14293797,\n",
       " 'N@5': 0.14415713,\n",
       " 'PSP@1': 0.09805626244659127,\n",
       " 'PSP@3': 0.0986113111983527,\n",
       " 'PSP@5': 0.10019778518095093,\n",
       " 'PSN@1': 0.098056264,\n",
       " 'PSN@3': 0.10458853,\n",
       " 'PSN@5': 0.109316155,\n",
       " 'R@5': 0.14616284431636717}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "metric.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a689caa6-945f-4752-8ed3-1b5b822b3d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
