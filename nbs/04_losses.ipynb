{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c57c5ab-ae84-44fb-9670-83bc3992948d",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f1223-5f09-451b-ad24-487123d97b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b5aa3-325a-440d-9a03-db8eed2bb236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b49ad-f819-4fb2-a8f0-c47a613be6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import functools, torch, torch.nn as nn, torch.nn.functional as F\n",
    "from typing import MutableSequence, Union\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import *\n",
    "\n",
    "from xcai.torch_core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77292218-e5bc-482f-b53e-8df0ff819ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27c3e88-0c88-41f8-a15a-c2b7f6dcf432",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7b96e-bd79-4abd-ae1b-d5ce33699ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.test_utils import *\n",
    "from xcai.models.BT000X import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0913313-aa02-45d9-aaf2-fc4372582d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "block = Test.from_cfg('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb6dae1-09e2-462f-bfd1-80aaf35ed0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a5239a-93f4-441a-bf98-6e324bbbec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    }
   ],
   "source": [
    "m = BT0001.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec10b3-6503-4d12-ad27-a7e32c643b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_logits, data_logits, lbl2data_data2ptr, data_embed, lbl2data_embed = m(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a106c1e-e88e-4591-886a-d4f1e599946d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24, 12]),\n",
       " torch.Size([24, 12]),\n",
       " torch.Size([10]),\n",
       " torch.Size([10, 768]),\n",
       " torch.Size([24, 768]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_logits.shape, data_logits.shape, lbl2data_data2ptr.shape, data_embed.shape, lbl2data_embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae671d-9334-490c-99eb-9465cac495bd",
   "metadata": {},
   "source": [
    "## BaseLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077406a-74a1-4a6a-86d8-a21cb5fb4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 reduce:Optional[str]=None, \n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.reduce = reduce\n",
    "\n",
    "    @property\n",
    "    def reduction(self) -> str: return self.reduce\n",
    "    \n",
    "    @reduction.setter\n",
    "    def reduction(self, v:str):\n",
    "        \"Sets the reduction style (typically 'mean', 'sum', or 'none')\" \n",
    "        self.reduce = v\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055118a-0228-406e-8d8b-40003b7c6ccc",
   "metadata": {},
   "source": [
    "## MultiCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42018177-6229-4765-b147-8642f6b0427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MultiCrossEntropy(BaseLoss):\n",
    "\n",
    "    def __init__(self,\n",
    "                 tn_targ:Optional[int]=None, \n",
    "                 ig_tok:Optional[int]=0,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.tn_targ, self.ig_tok = tn_targ, ig_tok\n",
    "        self.o = torch.ones(tn_targ, dtype=torch.int64) if tn_targ is not None else None\n",
    "        self._parameters = {'o': self.o}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4845e7-e46e-450f-9672-6362ed67cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 10\n",
    "batch = block.train.one_batch(bsz)\n",
    "data_logits, lbl2data_input_ids, lbl2data_data2ptr, data_embed, lbl2data_embed = m(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf88cc-f6dc-4ff7-aebf-59cdb52ae538",
   "metadata": {},
   "outputs": [],
   "source": [
    "mce_fn = MultiCrossEntropy(10_000, reduce='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cde5e9-8fed-4875-9621-d6885b08da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def __call__(cls:MultiCrossEntropy,\n",
    "             inp:torch.FloatTensor,\n",
    "             targ:torch.LongTensor,\n",
    "             n_inp2targ:torch.LongTensor):\n",
    "    tn_targ, targ_len = targ.shape\n",
    "    bsz, inp_len, mn_targ = inp.shape[0], inp.shape[1], n_inp2targ.max()\n",
    "    seq_len = min(targ_len, inp_len)\n",
    "    inp, targ = -F.log_softmax(inp, dim=2)[:, :seq_len].transpose(1,2), targ[:, :seq_len]\n",
    "    \n",
    "    inp2targ_ptr = n_inp2targ.cumsum(dim=0)-1\n",
    "    xn_inp2targ = mn_targ-n_inp2targ+1\n",
    "    r_targ = (\n",
    "        torch.ones(tn_targ, dtype=torch.int64, device=inp.device).scatter(0, inp2targ_ptr, xn_inp2targ)\n",
    "        if cls.tn_targ is None or tn_targ > cls.tn_targ else\n",
    "        cls.o[:tn_targ].scatter(0, inp2targ_ptr, xn_inp2targ)\n",
    "    )\n",
    "    xtarg = targ.repeat_interleave(r_targ, dim=0)\n",
    "\n",
    "    s = inp.gather(1, xtarg.view(bsz, -1, seq_len)).view(-1, seq_len)\n",
    "    s /= r_targ.repeat_interleave(r_targ, dim=0).view(-1, 1)\n",
    "    idx = torch.where(xtarg != cls.ig_tok)\n",
    "    loss = s[idx[0], idx[1]]\n",
    "    \n",
    "    if cls.reduction == 'mean': return (loss/len(torch.where(targ != cls.ig_tok)[0])).sum()\n",
    "    elif cls.reduction == 'sum': return loss.sum()\n",
    "    else: raise ValueError(f'`reduction` cannot be `{cls.reduction}`')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8215de-ee9e-4a77-9701-b196881af0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.8057, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mce_fn(data_logits, lbl2data_input_ids, lbl2data_data2ptr); loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8ebba6-362a-41f6-a2f4-57815e1196f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __call__(cls:MultiCrossEntropy, \n",
    "             inp:torch.FloatTensor, \n",
    "             targ:torch.LongTensor, \n",
    "             n_inp2targ:torch.LongTensor):\n",
    "    inp_len, targ_len = inp.shape[1], targ.shape[1]\n",
    "    seq_len = min(inp_len, targ_len)\n",
    "    inp, targ = -F.log_softmax(inp, dim=2)[:, :seq_len], targ[:, :seq_len].unsqueeze(2)\n",
    "    inp = inp.repeat_interleave(n_inp2targ, dim=0)\n",
    "    s = inp.gather(2, targ)\n",
    "    idx = torch.where(targ != cls.ig_tok)\n",
    "    loss = s[idx[0], idx[1]]\n",
    "    if cls.reduction == 'mean': return loss.mean()\n",
    "    elif cls.reduction == 'sum': return loss.sum()\n",
    "    else: raise ValueError(f'`reduction` cannot be `{cls.reduction}`')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06414870-be2c-4125-8f48-42ed3e2bd669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.8057, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mce_fn(data_logits, lbl2data_input_ids, lbl2data_data2ptr); loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f5f819-25fa-4a7f-b9e7-9fa0c612799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __call__(cls:MultiCrossEntropy, \n",
    "             inp:torch.FloatTensor, \n",
    "             targ:torch.LongTensor, \n",
    "             n_inp2targ:torch.LongTensor):\n",
    "    inp_len, targ_len = inp.shape[1], targ.shape[1]\n",
    "    seq_len = min(inp_len, targ_len)\n",
    "    inp, targ = -F.log_softmax(inp, dim=2)[:, :seq_len], targ[:, :seq_len]\n",
    "    num, s = 0, []\n",
    "    for i,n in zip(inp, n_inp2targ):\n",
    "        for _ in range(n):\n",
    "            s.append(i.gather(1, targ[num].view(-1, 1)).view(1, -1))\n",
    "            num += 1\n",
    "    s = torch.vstack(s)\n",
    "    idx = torch.where(targ != cls.ig_tok)\n",
    "    loss = s[idx[0], idx[1]]\n",
    "    if cls.reduction == 'mean': return loss.mean()\n",
    "    elif cls.reduction == 'sum': return loss.sum()\n",
    "    else: raise ValueError(f'`reduction` cannot be `{cls.reduction}`')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc27d2-0e2f-4d50-b1e7-27ae4ea336fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.8057, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mce_fn(data_logits, lbl2data_input_ids, lbl2data_data2ptr); loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a40e0b-6b16-420d-b59b-ef38d591f331",
   "metadata": {},
   "source": [
    "## MultiTriplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6078f2cb-f54a-41b3-8180-f3ce94f92602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MultiTriplet(BaseLoss):\n",
    "\n",
    "    def __init__(self,\n",
    "                 bsz:Optional[int]=None, \n",
    "                 tn_targ:Optional[int]=None,\n",
    "                 margin:Optional[float]=0.8,\n",
    "                 ig_tok:Optional[int]=0,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.bsz, self.tn_targ, self.margin, self.ig_tok = bsz, tn_targ, margin, ig_tok\n",
    "        self.t = torch.ones((bsz, bsz), dtype=torch.int64).triu() if bsz is not None else None\n",
    "        self.u = torch.arange(bsz, dtype=torch.int64) if bsz is not None else None\n",
    "        self.v = torch.ones(tn_targ, dtype=torch.int64) if tn_targ is not None else None\n",
    "        self._parameters = {'t':self.t, 'u':self.u, 'v':self.v}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c7bd7-76b5-4c8b-9454-c866eb50f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 10\n",
    "batch = block.train.one_batch(bsz)\n",
    "data_logits, lbl2data_input_ids, lbl2data_data2ptr, data_embed, lbl2data_embed = m(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e84212-8ab0-45cf-9879-0e4fb826be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_fn = MultiTriplet(bsz, 10_000, 0.8, reduce='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e34cec-1523-4de0-953f-d1f6828f1709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def __call__(cls:MultiTriplet, \n",
    "             inp:torch.FloatTensor, \n",
    "             targ:torch.LongTensor, \n",
    "             n_inp2targ:torch.LongTensor,\n",
    "             margin:Optional[float]=None):\n",
    "    cls.margin = cls.margin if margin is None else margin\n",
    "    bsz, tn_targ, mn_targ = inp.shape[0], targ.shape[0], n_inp2targ.max()\n",
    "    t, u = cls.t[:bsz,:bsz], cls.u[:bsz]\n",
    "    v = (\n",
    "        torch.ones(tn_targ, dtype=torch.int64, device=targ.device)\n",
    "        if tn_targ > cls.tn_targ else cls.v[:tn_targ]\n",
    "    )\n",
    "    targ2inp_ptr = u.repeat_interleave(n_inp2targ)\n",
    "    s = targ@inp.T\n",
    "    ps = s.gather(1, targ2inp_ptr.view(-1,1))\n",
    "    \n",
    "    inp2targ_ptr = CUDALongTensor.matmul(n_inp2targ[None], t).squeeze(0)-1\n",
    "    xn_inp2targ = mn_targ-n_inp2targ+1\n",
    "    \n",
    "    r_targ = v.scatter(0, inp2targ_ptr, xn_inp2targ)\n",
    "    \n",
    "    targ2inp_ptrx = targ2inp_ptr.repeat_interleave(r_targ)\n",
    "    mask, maskx = F.one_hot(targ2inp_ptr), F.one_hot(targ2inp_ptrx)\n",
    "    fmask = CUDALongTensor.matmul(maskx,mask.T)\n",
    "    psx = ps.repeat_interleave(r_targ).view(bsz, -1, 1)\n",
    "    s = s.T.view(bsz, 1, -1)\n",
    "    fs = (s - psx + cls.margin).view(-1, tn_targ)\n",
    "    fs /= r_targ.repeat_interleave(r_targ).view(-1, 1)\n",
    "    \n",
    "    idx = torch.where(fmask == 0)\n",
    "    loss = fs[idx[0], idx[1]]\n",
    "    loss, n = torch.where(loss > 0, loss, 0), (n_inp2targ.sum())**2 - (n_inp2targ**2).sum()\n",
    "    if cls.reduction == 'mean': return (loss/n).sum()\n",
    "    elif cls.reduction == 'sum': return loss.sum()\n",
    "    else: raise ValueError(f'`reduction` cannot be `{cls.reduction}`')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0380db-6899-4f26-a250-4439bfe4790f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1562, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mtl_fn(data_embed, lbl2data_embed, lbl2data_data2ptr); loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b3dc7-b9b4-48ab-a4c9-06aabab60374",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __call__(cls:MultiTriplet, \n",
    "             inp:torch.FloatTensor, \n",
    "             targ:torch.LongTensor, \n",
    "             n_inp2targ:torch.LongTensor, \n",
    "             margin:Optional[float]=None):\n",
    "    cls.margin = cls.margin if margin is None else margin\n",
    "    score = inp@targ.T\n",
    "    ptr, fs = 0, []\n",
    "    for i, n in enumerate(n_inp2targ):\n",
    "        ps = score[i, ptr:ptr+n].view(-1, 1)\n",
    "        s = (score[i] - ps + cls.margin).roll(-ptr, 1)\n",
    "        fs.append(s[:, n:].flatten())\n",
    "        ptr += n.item()\n",
    "    loss = torch.hstack(fs)\n",
    "    loss = torch.where(loss > 0, loss, 0)\n",
    "    if cls.reduction == 'mean': return loss.mean()\n",
    "    elif cls.reduction == 'sum': return loss.sum()\n",
    "    else: raise ValueError(f'`reduction` cannot be `{cls.reduction}`')\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0eb396-8946-413f-a3b6-1733699a80a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1562, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mtl_fn(data_embed, lbl2data_embed, lbl2data_data2ptr); loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761c41de-b88c-4f6e-986d-988001e2e312",
   "metadata": {},
   "source": [
    "## SoupCon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8647bfa-4493-462d-a9cf-13f9fb643554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SoupCon(BaseLoss):\n",
    "\n",
    "    @delegates(BaseLoss.__init__)\n",
    "    def __init__(self,\n",
    "                 bsz:Optional[int]=None, \n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.t = torch.arange(bsz, dtype=torch.int64) if bsz is not None else None\n",
    "        self._parameters = {'t':self.t}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55345837-6b36-4c71-962e-2944b5c25899",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 100\n",
    "batch = block.train.one_batch(bsz)\n",
    "data_logits, data_logits, lbl2data_data2ptr, data_embed, lbl2data_embed = m(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7de068d-48d9-4279-8401-4a3e61c04410",
   "metadata": {},
   "outputs": [],
   "source": [
    "scn_fn = SoupCon(bsz, reduce='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc706ba-3c2c-4b91-8ac7-38937b43c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def __call__(cls:SoupCon,\n",
    "             inp:torch.FloatTensor,\n",
    "             targ:torch.LongTensor,\n",
    "             n_inp2targ:torch.LongTensor):\n",
    "    bsz = inp.shape[0]\n",
    "    t = cls.t[:bsz]\n",
    "    targ2inp_ptr = t.repeat_interleave(n_inp2targ)\n",
    "    s = -F.log_softmax(targ@inp.T, dim=0)\n",
    "    ps = s.gather(1, targ2inp_ptr.unsqueeze(1)).squeeze(1)\n",
    "    if cls.reduce == 'mean':\n",
    "        ps /= n_inp2targ.repeat_interleave(n_inp2targ)\n",
    "        ps /= bsz\n",
    "        return ps.sum()\n",
    "    elif cls.reduce == 'sum': return ps.sum()\n",
    "    else: raise ValueError(f'`reduction` cannot be `{cls.reduction}`')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a286e0ea-d88e-4334-8200-82da4586f581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.1438, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = scn_fn(data_embed, lbl2data_embed, lbl2data_data2ptr); loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f364910-e0ab-44ea-b1f2-e55e7332d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __call__(cls:SoupCon, \n",
    "             inp:torch.FloatTensor, \n",
    "             targ:torch.LongTensor, \n",
    "             n_inp2targ:torch.LongTensor):\n",
    "    bsz = inp.shape[0]\n",
    "    s = -F.log_softmax(inp@targ.T, dim=1)\n",
    "    ptr, loss = 0, []\n",
    "    for i,n in zip(s, n_inp2targ):\n",
    "        ps = i[ptr:ptr+n]\n",
    "        ptr += n\n",
    "        if cls.reduce == 'mean': ps = ps/n\n",
    "        loss.append(ps)\n",
    "    loss = torch.hstack(loss)\n",
    "    if cls.reduce == 'mean': return (loss/bsz).sum()\n",
    "    elif cls.reduce == 'sum': return loss.sum()\n",
    "    else: raise ValueError(f'`reduction` cannot be `{cls.reduction}`')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3580b6cf-0270-40e6-bbb2-d6a52bd65691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.1438, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = scn_fn(data_embed, lbl2data_embed, lbl2data_data2ptr); loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e13a4b-6055-48be-9da7-48f79171d2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
