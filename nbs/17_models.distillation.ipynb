{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03db601c-f6a8-4244-9489-1e893d36a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68e71b9-a1f1-41a5-b9c5-d61c5f5f684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f75c653-edf1-4772-922e-fce670d99293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, numpy as np, torch.nn.functional as F, torch.nn as nn\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "from types import MethodType\n",
    "\n",
    "from xcai.core import store_attr\n",
    "from xcai.losses import Cosine, MultiTriplet, MarginMSEWithNegatives, MultiTripletWithNegatives\n",
    "from xcai.models.PPP0XX import XCModelOutput\n",
    "from xcai.models.oak import OAK001\n",
    "from xcai.models.radga import RADOutput\n",
    "from xcai.bandits import *\n",
    "\n",
    "from transformers import DistilBertPreTrainedModel,DistilBertConfig\n",
    "from transformers.utils.generic import ModelOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a491a-2a8f-4be4-97ce-4ebf0e856b9a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2755bff4-23d1-4415-88d8-5ad60fce5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.main import *\n",
    "from xcai.basics import *\n",
    "from xcai.models.oak import OAK003\n",
    "from xcai.models.PPP0XX import DBT023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff33efb6-d64a-4348-82c0-4a0e207160ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/suchith720/Projects/data/'\n",
    "\n",
    "config_key = \"data_meta\"\n",
    "config_dir = \"/Users/suchith720/Projects/mogicX/configs\"\n",
    "pkl_dir = f\"{data_dir}/processed/mogicX\"\n",
    "pkl_file = get_pkl_file(pkl_dir, 'wikiseealsotitles_data-oak-for-msmarco-with-hard-negatives-test_distilbert-base-uncased', \n",
    "                        True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd42b42-24f5-4040-a18e-95c112dcebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = f\"{config_dir}/39_oak-for-msmarco-with-hard-negatives_test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50462f17-4163-4b23-bce7-1ec176aa7e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/suchith720/Projects/data//processed/mogicX/wikiseealsotitles_data-oak-for-msmarco-with-hard-negatives-test_distilbert-base-uncased_sxc.joblib'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deafe42b-f702-47dd-a84e-edce8cd2e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = build_block(pkl_file, config_file, True, config_key=config_key, only_test=False, main_oversample=True, \n",
    "                    meta_oversample={\"cat_meta\":False, \"lnk_meta\":True}, n_slbl_samples=5, \n",
    "                    n_sdata_meta_samples={\"cat_meta\":2, \"lnk_meta\":4}, do_build=False, \n",
    "                    train_meta_topk={\"lnk_meta\":10}, test_meta_topk={\"lnk_meta\":10}, return_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c1919-9607-476a-b7e9-4d9981a3a1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9301c35-8d44-4b11-91b0-2e9b64d0692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "block.train.dset.meta['neg_meta'] = SMetaXCDataset(prefix='neg', data_meta=block.train.dset.meta['cat_meta'].data_meta, \n",
    "                                                   lbl_meta=block.train.dset.meta['cat_meta'].lbl_meta, \n",
    "                                                   meta_info=block.train.dset.meta['cat_meta'].meta_info, \n",
    "                                                   return_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f72c6f-1fae-4ba0-8fb1-5f922795a585",
   "metadata": {},
   "source": [
    "## Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bacec6-08e3-41b9-9223-83dd00b4a98b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49802d94-0e03-4f7b-af0e-5d98575d7256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class TCHOutput(ModelOutput):\n",
    "    data_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_repr: Optional[torch.FloatTensor] = None\n",
    "    neg2data_repr: Optional[torch.FloatTensor] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e441ef-38a2-4019-9229-cbf0701b13de",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6beb4d1f-e135-437e-9ab6-fbe61466a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TCHConfig(DistilBertConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_data:Optional[int]=None,\n",
    "        n_lbl:Optional[int]=None,\n",
    "        n_neg:Optional[int]=None,\n",
    "        embed_dim:Optional[int]=None,\n",
    "        normalize:Optional[bool]=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_data, self.n_lbl, self.n_neg, self.embed_dim, self.normalize = n_data, n_lbl, n_neg, embed_dim, normalize\n",
    "        super().__init__(**kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390c4d68-dfeb-4e49-bc09-6efea5312c49",
   "metadata": {},
   "source": [
    "### `TCH001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1933df48-d500-4058-9676-30823f7c17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TCH001(DistilBertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config:TCHConfig, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.data_repr = nn.Embedding(config.n_data, config.dim)\n",
    "        self.lbl_repr = nn.Embedding(config.n_lbl, config.dim)\n",
    "        self.register_buffer(\"neg2lbl_idx\", None if config.n_neg is None else torch.arange(config.n_neg), persistent=True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def set_neg2lbl_idx_mapping(self, neg2lbl_idx:torch.Tensor):\n",
    "        assert neg2lbl_idx.shape[0] == self.neg2lbl_idx.shape[0], f\"Shape mismatch, `neg2lbl_idx` should have {self.neg2lbl_idx.shape[0]} elements.\"\n",
    "        self.neg2lbl_idx.copy_(neg2lbl_idx)\n",
    "\n",
    "    def get_lbl_embeddings(self):\n",
    "        return self.lbl_repr.weight\n",
    "\n",
    "    def get_data_embeddings(self):\n",
    "        return self.data_repr.weight\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_embeddings(self, data_repr:torch.Tensor, lbl_repr:torch.Tensor):\n",
    "        self.data_repr.weight.copy_(data_repr)\n",
    "        self.lbl_repr.weight.copy_(lbl_repr)\n",
    "\n",
    "    def freeze_embeddings(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "        self.lbl_repr.requires_grad_(False)\n",
    "\n",
    "    def freeze_data_embeddings(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_embeddings(self):\n",
    "        self.data_repr.requires_grad_(True)\n",
    "        self.lbl_repr.requires_grad_(True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:torch.Tensor,\n",
    "        lbl2data_idx:torch.Tensor,\n",
    "        neg2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return TCHOutput(\n",
    "            data_repr=self.data_repr(data_idx),\n",
    "            lbl2data_repr= self.lbl_repr(lbl2data_idx),\n",
    "            neg2data_repr=None if neg2data_idx is None else self.lbl_repr(self.neg2lbl_idx[neg2data_idx]) \n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea6134-e189-41d0-94c5-66c6aec5d586",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c2ba2ce-1e2d-40bc-a9e1-fbc820906db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TCHConfig(n_data=block.train.dset.n_data, n_lbl=block.n_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f3e206f-eb00-4c24-a68a-9bc776574ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TCH001(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6387798-d0c6-4984-89bd-f719ffe66eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.neg2lbl_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bc4bbe3-209f-4a87-a741-64fa4cd8120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_repr, lbl_repr = torch.randn(block.train.dset.n_data, 768), torch.randn(block.n_lbl, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "613aa045-cdaa-4bc0-bbb9-02c25c5d3f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([693082, 768]), torch.Size([312330, 768]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_repr.shape, lbl_repr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10167607-637b-4f74-b69e-9812846a0af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_embeddings(data_repr, lbl_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f75b489-d2f7-409d-8d74-5cd99c737c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))\n",
    "b = prepare_batch(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d757aab-fb94-4486-9e98-32ca4bdeb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21b36904-0600-4a43-bf12-7f437314aa0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 768]), torch.Size([5, 768]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.data_repr.shape, o.lbl2data_repr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a235a21e-e604-42e2-9f0f-639599a25ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa8490c8-e507-4018-b480-621f0aca37cd",
   "metadata": {},
   "source": [
    "### `TCH002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50684fc0-782c-40eb-a03f-767cfe8741bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TCH002(DistilBertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config:TCHConfig, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.data_repr = nn.Embedding(config.n_data, config.dim)\n",
    "        self.lbl_repr = nn.Embedding(config.n_lbl, config.dim)\n",
    "        self.lbl_embeddings = nn.Embedding(config.n_lbl, config.dim)\n",
    "\n",
    "    def get_lbl_embeddings(self):\n",
    "        return self.lbl_repr.weight + self.lbl_embeddings.weight\n",
    "\n",
    "    def get_data_embeddings(self):\n",
    "        return self.data_repr.weight\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_representations(self, data_repr:torch.Tensor, lbl_repr:torch.Tensor):\n",
    "        self.data_repr.weight.copy_(data_repr)\n",
    "        self.lbl_repr.weight.copy_(lbl_repr)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_lbl_embeddings(self):\n",
    "        nn.init.zeros_(self.lbl_embeddings.weight)\n",
    "\n",
    "    def freeze_representations(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "        self.lbl_repr.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_representations(self):\n",
    "        self.data_repr.requires_grad_(True)\n",
    "        self.lbl_repr.requires_grad_(True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:torch.Tensor,\n",
    "        lbl2data_idx:torch.Tensor,\n",
    "        neg2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        data_repr = self.data_repr(data_idx)\n",
    "        lbl2data_repr = self.lbl_repr(lbl2data_idx) + self.lbl_embeddings(lbl2data_idx)\n",
    "        neg2data_repr = None if neg2data_idx is None else self.lbl_repr(neg2data_idx) + self.lbl_embeddings(neg2data_idx)\n",
    "        return TCHOutput(\n",
    "            data_repr=data_repr,\n",
    "            lbl2data_repr=lbl2data_repr,\n",
    "            neg2data_repr=neg2data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb5c5f-ab1f-4e9c-ad7f-d4318450f3c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5942858c-17b7-49bd-8200-c7deae854ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_teacher = TCH002(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fc1bbdf-371f-462a-9afb-da10c3a24279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_teacher.data_repr.weight.requires_grad, m_teacher.lbl_repr.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a563fa1e-72c5-4201-ad39-2b44f9913073",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_teacher.freeze_representations()\n",
    "m_teacher.init_lbl_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78d318e5-ce58-4efa-93a3-5f81fe10c40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False, True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_teacher.data_repr.weight.requires_grad,m_teacher.lbl_repr.weight.requires_grad, m_teacher.lbl_embeddings.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09c5eb33-3e9f-47a6-be99-051132ab8750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_teacher.lbl_embeddings.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a75c6fa-d7ff-4ade-b8d9-afd3c17f4cfc",
   "metadata": {},
   "source": [
    "### `TCH003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90e50e24-ee21-460e-b8b9-3d85ef1e4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TCH003(DistilBertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config:TCHConfig, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.data_repr = nn.Embedding(config.n_data, config.dim)\n",
    "\n",
    "    def get_data_embeddings(self):\n",
    "        return self.data_repr.weight\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_embeddings(self, data_repr:torch.Tensor):\n",
    "        self.data_repr.weight.copy_(data_repr)\n",
    "\n",
    "    def freeze_embeddings(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_representations(self):\n",
    "        self.data_repr.requires_grad_(True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:torch.Tensor,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        data_repr = self.data_repr(data_idx)\n",
    "        data_repr = F.normalize(data_repr, dim=1) if self.config.normalize else data_repr\n",
    "        return TCHOutput(\n",
    "            data_repr=data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792886d2-a127-43f3-8bac-067be6c87209",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa138ec4-8cc8-48c4-86ee-495db960e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TCHConfig(n_data=1000, embed_dim=4096, normalize=False)\n",
    "model = TCH003(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87ccabd2-2c77-4bd0-bb24-311971ce7daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_repr, data_idx = torch.randn(1000, 768), torch.randint(0, 1000, size=(10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51480520-a470-4518-aa4e-945700ff9ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_embeddings(data_repr)\n",
    "model.freeze_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d559a18-3f26-4be2-a865-47342bab7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(data_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0235075a-f99d-4056-8ef9-c5412dbb069a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26.6562, 28.0896, 28.5650, 27.4916, 27.0713, 27.2589, 28.2481, 27.8620,\n",
       "        27.5937, 27.8447])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.data_repr.norm(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5f756c-81d8-440e-9e14-9b52547cc825",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `TCH004`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bca00b84-2d6e-424e-ae78-2f40fe10d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TCH004(DistilBertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config:TCHConfig, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.data_repr = nn.Embedding(config.n_data, config.embed_dim)\n",
    "        self.transform = nn.Linear(config.embed_dim, config.dim)\n",
    "\n",
    "    def get_data_embeddings(self):\n",
    "        return self.data_repr.weight\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_embeddings(self, data_repr:torch.Tensor):\n",
    "        self.data_repr.weight.copy_(data_repr)\n",
    "\n",
    "    def freeze_embeddings(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_representations(self):\n",
    "        self.data_repr.requires_grad_(True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_transform(self, embed:Optional[torch.Tensor]=None):\n",
    "        if embed is None: nn.init.eye_(self.transform.weight)\n",
    "        else: self.transform.weight.copy_(embed)\n",
    "        nn.init.zeros_(self.transform.bias)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:torch.Tensor,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        data_repr = self.transform(self.data_repr(data_idx))\n",
    "        data_repr = F.normalize(data_repr, dim=1) if self.config.normalize else data_repr\n",
    "        return TCHOutput(\n",
    "            data_repr=data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1002f47d-febd-4f48-91ba-494b93fa08bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2f7fae0-b3e3-482b-9bbe-e8b8abb2142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TCHConfig(n_data=1000, embed_dim=4096, normalize=False)\n",
    "model = TCH004(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9361d2ac-7fde-4607-8f27-640e3ad9b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_repr, data_idx = torch.randn(1000, 4096), torch.randint(0, 1000, size=(10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3fb0e88c-8f7c-4654-bb99-609590916295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.init_embeddings(data_repr)\n",
    "model.init_transform(torch.eye(config.dim, config.embed_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ecc60be7-a008-429f-ac6a-1fcc600241b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(data_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f69fe042-74fd-4507-9d3a-9ea1d0766da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28.8158, 28.0094, 26.3769, 27.1537, 28.1371, 28.5593, 27.6033, 28.7885,\n",
       "        28.6897, 27.2464], grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.data_repr.norm(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aeb38b-d71d-4698-8c7c-1b29b0bef609",
   "metadata": {},
   "source": [
    "## Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256836b-86d3-483a-9b2b-4228c1885ac5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fc54973-2117-4851-82dc-e84d88ccd872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class DTLOutput(ModelOutput):\n",
    "    loss:Optional[torch.FloatTensor]=None\n",
    "    data_repr: Optional[torch.FloatTensor] = None\n",
    "    data_fused_repr:Optional[torch.FloatTensor] = None\n",
    "    lbl2data_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_fused_repr:Optional[torch.FloatTensor] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bde0fe-ec90-477e-825e-5b20586b78f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e87fd03-636e-488f-bf87-326ddfa1cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTLConfig(DistilBertConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        teacher_data_student_label_loss_weight:Optional[float]=1.0,\n",
    "        student_data_teacher_label_loss_weight:Optional[float]=1.0,\n",
    "        data_mse_loss_weight:Optional[float]=0.1,\n",
    "        label_mse_loss_weight:Optional[float]=0.1,\n",
    "        teacher_data_repr_name:Optional[str]='data_repr',\n",
    "        student_data_repr_name:Optional[str]='data_fused_repr',\n",
    "        teacher_lbl2data_repr_name:Optional[str]='lbl2data_repr',\n",
    "        student_lbl2data_repr_name:Optional[str]='lbl2data_repr',\n",
    "        teacher_neg2data_repr_name:Optional[str]='neg2data_repr',\n",
    "        student_neg2data_repr_name:Optional[str]='neg2data_repr',\n",
    "        bandit_learning_rate:Optional[float]=0.01,\n",
    "        bandit_minimum_value:Optional[float]=0.1,\n",
    "        bandit_collector:Optional[int]=20,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.margin, self.tau, self.apply_softmax, self.n_negatives = margin, tau, apply_softmax, n_negatives\n",
    "        self.teacher_data_student_label_loss_weight = teacher_data_student_label_loss_weight\n",
    "        self.student_data_teacher_label_loss_weight = student_data_teacher_label_loss_weight\n",
    "        self.data_mse_loss_weight, self.label_mse_loss_weight = data_mse_loss_weight, label_mse_loss_weight\n",
    "        self.teacher_data_repr_name, self.student_data_repr_name = teacher_data_repr_name, student_data_repr_name\n",
    "        self.teacher_lbl2data_repr_name, self.student_lbl2data_repr_name = teacher_lbl2data_repr_name, student_lbl2data_repr_name\n",
    "        self.teacher_neg2data_repr_name, self.student_neg2data_repr_name = teacher_neg2data_repr_name, student_neg2data_repr_name\n",
    "        self.bandit_learning_rate, self.bandit_minimum_value = bandit_learning_rate, bandit_minimum_value\n",
    "        self.bandit_collector = bandit_collector\n",
    "        super().__init__(**kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da73d63-2d03-436c-9102-a2e2558c3dcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `DTL001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "edfc3ff0-3810-4264-af2a-0b2b3ffe9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL001(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(margin=config.margin, n_negatives=config.n_negatives, tau=config.tau, \n",
    "                                        apply_softmax=config.apply_softmax, reduce='mean')\n",
    "\n",
    "        if hasattr(m_student, 'get_label_representation'):\n",
    "            def get_label_representation(\n",
    "                self,\n",
    "                data_idx:Optional[torch.Tensor]=None,\n",
    "                data_input_ids:Optional[torch.Tensor]=None,\n",
    "                data_attention_mask:Optional[torch.Tensor]=None,\n",
    "                **kwargs\n",
    "            ):\n",
    "                return self.m_student.get_label_representation(data_idx, data_input_ids, data_attention_mask, **kwargs)\n",
    "            self.get_label_representation = MethodType(get_label_representation, self)\n",
    "\n",
    "    def combine_losses(self, student_loss:float, tdsl_loss:float, sdtl_loss:float, dm_loss:float, lm_loss:float, \n",
    "                       student_data_repr:Optional[torch.Tensor]=None, student_lbl2data_repr:Optional[torch.Tensor]=None, **kwargs):\n",
    "        loss = student_loss\n",
    "        loss += self.config.teacher_data_student_label_loss_weight * tdsl_loss\n",
    "        loss += self.config.student_data_teacher_label_loss_weight * sdtl_loss\n",
    "        loss += self.config.data_mse_loss_weight * dm_loss + self.config.label_mse_loss_weight * lm_loss\n",
    "        return loss\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "        student_data_repr = getattr(student_o, self.config.student_data_repr_name, None)\n",
    "        student_lbl2data_repr = getattr(student_o, self.config.student_lbl2data_repr_name, None)\n",
    "\n",
    "        loss = None\n",
    "        if student_o.loss is not None:\n",
    "            with torch.no_grad(): teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
    "            teacher_data_repr = getattr(student_o, self.config.teacher_data_repr_name, None)\n",
    "            teacher_lbl2data_repr = getattr(student_o, self.config.teacher_lbl2data_repr_name, None)\n",
    "\n",
    "            tdsl_loss = 0.0\n",
    "            if teacher_data_repr is not None and student_lbl2data_repr is not None and self.config.teacher_data_student_label_loss_weight > 0:\n",
    "                tdsl_loss = self.rep_loss_fn(teacher_data_repr, student_lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                             kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            sdtl_loss = 0.0\n",
    "            if student_data_repr is not None and teacher_lbl2data_repr is not None and self.config.student_data_teacher_label_loss_weight > 0:\n",
    "                sdtl_loss = self.rep_loss_fn(student_data_repr, teacher_lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                             kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            dm_loss = 0.0\n",
    "            if teacher_data_repr is not None and student_data_repr is not None and self.config.data_mse_loss_weight > 0:\n",
    "                dm_loss = self.mse_loss_fn(teacher_data_repr, student_data_repr)\n",
    "\n",
    "            lm_loss = 0.0\n",
    "            if teacher_lbl2data_repr is not None and student_lbl2data_repr is not None and self.config.label_mse_loss_weight > 0:\n",
    "                lm_loss = self.mse_loss_fn(teacher_lbl2data_repr, student_lbl2data_repr)\n",
    "\n",
    "            loss = self.combine_losses(student_o.loss, tdsl_loss, sdtl_loss, dm_loss, lm_loss, \n",
    "                                       student_data_repr, student_lbl2data_repr, lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "\n",
    "        return DTLOutput(\n",
    "            loss=loss,\n",
    "            data_repr=getattr(student_o, 'data_repr', None),\n",
    "            data_fused_repr=getattr(student_o, 'data_fused_repr', None),\n",
    "            lbl2data_repr=getattr(student_o, 'lbl2data_repr', None),\n",
    "            lbl2data_fused_repr=getattr(student_o, 'lbl2data_fused_repr', None),\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a78aa-3918-4e7a-9893-d0c3c8a49709",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c261461-7748-4b0c-9632-a8699d8cab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TCHConfig(n_data=1000, embed_dim=4096, normalize=False)\n",
    "m_teacher = TCH004(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "874714fd-e21d-482c-b967-9355d82813e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK003 were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "mname = 'distilbert-base-uncased'\n",
    "meta_name = 'lnk'\n",
    "\n",
    "m_student = OAK003.from_pretrained(mname, margin=0.3, num_negatives=10, tau=0.1, apply_softmax=True,\n",
    "                                   \n",
    "                                   data_aug_meta_prefix=f'{meta_name}2data', lbl2data_aug_meta_prefix=None,\n",
    "                               \n",
    "                                   num_metadata=block.train.dset.meta[f'{meta_name}_meta'].n_meta,\n",
    "                                   \n",
    "                                   calib_margin=0.05, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                                   calib_loss_weight=0.1, use_calib_loss=True,\n",
    "                                   \n",
    "                                   use_query_loss=True,\n",
    "                                   \n",
    "                                   use_encoder_parallel=True, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13cd6e1a-7bb5-4a5a-9a6f-affd17a42af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DTLConfig(margin=0.3, tau=0.1, apply_softmax=False, n_negatives=5, \n",
    "                   teacher_data_student_label_loss_weight=1.0, student_data_teacher_label_loss_weight=1.0,\n",
    "                   data_mse_loss_weight=0.1, label_mse_loss_weight=0.1,\n",
    "                   teacher_data_repr_name='data_repr', student_data_repr_name='data_fused_repr',\n",
    "                   teacher_label_repr_name='lbl2data_repr', student_label_repr_name='lbl2data_repr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d8a728f7-cabf-462d-b149-c6a0def6fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL001(config, m_student=m_student, m_teacher=m_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1adae-4949-41a0-b43a-167854daf284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd84c719-65cb-446d-a4dc-26474dbf1cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(10)\n",
    "b = prepare_batch(model, batch, m_args=['data_input_ids', 'data_attention_mask', 'lbl2data_data2ptr', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx',\n",
    "                                        'lnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', \n",
    "                                        'lnk2data_attention_mask', 'plnk2data_data2ptr', 'plnk2data_idx',\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00ea3bc8-b733-4fc9-8854-9ded8d873110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "o = model(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c49c2af-b11c-4feb-b4df-c6a2bd1721e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6609, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944d34d-d6f0-40e7-ac13-98f7ac9331cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `DTL002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c48ebd6d-e8fe-479f-8356-6fc867b74162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL002(DTL001):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        rest_init = [self.config.teacher_data_student_label_loss_weight, self.config.student_data_teacher_label_loss_weight, \n",
    "                     self.config.data_mse_loss_weight, self.config.label_mse_loss_weight]\n",
    "        self.loss_weights = RLLossWeightsCumuluative(num_samples=len(rest_init), reward_func=AccMiniBatch, lr=self.config.bandit_learning_rate, \n",
    "                                                     collector=self.config.bandit_collector, std=0.1, min=self.config.bandit_minimum_value,\n",
    "                                                     rest_init=rest_init)\n",
    "\n",
    "    def combine_losses(self, student_loss:float, tdsl_loss:float, sdtl_loss:float, dm_loss:float, lm_loss:float, \n",
    "                       student_data_repr:Optional[torch.Tensor]=None, student_lbl2data_repr:Optional[torch.Tensor]=None, **kwargs):\n",
    "        ws = self.loss_weights.sample(kwargs['lbl2data_idx'].device)\n",
    "        if self.training:\n",
    "            self.loss_weights.step(student_data_repr, student_lbl2data_repr, kwargs['lbl2data_data2ptr'], \n",
    "                                   kwargs['lbl2data_idx'], kwargs['plbl2data_data2ptr'], \n",
    "                                   kwargs['plbl2data_idx'])\n",
    "        loss = student_loss + ws[0]*tdsl_loss + ws[1]*sdtl_loss + ws[2]*dm_loss + ws[3]*lm_loss\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e305f42-c82a-4fd9-a791-4801f3a2c9c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed9412bc-b06a-46a7-bb99-c53978689687",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TCHConfig(n_data=1000, embed_dim=4096, normalize=False)\n",
    "m_teacher = TCH004(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac942e0f-4a90-4092-8eeb-c7eb236a5d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK003 were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "mname = 'distilbert-base-uncased'\n",
    "meta_name = 'lnk'\n",
    "\n",
    "m_student = OAK003.from_pretrained(mname, margin=0.3, num_negatives=10, tau=0.1, apply_softmax=True,\n",
    "                                   \n",
    "                                   data_aug_meta_prefix=f'{meta_name}2data', lbl2data_aug_meta_prefix=None,\n",
    "                               \n",
    "                                   num_metadata=block.train.dset.meta[f'{meta_name}_meta'].n_meta,\n",
    "                                   \n",
    "                                   calib_margin=0.05, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                                   calib_loss_weight=0.1, use_calib_loss=True,\n",
    "                                   \n",
    "                                   use_query_loss=True,\n",
    "                                   \n",
    "                                   use_encoder_parallel=True, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92432fa5-2148-45e6-b555-c1a8f833065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DTLConfig(margin=0.3, tau=0.1, apply_softmax=False, n_negatives=5, \n",
    "                   teacher_data_student_label_loss_weight=1.0, student_data_teacher_label_loss_weight=1.0,\n",
    "                   data_mse_loss_weight=0.1, label_mse_loss_weight=0.1,\n",
    "                   teacher_data_repr_name='data_repr', student_data_repr_name='data_fused_repr',\n",
    "                   teacher_label_repr_name='lbl2data_repr', student_label_repr_name='lbl2data_repr', \n",
    "                   bandit_learning_rate=0.01, bandit_minimum_value=0.1, bandit_collector=20,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df81900c-d770-4f22-a6f2-011ad8c96cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL001(config, m_student=m_student, m_teacher=m_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3900de23-c418-4724-8b2a-7c72aa391b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa3963e8-a813-4db6-916b-e5e7f38696cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(10)\n",
    "b = prepare_batch(model, batch, m_args=['data_input_ids', 'data_attention_mask', 'lbl2data_data2ptr', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx',\n",
    "                                        'lnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', \n",
    "                                        'lnk2data_attention_mask', 'plnk2data_data2ptr', 'plnk2data_idx',\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8766cc33-2c3e-4c96-a4a0-0ca63a21f35b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suchith720/Projects/xcai/xcai/losses.py:27: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:55.)\n",
      "  torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device, size=size)\n"
     ]
    }
   ],
   "source": [
    "o = model(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ea5a554-52fa-455d-87e3-858d8459866a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6511, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913f363c-3a80-4a35-9164-2ed30c7a4375",
   "metadata": {},
   "source": [
    "### `DTL003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9d490b9-25c8-49a7-9b0d-bdbf2bb8b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL003(DTL001):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.rep_loss_fn = self.rep_loss_fn = MarginMSEWithNegatives()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        neg2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "        student_data_repr = getattr(student_o, self.config.student_data_repr_name, None)\n",
    "        student_lbl2data_repr = getattr(student_o, self.config.student_lbl2data_repr_name, None)\n",
    "        student_neg2data_repr = getattr(student_o, self.config.student_neg2data_repr_name, None)\n",
    "\n",
    "        loss = None\n",
    "        if student_o.loss is not None:\n",
    "            with torch.no_grad(): \n",
    "                teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx, neg2data_idx=neg2data_idx)\n",
    "            teacher_data_repr = getattr(student_o, self.config.teacher_data_repr_name, None)\n",
    "            teacher_lbl2data_repr = getattr(student_o, self.config.teacher_lbl2data_repr_name, None)\n",
    "            teacher_neg2data_repr = getattr(student_o, self.config.teacher_neg2data_repr_name, None)\n",
    "\n",
    "            tdsl_loss = 0.0\n",
    "            if (\n",
    "                teacher_data_repr is not None and student_lbl2data_repr is not None and \n",
    "                student_neg2data_repr is not None and self.config.teacher_data_student_label_loss_weight > 0\n",
    "            ):\n",
    "                tdsl_loss = self.rep_loss_fn(teacher_data_repr, student_lbl2data_repr, kwargs['lbl2data_scores'], \n",
    "                                             student_neg2data_repr, kwargs['neg2data_scores'], **kwargs)\n",
    "            \n",
    "            sdtl_loss = 0.0\n",
    "            if (\n",
    "                student_data_repr is not None and teacher_lbl2data_repr is not None and \n",
    "                teacher_neg2data_repr is not None and self.config.student_data_teacher_label_loss_weight > 0\n",
    "            ):\n",
    "                sdtl_loss = self.rep_loss_fn(student_data_repr, teacher_lbl2data_repr, kwargs['lbl2data_scores'], \n",
    "                                             teacher_neg2data_repr, kwargs['neg2data_scores'], **kwargs)\n",
    "                \n",
    "            dm_loss = 0.0\n",
    "            if teacher_data_repr is not None and student_data_repr is not None and self.config.data_mse_loss_weight > 0:\n",
    "                dm_loss = self.mse_loss_fn(teacher_data_repr, student_data_repr)\n",
    "\n",
    "            lm_loss = 0.0\n",
    "            if teacher_lbl2data_repr is not None and student_lbl2data_repr is not None and self.config.label_mse_loss_weight > 0:\n",
    "                lm_loss += self.mse_loss_fn(teacher_lbl2data_repr, student_lbl2data_repr)\n",
    "                \n",
    "            if teacher_neg2data_repr is not None and student_neg2data_repr is not None and self.config.label_mse_loss_weight > 0:\n",
    "                lm_loss += self.mse_loss_fn(teacher_neg2data_repr, student_neg2data_repr)\n",
    "\n",
    "            loss = self.combine_losses(student_o.loss, tdsl_loss, sdtl_loss, dm_loss, lm_loss, \n",
    "                                       student_data_repr, student_lbl2data_repr, lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "            \n",
    "        return DTLOutput(\n",
    "            loss=loss,\n",
    "            data_repr=getattr(student_o, 'data_repr', None),\n",
    "            data_fused_repr=getattr(student_o, 'data_fused_repr', None),\n",
    "            lbl2data_repr=getattr(student_o, 'lbl2data_repr', None),\n",
    "            lbl2data_fused_repr=getattr(student_o, 'lbl2data_fused_repr', None),\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49270c88-8ced-4939-b063-1e7e332f2e94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f12dbe18-1f8c-461c-8e96-aa786e8d4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TCHConfig(n_data=1000, embed_dim=4096, normalize=False)\n",
    "m_teacher = TCH004(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19bfe40-6e68-4227-bf09-0cf682d874c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d643badb-4346-4865-885d-1099191aeed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT023 were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.projector.bias', 'encoder.projector.weight', 'encoder.transform.bias', 'encoder.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "mname = 'distilbert-base-uncased'\n",
    "meta_name = 'lnk'\n",
    "\n",
    "m_student = DBT023.from_pretrained(mname, use_encoder_parallel=True, normalize=False, use_layer_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5080ab14-1982-4880-b586-36fc44bd1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DTLConfig(margin=0.3, tau=0.1, apply_softmax=False, n_negatives=5, \n",
    "                   teacher_data_student_label_loss_weight=1.0, student_data_teacher_label_loss_weight=1.0,\n",
    "                   data_mse_loss_weight=0.1, label_mse_loss_weight=0.1,\n",
    "                   teacher_data_repr_name='data_repr', student_data_repr_name='data_fused_repr',\n",
    "                   teacher_lbl2data_repr_name='lbl2data_repr', student_lbl2data_repr_name='lbl2data_repr', \n",
    "                   teacher_neg2data_repr_name='neg2data_repr', student_neg2data_repr_name='neg2data_repr',\n",
    "                   bandit_learning_rate=0.01, bandit_minimum_value=0.1, bandit_collector=20,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60f44677-3fd4-489b-bf37-aef621d36491",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL003(config, m_student=m_student, m_teacher=m_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbe4f4-6e27-4d2d-8555-b72af40b91ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a87ab3bf-7507-43df-b8c7-c85bc04e80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(10)\n",
    "b = prepare_batch(model, batch, m_args=['data_input_ids', 'data_attention_mask', 'lbl2data_data2ptr', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'lbl2data_scores', 'plbl2data_data2ptr', 'plbl2data_idx',\n",
    "                                        'neg2data_data2ptr', 'neg2data_idx', 'neg2data_input_ids', 'neg2data_attention_mask', \n",
    "                                        'neg2data_scores', 'pneg2data_data2ptr', 'pneg2data_idx',\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "79b9c5ef-dde5-4add-b2b5-e1e70a91b14e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "o = model(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f5dc776-7dbc-4a51-8715-884180f5dc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4043, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3af03b-a511-4921-b079-f07b030cffcd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `DTL004`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "312c9131-9d27-4311-8bd3-ef055a92754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL004(DTL001):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.rep_loss_fn = MultiTripletWithNegatives(margin=config.margin, n_negatives=config.n_negatives, \n",
    "                                                     tau=config.tau, apply_softmax=config.apply_softmax, \n",
    "                                                     reduce='mean')\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        neg2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "        student_data_repr = getattr(student_o, self.config.student_data_repr_name, None)\n",
    "        student_lbl2data_repr = getattr(student_o, self.config.student_lbl2data_repr_name, None)\n",
    "        student_neg2data_repr = getattr(student_o, self.config.student_neg2data_repr_name, None)\n",
    "\n",
    "        loss = None\n",
    "        if student_o.loss is not None:\n",
    "            with torch.no_grad(): \n",
    "                teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx, neg2data_idx=neg2data_idx)\n",
    "            teacher_data_repr = getattr(student_o, self.config.teacher_data_repr_name, None)\n",
    "            teacher_lbl2data_repr = getattr(student_o, self.config.teacher_lbl2data_repr_name, None)\n",
    "            teacher_neg2data_repr = getattr(student_o, self.config.teacher_neg2data_repr_name, None)\n",
    "\n",
    "            tdsl_loss = 0.0\n",
    "            if (\n",
    "                teacher_data_repr is not None and student_lbl2data_repr is not None and \n",
    "                student_neg2data_repr is not None and self.config.teacher_data_student_label_loss_weight > 0\n",
    "            ):\n",
    "                tdsl_loss = self.rep_loss_fn(teacher_data_repr, pos_targ=student_lbl2data_repr, \n",
    "                                             n_pos=kwargs['lbl2data_data2ptr'], pos_idx=kwargs['lbl2data_idx'], \n",
    "                                             neg_targ=student_neg2data_repr, n_neg=kwargs['neg2data_data2ptr'], \n",
    "                                             neg_idx=kwargs['neg2data_idx'], n_ppos=kwargs['plbl2data_data2ptr'], \n",
    "                                             ppos_idx=kwargs['plbl2data_idx'], **kwargs)\n",
    "                \n",
    "            sdtl_loss = 0.0\n",
    "            if (\n",
    "                student_data_repr is not None and teacher_lbl2data_repr is not None and \n",
    "                teacher_neg2data_repr is not None and self.config.student_data_teacher_label_loss_weight > 0\n",
    "            ):\n",
    "                sdtl_loss = self.rep_loss_fn(student_data_repr, pos_targ=teacher_lbl2data_repr, \n",
    "                                             n_pos=kwargs['lbl2data_data2ptr'], pos_idx=kwargs['lbl2data_idx'], \n",
    "                                             neg_targ=teacher_neg2data_repr, n_neg=kwargs['neg2data_data2ptr'], \n",
    "                                             neg_idx=kwargs['neg2data_idx'], n_ppos=kwargs['plbl2data_data2ptr'], \n",
    "                                             ppos_idx=kwargs['plbl2data_idx'], **kwargs)\n",
    "                \n",
    "            dm_loss = 0.0\n",
    "            if teacher_data_repr is not None and student_data_repr is not None and self.config.data_mse_loss_weight > 0:\n",
    "                dm_loss = self.mse_loss_fn(teacher_data_repr, student_data_repr)\n",
    "\n",
    "            lm_loss = 0.0\n",
    "            if teacher_lbl2data_repr is not None and student_lbl2data_repr is not None and self.config.label_mse_loss_weight > 0:\n",
    "                lm_loss += self.mse_loss_fn(teacher_lbl2data_repr, student_lbl2data_repr)\n",
    "                \n",
    "            if teacher_neg2data_repr is not None and student_neg2data_repr is not None and self.config.label_mse_loss_weight > 0:\n",
    "                lm_loss += self.mse_loss_fn(teacher_neg2data_repr, student_neg2data_repr)\n",
    "\n",
    "            loss = self.combine_losses(student_o.loss, tdsl_loss, sdtl_loss, dm_loss, lm_loss, \n",
    "                                       student_data_repr, student_lbl2data_repr, lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "\n",
    "        return DTLOutput(\n",
    "            loss=loss,\n",
    "            data_repr=getattr(student_o, 'data_repr', None),\n",
    "            data_fused_repr=getattr(student_o, 'data_fused_repr', None),\n",
    "            lbl2data_repr=getattr(student_o, 'lbl2data_repr', None),\n",
    "            lbl2data_fused_repr=getattr(student_o, 'lbl2data_fused_repr', None),\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40521b-148d-42db-8922-9b57bf77f656",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e3f910d8-edea-48b3-a76c-73e62d07fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TCHConfig(n_data=1000, embed_dim=4096, normalize=False)\n",
    "m_teacher = TCH004(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ee7d6-c3b8-4a77-9a4e-588604f62c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f16728a-739a-40dc-9b42-c1a1f5d463e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT023 were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.projector.bias', 'encoder.projector.weight', 'encoder.transform.bias', 'encoder.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "mname = 'distilbert-base-uncased'\n",
    "meta_name = 'lnk'\n",
    "\n",
    "m_student = DBT023.from_pretrained(mname, use_encoder_parallel=True, normalize=False, use_layer_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "48461977-593b-4a51-afb3-492fab59e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DTLConfig(margin=0.3, tau=0.1, apply_softmax=False, n_negatives=5, \n",
    "                   teacher_data_student_label_loss_weight=1.0, student_data_teacher_label_loss_weight=1.0,\n",
    "                   data_mse_loss_weight=0.1, label_mse_loss_weight=0.1,\n",
    "                   teacher_data_repr_name='data_repr', student_data_repr_name='data_fused_repr',\n",
    "                   teacher_lbl2data_repr_name='lbl2data_repr', student_lbl2data_repr_name='lbl2data_repr', \n",
    "                   teacher_neg2data_repr_name='neg2data_repr', student_neg2data_repr_name='neg2data_repr',\n",
    "                   bandit_learning_rate=0.01, bandit_minimum_value=0.1, bandit_collector=20,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "75d6da8c-52aa-4531-a5c8-8b5e6227f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL004(config, m_student=m_student, m_teacher=m_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6adff7b-826e-43e0-9530-7cd04ba66575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0285e0a6-40db-44f0-9378-5e52a630d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(10)\n",
    "b = prepare_batch(model, batch, m_args=['data_input_ids', 'data_attention_mask', 'lbl2data_data2ptr', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'lbl2data_scores', 'plbl2data_data2ptr', 'plbl2data_idx',\n",
    "                                        'neg2data_data2ptr', 'neg2data_idx', 'neg2data_input_ids', 'neg2data_attention_mask', \n",
    "                                        'neg2data_scores', 'pneg2data_data2ptr', 'pneg2data_idx',\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "451a0f59-ea8f-46dd-8aed-d740cc0f7196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "o = model(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7d8e105e-2d77-42ac-a63d-688f3c40be2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6274, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf303a-7ac9-4839-8e89-be12ef3e4db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
