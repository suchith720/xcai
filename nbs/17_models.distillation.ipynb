{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db601c-f6a8-4244-9489-1e893d36a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e71b9-a1f1-41a5-b9c5-d61c5f5f684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f75c653-edf1-4772-922e-fce670d99293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import torch, numpy as np\n",
    "from typing import Optional\n",
    "import torch.nn as nn\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from xcai.core import store_attr\n",
    "from xcai.losses import Cosine, MultiTriplet\n",
    "from xcai.models.PPP0XX import XCModelOutput\n",
    "from xcai.models.oak import OAK001\n",
    "from xcai.models.radga import RADOutput\n",
    "from transformers import DistilBertPreTrainedModel,DistilBertConfig\n",
    "from transformers.utils.generic import ModelOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755bff4-23d1-4415-88d8-5ad60fce5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,torch, pickle, numpy as np\n",
    "\n",
    "from xcai.block import *\n",
    "from xcai.basics import *\n",
    "from xcai.models.PPP0XX import DBT010\n",
    "from xcai.models.radga import RAD006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a491a-2a8f-4be4-97ce-4ebf0e856b9a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff33efb6-d64a-4348-82c0-4a0e207160ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealso_data-metas_distilbert-base-uncased_rm_radga-aug-cat-hlk-block-128.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50462f17-4163-4b23-bce7-1ec176aa7e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/scai/phd/aiz218323/scratch/datasets/processed/wikiseealso_data-metas_distilbert-base-uncased_rm_radga-aug-cat-hlk-block-128.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls {pkl_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deafe42b-f702-47dd-a84e-edce8cd2e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852f6fe-e923-4fbb-a0ce-70ff38a808b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "block.train.dset.data.data_info['aug_input_ids'] = block.train.dset.data.data_info['input_ids_aug_cat']\n",
    "block.train.dset.data.data_info['aug_attention_mask'] = block.train.dset.data.data_info['attention_mask_aug_cat']\n",
    "block.test.dset.data.data_info['aug_input_ids'] = block.test.dset.data.data_info['input_ids_aug_cat']\n",
    "block.test.dset.data.data_info['aug_attention_mask'] = block.test.dset.data.data_info['attention_mask_aug_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32199d9f-9658-4258-981b-bad4c4af8496",
   "metadata": {},
   "outputs": [],
   "source": [
    "block.train.dset.data.data_info['input_ids'] = block.train.dset.data.data_info['input_ids_aug_cat']\n",
    "block.train.dset.data.data_info['attention_mask'] = block.train.dset.data.data_info['attention_mask_aug_cat']\n",
    "block.test.dset.data.data_info['input_ids'] = block.test.dset.data.data_info['input_ids_aug_cat']\n",
    "block.test.dset.data.data_info['attention_mask'] = block.test.dset.data.data_info['attention_mask_aug_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a6c5f-55c0-46a2-9392-b42ff79c5f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf31a0fe-5a74-4ba7-b810-f1a2c4385098",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets/'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealso_data-metas_distilbert-base-uncased_rm_radga-cat-linker.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d69224-e55b-449c-bbc6-7831eeea4c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d8ec57-1a35-451a-ba1d-f690fcc9a6a1",
   "metadata": {},
   "source": [
    "## Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed233f6c-076e-478c-8240-f9f8c9c2ce12",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2584330-1d7f-459f-b650-4673f3689aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6459017-bae6-423f-8c6f-7c1d4ebcb58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = XCLearningArguments(\n",
    "    output_dir='/home/scai/phd/aiz218323/scratch/outputs/69-distillation-for-wikiseealso-1-4',\n",
    "    logging_first_step=True,\n",
    "    per_device_train_batch_size=800,\n",
    "    per_device_eval_batch_size=800,\n",
    "    representation_num_beams=200,\n",
    "    representation_accumulation_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=3000,\n",
    "    save_steps=3000,\n",
    "    save_total_limit=5,\n",
    "    num_train_epochs=300,\n",
    "    predict_with_representation=True,\n",
    "    representation_search_type='BRUTEFORCE',\n",
    "    adam_epsilon=1e-6,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-4,\n",
    "    group_by_cluster=True,\n",
    "    num_clustering_warmup_epochs=10,\n",
    "    num_cluster_update_epochs=5,\n",
    "    num_cluster_size_update_epochs=25,\n",
    "    clustering_type='EXPO',\n",
    "    minimum_cluster_size=2,\n",
    "    maximum_cluster_size=1600,\n",
    "    target_indices_key='plbl2data_idx',\n",
    "    target_pointer_key='plbl2data_data2ptr',\n",
    "    use_encoder_parallel=True,\n",
    "    max_grad_norm=None,\n",
    "    fp16=True,\n",
    "    label_names=['lbl2data_idx', 'lbl2data_input_ids', 'lbl2data_attention_mask'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c512277b-dac2-4668-83d5-3b63cc95ec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT010 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.dr_layer_norm.bias', 'encoder.dr_layer_norm.weight', 'encoder.dr_projector.bias', 'encoder.dr_projector.weight', 'encoder.dr_transform.bias', 'encoder.dr_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['distilbert.embeddings.word_embeddings.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = '/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-4'\n",
    "output_dir = f\"/home/scai/phd/aiz218323/scratch/outputs/{os.path.basename(model_output)}\"\n",
    "mname = f'{output_dir}/{os.path.basename(get_best_model(output_dir))}'\n",
    "\n",
    "m_teacher = DBT010.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', bsz=800, tn_targ=5000, margin=0.3, tau=0.1, \n",
    "                                   n_negatives=10, apply_softmax=True, use_encoder_parallel=True)\n",
    "\n",
    "model_weight_file,model_weights = f'{mname}/model.safetensors',{}\n",
    "with safe_open(model_weight_file, framework=\"pt\") as file:\n",
    "    for k in file.keys(): model_weights[k] = file.get_tensor(k)\n",
    "\n",
    "m_teacher.load_state_dict(model_weights, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9296ba6-3455-4f9d-8cb5-b736f8e384ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PrecRecl(block.n_lbl, block.test.data_lbl_filterer, prop=block.train.dset.data.data_lbl,\n",
    "                  pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193aade-479e-4bbb-96f1-a7f76bb8eadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "learn = XCLearner(\n",
    "    model=m_teacher, \n",
    "    args=args,\n",
    "    train_dataset=block.train.dset,\n",
    "    eval_dataset=block.test.dset,\n",
    "    data_collator=block.collator,\n",
    "    compute_metrics=metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2e6525-d162-406f-b2f2-6e2ef7c151cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc690ff89e84921a9aa3e546ca98fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "o = learn.predict(block.test.dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d27cc-c6c9-49a1-bc2d-7c523e20cb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>N@1</th>\n",
       "      <th>N@3</th>\n",
       "      <th>N@5</th>\n",
       "      <th>N@10</th>\n",
       "      <th>PSP@1</th>\n",
       "      <th>PSP@3</th>\n",
       "      <th>PSP@5</th>\n",
       "      <th>PSP@10</th>\n",
       "      <th>PSN@1</th>\n",
       "      <th>PSN@3</th>\n",
       "      <th>PSN@5</th>\n",
       "      <th>PSN@10</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@100</th>\n",
       "      <th>R@200</th>\n",
       "      <th>loss</th>\n",
       "      <th>runtime</th>\n",
       "      <th>samples_per_second</th>\n",
       "      <th>steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.9849</td>\n",
       "      <td>28.9636</td>\n",
       "      <td>21.6018</td>\n",
       "      <td>13.4459</td>\n",
       "      <td>44.9849</td>\n",
       "      <td>44.4991</td>\n",
       "      <td>45.9046</td>\n",
       "      <td>48.3028</td>\n",
       "      <td>31.7676</td>\n",
       "      <td>34.6033</td>\n",
       "      <td>37.4802</td>\n",
       "      <td>42.9854</td>\n",
       "      <td>31.7676</td>\n",
       "      <td>35.671</td>\n",
       "      <td>38.1608</td>\n",
       "      <td>41.1199</td>\n",
       "      <td>54.4304</td>\n",
       "      <td>70.9628</td>\n",
       "      <td>74.1619</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>289.8157</td>\n",
       "      <td>612.51</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P@1      P@3      P@5     P@10      N@1      N@3      N@5     N@10  \\\n",
       "0  44.9849  28.9636  21.6018  13.4459  44.9849  44.4991  45.9046  48.3028   \n",
       "\n",
       "     PSP@1    PSP@3    PSP@5   PSP@10    PSN@1   PSN@3    PSN@5   PSN@10  \\\n",
       "0  31.7676  34.6033  37.4802  42.9854  31.7676  35.671  38.1608  41.1199   \n",
       "\n",
       "      R@10    R@100    R@200    loss   runtime  samples_per_second  \\\n",
       "0  54.4304  70.9628  74.1619  0.0177  289.8157              612.51   \n",
       "\n",
       "   steps_per_second  \n",
       "0             0.383  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_metric(o.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b98573c-fbea-4303-9449-32bd09e1dc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>N@1</th>\n",
       "      <th>N@3</th>\n",
       "      <th>N@5</th>\n",
       "      <th>N@10</th>\n",
       "      <th>PSP@1</th>\n",
       "      <th>PSP@3</th>\n",
       "      <th>PSP@5</th>\n",
       "      <th>PSP@10</th>\n",
       "      <th>PSN@1</th>\n",
       "      <th>PSN@3</th>\n",
       "      <th>PSN@5</th>\n",
       "      <th>PSN@10</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@100</th>\n",
       "      <th>R@200</th>\n",
       "      <th>loss</th>\n",
       "      <th>runtime</th>\n",
       "      <th>samples_per_second</th>\n",
       "      <th>steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.1787</td>\n",
       "      <td>25.1231</td>\n",
       "      <td>18.8719</td>\n",
       "      <td>11.9556</td>\n",
       "      <td>39.1787</td>\n",
       "      <td>38.7991</td>\n",
       "      <td>40.2252</td>\n",
       "      <td>42.7056</td>\n",
       "      <td>27.7771</td>\n",
       "      <td>30.1143</td>\n",
       "      <td>32.8007</td>\n",
       "      <td>38.2846</td>\n",
       "      <td>27.7771</td>\n",
       "      <td>31.0783</td>\n",
       "      <td>33.3646</td>\n",
       "      <td>36.2856</td>\n",
       "      <td>49.0181</td>\n",
       "      <td>66.5973</td>\n",
       "      <td>70.1792</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>343.8718</td>\n",
       "      <td>516.224</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P@1      P@3      P@5     P@10      N@1      N@3      N@5     N@10  \\\n",
       "0  39.1787  25.1231  18.8719  11.9556  39.1787  38.7991  40.2252  42.7056   \n",
       "\n",
       "     PSP@1    PSP@3    PSP@5   PSP@10    PSN@1    PSN@3    PSN@5   PSN@10  \\\n",
       "0  27.7771  30.1143  32.8007  38.2846  27.7771  31.0783  33.3646  36.2856   \n",
       "\n",
       "      R@10    R@100    R@200    loss   runtime  samples_per_second  \\\n",
       "0  49.0181  66.5973  70.1792  0.0198  343.8718             516.224   \n",
       "\n",
       "   steps_per_second  \n",
       "0             0.323  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_metric(o.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395ca7e-748a-431f-959d-5234f8ade2db",
   "metadata": {},
   "source": [
    "### Query-label representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c3522-fd7a-478c-8e4a-f50afa84f05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65aff28f9da48198fec725ae7e0571c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = learn.train_dataset.data_dset\n",
    "dataloader = learn.get_test_dataloader(dataset)\n",
    "data_repr = learn.get_representation(dataloader, representation_attribute='data_repr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290d067-90cc-471f-99a0-3fe4f667edbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f011f3e2f4574c2d99d4ea7b653fbe9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = learn.train_dataset.lbl_dset\n",
    "dataloader = learn.get_test_dataloader(dataset)\n",
    "lbl_repr = learn.get_representation(dataloader, representation_attribute='data_repr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bacec6-08e3-41b9-9223-83dd00b4a98b",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49802d94-0e03-4f7b-af0e-5d98575d7256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class TCHOutput(ModelOutput):\n",
    "    data_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_repr: Optional[torch.FloatTensor] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390c4d68-dfeb-4e49-bc09-6efea5312c49",
   "metadata": {},
   "source": [
    "### `TCH001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933df48-d500-4058-9676-30823f7c17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TCH001(DistilBertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config, n_data:int, n_lbl:int, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('n_data,n_lbl')\n",
    "        self.data_repr = nn.Embedding(self.n_data, config.dim)\n",
    "        self.lbl_repr = nn.Embedding(self.n_lbl, config.dim)\n",
    "\n",
    "    def get_lbl_embeddings(self):\n",
    "        return self.lbl_repr.weight\n",
    "\n",
    "    def get_data_embeddings(self):\n",
    "        return self.data_repr.weight\n",
    "\n",
    "    def init_embeddings(self, data_repr:torch.Tensor, lbl_repr:torch.Tensor):\n",
    "        self.data_repr.weight.data = data_repr\n",
    "        self.lbl_repr.weight.data = lbl_repr\n",
    "\n",
    "    def freeze_embeddings(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "        self.lbl_repr.requires_grad_(False)\n",
    "\n",
    "    def freeze_data_embeddings(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_embeddings(self):\n",
    "        self.data_repr.requires_grad_(True)\n",
    "        self.lbl_repr.requires_grad_(True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:torch.Tensor,\n",
    "        lbl2data_idx:torch.Tensor,\n",
    "    ):\n",
    "        return TCHOutput(\n",
    "            data_repr=self.data_repr(data_idx),\n",
    "            lbl2data_repr= self.lbl_repr(lbl2data_idx),\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce2257-bc45-4198-af33-9eaef9b5c8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693082, 312330)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.train.dset.n_data, block.n_lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea6134-e189-41d0-94c5-66c6aec5d586",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e206f-eb00-4c24-a68a-9bc776574ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TCH001(DistilBertConfig(), n_data=block.train.dset.n_data, n_lbl=block.n_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10167607-637b-4f74-b69e-9812846a0af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_embeddings(data_repr, lbl_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75b489-d2f7-409d-8d74-5cd99c737c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))\n",
    "b = prepare_batch(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d757aab-fb94-4486-9e98-32ca4bdeb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b36904-0600-4a43-bf12-7f437314aa0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 768]), torch.Size([10, 768]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.data_repr.shape, o.lbl2data_repr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a235a21e-e604-42e2-9f0f-639599a25ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228f18f-597e-416d-a37e-7c8c7e7fa93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f'{model_output}/teacher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c443ca-f592-4c61-b728-62babfbaa1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971cc581-1868-481a-9a6b-e82dbcc74806",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = '/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-4'\n",
    "m_teacher = TCH001.from_pretrained(f'{model_output}/teacher', n_data=block.train.dset.n_data, n_lbl=block.n_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ccaaaa-bba9-4275-8495-c439a098167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_teacher.freeze_data_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c7a02e-1861-4d64-bec0-aacca9ed5e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_teacher.data_repr.weight.requires_grad,m_teacher.lbl_repr.weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8490c8-e507-4018-b480-621f0aca37cd",
   "metadata": {},
   "source": [
    "### `TCH002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50684fc0-782c-40eb-a03f-767cfe8741bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TCH002(DistilBertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config, n_data:int, n_lbl:int, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('n_data,n_lbl')\n",
    "        self.data_repr = nn.Embedding(self.n_data, config.dim)\n",
    "        self.lbl_repr = nn.Embedding(self.n_lbl, config.dim)\n",
    "        \n",
    "        self.lbl_embeddings = nn.Embedding(self.n_lbl, config.dim)\n",
    "\n",
    "    def get_lbl_embeddings(self):\n",
    "        return self.lbl_repr.weight + self.lbl_embeddings.weight\n",
    "\n",
    "    def get_data_embeddings(self):\n",
    "        return self.data_repr.weight\n",
    "\n",
    "    def init_representations(self, data_repr:torch.Tensor, lbl_repr:torch.Tensor):\n",
    "        self.data_repr.weight.data = data_repr\n",
    "        self.lbl_repr.weight.data = lbl_repr\n",
    "\n",
    "    def init_lbl_embeddings(self):\n",
    "        self.lbl_embeddings.weight.data = torch.zeros_like(self.lbl_repr.weight.data, dtype=torch.float32)\n",
    "\n",
    "    def freeze_representations(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "        self.lbl_repr.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_representations(self):\n",
    "        self.data_repr.requires_grad_(True)\n",
    "        self.lbl_repr.requires_grad_(True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:torch.Tensor,\n",
    "        lbl2data_idx:torch.Tensor,\n",
    "    ):\n",
    "        data_repr = self.data_repr(data_idx)\n",
    "        lbl2data_repr = self.lbl_repr(lbl2data_idx) + self.lbl_embeddings(lbl2data_idx)\n",
    "        return TCHOutput(\n",
    "            data_repr=data_repr,\n",
    "            lbl2data_repr=lbl2data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb5c5f-ab1f-4e9c-ad7f-d4318450f3c3",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942858c-17b7-49bd-8200-c7deae854ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TCH002 were not initialized from the model checkpoint at /home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-4/teacher and are newly initialized: ['lbl_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_output = '/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-4'\n",
    "m_teacher = TCH002.from_pretrained(f'{model_output}/teacher', n_data=block.train.dset.n_data, n_lbl=block.n_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1bbdf-371f-462a-9afb-da10c3a24279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_teacher.data_repr.weight.requires_grad, m_teacher.lbl_repr.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563fa1e-72c5-4201-ad39-2b44f9913073",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_teacher.freeze_representations()\n",
    "m_teacher.init_lbl_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d318e5-ce58-4efa-93a3-5f81fe10c40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False, True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_teacher.data_repr.weight.requires_grad,m_teacher.lbl_repr.weight.requires_grad, m_teacher.lbl_embeddings.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5eb33-3e9f-47a6-be99-051132ab8750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_teacher.lbl_embeddings.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a75c6fa-d7ff-4ade-b8d9-afd3c17f4cfc",
   "metadata": {},
   "source": [
    "### `TCH003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e50e24-ee21-460e-b8b9-3d85ef1e4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TCH003(DistilBertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config, n_data:int, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('n_data')\n",
    "        self.data_repr = nn.Embedding(self.n_data, config.dim)\n",
    "\n",
    "    def get_data_embeddings(self):\n",
    "        return self.data_repr.weight\n",
    "\n",
    "    def init_embeddings(self, data_repr:torch.Tensor):\n",
    "        self.data_repr.weight.data = data_repr\n",
    "\n",
    "    def freeze_embeddings(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_representations(self):\n",
    "        self.data_repr.requires_grad_(True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:torch.Tensor,\n",
    "    ):\n",
    "        data_repr = self.data_repr(data_idx)\n",
    "        return TCHOutput(\n",
    "            data_repr=data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792886d2-a127-43f3-8bac-067be6c87209",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa138ec4-8cc8-48c4-86ee-495db960e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = '/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-4'\n",
    "m_teacher = TCH003.from_pretrained(f'{model_output}/teacher', n_data=block.train.dset.n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51480520-a470-4518-aa4e-945700ff9ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_teacher.init_embeddings(torch.zeros(block.train.dset.n_data, 768))\n",
    "m_teacher.freeze_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d559a18-3f26-4be2-a865-47342bab7af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_teacher.data_repr.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aeb38b-d71d-4698-8c7c-1b29b0bef609",
   "metadata": {},
   "source": [
    "## Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d142f-ec80-4dff-a280-664602c8438f",
   "metadata": {},
   "source": [
    "### `DTL001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d66e41-0575-4708-a12a-380042c2b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL001(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert,m_teacher.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        embed_sim_loss_weight:Optional[float]=1.0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        self.s_lw = embed_sim_loss_weight\n",
    "        \n",
    "        self.loss_fn = Cosine(reduce='mean')\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        data_aug_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_aug_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, **kwargs)\n",
    "\n",
    "        loss = None\n",
    "        if data_aug_input_ids is not None and student_o.loss is not None:\n",
    "            with torch.no_grad(): \n",
    "                teacher_o = self.m_teacher(data_input_ids=data_aug_input_ids, data_attention_mask=data_aug_attention_mask, **kwargs)\n",
    "\n",
    "            dloss = self.loss_fn(student_o.data_embed, data_attention_mask, teacher_o.data_embed, data_aug_attention_mask)\n",
    "            dloss += self.loss_fn(student_o.lbl2data_embed, kwargs['lbl2data_attention_mask'], \n",
    "                                  teacher_o.lbl2data_embed, kwargs['lbl2data_attention_mask'])\n",
    "            loss = student_o.loss + self.s_lw * dloss\n",
    "            \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            data_repr=student_o.data_repr,\n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f397a48-7346-479c-8ca1-6ab948fc419d",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e46769-0341-4dfb-be4b-2469e3c9ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa06359-1fda-4b39-b60d-ecbda192216e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT010 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.dr_layer_norm.bias', 'encoder.dr_layer_norm.weight', 'encoder.dr_projector.bias', 'encoder.dr_projector.weight', 'encoder.dr_transform.bias', 'encoder.dr_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['distilbert.embeddings.word_embeddings.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = '/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-1'\n",
    "output_dir = f\"/home/scai/phd/aiz218323/scratch/outputs/{os.path.basename(model_output)}\"\n",
    "mname = f'{output_dir}/{os.path.basename(get_best_model(output_dir))}'\n",
    "\n",
    "m_teacher = DBT010.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', bsz=800, tn_targ=5000, margin=0.3, tau=0.1, \n",
    "                                   n_negatives=10, apply_softmax=True, use_encoder_parallel=True)\n",
    "\n",
    "model_weight_file,model_weights = f'{mname}/model.safetensors',{}\n",
    "with safe_open(model_weight_file, framework=\"pt\") as file:\n",
    "    for k in file.keys(): model_weights[k] = file.get_tensor(k)\n",
    "\n",
    "m_teacher.load_state_dict(model_weights, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154cb90-fb7f-4d8b-b284-592c60fc1a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT010 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.dr_layer_norm.bias', 'encoder.dr_layer_norm.weight', 'encoder.dr_projector.bias', 'encoder.dr_projector.weight', 'encoder.dr_transform.bias', 'encoder.dr_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "m_student = DBT010.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', bsz=800, tn_targ=5000, margin=0.3, tau=0.1, \n",
    "                                       n_negatives=10, apply_softmax=True, use_encoder_parallel=True)\n",
    "m_student.init_dr_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586e82f-2a46-447a-bb42-0dccd9aa75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL001(DistilBertConfig(), m_student=m_student, m_teacher=m_teacher, embed_sim_loss_weight=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae04280e-1723-4bcd-83c1-d1835b110b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))\n",
    "b = prepare_batch(model, batch, m_args=['lbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c85d4-d2f7-4877-8d41-dda3adebf5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,b = model.to('cuda'), b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd268ce2-45f0-44a2-b57e-b18e346d328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = m(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d8fa61-beaa-4e52-bb4b-d7ec60d2ea90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6006, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69090f60-6bee-406d-b137-c368830a6e59",
   "metadata": {},
   "source": [
    "### `DTL002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6407a6-761f-4c36-ade3-ccde9bae9f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL002(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        bsz:Optional[int]=None,\n",
    "        tn_targ:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        distil_loss_weight:Optional[float]=1.0,\n",
    "        mse_loss_weight:Optional[float]=0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        vself.d_lw,self.m_lw = distil_loss_weight,mse_loss_weight\n",
    "        store_attr('m_student,m_teacher')\n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                        apply_softmax=apply_softmax, reduce='mean')\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                                   lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "\n",
    "        loss = None\n",
    "        if lbl2data_idx is not None and student_o.loss is not None:\n",
    "            with torch.no_grad(): \n",
    "                teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
    "\n",
    "            dloss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                     kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "            \n",
    "            dloss += self.rep_loss_fn(student_o.data_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                      kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            mloss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_repr) + self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
    "            \n",
    "            loss = student_o.loss + self.d_lw * dloss + self.m_lw * mloss\n",
    "            \n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            data_repr=student_o.data_repr,\n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ebb3ed-a8ee-48a1-8170-427d59cc331b",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2927897-e647-448a-a9f6-b799e4768529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = '/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-1'\n",
    "m_teacher = TCH001.from_pretrained(f'{model_output}/teacher', n_data=block.train.dset.n_data, n_lbl=block.n_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd05ec-d20a-4b66-97d3-f0f88c02f3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DBT010 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.dr_layer_norm.bias', 'encoder.dr_layer_norm.weight', 'encoder.dr_projector.bias', 'encoder.dr_projector.weight', 'encoder.dr_transform.bias', 'encoder.dr_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "m_student = DBT010.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', bsz=800, tn_targ=5000, margin=0.3, tau=0.1, \n",
    "                                   n_negatives=10, apply_softmax=True, use_encoder_parallel=True)\n",
    "m_student.init_dr_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9679da-87b5-4bf3-bce8-163c2947b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL002(DistilBertConfig(), m_student=m_student, m_teacher=m_teacher, bsz=1024, margin=0.3, tau=0.1, \n",
    "               n_negatives=10, apply_softmax=True, distil_loss_weight=1.0, mse_loss_weight=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c0a152-18c3-44f7-be0a-969a1add9d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))\n",
    "b = prepare_batch(model, batch, m_args=['lbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc95de0-016b-4490-be25-972d7119c0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'data_input_ids', 'data_attention_mask', 'data_idx'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb247d0-c71a-4331-b790-95e73aac01d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,b = model.to('cuda'), b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f8811-04ca-4939-8cf7-5cfb484a5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = m(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55dd5a-5c77-4781-a304-50eb9976a525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6356, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da73d63-2d03-436c-9102-a2e2558c3dcb",
   "metadata": {},
   "source": [
    "### `DTL003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc3ff0-3810-4264-af2a-0b2b3ffe9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL003(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        bsz:Optional[int]=None,\n",
    "        tn_targ:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        teacher_data_student_label_loss_weight:Optional[float]=1.0,\n",
    "        student_data_teacher_label_loss_weight:Optional[float]=1.0,\n",
    "        data_mse_loss_weight:Optional[float]=0.1,\n",
    "        label_mse_loss_weight:Optional[float]=0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        store_attr('teacher_data_student_label_loss_weight,student_data_teacher_label_loss_weight')\n",
    "        store_attr('data_mse_loss_weight,label_mse_loss_weight')\n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                        apply_softmax=apply_softmax, reduce='mean')\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                                   lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "\n",
    "        loss = None\n",
    "        if lbl2data_idx is not None and student_o.loss is not None:\n",
    "            with torch.no_grad(): \n",
    "                teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
    "\n",
    "            tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "            \n",
    "            sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
    "            lm_loss = self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
    "            \n",
    "            loss = student_o.loss\n",
    "            loss += self.teacher_data_student_label_loss_weight * tdsl_loss\n",
    "            loss += self.student_data_teacher_label_loss_weight * sdtl_loss\n",
    "            loss += self.data_mse_loss_weight * dm_loss + self.label_mse_loss_weight * lm_loss\n",
    "            \n",
    "\n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=student_o.data_repr,\n",
    "            data_fused_repr=student_o.data_fused_repr,\n",
    "            \n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "            lbl2data_fused_repr=student_o.lbl2data_fused_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a78aa-3918-4e7a-9893-d0c3c8a49709",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c261461-7748-4b0c-9632-a8699d8cab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = '/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-1'\n",
    "m_teacher = TCH001.from_pretrained(f'{model_output}/teacher', n_data=block.train.dset.n_data, n_lbl=block.n_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874714fd-e21d-482c-b967-9355d82813e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RAD006 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "m_student = RAD006.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=5000, num_batch_labels=5000, \n",
    "                                   margin=0.3, num_negatives=10, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                                   data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                                   data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "    \n",
    "                                   resize_length=5000, use_noise=False, shuffle_noise_pct=0.5, dropout_noise_pct=0.1,\n",
    "                                   \n",
    "                                   use_query_loss=True,\n",
    "    \n",
    "                                   calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, calib_loss_weight=0.1,\n",
    "                                   use_calib_loss=True,\n",
    "                                   \n",
    "                                   meta_loss_weight=0.0, fusion_loss_weight=0.0, use_fusion_loss=False,\n",
    "                                   use_encoder_parallel=False)\n",
    "\n",
    "m_student.init_retrieval_head()\n",
    "m_student.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a728f7-cabf-462d-b149-c6a0def6fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL003(DistilBertConfig(), m_student=m_student, m_teacher=m_teacher, bsz=1024, margin=0.3, tau=0.1, n_negatives=10, apply_softmax=True, \n",
    "               teacher_data_student_label_loss_weight=1.0, student_data_teacher_label_loss_weight=0.1, \n",
    "               data_mse_loss_weight=0.1,label_mse_loss_weight=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84c719-65cb-446d-a4dc-26474dbf1cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))\n",
    "b = prepare_batch(model, batch, m_args=['lbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx',\n",
    "                                        'lnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', \n",
    "                                        'lnk2data_attention_mask', 'plnk2data_data2ptr', 'plnk2data_idx'\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c373e-c307-4f92-8afe-251c8b78f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,b = model.to('cuda'), b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea3bc8-b733-4fc9-8854-9ded8d873110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(42)forward()\n",
      "     40         import pdb; pdb.set_trace()\n",
      "     41 \n",
      "---> 42         student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     43                                    lbl2data_idx=lbl2data_idx, **kwargs)\n",
      "     44 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.m_student.encoder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder006(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dr_head): RepresentationHead(\n",
      "    (transform): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (projector): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (meta_head): RepresentationHead(\n",
      "    (transform): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (projector): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (cross_head): CrossAttention(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b self.m_student.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 1 at /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py:1310\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b self.m_student.encoder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** The specified object 'self.m_student.encoder' is not a function or was not found along sys.path.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b self.m_student.encoder.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 2 at /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py:457\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(43)forward()\n",
      "     41 \n",
      "     42         student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 43                                    lbl2data_idx=lbl2data_idx, **kwargs)\n",
      "     44 \n",
      "     45         loss = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(42)forward()\n",
      "     40         import pdb; pdb.set_trace()\n",
      "     41 \n",
      "---> 42         student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     43                                    lbl2data_idx=lbl2data_idx, **kwargs)\n",
      "     44 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(43)forward()\n",
      "     41 \n",
      "     42         student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 43                                    lbl2data_idx=lbl2data_idx, **kwargs)\n",
      "     44 \n",
      "     45         loss = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(42)forward()\n",
      "     40         import pdb; pdb.set_trace()\n",
      "     41 \n",
      "---> 42         student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     43                                    lbl2data_idx=lbl2data_idx, **kwargs)\n",
      "     44 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1507)_wrapped_call_impl()\n",
      "   1505         return result\n",
      "   1506 \n",
      "-> 1507     def _wrapped_call_impl(self, *args, **kwargs):\n",
      "   1508         if self._compiled_call_impl is not None:\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1325)forward()\n",
      "   1323         **kwargs\n",
      "   1324     ):  \n",
      "-> 1325         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "   1326 \n",
      "   1327         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['plnk2data_idx', 'plnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', 'lnk2data_attention_mask', 'lnk2data_data2ptr'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1327)forward()\n",
      "   1325         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "   1326 \n",
      "-> 1327         if self.use_encoder_parallel:\n",
      "   1328             encoder = XCDataParallel(module=self.encoder)\n",
      "   1329         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1329)forward()\n",
      "   1327         if self.use_encoder_parallel:\n",
      "   1328             encoder = XCDataParallel(module=self.encoder)\n",
      "-> 1329         else: encoder = self.encoder\n",
      "   1330 \n",
      "   1331         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1331)forward()\n",
      "   1329         else: encoder = self.encoder\n",
      "   1330 \n",
      "-> 1331         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "   1332         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "   1333                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1332)forward()\n",
      "   1330 \n",
      "   1331         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "-> 1332         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "   1333                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "   1334 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lnk2data_attention_mask', 'lnk2data_input_ids', 'lnk2data_data2ptr'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_meta_kwargs['lnk2data_attention_mask'].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 10])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_meta_kwargs['lnk2data_input_ids'].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 10])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_meta_kwargs['lnk2data_data2ptr'].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1333)forward()\n",
      "   1331         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "   1332         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "-> 1333                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "   1334 \n",
      "   1335 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1332)forward()\n",
      "   1330 \n",
      "   1331         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "-> 1332         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "   1333                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "   1334 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1333)forward()\n",
      "   1331         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "   1332         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "-> 1333                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "   1334 \n",
      "   1335 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1332)forward()\n",
      "   1330 \n",
      "   1331         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "-> 1332         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "   1333                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "   1334 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1507)_wrapped_call_impl()\n",
      "   1505         return result\n",
      "   1506 \n",
      "-> 1507     def _wrapped_call_impl(self, *args, **kwargs):\n",
      "   1508         if self._compiled_call_impl is not None:\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(466)forward()\n",
      "    464         **kwargs\n",
      "    465     ):\n",
      "--> 466         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    467 \n",
      "    468         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(468)forward()\n",
      "    466         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    467 \n",
      "--> 468         if data_type is not None and data_type == \"meta\":\n",
      "    469             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    470         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(471)forward()\n",
      "    469             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    470         else:\n",
      "--> 471             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    472 \n",
      "    473         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(473)forward()\n",
      "    471             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    472 \n",
      "--> 473         data_fused_repr = meta_repr = None\n",
      "    474         if data_aug_meta_prefix is not None:\n",
      "    475             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(474)forward()\n",
      "    472 \n",
      "    473         data_fused_repr = meta_repr = None\n",
      "--> 474         if data_aug_meta_prefix is not None:\n",
      "    475             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    476             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(475)forward()\n",
      "    473         data_fused_repr = meta_repr = None\n",
      "    474         if data_aug_meta_prefix is not None:\n",
      "--> 475             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    476             if len(meta_kwargs):\n",
      "    477                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(476)forward()\n",
      "    474         if data_aug_meta_prefix is not None:\n",
      "    475             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "--> 476             if len(meta_kwargs):\n",
      "    477                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    478                                                                              data_attention_mask,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lnk2data'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(477)forward()\n",
      "    475             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    476             if len(meta_kwargs):\n",
      "--> 477                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    478                                                                              data_attention_mask,\n",
      "    479                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(478)forward()\n",
      "    476             if len(meta_kwargs):\n",
      "    477                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "--> 478                                                                              data_attention_mask,\n",
      "    479                                                                              meta_kwargs)\n",
      "    480                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(479)forward()\n",
      "    477                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    478                                                                              data_attention_mask,\n",
      "--> 479                                                                              meta_kwargs)\n",
      "    480                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    481 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(477)forward()\n",
      "    475             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    476             if len(meta_kwargs):\n",
      "--> 477                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    478                                                                              data_attention_mask,\n",
      "    479                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1236)fuse_meta_into_embeddings()\n",
      "   1234         return m_repr,m_repr_mask\n",
      "   1235 \n",
      "-> 1236     def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "   1237         meta_repr = {}\n",
      "   1238 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1237)fuse_meta_into_embeddings()\n",
      "   1235 \n",
      "   1236     def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "-> 1237         meta_repr = {}\n",
      "   1238 \n",
      "   1239         for m_key, m_args in meta_kwargs.items():\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1239)fuse_meta_into_embeddings()\n",
      "   1237         meta_repr = {}\n",
      "   1238 \n",
      "-> 1239         for m_key, m_args in meta_kwargs.items():\n",
      "   1240             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "   1241             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1240)fuse_meta_into_embeddings()\n",
      "   1238 \n",
      "   1239         for m_key, m_args in meta_kwargs.items():\n",
      "-> 1240             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "   1241             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "   1242 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1241)fuse_meta_into_embeddings()\n",
      "   1239         for m_key, m_args in meta_kwargs.items():\n",
      "   1240             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "-> 1241             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "   1242 \n",
      "   1243             if len(idx):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  idx.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1243)fuse_meta_into_embeddings()\n",
      "   1241             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "   1242 \n",
      "-> 1243             if len(idx):\n",
      "   1244                 if 'meta_repr' in m_args:\n",
      "   1245                     m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_repr[m_key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 768))\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1244)fuse_meta_into_embeddings()\n",
      "   1242 \n",
      "   1243             if len(idx):\n",
      "-> 1244                 if 'meta_repr' in m_args:\n",
      "   1245                     m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
      "   1246                     m_repr,m_repr_mask = self.resize(m_repr, m_repr_mask, m_args['data2ptr'][idx])\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1249)fuse_meta_into_embeddings()\n",
      "   1247                     m_repr_mask = m_repr_mask.bool()\n",
      "   1248                 else:\n",
      "-> 1249                     m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
      "   1250                                                                 m_args['data2ptr'][idx])\n",
      "   1251                     n_meta = m_args['data2ptr'].max()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1250)fuse_meta_into_embeddings()\n",
      "   1248                 else:\n",
      "   1249                     m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
      "-> 1250                                                                 m_args['data2ptr'][idx])\n",
      "   1251                     n_meta = m_args['data2ptr'].max()\n",
      "   1252                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1249)fuse_meta_into_embeddings()\n",
      "   1247                     m_repr_mask = m_repr_mask.bool()\n",
      "   1248                 else:\n",
      "-> 1249                     m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
      "   1250                                                                 m_args['data2ptr'][idx])\n",
      "   1251                     n_meta = m_args['data2ptr'].max()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1251)fuse_meta_into_embeddings()\n",
      "   1249                     m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
      "   1250                                                                 m_args['data2ptr'][idx])\n",
      "-> 1251                     n_meta = m_args['data2ptr'].max()\n",
      "   1252                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "   1253 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_input_ids.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 10])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_attention_mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 10])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1252)fuse_meta_into_embeddings()\n",
      "   1250                                                                 m_args['data2ptr'][idx])\n",
      "   1251                     n_meta = m_args['data2ptr'].max()\n",
      "-> 1252                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "   1253 \n",
      "   1254                     m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n_meta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1254)fuse_meta_into_embeddings()\n",
      "   1252                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "   1253 \n",
      "-> 1254                     m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
      "   1255                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "   1256 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1255)fuse_meta_into_embeddings()\n",
      "   1253 \n",
      "   1254                     m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
      "-> 1255                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "   1256 \n",
      "   1257                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1257)fuse_meta_into_embeddings()\n",
      "   1255                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "   1256 \n",
      "-> 1257                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "   1258                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "   1259 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1258)fuse_meta_into_embeddings()\n",
      "   1256 \n",
      "   1257                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "-> 1258                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "   1259 \n",
      "   1260                 if self.use_noise: m_repr, m_repr_mask = self.add_noise(m_repr.clone(), m_repr_mask.clone())\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1260)fuse_meta_into_embeddings()\n",
      "   1258                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "   1259 \n",
      "-> 1260                 if self.use_noise: m_repr, m_repr_mask = self.add_noise(m_repr.clone(), m_repr_mask.clone())\n",
      "   1261 \n",
      "   1262                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1262)fuse_meta_into_embeddings()\n",
      "   1260                 if self.use_noise: m_repr, m_repr_mask = self.add_noise(m_repr.clone(), m_repr_mask.clone())\n",
      "   1261 \n",
      "-> 1262                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "   1263 \n",
      "   1264                 if self.use_noise:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  embed.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1264)fuse_meta_into_embeddings()\n",
      "   1262                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "   1263 \n",
      "-> 1264                 if self.use_noise:\n",
      "   1265                     noise_mask = torch.rand(len(idx), device=fused_embed.device) > self.dropout_noise_pct\n",
      "   1266                     embed[idx[noise_mask]] += fused_embed[noise_mask]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.use_noise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1268)fuse_meta_into_embeddings()\n",
      "   1266                     embed[idx[noise_mask]] += fused_embed[noise_mask]\n",
      "   1267                 else:\n",
      "-> 1268                     embed[idx] += fused_embed\n",
      "   1269 \n",
      "   1270         return embed, meta_repr\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  fused_embed.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1239)fuse_meta_into_embeddings()\n",
      "   1237         meta_repr = {}\n",
      "   1238 \n",
      "-> 1239         for m_key, m_args in meta_kwargs.items():\n",
      "   1240             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "   1241             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1270)fuse_meta_into_embeddings()\n",
      "   1268                     embed[idx] += fused_embed\n",
      "   1269 \n",
      "-> 1270         return embed, meta_repr\n",
      "   1271 \n",
      "   1272 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[[-0....PutBackward0>), {'lnk2data': tensor([[-0.0...DivBackward0>)})\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1270)fuse_meta_into_embeddings()\n",
      "   1268                     embed[idx] += fused_embed\n",
      "   1269 \n",
      "-> 1270         return embed, meta_repr\n",
      "   1271 \n",
      "   1272 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(480)forward()\n",
      "    478                                                                              data_attention_mask,\n",
      "    479                                                                              meta_kwargs)\n",
      "--> 480                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    481 \n",
      "    482         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(482)forward()\n",
      "    480                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    481 \n",
      "--> 482         return EncoderOutput(\n",
      "    483             rep=data_repr,\n",
      "    484             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(483)forward()\n",
      "    481 \n",
      "    482         return EncoderOutput(\n",
      "--> 483             rep=data_repr,\n",
      "    484             fused_rep=data_fused_repr,\n",
      "    485             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(484)forward()\n",
      "    482         return EncoderOutput(\n",
      "    483             rep=data_repr,\n",
      "--> 484             fused_rep=data_fused_repr,\n",
      "    485             meta_repr=meta_repr,\n",
      "    486         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(485)forward()\n",
      "    483             rep=data_repr,\n",
      "    484             fused_rep=data_fused_repr,\n",
      "--> 485             meta_repr=meta_repr,\n",
      "    486         )\n",
      "    487 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(482)forward()\n",
      "    480                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    481 \n",
      "--> 482         return EncoderOutput(\n",
      "    483             rep=data_repr,\n",
      "    484             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...vBackward0>)})\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(482)forward()\n",
      "    480                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    481 \n",
      "--> 482         return EncoderOutput(\n",
      "    483             rep=data_repr,\n",
      "    484             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...vBackward0>)})\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1511)_wrapped_call_impl()\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1510         else:\n",
      "-> 1511             return self._call_impl(*args, **kwargs)\n",
      "   1512 \n",
      "   1513     def _call_impl(self, *args, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1336)forward()\n",
      "   1334 \n",
      "   1335 \n",
      "-> 1336         loss = None; lbl2data_o = EncoderOutput()\n",
      "   1337         if lbl2data_input_ids is not None:\n",
      "   1338             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1337)forward()\n",
      "   1335 \n",
      "   1336         loss = None; lbl2data_o = EncoderOutput()\n",
      "-> 1337         if lbl2data_input_ids is not None:\n",
      "   1338             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "   1339             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1338)forward()\n",
      "   1336         loss = None; lbl2data_o = EncoderOutput()\n",
      "   1337         if lbl2data_input_ids is not None:\n",
      "-> 1338             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "   1339             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "   1340                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1339)forward()\n",
      "   1337         if lbl2data_input_ids is not None:\n",
      "   1338             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "-> 1339             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "   1340                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "   1341 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1340)forward()\n",
      "   1338             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "   1339             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "-> 1340                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "   1341 \n",
      "   1342             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1339)forward()\n",
      "   1337         if lbl2data_input_ids is not None:\n",
      "   1338             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "-> 1339             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "   1340                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "   1341 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1340)forward()\n",
      "   1338             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "   1339             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "-> 1340                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "   1341 \n",
      "   1342             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1339)forward()\n",
      "   1337         if lbl2data_input_ids is not None:\n",
      "   1338             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "-> 1339             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "   1340                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "   1341 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(466)forward()\n",
      "    464         **kwargs\n",
      "    465     ):\n",
      "--> 466         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    467 \n",
      "    468         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(468)forward()\n",
      "    466         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    467 \n",
      "--> 468         if data_type is not None and data_type == \"meta\":\n",
      "    469             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    470         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(471)forward()\n",
      "    469             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    470         else:\n",
      "--> 471             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    472 \n",
      "    473         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(473)forward()\n",
      "    471             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    472 \n",
      "--> 473         data_fused_repr = meta_repr = None\n",
      "    474         if data_aug_meta_prefix is not None:\n",
      "    475             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(474)forward()\n",
      "    472 \n",
      "    473         data_fused_repr = meta_repr = None\n",
      "--> 474         if data_aug_meta_prefix is not None:\n",
      "    475             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    476             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(482)forward()\n",
      "    480                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    481 \n",
      "--> 482         return EncoderOutput(\n",
      "    483             rep=data_repr,\n",
      "    484             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(483)forward()\n",
      "    481 \n",
      "    482         return EncoderOutput(\n",
      "--> 483             rep=data_repr,\n",
      "    484             fused_rep=data_fused_repr,\n",
      "    485             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(484)forward()\n",
      "    482         return EncoderOutput(\n",
      "    483             rep=data_repr,\n",
      "--> 484             fused_rep=data_fused_repr,\n",
      "    485             meta_repr=meta_repr,\n",
      "    486         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(485)forward()\n",
      "    483             rep=data_repr,\n",
      "    484             fused_rep=data_fused_repr,\n",
      "--> 485             meta_repr=meta_repr,\n",
      "    486         )\n",
      "    487 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(482)forward()\n",
      "    480                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    481 \n",
      "--> 482         return EncoderOutput(\n",
      "    483             rep=data_repr,\n",
      "    484             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(482)forward()\n",
      "    480                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    481 \n",
      "--> 482         return EncoderOutput(\n",
      "    483             rep=data_repr,\n",
      "    484             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1342)forward()\n",
      "   1340                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "   1341 \n",
      "-> 1342             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "   1343                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "   1344 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_o.fused_rep.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_o.rep.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1343)forward()\n",
      "   1341 \n",
      "   1342             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "-> 1343                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "   1344 \n",
      "   1345             if self.use_query_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1342)forward()\n",
      "   1340                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "   1341 \n",
      "-> 1342             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "   1343                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "   1344 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1345)forward()\n",
      "   1343                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "   1344 \n",
      "-> 1345             if self.use_query_loss:\n",
      "   1346                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "   1347                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1346)forward()\n",
      "   1344 \n",
      "   1345             if self.use_query_loss:\n",
      "-> 1346                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "   1347                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "   1348 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1347)forward()\n",
      "   1345             if self.use_query_loss:\n",
      "   1346                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "-> 1347                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "   1348 \n",
      "   1349             if self.use_calib_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1346)forward()\n",
      "   1344 \n",
      "   1345             if self.use_query_loss:\n",
      "-> 1346                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "   1347                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "   1348 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1349)forward()\n",
      "   1347                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "   1348 \n",
      "-> 1349             if self.use_calib_loss:\n",
      "   1350                 loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "   1351                                               plbl2data_data2ptr,plbl2data_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.use_calib_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1350)forward()\n",
      "   1348 \n",
      "   1349             if self.use_calib_loss:\n",
      "-> 1350                 loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "   1351                                               plbl2data_data2ptr,plbl2data_idx)\n",
      "   1352 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1351)forward()\n",
      "   1349             if self.use_calib_loss:\n",
      "   1350                 loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "-> 1351                                               plbl2data_data2ptr,plbl2data_idx)\n",
      "   1352 \n",
      "   1353             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1350)forward()\n",
      "   1348 \n",
      "   1349             if self.use_calib_loss:\n",
      "-> 1350                 loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "   1351                                               plbl2data_data2ptr,plbl2data_idx)\n",
      "   1352 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1353)forward()\n",
      "   1351                                               plbl2data_data2ptr,plbl2data_idx)\n",
      "   1352 \n",
      "-> 1353             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "   1354 \n",
      "   1355             if self.use_fusion_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_o.fused_rep.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_o.rep.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1355)forward()\n",
      "   1353             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "   1354 \n",
      "-> 1355             if self.use_fusion_loss:\n",
      "   1356                 loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
      "   1357                 loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1359)forward()\n",
      "   1357                 loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "   1358 \n",
      "-> 1359         if not return_dict:\n",
      "   1360             o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
      "   1361             return ((loss,) + o) if loss is not None else o\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1364)forward()\n",
      "   1362 \n",
      "   1363 \n",
      "-> 1364         return RADOutput(\n",
      "   1365             loss=loss,\n",
      "   1366 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1365)forward()\n",
      "   1363 \n",
      "   1364         return RADOutput(\n",
      "-> 1365             loss=loss,\n",
      "   1366 \n",
      "   1367             data_repr=data_o.rep,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1367)forward()\n",
      "   1365             loss=loss,\n",
      "   1366 \n",
      "-> 1367             data_repr=data_o.rep,\n",
      "   1368             data_fused_repr=data_o.fused_rep,\n",
      "   1369 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1368)forward()\n",
      "   1366 \n",
      "   1367             data_repr=data_o.rep,\n",
      "-> 1368             data_fused_repr=data_o.fused_rep,\n",
      "   1369 \n",
      "   1370             lbl2data_repr=lbl2data_o.rep,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1370)forward()\n",
      "   1368             data_fused_repr=data_o.fused_rep,\n",
      "   1369 \n",
      "-> 1370             lbl2data_repr=lbl2data_o.rep,\n",
      "   1371             lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
      "   1372         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1371)forward()\n",
      "   1369 \n",
      "   1370             lbl2data_repr=lbl2data_o.rep,\n",
      "-> 1371             lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
      "   1372         )\n",
      "   1373 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1364)forward()\n",
      "   1362 \n",
      "   1363 \n",
      "-> 1364         return RADOutput(\n",
      "   1365             loss=loss,\n",
      "   1366 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "RADOutput(los...sed_repr=None)\n",
      "> /scratch/scai/phd/aiz218323/Projects/xcai/xcai/models/radga.py(1364)forward()\n",
      "   1362 \n",
      "   1363 \n",
      "-> 1364         return RADOutput(\n",
      "   1365             loss=loss,\n",
      "   1366 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "RADOutput(los...sed_repr=None)\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1511)_wrapped_call_impl()\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1510         else:\n",
      "-> 1511             return self._call_impl(*args, **kwargs)\n",
      "   1512 \n",
      "   1513     def _call_impl(self, *args, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(45)forward()\n",
      "     43                                    lbl2data_idx=lbl2data_idx, **kwargs)\n",
      "     44 \n",
      "---> 45         loss = None\n",
      "     46         if lbl2data_idx is not None and student_o.loss is not None:\n",
      "     47             with torch.no_grad():\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(46)forward()\n",
      "     44 \n",
      "     45         loss = None\n",
      "---> 46         if lbl2data_idx is not None and student_o.loss is not None:\n",
      "     47             with torch.no_grad():\n",
      "     48                 teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(47)forward()\n",
      "     45         loss = None\n",
      "     46         if lbl2data_idx is not None and student_o.loss is not None:\n",
      "---> 47             with torch.no_grad():\n",
      "     48                 teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
      "     49 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(48)forward()\n",
      "     46         if lbl2data_idx is not None and student_o.loss is not None:\n",
      "     47             with torch.no_grad():\n",
      "---> 48                 teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
      "     49 \n",
      "     50             tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(50)forward()\n",
      "     48                 teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
      "     49 \n",
      "---> 50             tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "     51                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     52 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  teacher_o.data_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  student_o.lbl2data_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(51)forward()\n",
      "     49 \n",
      "     50             tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "---> 51                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     52 \n",
      "     53             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(50)forward()\n",
      "     48                 teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
      "     49 \n",
      "---> 50             tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "     51                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     52 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(51)forward()\n",
      "     49 \n",
      "     50             tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "---> 51                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     52 \n",
      "     53             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(50)forward()\n",
      "     48                 teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
      "     49 \n",
      "---> 50             tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "     51                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     52 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(53)forward()\n",
      "     51                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     52 \n",
      "---> 53             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "     54                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     55 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  tdsl_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(54)forward()\n",
      "     52 \n",
      "     53             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "---> 54                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     55 \n",
      "     56             dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  student_o.data_fused_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  teacher_o.lbl2data_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(53)forward()\n",
      "     51                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     52 \n",
      "---> 53             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "     54                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     55 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(54)forward()\n",
      "     52 \n",
      "     53             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "---> 54                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     55 \n",
      "     56             dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(53)forward()\n",
      "     51                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     52 \n",
      "---> 53             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "     54                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     55 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(56)forward()\n",
      "     54                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     55 \n",
      "---> 56             dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
      "     57             lm_loss = self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
      "     58 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(57)forward()\n",
      "     55 \n",
      "     56             dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
      "---> 57             lm_loss = self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
      "     58 \n",
      "     59             loss = student_o.loss\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(59)forward()\n",
      "     57             lm_loss = self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
      "     58 \n",
      "---> 59             loss = student_o.loss\n",
      "     60             loss += self.teacher_data_student_label_loss_weight * tdsl_loss\n",
      "     61             loss += self.student_data_teacher_label_loss_weight * sdtl_loss\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  student_o.loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0424, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(60)forward()\n",
      "     58 \n",
      "     59             loss = student_o.loss\n",
      "---> 60             loss += self.teacher_data_student_label_loss_weight * tdsl_loss\n",
      "     61             loss += self.student_data_teacher_label_loss_weight * sdtl_loss\n",
      "     62             loss += self.data_mse_loss_weight * dm_loss + self.label_mse_loss_weight * lm_loss\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(61)forward()\n",
      "     59             loss = student_o.loss\n",
      "     60             loss += self.teacher_data_student_label_loss_weight * tdsl_loss\n",
      "---> 61             loss += self.student_data_teacher_label_loss_weight * sdtl_loss\n",
      "     62             loss += self.data_mse_loss_weight * dm_loss + self.label_mse_loss_weight * lm_loss\n",
      "     63 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.teacher_data_student_label_loss_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  tdsl_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1338, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  sdtl_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2057, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(62)forward()\n",
      "     60             loss += self.teacher_data_student_label_loss_weight * tdsl_loss\n",
      "     61             loss += self.student_data_teacher_label_loss_weight * sdtl_loss\n",
      "---> 62             loss += self.data_mse_loss_weight * dm_loss + self.label_mse_loss_weight * lm_loss\n",
      "     63 \n",
      "     64 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  dm_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0163, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lm_loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0100, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(65)forward()\n",
      "     63 \n",
      "     64 \n",
      "---> 65         return RADOutput(\n",
      "     66             loss=loss,\n",
      "     67 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(66)forward()\n",
      "     64 \n",
      "     65         return RADOutput(\n",
      "---> 66             loss=loss,\n",
      "     67 \n",
      "     68             data_repr=student_o.data_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(68)forward()\n",
      "     66             loss=loss,\n",
      "     67 \n",
      "---> 68             data_repr=student_o.data_repr,\n",
      "     69             data_fused_repr=student_o.data_fused_repr,\n",
      "     70 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(69)forward()\n",
      "     67 \n",
      "     68             data_repr=student_o.data_repr,\n",
      "---> 69             data_fused_repr=student_o.data_fused_repr,\n",
      "     70 \n",
      "     71             lbl2data_repr=student_o.lbl2data_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(71)forward()\n",
      "     69             data_fused_repr=student_o.data_fused_repr,\n",
      "     70 \n",
      "---> 71             lbl2data_repr=student_o.lbl2data_repr,\n",
      "     72             lbl2data_fused_repr=student_o.lbl2data_fused_repr,\n",
      "     73         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(72)forward()\n",
      "     70 \n",
      "     71             lbl2data_repr=student_o.lbl2data_repr,\n",
      "---> 72             lbl2data_fused_repr=student_o.lbl2data_fused_repr,\n",
      "     73         )\n",
      "     74 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_40248/676308714.py(65)forward()\n",
      "     63 \n",
      "     64 \n",
      "---> 65         return RADOutput(\n",
      "     66             loss=loss,\n",
      "     67 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "RADOutput(los...sed_repr=None)\n",
      "> /tmp/ipykernel_40248/676308714.py(65)forward()\n",
      "     63 \n",
      "     64 \n",
      "---> 65         return RADOutput(\n",
      "     66             loss=loss,\n",
      "     67 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "RADOutput(los...sed_repr=None)\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1520)_call_impl()\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "-> 1520             return forward_call(*args, **kwargs)\n",
      "   1521 \n",
      "   1522         try:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "RADOutput(los...sed_repr=None)\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1511)_wrapped_call_impl()\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1510         else:\n",
      "-> 1511             return self._call_impl(*args, **kwargs)\n",
      "   1512 \n",
      "   1513     def _call_impl(self, *args, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> /tmp/ipykernel_40248/1822690529.py(1)<module>()\n",
      "----> 1 o = m(**b)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py(3553)run_code()\n",
      "   3551             finally:\n",
      "   3552                 # Reset our crash handler in place\n",
      "-> 3553                 sys.excepthook = old_excepthook\n",
      "   3554         except SystemExit as e:\n",
      "   3555             if result is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py(3574)run_code()\n",
      "   3572             self.showtraceback(running_compiled_code=True)\n",
      "   3573         else:\n",
      "-> 3574             outflag = False\n",
      "   3575         return outflag\n",
      "   3576 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "o = m(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c49c2af-b11c-4feb-b4df-c6a2bd1721e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cd6da-69dc-4728-96b5-cd980472c234",
   "metadata": {},
   "source": [
    "### `DTL004`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64dfd3e-ffd1-4547-8023-c3df6f409e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL004(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        bsz:Optional[int]=None,\n",
    "        tn_targ:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        teacher_data_student_label_loss_weight:Optional[float]=1.0,\n",
    "        student_data_teacher_label_loss_weight:Optional[float]=1.0,\n",
    "        data_mse_loss_weight:Optional[float]=0.1,\n",
    "        label_mse_loss_weight:Optional[float]=0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        store_attr('teacher_data_student_label_loss_weight,student_data_teacher_label_loss_weight')\n",
    "        store_attr('data_mse_loss_weight,label_mse_loss_weight')\n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                        apply_softmax=apply_softmax, reduce='mean')\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                                   lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "\n",
    "        loss = None\n",
    "        if lbl2data_idx is not None and student_o.loss is not None:\n",
    "            teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
    "\n",
    "            tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "            \n",
    "            sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
    "            lm_loss = self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
    "            \n",
    "            loss = student_o.loss\n",
    "            loss += self.teacher_data_student_label_loss_weight * tdsl_loss\n",
    "            loss += self.student_data_teacher_label_loss_weight * sdtl_loss\n",
    "            loss += self.data_mse_loss_weight * dm_loss + self.label_mse_loss_weight * lm_loss\n",
    "            \n",
    "\n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=student_o.data_repr,\n",
    "            data_fused_repr=student_o.data_fused_repr,\n",
    "            \n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "            lbl2data_fused_repr=student_o.lbl2data_fused_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f0611-7255-47c1-98e2-f250cba4abe6",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf00bba-eded-429c-bdae-9121830fa5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TCH002 were not initialized from the model checkpoint at /home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-4/teacher and are newly initialized: ['data_embeddings.weight', 'lbl_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_output = '/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-4'\n",
    "m_teacher = TCH002.from_pretrained(f'{model_output}/teacher', n_data=block.train.dset.n_data, n_lbl=block.n_lbl)\n",
    "\n",
    "m_teacher.freeze_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e3eaa-a366-440c-9f98-5a397f6ce459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a1d21-9998-4880-9694-b7a6d06f1fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c120983-52b9-4880-bdcc-b90fedd418e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK001 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-cos-v5 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "m_student = OAK001.from_pretrained('sentence-transformers/msmarco-distilbert-cos-v5', batch_size=1000, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=True,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "\n",
    "model.encoder.set_meta_embeddings(torch.zeros(block.train.dset.meta['lnk_meta'].n_meta, model.config.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d44971-6d1d-4530-ae9e-c899b0bd16b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL004(DistilBertConfig(), m_student=m_student, m_teacher=m_teacher, bsz=1024, margin=0.3, tau=0.1, n_negatives=10, \n",
    "               apply_softmax=True, teacher_data_student_label_loss_weight=1.0, student_data_teacher_label_loss_weight=0.1, \n",
    "               data_mse_loss_weight=0.1,label_mse_loss_weight=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f74b7-ac59-4d07-a84d-a2cc12fc7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))\n",
    "b = prepare_batch(model, batch, m_args=['lbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx',\n",
    "                                        'lnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', \n",
    "                                        'lnk2data_attention_mask', 'plnk2data_data2ptr', 'plnk2data_idx'\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f8615-cd49-4d00-915c-1996de1c21ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,b = model.to('cuda'), b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af593fc5-dca0-4e6f-8a00-ff9fe3e23ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = m(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35fe4ea-ebac-4fff-ab3c-0c095e22f04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1536, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6a3143-8a16-4f25-9fce-f118a4ffa9c7",
   "metadata": {},
   "source": [
    "### `DTL005`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0831598f-85f9-477b-8525-cd0770367f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL005(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        bsz:Optional[int]=None,\n",
    "        tn_targ:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        teacher_data_student_label_loss_weight:Optional[float]=1.0,\n",
    "        data_mse_loss_weight:Optional[float]=0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        store_attr('teacher_data_student_label_loss_weight,data_mse_loss_weight')\n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                        apply_softmax=apply_softmax, reduce='mean')\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, **kwargs)\n",
    "\n",
    "        loss = None\n",
    "        if student_o.loss is not None:\n",
    "            teacher_o = self.m_teacher(data_idx=data_idx)\n",
    "\n",
    "            tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], kwargs['lbl2data_idx'], \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
    "            \n",
    "            loss = student_o.loss\n",
    "            loss += self.teacher_data_student_label_loss_weight * tdsl_loss\n",
    "            loss += self.data_mse_loss_weight * dm_loss\n",
    "\n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=student_o.data_repr,\n",
    "            data_fused_repr=student_o.data_fused_repr,\n",
    "            \n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "            lbl2data_fused_repr=student_o.lbl2data_fused_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d3e1b8-11ca-425e-9cce-e87d3164db3c",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f0ee7-49a0-4cf0-9731-38949b181e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = '/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-4'\n",
    "m_teacher = TCH003.from_pretrained(f'{model_output}/teacher', n_data=block.train.dset.n_data, n_lbl=block.n_lbl)\n",
    "\n",
    "m_teacher.freeze_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d8aafb-930a-4c5d-9302-d8be2da80bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b99ffa-e537-4d66-8aa5-1111f9ea4336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK001 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-cos-v5 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "m_student = OAK001.from_pretrained('sentence-transformers/msmarco-distilbert-cos-v5', batch_size=1000, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=True,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "m_student.init_retrieval_head()\n",
    "m_student.init_cross_head()\n",
    "\n",
    "m_student.encoder.set_meta_embeddings(torch.zeros(block.train.dset.meta['lnk_meta'].n_meta, m_student.config.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d3b47-779f-4c2d-bf3b-3419d4108e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL005(DistilBertConfig(), m_student=m_student, m_teacher=m_teacher, bsz=1024, margin=0.3, tau=0.1, n_negatives=10, \n",
    "               apply_softmax=True, teacher_data_student_label_loss_weight=1.0, data_mse_loss_weight=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61270d1c-42a0-478c-b18e-80ba68b0ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))\n",
    "b = prepare_batch(model, batch, m_args=['lbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx',\n",
    "                                        'lnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', \n",
    "                                        'lnk2data_attention_mask', 'plnk2data_data2ptr', 'plnk2data_idx'\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a60de-fb4f-4d76-8520-059273804249",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,b = model.to('cuda'), b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca768bd-1e51-4561-8edc-395537527c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = m(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f74b6-b358-4c32-a027-0041fe8ec411",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12178e7-6f51-4de3-9ab3-740dab89d4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
