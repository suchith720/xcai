{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03db601c-f6a8-4244-9489-1e893d36a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68e71b9-a1f1-41a5-b9c5-d61c5f5f684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f75c653-edf1-4772-922e-fce670d99293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, numpy as np, torch.nn.functional as F, torch.nn as nn\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "from types import MethodType\n",
    "\n",
    "from xcai.core import store_attr\n",
    "from xcai.losses import Cosine, MultiTriplet\n",
    "from xcai.models.PPP0XX import XCModelOutput\n",
    "from xcai.models.oak import OAK001\n",
    "from xcai.models.radga import RADOutput\n",
    "from xcai.bandits import *\n",
    "\n",
    "from transformers import DistilBertPreTrainedModel,DistilBertConfig\n",
    "from transformers.utils.generic import ModelOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a491a-2a8f-4be4-97ce-4ebf0e856b9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2755bff4-23d1-4415-88d8-5ad60fce5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.main import *\n",
    "from xcai.basics import *\n",
    "from xcai.models.oak import OAK003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff33efb6-d64a-4348-82c0-4a0e207160ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/suchith720/Projects/data/'\n",
    "\n",
    "config_key = \"data_meta\"\n",
    "config_dir = \"/Users/suchith720/Projects/mogicX/configs\"\n",
    "pkl_dir = f\"{data_dir}/processed/mogicX\"\n",
    "pkl_file = get_pkl_file(pkl_dir, 'wikiseealsotitles_data-oak-for-msmarco-with-hard-negatives-test_distilbert-base-uncased', \n",
    "                        True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd42b42-24f5-4040-a18e-95c112dcebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = f\"{config_dir}/39_oak-for-msmarco-with-hard-negatives_test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50462f17-4163-4b23-bce7-1ec176aa7e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/suchith720/Projects/data//processed/mogicX/wikiseealsotitles_data-oak-for-msmarco-with-hard-negatives-test_distilbert-base-uncased_sxc.joblib'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deafe42b-f702-47dd-a84e-edce8cd2e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = build_block(pkl_file, config_file, True, config_key=config_key, only_test=False, main_oversample=True, \n",
    "                    meta_oversample={\"cat_meta\":False, \"lnk_meta\":True}, n_slbl_samples=5, \n",
    "                    n_sdata_meta_samples={\"cat_meta\":2, \"lnk_meta\":4}, do_build=False, \n",
    "                    train_meta_topk={\"lnk_meta\":10}, test_meta_topk={\"lnk_meta\":10}, return_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f72c6f-1fae-4ba0-8fb1-5f922795a585",
   "metadata": {},
   "source": [
    "## Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bacec6-08e3-41b9-9223-83dd00b4a98b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49802d94-0e03-4f7b-af0e-5d98575d7256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class TCHOutput(ModelOutput):\n",
    "    data_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_repr: Optional[torch.FloatTensor] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e441ef-38a2-4019-9229-cbf0701b13de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6beb4d1f-e135-437e-9ab6-fbe61466a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TCHConfig(DistilBertConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_data:Optional[int]=None,\n",
    "        n_lbl:Optional[int]=None,\n",
    "        embed_dim:Optional[int]=None,\n",
    "        normalize:Optional[bool]=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_data, self.n_lbl, self.embed_dim, self.normalize = n_data, n_lbl, embed_dim, normalize\n",
    "        super().__init__(**kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390c4d68-dfeb-4e49-bc09-6efea5312c49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `TCH001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1933df48-d500-4058-9676-30823f7c17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TCH001(DistilBertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config:TCHConfig, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.data_repr = nn.Embedding(config.n_data, config.dim)\n",
    "        self.lbl_repr = nn.Embedding(config.n_lbl, config.dim)\n",
    "\n",
    "    def get_lbl_embeddings(self):\n",
    "        return self.lbl_repr.weight\n",
    "\n",
    "    def get_data_embeddings(self):\n",
    "        return self.data_repr.weight\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_embeddings(self, data_repr:torch.Tensor, lbl_repr:torch.Tensor):\n",
    "        self.data_repr.weight.copy_(data_repr)\n",
    "        self.lbl_repr.weight.copy_(lbl_repr)\n",
    "\n",
    "    def freeze_embeddings(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "        self.lbl_repr.requires_grad_(False)\n",
    "\n",
    "    def freeze_data_embeddings(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_embeddings(self):\n",
    "        self.data_repr.requires_grad_(True)\n",
    "        self.lbl_repr.requires_grad_(True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:torch.Tensor,\n",
    "        lbl2data_idx:torch.Tensor,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return TCHOutput(\n",
    "            data_repr=self.data_repr(data_idx),\n",
    "            lbl2data_repr= self.lbl_repr(lbl2data_idx),\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea6134-e189-41d0-94c5-66c6aec5d586",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c2ba2ce-1e2d-40bc-a9e1-fbc820906db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TCHConfig(n_data=block.train.dset.n_data, n_lbl=block.n_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f3e206f-eb00-4c24-a68a-9bc776574ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TCH001(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bc4bbe3-209f-4a87-a741-64fa4cd8120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_repr, lbl_repr = torch.randn(block.train.dset.n_data, 768), torch.randn(block.n_lbl, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "613aa045-cdaa-4bc0-bbb9-02c25c5d3f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([693082, 768]), torch.Size([312330, 768]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_repr.shape, lbl_repr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10167607-637b-4f74-b69e-9812846a0af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_embeddings(data_repr, lbl_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f75b489-d2f7-409d-8d74-5cd99c737c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))\n",
    "b = prepare_batch(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d757aab-fb94-4486-9e98-32ca4bdeb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21b36904-0600-4a43-bf12-7f437314aa0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 768]), torch.Size([5, 768]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.data_repr.shape, o.lbl2data_repr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a235a21e-e604-42e2-9f0f-639599a25ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa8490c8-e507-4018-b480-621f0aca37cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `TCH002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50684fc0-782c-40eb-a03f-767cfe8741bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TCH002(DistilBertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config:TCHConfig, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.data_repr = nn.Embedding(config.n_data, config.dim)\n",
    "        self.lbl_repr = nn.Embedding(config.n_lbl, config.dim)\n",
    "        self.lbl_embeddings = nn.Embedding(config.n_lbl, config.dim)\n",
    "\n",
    "    def get_lbl_embeddings(self):\n",
    "        return self.lbl_repr.weight + self.lbl_embeddings.weight\n",
    "\n",
    "    def get_data_embeddings(self):\n",
    "        return self.data_repr.weight\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_representations(self, data_repr:torch.Tensor, lbl_repr:torch.Tensor):\n",
    "        self.data_repr.weight.copy_(data_repr)\n",
    "        self.lbl_repr.weight.copy_(lbl_repr)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_lbl_embeddings(self):\n",
    "        nn.init.zeros_(self.lbl_embeddings.weight)\n",
    "\n",
    "    def freeze_representations(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "        self.lbl_repr.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_representations(self):\n",
    "        self.data_repr.requires_grad_(True)\n",
    "        self.lbl_repr.requires_grad_(True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:torch.Tensor,\n",
    "        lbl2data_idx:torch.Tensor,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        data_repr = self.data_repr(data_idx)\n",
    "        lbl2data_repr = self.lbl_repr(lbl2data_idx) + self.lbl_embeddings(lbl2data_idx)\n",
    "        return TCHOutput(\n",
    "            data_repr=data_repr,\n",
    "            lbl2data_repr=lbl2data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb5c5f-ab1f-4e9c-ad7f-d4318450f3c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5942858c-17b7-49bd-8200-c7deae854ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_teacher = TCH002(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fc1bbdf-371f-462a-9afb-da10c3a24279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_teacher.data_repr.weight.requires_grad, m_teacher.lbl_repr.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a563fa1e-72c5-4201-ad39-2b44f9913073",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_teacher.freeze_representations()\n",
    "m_teacher.init_lbl_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78d318e5-ce58-4efa-93a3-5f81fe10c40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False, True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_teacher.data_repr.weight.requires_grad,m_teacher.lbl_repr.weight.requires_grad, m_teacher.lbl_embeddings.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09c5eb33-3e9f-47a6-be99-051132ab8750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_teacher.lbl_embeddings.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a75c6fa-d7ff-4ade-b8d9-afd3c17f4cfc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `TCH003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90e50e24-ee21-460e-b8b9-3d85ef1e4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TCH003(DistilBertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config:TCHConfig, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.data_repr = nn.Embedding(config.n_data, config.dim)\n",
    "\n",
    "    def get_data_embeddings(self):\n",
    "        return self.data_repr.weight\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_embeddings(self, data_repr:torch.Tensor):\n",
    "        self.data_repr.weight.copy_(data_repr)\n",
    "\n",
    "    def freeze_embeddings(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_representations(self):\n",
    "        self.data_repr.requires_grad_(True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:torch.Tensor,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        data_repr = self.data_repr(data_idx)\n",
    "        data_repr = F.normalize(data_repr, dim=1) if self.config.normalize else data_repr\n",
    "        return TCHOutput(\n",
    "            data_repr=data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792886d2-a127-43f3-8bac-067be6c87209",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa138ec4-8cc8-48c4-86ee-495db960e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TCHConfig(n_data=1000, embed_dim=4096, normalize=False)\n",
    "model = TCH003(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87ccabd2-2c77-4bd0-bb24-311971ce7daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_repr, data_idx = torch.randn(1000, 768), torch.randint(0, 1000, size=(10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51480520-a470-4518-aa4e-945700ff9ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_embeddings(data_repr)\n",
    "model.freeze_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d559a18-3f26-4be2-a865-47342bab7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(data_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0235075a-f99d-4056-8ef9-c5412dbb069a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26.6562, 28.0896, 28.5650, 27.4916, 27.0713, 27.2589, 28.2481, 27.8620,\n",
       "        27.5937, 27.8447])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.data_repr.norm(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5f756c-81d8-440e-9e14-9b52547cc825",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `TCH004`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bca00b84-2d6e-424e-ae78-2f40fe10d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TCH004(DistilBertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config:TCHConfig, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.data_repr = nn.Embedding(config.n_data, config.embed_dim)\n",
    "        self.transform = nn.Linear(config.embed_dim, config.dim)\n",
    "\n",
    "    def get_data_embeddings(self):\n",
    "        return self.data_repr.weight\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_embeddings(self, data_repr:torch.Tensor):\n",
    "        self.data_repr.weight.copy_(data_repr)\n",
    "\n",
    "    def freeze_embeddings(self):\n",
    "        self.data_repr.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_representations(self):\n",
    "        self.data_repr.requires_grad_(True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_transform(self, embed:Optional[torch.Tensor]=None):\n",
    "        if embed is None: nn.init.eye_(self.transform.weight)\n",
    "        else: self.transform.weight.copy_(embed)\n",
    "        nn.init.zeros_(self.transform.bias)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:torch.Tensor,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        data_repr = self.transform(self.data_repr(data_idx))\n",
    "        data_repr = F.normalize(data_repr, dim=1) if self.config.normalize else data_repr\n",
    "        return TCHOutput(\n",
    "            data_repr=data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1002f47d-febd-4f48-91ba-494b93fa08bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2f7fae0-b3e3-482b-9bbe-e8b8abb2142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TCHConfig(n_data=1000, embed_dim=4096, normalize=False)\n",
    "model = TCH004(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9361d2ac-7fde-4607-8f27-640e3ad9b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_repr, data_idx = torch.randn(1000, 4096), torch.randint(0, 1000, size=(10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3fb0e88c-8f7c-4654-bb99-609590916295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.init_embeddings(data_repr)\n",
    "model.init_transform(torch.eye(config.dim, config.embed_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ecc60be7-a008-429f-ac6a-1fcc600241b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(data_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f69fe042-74fd-4507-9d3a-9ea1d0766da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28.8158, 28.0094, 26.3769, 27.1537, 28.1371, 28.5593, 27.6033, 28.7885,\n",
       "        28.6897, 27.2464], grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.data_repr.norm(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aeb38b-d71d-4698-8c7c-1b29b0bef609",
   "metadata": {},
   "source": [
    "## Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256836b-86d3-483a-9b2b-4228c1885ac5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2fc54973-2117-4851-82dc-e84d88ccd872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class DTLOutput(ModelOutput):\n",
    "    loss:Optional[torch.FloatTensor]=None\n",
    "    data_repr: Optional[torch.FloatTensor] = None\n",
    "    data_fused_repr:Optional[torch.FloatTensor] = None\n",
    "    lbl2data_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_fused_repr:Optional[torch.FloatTensor] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bde0fe-ec90-477e-825e-5b20586b78f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e87fd03-636e-488f-bf87-326ddfa1cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTLConfig(DistilBertConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        teacher_data_student_label_loss_weight:Optional[float]=1.0,\n",
    "        student_data_teacher_label_loss_weight:Optional[float]=1.0,\n",
    "        data_mse_loss_weight:Optional[float]=0.1,\n",
    "        label_mse_loss_weight:Optional[float]=0.1,\n",
    "        teacher_data_repr_name:Optional[str]='data_repr',\n",
    "        student_data_repr_name:Optional[str]='data_fused_repr',\n",
    "        teacher_label_repr_name:Optional[str]='data_repr',\n",
    "        student_label_repr_name:Optional[str]='data_repr',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.margin, self.tau, self.apply_softmax, self.n_negatives = margin, tau, apply_softmax, n_negatives\n",
    "        self.teacher_data_student_label_loss_weight = teacher_data_student_label_loss_weight\n",
    "        self.student_data_teacher_label_loss_weight = student_data_teacher_label_loss_weight\n",
    "        self.data_mse_loss_weight, self.label_mse_loss_weight = data_mse_loss_weight, label_mse_loss_weight\n",
    "        self.teacher_data_repr_name, self.student_data_repr_name = teacher_data_repr_name, student_data_repr_name\n",
    "        self.teacher_label_repr_name, self.student_label_repr_name = teacher_label_repr_name, student_label_repr_name\n",
    "        super().__init__(**kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da73d63-2d03-436c-9102-a2e2558c3dcb",
   "metadata": {},
   "source": [
    "### `DTL001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "edfc3ff0-3810-4264-af2a-0b2b3ffe9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL001(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(margin=config.margin, n_negatives=config.n_negatives, tau=config.tau, \n",
    "                                        apply_softmax=config.apply_softmax, reduce='mean')\n",
    "\n",
    "        if hasattr(m_student, 'get_label_representation'):\n",
    "            def get_label_representation(\n",
    "                self,\n",
    "                data_idx:Optional[torch.Tensor]=None,\n",
    "                data_input_ids:Optional[torch.Tensor]=None,\n",
    "                data_attention_mask:Optional[torch.Tensor]=None,\n",
    "                **kwargs\n",
    "            ):\n",
    "                return self.m_student.get_label_representation(data_idx, data_input_ids, data_attention_mask, **kwargs)\n",
    "            self.get_label_representation = MethodType(get_label_representation, self)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "        student_data_repr = getattr(student_o, self.config.student_data_repr_name, None)\n",
    "        student_label_repr = getattr(student_o, self.config.student_label_repr_name, None)\n",
    "\n",
    "        loss = None\n",
    "        if student_o.loss is not None:\n",
    "            with torch.no_grad(): teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
    "            teacher_data_repr = getattr(student_o, self.config.teacher_data_repr_name, None)\n",
    "            teacher_label_repr = getattr(student_o, self.config.teacher_label_repr_name, None)\n",
    "\n",
    "            tdsl_loss = 0.0\n",
    "            if teacher_data_repr is not None and student_label_repr is not None:\n",
    "                tdsl_loss = self.rep_loss_fn(teacher_data_repr, student_label_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                             kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            sdtl_loss = 0.0\n",
    "            if student_data_repr is not None and teacher_label_repr is not None:\n",
    "                sdtl_loss = self.rep_loss_fn(student_data_repr, teacher_label_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                             kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            dm_loss = 0.0\n",
    "            if teacher_data_repr is not None and student_data_repr is not None:\n",
    "                dm_loss = self.mse_loss_fn(teacher_data_repr, student_data_repr)\n",
    "\n",
    "            lm_loss = 0.0\n",
    "            if teacher_label_repr is not None and student_label_repr is not None:\n",
    "                lm_loss = self.mse_loss_fn(teacher_label_repr, student_label_repr)\n",
    "            \n",
    "            loss = student_o.loss\n",
    "            loss += self.config.teacher_data_student_label_loss_weight * tdsl_loss\n",
    "            loss += self.config.student_data_teacher_label_loss_weight * sdtl_loss\n",
    "            loss += self.config.data_mse_loss_weight * dm_loss + self.config.label_mse_loss_weight * lm_loss\n",
    "\n",
    "        return DTLOutput(\n",
    "            loss=loss,\n",
    "            data_repr=student_o.data_repr,\n",
    "            data_fused_repr=student_o.data_fused_repr,\n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "            lbl2data_fused_repr=student_o.lbl2data_fused_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a78aa-3918-4e7a-9893-d0c3c8a49709",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5c261461-7748-4b0c-9632-a8699d8cab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TCHConfig(n_data=1000, embed_dim=4096, normalize=False)\n",
    "m_teacher = TCH004(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "874714fd-e21d-482c-b967-9355d82813e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK003 were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'encoder.pretrained_meta_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "mname = 'distilbert-base-uncased'\n",
    "meta_name = 'lnk'\n",
    "\n",
    "m_student = OAK003.from_pretrained(mname, margin=0.3, num_negatives=10, tau=0.1, apply_softmax=True,\n",
    "                                   \n",
    "                                   data_aug_meta_prefix=f'{meta_name}2data', lbl2data_aug_meta_prefix=None,\n",
    "                               \n",
    "                                   num_metadata=block.train.dset.meta[f'{meta_name}_meta'].n_meta,\n",
    "                                   \n",
    "                                   calib_margin=0.05, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                                   calib_loss_weight=0.1, use_calib_loss=True,\n",
    "                                   \n",
    "                                   use_query_loss=True,\n",
    "                                   \n",
    "                                   use_encoder_parallel=True, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "13cd6e1a-7bb5-4a5a-9a6f-affd17a42af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DTLConfig(margin=0.3, tau=0.1, apply_softmax=False, n_negatives=5, \n",
    "                   teacher_data_student_label_loss_weight=1.0, student_data_teacher_label_loss_weight=1.0,\n",
    "                   data_mse_loss_weight=0.1, label_mse_loss_weight=0.1,\n",
    "                   teacher_data_repr_name='data_repr', student_data_repr_name='data_fused_repr',\n",
    "                   teacher_label_repr_name='data_repr', student_label_repr_name='data_repr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d8a728f7-cabf-462d-b149-c6a0def6fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL001(config, m_student=m_student, m_teacher=m_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1adae-4949-41a0-b43a-167854daf284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cd84c719-65cb-446d-a4dc-26474dbf1cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(10)\n",
    "b = prepare_batch(model, batch, m_args=['data_input_ids', 'data_attention_mask', 'lbl2data_data2ptr', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx',\n",
    "                                        'lnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', \n",
    "                                        'lnk2data_attention_mask', 'plnk2data_data2ptr', 'plnk2data_idx',\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4f6ee52b-014b-43be-b542-c574d528ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model.m_student(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "15a8fc8f-669b-4538-996d-e41ba840a8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0989, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "00ea3bc8-b733-4fc9-8854-9ded8d873110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 43 is out of bounds for dimension 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[115], line 48\u001b[0m, in \u001b[0;36mDTL001.forward\u001b[0;34m(self, data_idx, lbl2data_idx, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m tdsl_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m teacher_data_repr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m student_label_repr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     tdsl_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrep_loss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher_data_repr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_label_repr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlbl2data_data2ptr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbl2data_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplbl2data_data2ptr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplbl2data_idx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m sdtl_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m student_data_repr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m teacher_label_repr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mogic/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Projects/xcai/xcai/losses.py:309\u001b[0m, in \u001b[0;36mMultiTriplet.forward\u001b[0;34m(self, inp, targ, n_inp2targ, inp2targ_idx, n_pinp2targ, pinp2targ_idx, margin, tau, apply_softmax, n_negatives, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    297\u001b[0m     inp:torch\u001b[38;5;241m.\u001b[39mFloatTensor, \u001b[38;5;66;03m# bs x dim\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_inp2targ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp2targ_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_pinp2targ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpinp2targ_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmargin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmargin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mapply_softmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapply_softmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_negatives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_negatives\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/xcai/xcai/losses.py:250\u001b[0m, in \u001b[0;36mBaseMultiTriplet.forward\u001b[0;34m(self, n_inp2targ, inp2targ_idx, n_pinp2targ, pinp2targ_idx, inp, targ, scores, margin, tau, apply_softmax, n_negatives, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m pinp2targ_idx, n_pinp2targ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_redundant_indices(inp2targ_idx, n_inp2targ, pinp2targ_idx, n_pinp2targ)\n\u001b[1;32m    248\u001b[0m inp2targ_idx, pinp2targ_idx, indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_indices(inp2targ_idx, n_inp2targ, pinp2targ_idx, n_pinp2targ)\n\u001b[0;32m--> 250\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m scores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m scores[:, indices]\n\u001b[1;32m    252\u001b[0m pos_indices, pos_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign_indices(inp2targ_idx, n_inp2targ)\n\u001b[1;32m    253\u001b[0m pos_scores \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m1\u001b[39m, pos_indices)\n",
      "File \u001b[0;32m~/Projects/xcai/xcai/losses.py:221\u001b[0m, in \u001b[0;36mBaseMultiTriplet.compute_scores\u001b[0;34m(self, inp, targ, indices)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_scores\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp, targ, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: targ \u001b[38;5;241m=\u001b[39m \u001b[43mtarg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inp\u001b[38;5;129m@targ\u001b[39m\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mIndexError\u001b[0m: index 43 is out of bounds for dimension 0 with size 10"
     ]
    }
   ],
   "source": [
    "o = model(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c49c2af-b11c-4feb-b4df-c6a2bd1721e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6bf6a-33d7-4639-878b-37066db13228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeeddb2-f0ca-48c3-b809-59cb09d2a09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b6a3143-8a16-4f25-9fce-f118a4ffa9c7",
   "metadata": {},
   "source": [
    "### `DTL005`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0831598f-85f9-477b-8525-cd0770367f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL005(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        bsz:Optional[int]=None,\n",
    "        tn_targ:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        teacher_data_student_label_loss_weight:Optional[float]=1.0,\n",
    "        data_mse_loss_weight:Optional[float]=0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        store_attr('teacher_data_student_label_loss_weight,data_mse_loss_weight')\n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                        apply_softmax=apply_softmax, reduce='mean')\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, **kwargs)\n",
    "\n",
    "        loss = None\n",
    "        if student_o.loss is not None:\n",
    "            teacher_o = self.m_teacher(data_idx=data_idx)\n",
    "\n",
    "            tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], kwargs['lbl2data_idx'], \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
    "            \n",
    "            loss = student_o.loss\n",
    "            loss += self.teacher_data_student_label_loss_weight * tdsl_loss\n",
    "            loss += self.data_mse_loss_weight * dm_loss\n",
    "\n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=student_o.data_repr,\n",
    "            data_fused_repr=student_o.data_fused_repr,\n",
    "            \n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "            lbl2data_fused_repr=student_o.lbl2data_fused_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d3e1b8-11ca-425e-9cce-e87d3164db3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b99ffa-e537-4d66-8aa5-1111f9ea4336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK001 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-cos-v5 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "m_student = OAK001.from_pretrained('sentence-transformers/msmarco-distilbert-cos-v5', batch_size=1000, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=True,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "m_student.init_retrieval_head()\n",
    "m_student.init_cross_head()\n",
    "\n",
    "m_student.encoder.set_meta_embeddings(torch.zeros(block.train.dset.meta['lnk_meta'].n_meta, m_student.config.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d3b47-779f-4c2d-bf3b-3419d4108e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL005(DistilBertConfig(), m_student=m_student, m_teacher=m_teacher, bsz=1024, margin=0.3, tau=0.1, n_negatives=10, \n",
    "               apply_softmax=True, teacher_data_student_label_loss_weight=1.0, data_mse_loss_weight=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61270d1c-42a0-478c-b18e-80ba68b0ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))\n",
    "b = prepare_batch(model, batch, m_args=['lbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx',\n",
    "                                        'lnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', \n",
    "                                        'lnk2data_attention_mask', 'plnk2data_data2ptr', 'plnk2data_idx'\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a60de-fb4f-4d76-8520-059273804249",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,b = model.to('cuda'), b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca768bd-1e51-4561-8edc-395537527c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = m(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f74b6-b358-4c32-a027-0041fe8ec411",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca885b6-6697-4be2-9781-b8221cc49128",
   "metadata": {},
   "source": [
    "### `DTL006`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb66dc9-92b3-4096-8e6e-9c605fe47828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL006(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        bsz:Optional[int]=None,\n",
    "        tn_targ:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        teacher_data_student_label_loss_weight:Optional[float]=1.0,\n",
    "        student_data_teacher_label_loss_weight:Optional[float]=1.0,\n",
    "        data_mse_loss_weight:Optional[float]=0.1,\n",
    "        label_mse_loss_weight:Optional[float]=0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        store_attr('teacher_data_student_label_loss_weight,student_data_teacher_label_loss_weight')\n",
    "        store_attr('data_mse_loss_weight,label_mse_loss_weight')\n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                        apply_softmax=apply_softmax, reduce='mean')\n",
    "\n",
    "    def get_label_representation(self, data_idx:torch.Tensor, **kwargs):\n",
    "        return self.m_student.get_label_representation(data_idx, **kwargs)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(data_idx=data_idx, lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "\n",
    "        loss = None\n",
    "        if lbl2data_idx is not None and student_o.loss is not None:\n",
    "            teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
    "\n",
    "            tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "            \n",
    "            sdtl_loss = self.rep_loss_fn(student_o.data_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_repr)\n",
    "            lm_loss = self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
    "            \n",
    "            loss = student_o.loss\n",
    "            loss += self.teacher_data_student_label_loss_weight * tdsl_loss\n",
    "            loss += self.student_data_teacher_label_loss_weight * sdtl_loss\n",
    "            loss += self.data_mse_loss_weight * dm_loss + self.label_mse_loss_weight * lm_loss\n",
    "            \n",
    "\n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            data_repr=student_o.data_repr,\n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31da3a6e-3bc4-45f4-ad3f-7d9c1f35d1eb",
   "metadata": {},
   "source": [
    "### `DTL007`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3090a-ca62-4fff-a0f4-cce8f1f40d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL007(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        bsz:Optional[int]=None,\n",
    "        tn_targ:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        teacher_data_student_label_loss_weight:Optional[float]=1.0,\n",
    "        student_data_teacher_label_loss_weight:Optional[float]=1.0,\n",
    "        data_mse_loss_weight:Optional[float]=0.1,\n",
    "        label_mse_loss_weight:Optional[float]=0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        store_attr('teacher_data_student_label_loss_weight,student_data_teacher_label_loss_weight')\n",
    "        store_attr('data_mse_loss_weight,label_mse_loss_weight')\n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                        apply_softmax=apply_softmax, reduce='mean')\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                                   lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "\n",
    "        loss = None\n",
    "        if lbl2data_idx is not None and student_o.loss is not None:\n",
    "            teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
    "\n",
    "            tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "            \n",
    "            sdtl_loss = self.rep_loss_fn(student_o.data_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_repr)\n",
    "            lm_loss = self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
    "            \n",
    "            loss = student_o.loss\n",
    "            loss += self.teacher_data_student_label_loss_weight * tdsl_loss\n",
    "            loss += self.student_data_teacher_label_loss_weight * sdtl_loss\n",
    "            loss += self.data_mse_loss_weight * dm_loss + self.label_mse_loss_weight * lm_loss\n",
    "            \n",
    "\n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            data_repr=student_o.data_repr,            \n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb939899-3937-43f4-a0bc-5a8dc8be1ebe",
   "metadata": {},
   "source": [
    "### `DTL008`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3715d-4771-445f-a774-8d162b4b14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL008(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        bsz:Optional[int]=None,\n",
    "        tn_targ:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        teacher_data_student_label_loss_weight:Optional[float]=1.0,\n",
    "        data_mse_loss_weight:Optional[float]=0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        store_attr('teacher_data_student_label_loss_weight,data_mse_loss_weight')\n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                        apply_softmax=apply_softmax, reduce='mean')\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, **kwargs)\n",
    "\n",
    "        loss = None\n",
    "        if student_o.loss is not None:\n",
    "            teacher_o = self.m_teacher(data_idx=data_idx)\n",
    "\n",
    "            tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], kwargs['lbl2data_idx'], \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_repr)\n",
    "            \n",
    "            loss = student_o.loss\n",
    "            loss += self.teacher_data_student_label_loss_weight * tdsl_loss\n",
    "            loss += self.data_mse_loss_weight * dm_loss\n",
    "\n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            data_repr=student_o.data_repr,            \n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "        )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b3b53a-08f5-4880-88f1-f6ba716653ae",
   "metadata": {},
   "source": [
    "### `DTL009`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a472e-c4b9-4d61-b94c-139206f9a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL009(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        bsz:Optional[int]=None,\n",
    "        tn_targ:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        student_loss_weight:Optional[float]=1.0,\n",
    "        teacher_data_student_label_loss_weight:Optional[float]=1.0,\n",
    "        student_data_teacher_label_loss_weight:Optional[float]=1.0,\n",
    "        data_mse_loss_weight:Optional[float]=0.1,\n",
    "        label_mse_loss_weight:Optional[float]=0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        store_attr('student_loss_weight,teacher_data_student_label_loss_weight,student_data_teacher_label_loss_weight')\n",
    "        store_attr('data_mse_loss_weight,label_mse_loss_weight')\n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                        apply_softmax=apply_softmax, reduce='mean')\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                                   lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "\n",
    "        loss = None\n",
    "        if lbl2data_idx is not None and student_o.loss is not None:\n",
    "            teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
    "\n",
    "            tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "            \n",
    "            sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
    "            lm_loss = self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
    "            \n",
    "            loss = self.student_loss_weight * student_o.loss\n",
    "            loss += self.teacher_data_student_label_loss_weight * tdsl_loss\n",
    "            loss += self.student_data_teacher_label_loss_weight * sdtl_loss\n",
    "            loss += self.data_mse_loss_weight * dm_loss + self.label_mse_loss_weight * lm_loss\n",
    "            \n",
    "\n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=student_o.data_repr,\n",
    "            data_fused_repr=student_o.data_fused_repr,\n",
    "            \n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "            lbl2data_fused_repr=student_o.lbl2data_fused_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944d34d-d6f0-40e7-ac13-98f7ac9331cb",
   "metadata": {},
   "source": [
    "### `DTL010`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ebd6d-e8fe-479f-8356-6fc867b74162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL010(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        bsz:Optional[int]=None,\n",
    "        tn_targ:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        student_loss_weight:Optional[float]=1.0,\n",
    "        teacher_data_student_label_loss_weight:Optional[float]=1.0,\n",
    "        student_data_teacher_label_loss_weight:Optional[float]=1.0,\n",
    "        data_mse_loss_weight:Optional[float]=0.1,\n",
    "        label_mse_loss_weight:Optional[float]=0.1,\n",
    "\n",
    "        bandit_learning_rate:Optional[float]=0.01,\n",
    "        bandit_minimum_value:Optional[float]=0.1,\n",
    "        bandit_collector:Optional[int]=20,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        self.loss_weights = RLLossWeightsCumuluative(num_samples=5, reward_func=AccMiniBatch, lr=bandit_learning_rate, \n",
    "                                                     collector=bandit_collector, std=0.1, min=bandit_minimum_value,\n",
    "                                                     rest_init=[student_loss_weight,\n",
    "                                                                teacher_data_student_label_loss_weight, \n",
    "                                                                student_data_teacher_label_loss_weight, \n",
    "                                                                data_mse_loss_weight, label_mse_loss_weight])\n",
    "        \n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                        apply_softmax=apply_softmax, reduce='mean')\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                                   lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "\n",
    "        loss = None\n",
    "        if lbl2data_idx is not None and student_o.loss is not None:\n",
    "            teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
    "\n",
    "            tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "            \n",
    "            sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
    "            lm_loss = self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
    "\n",
    "            ws = self.loss_weights.sample(lbl2data_idx.device)\n",
    "\n",
    "            if self.training:\n",
    "                self.loss_weights.step(student_o.data_fused_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx,\n",
    "                                       kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'])\n",
    "            \n",
    "            loss = ws[0] * student_o.loss + ws[1] * tdsl_loss + ws[2] * sdtl_loss + ws[3] * dm_loss + ws[4] * lm_loss\n",
    "            \n",
    "\n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=student_o.data_repr,\n",
    "            data_fused_repr=student_o.data_fused_repr,\n",
    "            \n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "            lbl2data_fused_repr=student_o.lbl2data_fused_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e305f42-c82a-4fd9-a791-4801f3a2c9c2",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da919fbe-1e20-4662-918f-88a084273598",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = '/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-4'\n",
    "m_teacher = TCH001.from_pretrained(f'{model_output}/teacher', n_data=block.train.dset.n_data, n_lbl=block.n_lbl)\n",
    "\n",
    "m_teacher.freeze_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dbe841-5d8e-4724-bfcd-c57dcface170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK001 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-cos-v5 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "m_student = OAK001.from_pretrained('sentence-transformers/msmarco-distilbert-cos-v5', batch_size=1000, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=True,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "m_student.init_retrieval_head()\n",
    "m_student.init_cross_head()\n",
    "\n",
    "m_student.encoder.set_meta_embeddings(torch.zeros(block.train.dset.meta['lnk_meta'].n_meta, m_student.config.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e343abd-d3dd-4d7e-ab20-a596f27e22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL010(DistilBertConfig(), m_student=m_student, m_teacher=m_teacher, bsz=1024, margin=0.3, tau=0.1, n_negatives=10, \n",
    "               apply_softmax=True, bandit_learning_rate=0.001, bandit_minimum_value=0.01, \n",
    "               teacher_data_student_label_loss_weight=1.0, student_data_teacher_label_loss_weight=0.1, \n",
    "               data_mse_loss_weight=0.1,label_mse_loss_weight=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c0f85a-b259-4824-bad9-0f91bc9de45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))\n",
    "b = prepare_batch(model, batch, m_args=['lbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx',\n",
    "                                        'lnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', \n",
    "                                        'lnk2data_attention_mask', 'plnk2data_data2ptr', 'plnk2data_idx'\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2da433e-4538-4729-bc19-36c0a312ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,b = model.to('cuda'), b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876fa81-1763-4c2d-bd6f-7504231ba611",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e643c-d33f-4da0-bf85-8c2fb1ef0215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6928035-038b-4426-9644-34d950e38c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/2066784281.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b)\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "o = func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75575e28-27ca-4882-a7ef-dde06636f362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1139, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153388cf-039f-42a0-8a1c-a21a61238043",
   "metadata": {},
   "source": [
    "### `DTL011`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96500f90-7134-4365-8383-57648c984167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL011(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        bsz:Optional[int]=None,\n",
    "        tn_targ:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "\n",
    "        bandit_learning_rate:Optional[float]=0.01,\n",
    "        bandit_minimum_value:Optional[float]=0.1,\n",
    "        bandit_collector:Optional[int]=20,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        self.loss_weights = RLLossWeightsCumuluative(num_samples=4, reward_func=AccMiniBatch, lr=bandit_learning_rate, \n",
    "                                                     collector=bandit_collector, std=0.1, min=bandit_minimum_value, \n",
    "                                                     rest_init=bandit_minimum_value)\n",
    "        \n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                        apply_softmax=apply_softmax, reduce='mean')\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        \n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                                   lbl2data_idx=lbl2data_idx, **kwargs)\n",
    "\n",
    "        loss = None\n",
    "        if lbl2data_idx is not None and student_o.loss is not None:\n",
    "            teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
    "\n",
    "            tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "            \n",
    "            sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
    "            lm_loss = self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
    "\n",
    "            ws = self.loss_weights.sample(lbl2data_idx.device)\n",
    "\n",
    "            if self.training:\n",
    "                self.loss_weights.step(student_o.data_fused_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx,\n",
    "                                       kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'])\n",
    "            \n",
    "            loss = student_o.loss + ws[0] * tdsl_loss + ws[1] * sdtl_loss + ws[2] * dm_loss + ws[3] * lm_loss\n",
    "            \n",
    "\n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=student_o.data_repr,\n",
    "            data_fused_repr=student_o.data_fused_repr,\n",
    "            \n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "            lbl2data_fused_repr=student_o.lbl2data_fused_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fe2d88-3336-4c7a-8e39-5d3aa8e42a45",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d876e70-7534-421a-aeda-6c7a30d7403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = '/home/scai/phd/aiz218323/scratch/outputs/67-ngame-ep-for-wikiseealso-with-input-concatenation-1-4'\n",
    "m_teacher = TCH001.from_pretrained(f'{model_output}/teacher', n_data=block.train.dset.n_data, n_lbl=block.n_lbl)\n",
    "\n",
    "m_teacher.freeze_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7809889a-013d-49dd-bd3d-078b4d1e3db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK001 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-cos-v5 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "m_student = OAK001.from_pretrained('sentence-transformers/msmarco-distilbert-cos-v5', batch_size=1000, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=10, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=True,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "m_student.init_retrieval_head()\n",
    "m_student.init_cross_head()\n",
    "\n",
    "m_student.encoder.set_meta_embeddings(torch.zeros(block.train.dset.meta['lnk_meta'].n_meta, m_student.config.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65986a34-e1ff-48e8-a2cd-2a63272c1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL011(DistilBertConfig(), m_student=m_student, m_teacher=m_teacher, bsz=1024, margin=0.3, tau=0.1, \n",
    "               n_negatives=10, apply_softmax=True, bandit_learning_rate=0.01, bandit_minimum_value=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ace803-5aae-4ea5-b08e-5eb2a23a44b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))\n",
    "b = prepare_batch(model, batch, m_args=['lbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx',\n",
    "                                        'lnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', \n",
    "                                        'lnk2data_attention_mask', 'plnk2data_data2ptr', 'plnk2data_idx'\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe7f46c-ce32-4198-8945-afcd1373a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,b = model.to('cuda'), b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74b5c5-4b29-47f3-8182-a88c1c45ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02281bf0-6fd2-4168-8142-cde6d1f9ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a1acb-7c62-4de3-ab12-bb8e121784bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/2066784281.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b)\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 1 at /tmp/ipykernel_18051/802618658.py:28\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(37)forward()\n",
      "     35         **kwargs\n",
      "     36     ):\n",
      "---> 37         student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     38                                    lbl2data_idx=lbl2data_idx, **kwargs)\n",
      "     39 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(38)forward()\n",
      "     36     ):\n",
      "     37         student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 38                                    lbl2data_idx=lbl2data_idx, **kwargs)\n",
      "     39 \n",
      "     40         loss = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(37)forward()\n",
      "     35         **kwargs\n",
      "     36     ):\n",
      "---> 37         student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     38                                    lbl2data_idx=lbl2data_idx, **kwargs)\n",
      "     39 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(38)forward()\n",
      "     36     ):\n",
      "     37         student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 38                                    lbl2data_idx=lbl2data_idx, **kwargs)\n",
      "     39 \n",
      "     40         loss = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(37)forward()\n",
      "     35         **kwargs\n",
      "     36     ):\n",
      "---> 37         student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     38                                    lbl2data_idx=lbl2data_idx, **kwargs)\n",
      "     39 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(40)forward()\n",
      "     38                                    lbl2data_idx=lbl2data_idx, **kwargs)\n",
      "     39 \n",
      "---> 40         loss = None\n",
      "     41         if lbl2data_idx is not None and student_o.loss is not None:\n",
      "     42             teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  student_o.loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0890, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(41)forward()\n",
      "     39 \n",
      "     40         loss = None\n",
      "---> 41         if lbl2data_idx is not None and student_o.loss is not None:\n",
      "     42             teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
      "     43 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(42)forward()\n",
      "     40         loss = None\n",
      "     41         if lbl2data_idx is not None and student_o.loss is not None:\n",
      "---> 42             teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
      "     43 \n",
      "     44             tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(44)forward()\n",
      "     42             teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
      "     43 \n",
      "---> 44             tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "     45                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     46 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(45)forward()\n",
      "     43 \n",
      "     44             tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "---> 45                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     46 \n",
      "     47             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(44)forward()\n",
      "     42             teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
      "     43 \n",
      "---> 44             tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "     45                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     46 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(45)forward()\n",
      "     43 \n",
      "     44             tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "---> 45                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     46 \n",
      "     47             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(44)forward()\n",
      "     42             teacher_o = self.m_teacher(data_idx=data_idx, lbl2data_idx=lbl2data_idx)\n",
      "     43 \n",
      "---> 44             tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "     45                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     46 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(47)forward()\n",
      "     45                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     46 \n",
      "---> 47             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "     48                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     49 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(48)forward()\n",
      "     46 \n",
      "     47             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "---> 48                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     49 \n",
      "     50             dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(47)forward()\n",
      "     45                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     46 \n",
      "---> 47             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "     48                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     49 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(48)forward()\n",
      "     46 \n",
      "     47             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "---> 48                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     49 \n",
      "     50             dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(47)forward()\n",
      "     45                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     46 \n",
      "---> 47             sdtl_loss = self.rep_loss_fn(student_o.data_fused_repr, teacher_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx, \n",
      "     48                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     49 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(50)forward()\n",
      "     48                                          kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
      "     49 \n",
      "---> 50             dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
      "     51             lm_loss = self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
      "     52 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(51)forward()\n",
      "     49 \n",
      "     50             dm_loss = self.mse_loss_fn(teacher_o.data_repr, student_o.data_fused_repr)\n",
      "---> 51             lm_loss = self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
      "     52 \n",
      "     53             ws = self.loss_weights.sample(lbl2data_idx.device)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(53)forward()\n",
      "     51             lm_loss = self.mse_loss_fn(teacher_o.lbl2data_repr, student_o.lbl2data_repr)\n",
      "     52 \n",
      "---> 53             ws = self.loss_weights.sample(lbl2data_idx.device)\n",
      "     54 \n",
      "     55             if self.training:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(55)forward()\n",
      "     53             ws = self.loss_weights.sample(lbl2data_idx.device)\n",
      "     54 \n",
      "---> 55             if self.training:\n",
      "     56                 self.loss_weights.step(student_o.data_fused_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx,\n",
      "     57                                        kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'])\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  ws\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0500, 0.0845, 0.0500, 0.0500])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.loss_weight.std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'DTL011' object has no attribute 'loss_weight'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.loss_weights.std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1000, 0.1000, 0.1000, 0.1000])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.loss_weights.mu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.0500, 0.0500, 0.0500, 0.0500], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.loss_weights.w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0500, 0.0845, 0.0500, 0.0500])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(56)forward()\n",
      "     54 \n",
      "     55             if self.training:\n",
      "---> 56                 self.loss_weights.step(student_o.data_fused_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx,\n",
      "     57                                        kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'])\n",
      "     58 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(57)forward()\n",
      "     55             if self.training:\n",
      "     56                 self.loss_weights.step(student_o.data_fused_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx,\n",
      "---> 57                                        kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'])\n",
      "     58 \n",
      "     59             loss = student_o.loss + ws[0] * tdsl_loss + ws[1] * sdtl_loss + ws[2] * dm_loss + ws[3] * lm_loss\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(56)forward()\n",
      "     54 \n",
      "     55             if self.training:\n",
      "---> 56                 self.loss_weights.step(student_o.data_fused_repr, student_o.lbl2data_repr, kwargs['lbl2data_data2ptr'], lbl2data_idx,\n",
      "     57                                        kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'])\n",
      "     58 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(59)forward()\n",
      "     57                                        kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'])\n",
      "     58 \n",
      "---> 59             loss = student_o.loss + ws[0] * tdsl_loss + ws[1] * sdtl_loss + ws[2] * dm_loss + ws[3] * lm_loss\n",
      "     60 \n",
      "     61 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  len(ws)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(62)forward()\n",
      "     60 \n",
      "     61 \n",
      "---> 62         return RADOutput(\n",
      "     63             loss=loss,\n",
      "     64 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(63)forward()\n",
      "     61 \n",
      "     62         return RADOutput(\n",
      "---> 63             loss=loss,\n",
      "     64 \n",
      "     65             data_repr=student_o.data_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0924, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(65)forward()\n",
      "     63             loss=loss,\n",
      "     64 \n",
      "---> 65             data_repr=student_o.data_repr,\n",
      "     66             data_fused_repr=student_o.data_fused_repr,\n",
      "     67 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(66)forward()\n",
      "     64 \n",
      "     65             data_repr=student_o.data_repr,\n",
      "---> 66             data_fused_repr=student_o.data_fused_repr,\n",
      "     67 \n",
      "     68             lbl2data_repr=student_o.lbl2data_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(68)forward()\n",
      "     66             data_fused_repr=student_o.data_fused_repr,\n",
      "     67 \n",
      "---> 68             lbl2data_repr=student_o.lbl2data_repr,\n",
      "     69             lbl2data_fused_repr=student_o.lbl2data_fused_repr,\n",
      "     70         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(69)forward()\n",
      "     67 \n",
      "     68             lbl2data_repr=student_o.lbl2data_repr,\n",
      "---> 69             lbl2data_fused_repr=student_o.lbl2data_fused_repr,\n",
      "     70         )\n",
      "     71 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_18051/802618658.py(62)forward()\n",
      "     60 \n",
      "     61 \n",
      "---> 62         return RADOutput(\n",
      "     63             loss=loss,\n",
      "     64 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "RADOutput(los...sed_repr=None)\n",
      "> /tmp/ipykernel_18051/802618658.py(62)forward()\n",
      "     60 \n",
      "     61 \n",
      "---> 62         return RADOutput(\n",
      "     63             loss=loss,\n",
      "     64 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "o = func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848de9fd-ec96-4a24-9973-63d6e2ab350b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970dd96c-66c1-4d6f-8403-12b8f7133309",
   "metadata": {},
   "source": [
    "### `DTL012`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179da3e-27e0-4c06-820b-5baba07f3e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DTL012(DistilBertPreTrainedModel):\n",
    "    use_representation,use_generation = True,False\n",
    "    _tied_weights_keys = [\"m_student.encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        m_student:nn.Module,\n",
    "        m_teacher:nn.Module,\n",
    "        bsz:Optional[int]=None,\n",
    "        tn_targ:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        teacher_data_student_label_loss_weight:Optional[float]=1.0,\n",
    "        data_mse_loss_weight:Optional[float]=0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        store_attr('m_student,m_teacher')\n",
    "        store_attr('teacher_data_student_label_loss_weight,data_mse_loss_weight')\n",
    "        self.mse_loss_fn = nn.MSELoss()\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                        apply_softmax=apply_softmax, reduce='mean')\n",
    "        self.transform = nn.Linear(config.dim, m_teacher.data_repr.embedding_dim)\n",
    "\n",
    "    def init_transform(self, embed:Optional[torch.Tensor]=None):\n",
    "        if embed is None:\n",
    "            self.transform.weight.data = torch.eye(self.transform.out_features, self.transform.in_features, \n",
    "                                                   dtype=self.transform.weight.dtype)\n",
    "        else:\n",
    "            if self.transform.in_features != embed.shape[1] or self.transform.out_features != embed.shape[0]:\n",
    "                raise ValueError(f'Shape mismatch, input embedding: {embed.shape[0]}X{embed.shape[1]}')\n",
    "            self.transform.weight.data = embed\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        data_idx:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        student_o = self.m_student(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, **kwargs)\n",
    "\n",
    "        loss = None\n",
    "        if student_o.loss is not None:\n",
    "            teacher_o = self.m_teacher(data_idx=data_idx)\n",
    "\n",
    "            lbl2data_repr = F.normalize(self.transform(student_o.lbl2data_repr), dim=1)\n",
    "            data_fused_repr = F.normalize(self.transform(student_o.data_fused_repr), dim=1)\n",
    "            \n",
    "            tdsl_loss = self.rep_loss_fn(teacher_o.data_repr, lbl2data_repr, kwargs['lbl2data_data2ptr'], kwargs['lbl2data_idx'], \n",
    "                                         kwargs['plbl2data_data2ptr'], kwargs['plbl2data_idx'], **kwargs)\n",
    "\n",
    "            dm_loss = self.mse_loss_fn(teacher_o.data_repr, data_fused_repr)\n",
    "            \n",
    "            loss = student_o.loss\n",
    "            loss += self.teacher_data_student_label_loss_weight * tdsl_loss\n",
    "            loss += self.data_mse_loss_weight * dm_loss\n",
    "\n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=student_o.data_repr,\n",
    "            data_fused_repr=student_o.data_fused_repr,\n",
    "            \n",
    "            lbl2data_repr=student_o.lbl2data_repr,\n",
    "            lbl2data_fused_repr=student_o.lbl2data_fused_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f362fa5c-e516-4e3e-b437-f763e079fb70",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4709b04-5c8f-4afd-ba24-78fee242347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OAK001 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-cos-v5 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "m_student = OAK001.from_pretrained('sentence-transformers/msmarco-distilbert-cos-v5', batch_size=1000, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='lnk2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               num_metadata=block.train.dset.meta['lnk_meta'].n_meta, resize_length=5000,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=False, \n",
    "                               calib_loss_weight=0.1, use_calib_loss=True,\n",
    "\n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               meta_loss_weight=0.0, \n",
    "                               \n",
    "                               fusion_loss_weight=0.1, use_fusion_loss=False,\n",
    "                               \n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "m_student.init_retrieval_head()\n",
    "m_student.init_cross_head()\n",
    "\n",
    "m_student.encoder.set_meta_embeddings(torch.zeros(block.train.dset.meta['lnk_meta'].n_meta, m_student.config.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d7f05-bf5d-446d-b190-bb0c3cfb9316",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DTL012(DistilBertConfig(), m_student=m_student, m_teacher=m_teacher, bsz=1024, margin=0.3, tau=0.1, n_negatives=10, \n",
    "               apply_softmax=True, teacher_data_student_label_loss_weight=1.0, data_mse_loss_weight=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e065c-d63a-42b6-8321-35c5784de652",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))\n",
    "b = prepare_batch(model, batch, m_args=['lbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', \n",
    "                                        'lbl2data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx',\n",
    "                                        'lnk2data_data2ptr', 'lnk2data_idx', 'lnk2data_input_ids', \n",
    "                                        'lnk2data_attention_mask', 'plnk2data_data2ptr', 'plnk2data_idx'\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68217376-a46e-4706-9ef9-4fdddfa0bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,b = model.to('cuda'), b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea07a42-d928-4242-8874-3664cf1d4bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = m(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4080fcc-2a15-4bdb-8a48-9bde7a72ef32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1215, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e0361-5df5-4a8a-bd59-62425f5ceba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
