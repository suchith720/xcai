{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f8c4b0-a146-44bf-b9c0-140ee9bd4aa3",
   "metadata": {},
   "source": [
    "# `Miscellaneous`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab7f9691-1c78-4bd1-93bc-7536ecf92e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98bfb9c-a031-4913-810f-b47b342165da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, torch ,json, torch.multiprocessing as mp, joblib, numpy as np, scipy.sparse as sp, argparse\n",
    "from typing import Optional, Union, Callable, List\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from xclib.utils.sparse import retain_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b073af23-e537-471a-8cc7-a8f04811fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from xcai.core import *\n",
    "from xcai.data import *\n",
    "from xcai.sdata import SXCDataset, SMainXCDataset\n",
    "\n",
    "from xcai.basics import *\n",
    "from xcai.models.PPP0XX import DBT009, DBTConfig\n",
    "from xcai.models.upma import UPA000, UPMAConfig\n",
    "from xcai.models.PPP0XX import DBT023, DBTConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1b05d4-de76-4ace-8c88-87765775b228",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e2c0ab-b869-4683-82c2-04c939e76b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_info(save_file:str, meta_file:str, mname:str, sequence_length:Optional[int]=32):\n",
    "    os.makedirs(os.path.dirname(save_file), exist_ok=True)\n",
    "    if os.path.exists(save_file):\n",
    "        meta_info = joblib.load(save_file)\n",
    "    else:\n",
    "        meta_info = Info.from_txt(meta_file, max_sequence_length=sequence_length, padding=True, return_tensors='pt',\n",
    "                                  info_column_names=[\"identifier\", \"input_text\"], tokenization_column=\"input_text\",\n",
    "                                  use_tokenizer=True, tokenizer=mname)\n",
    "        joblib.dump(meta_info, save_file)\n",
    "    return meta_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de7cd944-e359-40c7-941a-2f9a95e68505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def collate_beir_metrics(metric_dir:str):\n",
    "    beir_metrics = {}\n",
    "    for dataset in BEIR_DATASETS:\n",
    "        dataset = dataset.replace(\"/\", \"-\")\n",
    "        \n",
    "        fname = f\"{metric_dir}/{dataset}.json\"\n",
    "        if os.path.exists(fname):\n",
    "            with open(fname) as file:\n",
    "                beir_metrics.update(json.load(file))\n",
    "            \n",
    "    with open(f\"{metric_dir}/beir.json\", \"w\") as file:\n",
    "        json.dump(beir_metrics, file, indent=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73776e34-8cf4-4f0a-b3bb-f8b03be2eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def additional_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--pct\", type=float, default=1.0)\n",
    "    parser.add_argument(\"--use_all\", action=\"store_true\")\n",
    "    parser.add_argument(\"--use_task_specific_metadata\", action=\"store_true\")\n",
    "    parser.add_argument(\"--use_training_test_set\", action=\"store_true\")\n",
    "    return parser.parse_known_args()[0]\n",
    "\n",
    "def get_random_idx(n_data:int, pct:float):\n",
    "    n_trn = int(pct * n_data)\n",
    "    return np.random.permutation(n_data)[:n_trn]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c1a562-5c1d-4327-b037-a9f100a38960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_label_dataset(dataset:SXCDataset, mname:str, args:argparse.ArgumentParser):\n",
    "    lbl_info = dataset.data.lbl_info\n",
    "    dataset = SXCDataset(SMainXCDataset(data_info=lbl_info, lbl_info=lbl_info))\n",
    "    mname = mname.split(\"/\")[1] if \"/\" in mname else mname\n",
    "    args.prediction_suffix = f\"labels_{mname}\" if args.use_pretrained else \"labels\"\n",
    "    return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7c4d74-e7ed-49cf-b1c7-7adbba359cb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## BeIR datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85558afa-0be2-4aee-8cea-6526025113dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "BEIR_DATASETS = [\n",
    "    \"arguana\",\n",
    "    \"msmarco\",\n",
    "    \"climate-fever\",\n",
    "    \"dbpedia-entity\",\n",
    "    \"fever\",\n",
    "    \"fiqa\",\n",
    "    \"hotpotqa\",\n",
    "    \"nfcorpus\",\n",
    "    \"nq\",\n",
    "    \"quora\",\n",
    "    \"scidocs\",\n",
    "    \"scifact\",\n",
    "    \"webis-touche2020\",\n",
    "    \"trec-covid\",\n",
    "    \"cqadupstack/android\",\n",
    "    \"cqadupstack/english\",\n",
    "    \"cqadupstack/gaming\",\n",
    "    \"cqadupstack/gis\",\n",
    "    \"cqadupstack/mathematica\",\n",
    "    \"cqadupstack/physics\",\n",
    "    \"cqadupstack/programmers\",\n",
    "    \"cqadupstack/stats\",\n",
    "    \"cqadupstack/tex\",\n",
    "    \"cqadupstack/unix\",\n",
    "    \"cqadupstack/webmasters\",\n",
    "    \"cqadupstack/wordpress\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b762d-e78c-43d3-85d4-e0a8f37d7bdc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `Linker utils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06c784ed-f0f1-4bfe-8b7d-0b0c8aee6fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_linker_block(dataset:str, config_file:str, input_args:argparse.ArgumentParser, extra_args:Optional[argparse.ArgumentParser]=None, \n",
    "                      main_max_data_sequence_length:Optional[int]=32):\n",
    "    config_key, fname = get_config_key(config_file)\n",
    "    pkl_file = get_pkl_file(input_args.pickle_dir, f\"{dataset}_{fname}_distilbert-base-uncased\", input_args.use_sxc_sampler,\n",
    "                            input_args.exact, input_args.only_test)\n",
    "\n",
    "    os.makedirs(os.path.dirname(pkl_file), exist_ok=True)\n",
    "    block = build_block(pkl_file, config_file, input_args.use_sxc_sampler, config_key, do_build=input_args.build_block, only_test=input_args.only_test,\n",
    "                        n_slbl_samples=1, main_oversample=False, main_max_data_sequence_length=main_max_data_sequence_length)\n",
    "\n",
    "    do_inference = check_inference_mode(input_args)\n",
    "    if do_inference:\n",
    "        train_dset = None if block.train is None else block.train.dset\n",
    "        test_dset = block.test.dset.get_valid_dset() if extra_args.use_training_test_set else block.test.dset\n",
    "    else:\n",
    "        train_dset = block.train.dset.get_valid_dset()\n",
    "        test_dset = block.test.dset.get_valid_dset()\n",
    "        if extra_args.pct < 1.0:\n",
    "            train_dset = train_dset._getitems(get_random_idx(len(train_dset), extra_args.pct))\n",
    "\n",
    "    return train_dset, test_dset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0fa0ea5e-a9f3-4fa0-bf78-98612f0bfc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def linker_run(output_dir:str, input_args:argparse.ArgumentParser, mname:str, test_dset:Union[XCDataset, SXCDataset],\n",
    "               train_dset:Optional[Union[XCDataset, SXCDataset]]=None, label_dset:Optional[Union[XCDataset, SXCDataset]]=None,\n",
    "               collator:Optional[Callable]=identity_collate_fn, save_dir_name:Optional[str]=None):\n",
    "\n",
    "    args = XCLearningArguments(\n",
    "        output_dir=output_dir,\n",
    "        logging_first_step=True,\n",
    "        per_device_train_batch_size=800,\n",
    "        per_device_eval_batch_size=800,\n",
    "        representation_num_beams=200,\n",
    "        representation_accumulation_steps=10,\n",
    "        save_strategy=\"steps\",\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=5000,\n",
    "        save_steps=5000,\n",
    "        save_total_limit=5,\n",
    "        num_train_epochs=300,\n",
    "        predict_with_representation=True,\n",
    "        representation_search_type='BRUTEFORCE',\n",
    "        adam_epsilon=1e-6,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        learning_rate=2e-4,\n",
    "\n",
    "        group_by_cluster=True,\n",
    "        num_clustering_warmup_epochs=10,\n",
    "        num_cluster_update_epochs=5,\n",
    "        num_cluster_size_update_epochs=25,\n",
    "        clustering_type='EXPO',\n",
    "        minimum_cluster_size=2,\n",
    "        maximum_cluster_size=1600,\n",
    "\n",
    "        metric_for_best_model='N@10',\n",
    "        load_best_model_at_end=True,\n",
    "        target_indices_key='plbl2data_idx',\n",
    "        target_pointer_key='plbl2data_data2ptr',\n",
    "\n",
    "        use_encoder_parallel=True,\n",
    "        max_grad_norm=None,\n",
    "        fp16=True,\n",
    "\n",
    "        use_cpu_for_searching=True,\n",
    "        use_cpu_for_clustering=True,\n",
    "    )\n",
    "\n",
    "    config = DBTConfig(\n",
    "        margin = 0.3,\n",
    "        num_negatives = 10,\n",
    "        tau = 0.1,\n",
    "        apply_softmax = True,\n",
    "        reduction = \"mean\",\n",
    "\n",
    "        normalize = True,\n",
    "        use_layer_norm = True,\n",
    "\n",
    "        use_encoder_parallel = True,\n",
    "        loss_function = \"triplet\"\n",
    "    )\n",
    "\n",
    "    def model_fn(mname, config):\n",
    "        return DBT009.from_pretrained(mname, config=config)\n",
    "\n",
    "    do_inference = check_inference_mode(input_args)\n",
    "    model = load_model(args.output_dir, model_fn, {\"mname\": mname, \"config\": config}, do_inference=do_inference,\n",
    "                       use_pretrained=input_args.use_pretrained)\n",
    "\n",
    "    metric = PrecReclMrr(test_dset.data.n_lbl, test_dset.data.data_lbl_filterer, prop=None if train_dset is None else train_dset.data.data_lbl,\n",
    "                         pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200], mk=[5, 10, 20])\n",
    "\n",
    "    learn = XCLearner(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dset,\n",
    "        eval_dataset=test_dset,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=metric,\n",
    "    )\n",
    "\n",
    "    eval_dataset = get_label_dataset(test_dset, mname, input_args) if input_args.label_similarity else None\n",
    "\n",
    "    return main(learn, input_args, n_lbl=test_dset.data.n_lbl, eval_dataset=eval_dataset, \n",
    "                eval_k=10, train_k=10, label_dataset=label_dset, label_k=10, save_dir_name=save_dir_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2b6390-2360-4014-89c0-8113e9268745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ebe6c27c-8ec4-4716-b136-b5c61e79b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def linker_beir_inference(output_dir:str, input_args:argparse.ArgumentParser, mname:str, \n",
    "                          save_file_name:str, meta_file:str, datasets:Optional[List]=None, \n",
    "                          pred_dir_name:Optional[str]=None, use_task_specific_metadata:Optional[bool]=False, \n",
    "                          meta_sequence_length:Optional[int]=64, get_label_predictions:Optional[bool]=False):\n",
    "    \n",
    "    metric_dir = f\"{output_dir}/metrics\"\n",
    "    os.makedirs(metric_dir, exist_ok=True)\n",
    "\n",
    "    input_args.only_test = input_args.do_test_inference = input_args.save_test_prediction = True\n",
    "    \n",
    "    # meta-data\n",
    "    if not use_task_specific_metadata:\n",
    "        meta_info = load_info(f\"{input_args.pickle_dir}/{save_file_name}.joblib\",\n",
    "                              f\"/data/datasets/beir/msmarco/XC/{meta_file}\",\n",
    "                              mname, sequence_length=meta_sequence_length)\n",
    "\n",
    "    os.makedirs(f\"{input_args.pickle_dir}/beir/\", exist_ok=True)\n",
    "\n",
    "    datasets = BEIR_DATASETS if datasets is None else datasets\n",
    "    for dataset in tqdm(datasets):\n",
    "        print(dataset)\n",
    "        dataset_prefix = dataset.replace(\"/\", \"-\")\n",
    "        \n",
    "        # test-data\n",
    "        test_info = load_info(f\"{input_args.pickle_dir}/beir/{dataset_prefix}.joblib\",\n",
    "                              f\"/data/datasets/beir/{dataset}/XC/raw_data/test.raw.csv\",\n",
    "                              mname, sequence_length=32)\n",
    "        \n",
    "        # meta-data\n",
    "        if use_task_specific_metadata:\n",
    "            fname = f\"/data/datasets/beir/{dataset}/XC/{meta_file}\"\n",
    "            if os.path.exists(fname):\n",
    "                meta_info = load_info(f\"{input_args.pickle_dir}/beir/{save_file_name}/{dataset_prefix}.joblib\",\n",
    "                                      fname, mname, sequence_length=meta_sequence_length)\n",
    "            else:\n",
    "                print(f\"WARNING:: Missing raw file at {fname}. Dataset '{dataset_prefix}' will be skipped.\")\n",
    "                continue\n",
    "                \n",
    "        # dataset\n",
    "        test_dset = SXCDataset(SMainXCDataset(data_info=test_info, lbl_info=meta_info))\n",
    "\n",
    "        # label-data\n",
    "        label_dset = None\n",
    "        if get_label_predictions:\n",
    "            input_args.do_label_inference = input_args.save_label_prediction = True\n",
    "            \n",
    "            lbl_info = load_info(f\"{input_args.pickle_dir}/beir/{dataset_prefix}-label.joblib\", \n",
    "                                 f\"/data/datasets/beir/{dataset}/XC/raw_data/label.raw.csv\",\n",
    "                                 mname, sequence_length=128)\n",
    "            label_dset = SXCDataset(SMainXCDataset(data_info=lbl_info, lbl_info=meta_info))\n",
    "            \n",
    "        input_args.prediction_suffix = dataset_prefix\n",
    "        trn_repr, tst_repr, lbl_repr, trn_pred, tst_pred, trn_metric, tst_metric = linker_run(output_dir, input_args, mname, test_dset, \n",
    "                                                                                              save_dir_name=pred_dir_name, label_dset=label_dset)\n",
    "\n",
    "        with open(f\"{metric_dir}/{dataset_prefix}.json\", \"w\") as file:\n",
    "            json.dump({dataset: tst_metric}, file, indent=4)\n",
    "\n",
    "    collate_beir_metrics(metric_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e729664c-1aa4-446d-8521-c4e01510e775",
   "metadata": {},
   "source": [
    "## `UPMA utils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "01e6c5eb-8261-4e26-a556-c9c2be89849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def upma_beir_inference(output_dir:str, input_args:argparse.ArgumentParser, mname:str, meta_save_fname:str, \n",
    "                        meta_file:str, linker_dir:str, n_data_lnk_samples:Optional[int]=5, n_lbl_lnk_samples:Optional[int]=5, \n",
    "                        data_lnk_topk:Optional[int]=5, lbl_lnk_topk:Optional[int]=5, eval_batch_size:Optional[int]=400, \n",
    "                        datasets:Optional[List]=None, pred_dir_name:Optional[str]=None, data_repr_pooling:Optional[bool]=True, \n",
    "                        memory_injection_layer:Optional[Union[int, List]]=6, memory_type:Optional[Union[str, List]]=\"embeddings\", \n",
    "                        n_memory_layers:Optional[int]=3, use_label_memory:Optional[bool]=False, num_input_metadata:Optional[int]=5):\n",
    "    \n",
    "    metric_dir = f\"{output_dir}/metrics\"\n",
    "    os.makedirs(metric_dir, exist_ok=True)\n",
    "\n",
    "    input_args.only_test = input_args.do_test_inference = input_args.save_test_prediction = True\n",
    "\n",
    "    meta_info = load_info(f\"{input_args.pickle_dir}/{meta_save_fname}.joblib\", meta_file, mname, \n",
    "                          sequence_length=64)\n",
    "\n",
    "    datasets = BEIR_DATASETS if datasets is None else datasets\n",
    "    for dataset in tqdm(datasets):\n",
    "        print(dataset)\n",
    "\n",
    "        config_file = f\"/data/datasets/beir/{dataset}/XC/configs/data.json\"\n",
    "        train_dset, test_dset = load_upma_block(dataset, config_file, input_args)\n",
    "\n",
    "        dataset = dataset.replace(\"/\", \"-\")\n",
    "        data_meta = retain_topk(sp.load_npz(f\"{linker_dir}/predictions/test_predictions_{dataset}.npz\"), k=data_lnk_topk)\n",
    "        lbl_meta = (\n",
    "            retain_topk(sp.load_npz(f\"{linker_dir}/predictions/label_predictions_{dataset}.npz\"), k=lbl_lnk_topk) \n",
    "            if use_label_memory else None\n",
    "        )\n",
    "        \n",
    "        meta_kwargs = {\n",
    "            \"lnk_meta\": SMetaXCDataset(prefix=\"lnk\", data_meta=data_meta, lbl_meta=lbl_meta, meta_info=meta_info, n_sdata_meta_samples=n_data_lnk_samples,\n",
    "                                       n_slbl_meta_samples=n_lbl_lnk_samples, return_scores=True, meta_oversample=True),\n",
    "        }\n",
    "        test_dset = SXCDataset(test_dset.data, **meta_kwargs)\n",
    "\n",
    "        input_args.prediction_suffix = dataset\n",
    "        trn_repr, tst_repr, lbl_repr, trn_pred, tst_pred, trn_metric, tst_metric = upma_run(output_dir, input_args, mname, test_dset, train_dset, \n",
    "                                                                                            eval_batch_size=eval_batch_size, save_dir_name=pred_dir_name, \n",
    "                                                                                            data_repr_pooling=data_repr_pooling, \n",
    "                                                                                            memory_injection_layer=memory_injection_layer, \n",
    "                                                                                            use_label_memory=use_label_memory, memory_type=memory_type, \n",
    "                                                                                            n_memory_layers=n_memory_layers, \n",
    "                                                                                            num_input_metadata=num_input_metadata)\n",
    "        \n",
    "        with open(f\"{metric_dir}/{dataset}.json\", \"w\") as file:\n",
    "            json.dump({dataset: tst_metric}, file, indent=4)\n",
    "\n",
    "    collate_beir_metrics(metric_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55dd6ba-9df3-46d9-8acd-81133adabe3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3fdebba8-ce75-49a8-8aa1-607000aefbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_upma_block(dataset:str, config_file:str, input_args:argparse.ArgumentParser, n_data_lnk_samples:Optional[int]=5, \n",
    "                    n_lbl_lnk_samples:Optional[int]=5, n_neg_lnk_samples:Optional[int]=5, data_lnk_topk:Optional[int]=5, \n",
    "                    lbl_lnk_topk:Optional[int]=5, neg_lnk_topk:Optional[int]=5):\n",
    "    config_key, fname = get_config_key(config_file)\n",
    "    pkl_file = get_pkl_file(input_args.pickle_dir, f\"{dataset}_{fname}_distilbert-base-uncased\", input_args.use_sxc_sampler,\n",
    "                            input_args.exact, input_args.only_test)\n",
    "\n",
    "    os.makedirs(os.path.dirname(pkl_file), exist_ok=True)\n",
    "    block = build_block(pkl_file, config_file, input_args.use_sxc_sampler, config_key, do_build=input_args.build_block, \n",
    "                        only_test=input_args.only_test, main_oversample=True, meta_oversample=True, return_scores=True, \n",
    "                        n_slbl_samples=1, n_sdata_meta_samples={\"lnk_meta\": n_data_lnk_samples, \"neg_meta\": 1},\n",
    "                        n_slbl_meta_samples={\"lnk_meta\": n_lbl_lnk_samples, \"neg_meta\": 1},\n",
    "                        n_sneg_meta_samples={\"lnk_meta\": n_neg_lnk_samples, \"neg_meta\": 1},\n",
    "                        \n",
    "                        train_data_meta_topk={\"lnk_meta\": data_lnk_topk}, test_data_meta_topk={\"lnk_meta\": data_lnk_topk}, \n",
    "                        train_label_meta_topk={\"lnk_meta\": lbl_lnk_topk}, test_label_meta_topk={\"lnk_meta\": lbl_lnk_topk},\n",
    "                        train_neg_meta_topk={\"lnk_meta\": neg_lnk_topk}, test_neg_meta_topk={\"lnk_meta\": neg_lnk_topk},)\n",
    "    \n",
    "    train_dset, test_dset = None if block.train is None else block.train.dset, block.test.dset\n",
    "\n",
    "    return train_dset, test_dset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4410a8-dc20-4c00-939c-22461f527b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ea65d184-2ccb-4aa8-aadd-973804b7cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def upma_run(output_dir:str, input_args:argparse.ArgumentParser, mname:str, test_dset:Union[XCDataset, SXCDataset],\n",
    "             train_dset:Optional[Union[XCDataset, SXCDataset]]=None, collator:Optional[Callable]=identity_collate_fn, \n",
    "             train_batch_size:Optional[int]=128, eval_batch_size:Optional[int]=400, save_dir_name:Optional[str]=None,\n",
    "             data_repr_pooling:Optional[bool]=True, memory_injection_layer:Optional[Union[int, List]]=6, \n",
    "             memory_type:Optional[Union[str, List]]=\"embeddings\", n_memory_layers:Optional[int]=3, \n",
    "             use_label_memory:Optional[bool]=False, num_input_metadata:Optional[int]=5):\n",
    "\n",
    "    label_names = [\"plbl2data_idx\", \"plbl2data_data2ptr\", \"lnk2data_idx\", \"lnk2data_data2ptr\", \"lnk2data_scores\"]\n",
    "    if \"encoder\" in label_names: label_names = label_names + [\"lnk2data_input_ids\", \"lnk2data_attention_mask\"]\n",
    "    \n",
    "    label_memory_names = [\"lnk2lbl_idx\", \"lnk2lbl_data2ptr\", \"lnk2lbl_lbl2ptr\", \"lnk2lbl_scores\", \n",
    "                          \"lnk2neg_idx\", \"lnk2neg_data2ptr\", \"lnk2neg_neg2ptr\", \"lnk2neg_scores\"]\n",
    "    if \"encoder\" in label_names:\n",
    "        label_memory_names = label_memory_names + [\"lnk2lbl_input_ids\", \"lnk2lbl_attention_mask\", \"lnk2neg_input_ids\", \"lnk2neg_attention_mask\"]\n",
    "    \n",
    "    label_names = label_names + label_memory_names if use_label_memory else label_names\n",
    "    use_label_metadata = lbl2data_inject_memory = neg2data_inject_memory = use_label_memory\n",
    "\n",
    "    memory_type = memory_type if isinstance(memory_type, list) else [memory_type]\n",
    "    memory_injection_layer = memory_injection_layer if isinstance(memory_injection_layer, list) else [memory_injection_layer]\n",
    "    \n",
    "    args = XCLearningArguments(\n",
    "        output_dir=output_dir,\n",
    "        logging_first_step=True,\n",
    "        per_device_train_batch_size=train_batch_size,\n",
    "        per_device_eval_batch_size=eval_batch_size,\n",
    "        representation_num_beams=200,\n",
    "        representation_accumulation_steps=10,\n",
    "        save_strategy=\"steps\",\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=5000,\n",
    "        save_steps=5000,\n",
    "        save_total_limit=5,\n",
    "        num_train_epochs=50,\n",
    "        predict_with_representation=True,\n",
    "        representation_search_type='BRUTEFORCE',\n",
    "        search_normalize=False,\n",
    "\n",
    "        adam_epsilon=1e-6,\n",
    "        warmup_steps=1000,\n",
    "        weight_decay=0.01,\n",
    "        learning_rate=6e-5,\n",
    "        label_names=label_names,\n",
    "\n",
    "        group_by_cluster=True,\n",
    "        use_data_metadata_for_clustering=True,\n",
    "        num_clustering_warmup_epochs=10,\n",
    "        num_cluster_update_epochs=5,\n",
    "        num_cluster_size_update_epochs=25,\n",
    "        clustering_type='EXPO',\n",
    "        minimum_cluster_size=2,\n",
    "        maximum_cluster_size=1600,\n",
    "\n",
    "        data_aug_meta_name=\"lnk\",\n",
    "        use_label_metadata=use_label_metadata,\n",
    "\n",
    "        metric_for_best_model='N@10',\n",
    "        load_best_model_at_end=True,\n",
    "        target_indices_key='plbl2data_idx',\n",
    "        target_pointer_key='plbl2data_data2ptr',\n",
    "\n",
    "        use_encoder_parallel=True,\n",
    "        max_grad_norm=None,\n",
    "        fp16=True,\n",
    "\n",
    "        use_cpu_for_searching=True,\n",
    "        use_cpu_for_clustering=True,\n",
    "    )\n",
    "\n",
    "    config = UPMAConfig(\n",
    "        memory_module_names = memory_type,\n",
    "        memory_injection_layers = memory_injection_layer,\n",
    "\n",
    "        num_total_metadata = test_dset.meta[\"lnk_meta\"].n_meta,\n",
    "        num_input_metadata = num_input_metadata,\n",
    "        metadata_dropout = 0.1,\n",
    "\n",
    "        n_memory_layers = 3,\n",
    "\n",
    "        data_aug_meta_prefix=\"lnk2data\",\n",
    "        lbl2data_aug_meta_prefix=\"lnk2lbl\",\n",
    "        neg2data_aug_meta_prefix=\"lnk2neg\",\n",
    "\n",
    "        data_inject_memory=True,\n",
    "        lbl2data_inject_memory=lbl2data_inject_memory,\n",
    "        neg2data_inject_memory=neg2data_inject_memory,\n",
    "\n",
    "        data_repr_pooling=data_repr_pooling,\n",
    "        data_normalize=False,\n",
    "\n",
    "        margin=0.3,\n",
    "        num_negatives=10,\n",
    "        tau=0.1,\n",
    "        apply_softmax=True,\n",
    "        reduction=\"mean\",\n",
    "\n",
    "        calib_margin=0.3,\n",
    "        calib_num_negatives=10,\n",
    "        calib_tau=0.1,\n",
    "        calib_apply_softmax=False,\n",
    "\n",
    "        calib_loss_weight=0.1,\n",
    "        use_calib_loss=True,\n",
    "\n",
    "        use_encoder_parallel=True,\n",
    "        loss_function=\"margin\",\n",
    "\n",
    "        initialize_memory_embeddings_from_injection_layer_mean=True,\n",
    "        metadata_embedding_file=f\"{output_dir}/metadata/gpt-substring.pth\",\n",
    "    )\n",
    "\n",
    "    def model_fn(mname:Optional[str]=None):\n",
    "        meta_dset = test_dset.meta_dset(\"lnk_meta\")\n",
    "        model = UPA000.from_pretrained(config, mname=mname, meta_dset=meta_dset, batch_size=1000)\n",
    "        return model\n",
    "\n",
    "    metric = PrecReclMrr(test_dset.n_lbl, test_dset.data.data_lbl_filterer, pk=10, rk=200, rep_pk=[1, 3, 5, 10],\n",
    "                         rep_rk=[10, 100, 200], mk=[5, 10, 20])\n",
    "\n",
    "    model = load_model(args.output_dir, model_fn, do_inference=check_inference_mode(input_args), use_pretrained=input_args.use_pretrained)\n",
    "\n",
    "    learn = XCLearner(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dset,\n",
    "        eval_dataset=test_dset,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=metric,\n",
    "    )\n",
    "\n",
    "    return main(learn, input_args, n_lbl=test_dset.n_lbl, save_dir_name=save_dir_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feed1f6-8331-428c-8295-a954578e8bcc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `Early-fusion utils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff03e751-d389-42ff-9949-d761a8a13809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def early_fusion_run(output_dir:str, input_args:argparse.ArgumentParser, mname:str, test_dset:Union[XCDataset, SXCDataset],\n",
    "                     train_dset:Optional[Union[XCDataset, SXCDataset]]=None, collator:Optional[Callable]=identity_collate_fn, \n",
    "                     save_dir_name:Optional[str]=None):\n",
    "\n",
    "    args = XCLearningArguments(\n",
    "        output_dir=output_dir,\n",
    "        logging_first_step=True,\n",
    "        per_device_train_batch_size=128,\n",
    "        per_device_eval_batch_size=1600,\n",
    "        representation_num_beams=200,\n",
    "        representation_accumulation_steps=10,\n",
    "        save_strategy=\"steps\",\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=5000,\n",
    "        save_steps=5000,\n",
    "        save_total_limit=5,\n",
    "        num_train_epochs=50,\n",
    "        predict_with_representation=True,\n",
    "        representation_search_type='BRUTEFORCE',\n",
    "        search_normalize=False,\n",
    "\n",
    "        adam_epsilon=1e-6,\n",
    "        warmup_steps=1000,\n",
    "        weight_decay=0.01,\n",
    "        learning_rate=6e-5,\n",
    "        label_names=['plbl2data_idx', 'plbl2data_data2ptr'],\n",
    "\n",
    "        group_by_cluster=True,\n",
    "        num_clustering_warmup_epochs=10,\n",
    "        num_cluster_update_epochs=5,\n",
    "        num_cluster_size_update_epochs=25,\n",
    "        clustering_type='EXPO',\n",
    "        minimum_cluster_size=2,\n",
    "        maximum_cluster_size=1600,\n",
    "\n",
    "        metric_for_best_model='P@1',\n",
    "        load_best_model_at_end=True,\n",
    "        target_indices_key='plbl2data_idx',\n",
    "        target_pointer_key='plbl2data_data2ptr',\n",
    "\n",
    "        use_encoder_parallel=True,\n",
    "        max_grad_norm=None,\n",
    "        fp16=True,\n",
    "\n",
    "        use_cpu_for_searching=True,\n",
    "        use_cpu_for_clustering=True,\n",
    "    )\n",
    "\n",
    "    config = DBTConfig(\n",
    "        normalize = False,\n",
    "        use_layer_norm = False,\n",
    "        use_encoder_parallel = True,\n",
    "    )\n",
    "\n",
    "    def model_fn(mname, config):\n",
    "        return DBT023.from_pretrained(mname, config=config)\n",
    "\n",
    "    do_inference = check_inference_mode(input_args)\n",
    "    model = load_model(args.output_dir, model_fn, {\"mname\": mname, \"config\": config}, do_inference=do_inference,\n",
    "                       use_pretrained=input_args.use_pretrained)\n",
    "\n",
    "    metric = PrecReclMrr(test_dset.data.n_lbl, test_dset.data.data_lbl_filterer, prop=None if train_dset is None else train_dset.data.data_lbl,\n",
    "                         pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200], mk=[5, 10, 20])\n",
    "\n",
    "    learn = XCLearner(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dset,\n",
    "        eval_dataset=test_dset,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=metric,\n",
    "    )\n",
    "\n",
    "    return main(learn, input_args, n_lbl=test_dset.data.n_lbl, eval_k=10, train_k=10, save_dir_name=save_dir_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "38e42849-1b88-468f-8c7b-861bb4f17e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_early_fusion_block(dataset:str, config_file:str, input_args:argparse.ArgumentParser):\n",
    "    config_key, fname = get_config_key(config_file)\n",
    "    pkl_file = get_pkl_file(input_args.pickle_dir, f\"{dataset}_{fname}_distilbert-base-uncased\", input_args.use_sxc_sampler,\n",
    "                            input_args.exact, input_args.only_test)\n",
    "\n",
    "    os.makedirs(os.path.dirname(pkl_file), exist_ok=True)\n",
    "    block = build_block(pkl_file, config_file, input_args.use_sxc_sampler, config_key, do_build=input_args.build_block,\n",
    "                        only_test=input_args.only_test, n_slbl_samples=1, main_oversample=False, n_sdata_meta_samples=1,\n",
    "                        meta_oversample=False, return_scores=True)\n",
    "    train_dset, test_dset = None if block.train is None else block.train.dset, block.test.dset\n",
    "\n",
    "    return train_dset, test_dset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0172c99-03e6-46bf-8732-36ee608abb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def early_fusion_beir_inference(output_dir:str, input_args:argparse.ArgumentParser, mname:str, linker_dir:str, \n",
    "                                datasets:Optional[List]=None, raw_dir_name:Optional[str]=\"raw_data\", \n",
    "                                metric_dir_name:Optional[str]=\"metrics\", pred_dir_name:Optional[str]=None):\n",
    "    \n",
    "    metric_dir = f\"{output_dir}/{metric_dir_name}\"\n",
    "    os.makedirs(metric_dir, exist_ok=True)\n",
    "\n",
    "    input_args.only_test = input_args.do_test_inference = input_args.save_test_prediction = True\n",
    "\n",
    "    datasets = BEIR_DATASETS if datasets is None else datasets\n",
    "    for dataset in tqdm(datasets):\n",
    "        print(dataset)\n",
    "\n",
    "        config_file = f\"/data/datasets/beir/{dataset}/XC/configs/data.json\"\n",
    "        train_dset, test_dset = load_early_fusion_block(dataset, config_file, input_args)\n",
    "\n",
    "        dataset = dataset.replace(\"/\", \"-\")\n",
    "        linker_dir_name, cross_name = os.path.basename(linker_dir.rstrip(\"/\")), raw_dir_name.rstrip(\"/\")\n",
    "        linker_dir_name = f\"{linker_dir_name}/{cross_name.split('/')[1]}\" if \"/\" in cross_name else linker_dir_name\n",
    "\n",
    "        data_file = f\"{linker_dir}/{raw_dir_name}/test_{dataset}.raw.csv\"\n",
    "        if not os.path.exists(data_file):\n",
    "            print(f\"WARNING:: Missing raw file at {data_file}. Dataset '{dataset}' will be skipped.\")\n",
    "            continue\n",
    "        \n",
    "        data_info = load_info(f\"{input_args.pickle_dir}/{linker_dir_name}/{dataset}.joblib\",\n",
    "                              data_file, mname, sequence_length=128)\n",
    "        test_dset = SXCDataset(SMainXCDataset(data_info=data_info, data_lbl=test_dset.data.data_lbl, lbl_info=test_dset.data.lbl_info))\n",
    "\n",
    "        input_args.prediction_suffix = dataset\n",
    "        trn_repr, tst_repr, lbl_repr, trn_pred, tst_pred, trn_metric, tst_metric = early_fusion_run(output_dir, input_args, mname, test_dset, train_dset, \n",
    "                                                                                                    save_dir_name=pred_dir_name)\n",
    "        with open(f\"{metric_dir}/{dataset}.json\", \"w\") as file:\n",
    "            json.dump({dataset: tst_metric}, file, indent=4)\n",
    "\n",
    "    collate_beir_metrics(metric_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb505b-8355-41ca-9331-6bc3a38da373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c5a103-ad83-4809-ba9c-07e242b3704b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
