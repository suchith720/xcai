{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f8c4b0-a146-44bf-b9c0-140ee9bd4aa3",
   "metadata": {},
   "source": [
    "# `Miscellaneous`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab7f9691-1c78-4bd1-93bc-7536ecf92e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a98bfb9c-a031-4913-810f-b47b342165da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, torch ,json, torch.multiprocessing as mp, joblib, numpy as np, scipy.sparse as sp, argparse\n",
    "from typing import Optional, Union, Callable, List\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b073af23-e537-471a-8cc7-a8f04811fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from xcai.core import *\n",
    "from xcai.data import *\n",
    "\n",
    "from xcai.basics import *\n",
    "from xcai.models.PPP0XX import DBT009, DBTConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1b05d4-de76-4ace-8c88-87765775b228",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37e2c0ab-b869-4683-82c2-04c939e76b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_info(save_file:str, meta_file:str, mname:str, sequence_length:Optional[int]=32):\n",
    "    os.makedirs(os.path.dirname(save_file), exist_ok=True)\n",
    "    if os.path.exists(save_file):\n",
    "        meta_info = joblib.load(save_file)\n",
    "    else:\n",
    "        meta_info = Info.from_txt(meta_file, max_sequence_length=sequence_length, padding=True, return_tensors='pt',\n",
    "                                  info_column_names=[\"identifier\", \"input_text\"], tokenization_column=\"input_text\",\n",
    "                                  use_tokenizer=True, tokenizer=mname)\n",
    "        joblib.dump(meta_info, save_file)\n",
    "    return meta_info\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7c4d74-e7ed-49cf-b1c7-7adbba359cb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## BeIR datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85558afa-0be2-4aee-8cea-6526025113dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "DATASETS = [\n",
    "    \"arguana\",\n",
    "    \"msmarco\",\n",
    "    \"climate-fever\",\n",
    "    \"dbpedia-entity\",\n",
    "    \"fever\",\n",
    "    \"fiqa\",\n",
    "    \"hotpotqa\",\n",
    "    \"nfcorpus\",\n",
    "    \"nq\",\n",
    "    \"quora\",\n",
    "    \"scidocs\",\n",
    "    \"scifact\",\n",
    "    \"webis-touche2020\",\n",
    "    \"trec-covid\",\n",
    "    \"cqadupstack/android\",\n",
    "    \"cqadupstack/english\",\n",
    "    \"cqadupstack/gaming\",\n",
    "    \"cqadupstack/gis\",\n",
    "    \"cqadupstack/mathematica\",\n",
    "    \"cqadupstack/physics\",\n",
    "    \"cqadupstack/programmers\",\n",
    "    \"cqadupstack/stats\",\n",
    "    \"cqadupstack/tex\",\n",
    "    \"cqadupstack/unix\",\n",
    "    \"cqadupstack/webmasters\",\n",
    "    \"cqadupstack/wordpress\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b762d-e78c-43d3-85d4-e0a8f37d7bdc",
   "metadata": {},
   "source": [
    "## `Linker utils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73776e34-8cf4-4f0a-b3bb-f8b03be2eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def additional_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--pct\", type=float, default=1.0)\n",
    "    parser.add_argument(\"--use_all\", action=\"store_true\")\n",
    "    parser.add_argument(\"--use_training_test_set\", action=\"store_true\")\n",
    "    return parser.parse_known_args()[0]\n",
    "\n",
    "\n",
    "def get_random_idx(n_data:int, pct:float):\n",
    "    n_trn = int(pct * n_data)\n",
    "    return np.random.permutation(n_data)[:n_trn]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06c784ed-f0f1-4bfe-8b7d-0b0c8aee6fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_linker_block(dataset:str, config_file:str, input_args:argparse.ArgumentParser, \n",
    "                      extra_args:Optional[argparse.ArgumentParser]=None):\n",
    "    config_key, fname = get_config_key(config_file)\n",
    "    pkl_file = get_pkl_file(input_args.pickle_dir, f\"{dataset}_{fname}_distilbert-base-uncased\", input_args.use_sxc_sampler,\n",
    "                            input_args.exact, input_args.only_test)\n",
    "\n",
    "    os.makedirs(os.path.dirname(pkl_file), exist_ok=True)\n",
    "    block = build_block(pkl_file, config_file, input_args.use_sxc_sampler, config_key, do_build=input_args.build_block, only_test=input_args.only_test,\n",
    "                        n_slbl_samples=1, main_oversample=False)\n",
    "\n",
    "    do_inference = check_inference_mode(input_args)\n",
    "    if do_inference:\n",
    "        train_dset = None if block.train is None else block.train.dset\n",
    "        test_dset = block.test.dset.get_valid_dset() if extra_args.use_training_test_set else block.test.dset\n",
    "    else:\n",
    "        train_dset = block.train.dset.get_valid_dset()\n",
    "        test_dset = block.test.dset.get_valid_dset()\n",
    "        if extra_args.pct < 1.0:\n",
    "            train_dset = train_dset._getitems(get_random_idx(len(train_dset), extra_args.pct))\n",
    "\n",
    "    return train_dset, test_dset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fa0ea5e-a9f3-4fa0-bf78-98612f0bfc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def linker_run(output_dir:str, input_args:argparse.ArgumentParser, mname:str, test_dset:Union[XCDataset, SXCDataset],\n",
    "               train_dset:Optional[Union[XCDataset, SXCDataset]]=None, collator:Optional[Callable]=identity_collate_fn):\n",
    "\n",
    "    args = XCLearningArguments(\n",
    "        output_dir=output_dir,\n",
    "        logging_first_step=True,\n",
    "        per_device_train_batch_size=800,\n",
    "        per_device_eval_batch_size=800,\n",
    "        representation_num_beams=200,\n",
    "        representation_accumulation_steps=10,\n",
    "        save_strategy=\"steps\",\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=5000,\n",
    "        save_steps=5000,\n",
    "        save_total_limit=5,\n",
    "        num_train_epochs=300,\n",
    "        predict_with_representation=True,\n",
    "        representation_search_type='BRUTEFORCE',\n",
    "        adam_epsilon=1e-6,                                                                                                                                          warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        learning_rate=2e-4,\n",
    "\n",
    "        group_by_cluster=True,\n",
    "        num_clustering_warmup_epochs=10,\n",
    "        num_cluster_update_epochs=5,\n",
    "        num_cluster_size_update_epochs=25,\n",
    "        clustering_type='EXPO',\n",
    "        minimum_cluster_size=2,\n",
    "        maximum_cluster_size=1600,\n",
    "\n",
    "        metric_for_best_model='N@10',\n",
    "        load_best_model_at_end=True,\n",
    "        target_indices_key='plbl2data_idx',\n",
    "        target_pointer_key='plbl2data_data2ptr',\n",
    "\n",
    "        use_encoder_parallel=True,\n",
    "        max_grad_norm=None,\n",
    "        fp16=True,\n",
    "\n",
    "        use_cpu_for_searching=True,\n",
    "        use_cpu_for_clustering=True,\n",
    "    )\n",
    "\n",
    "    config = DBTConfig(\n",
    "        margin = 0.3,\n",
    "        num_negatives = 10,\n",
    "        tau = 0.1,\n",
    "        apply_softmax = True,\n",
    "        reduction = \"mean\",\n",
    "\n",
    "        normalize = True,\n",
    "        use_layer_norm = True,\n",
    "\n",
    "        use_encoder_parallel = True,\n",
    "        loss_function = \"triplet\"\n",
    "    )\n",
    "\n",
    "    def model_fn(mname, config):\n",
    "        return DBT009.from_pretrained(mname, config=config)\n",
    "\n",
    "    do_inference = check_inference_mode(input_args)\n",
    "    model = load_model(args.output_dir, model_fn, {\"mname\": mname, \"config\": config}, do_inference=do_inference,\n",
    "                       use_pretrained=input_args.use_pretrained)\n",
    "\n",
    "    metric = PrecReclMrr(test_dset.data.n_lbl, test_dset.data.data_lbl_filterer, prop=None if train_dset is None else train_dset.data.data_lbl,\n",
    "                         pk=10, rk=200, rep_pk=[1, 3, 5, 10], rep_rk=[10, 100, 200], mk=[5, 10, 20])\n",
    "\n",
    "    learn = XCLearner(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dset,\n",
    "        eval_dataset=test_dset,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=metric,\n",
    "    )\n",
    "\n",
    "    return main(learn, input_args, n_lbl=test_dset.data.n_lbl, eval_k=10, train_k=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22afec31-4cd6-4f5a-b7d8-3a1a1ed451c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6c5eb-8261-4e26-a556-c9c2be89849b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
