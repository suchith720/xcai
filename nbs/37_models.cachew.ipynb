{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b84d227-6f70-4060-82c0-40648d681f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.cachew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a33728-6828-4b79-a40e-4054c830d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8dcb50-00fe-4d0b-b2f2-fbb6b09049dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "290df3ff-0ce1-4791-ae32-c758f12d67e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scai/phd/aiz218323/scratch/anaconda3/envs/mogic/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import torch, torch.nn as nn, torch.nn.functional as F, re\n",
    "from typing import Optional, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from transformers.utils.generic import ModelOutput\n",
    "from transformers import PretrainedConfig, DistilBertConfig, DistilBertPreTrainedModel, DistilBertModel\n",
    "from transformers.models.distilbert.modeling_distilbert import create_sinusoidal_embeddings, TransformerBlock\n",
    "\n",
    "from xcai.losses import *\n",
    "from xcai.learner import XCDataParallel\n",
    "from xcai.models.modeling_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76abb7-8560-490d-8cb5-a8ee46299b44",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb535de-64ed-4430-8fcb-35eaead49eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08dd4c65-aaa1-44eb-9fb9-039d6807de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/scratch/scai/phd/aiz218323/outputs/mogicX/03_ngame-for-wikiseealsotitles'\n",
    "\n",
    "data_dir = '/home/scai/phd/aiz218323/scratch/datasets/benchmarks/'\n",
    "config_file = 'wikiseealsotitles'\n",
    "config_key = 'data_meta'\n",
    "\n",
    "mname = 'sentence-transformers/msmarco-distilbert-base-v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b9fe27-0065-4a54-a70a-f867a45c6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/scratch/scai/phd/aiz218323/datasets/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9867f45-61e8-466c-b015-afb4c68d1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = f'{pkl_dir}/mogicX/wikiseealsotitles_data-meta_distilbert-base-uncased_sxc.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55640a26-6348-4644-917d-f7779092b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = build_block(pkl_file, config_file, True, config_key, data_dir=data_dir, n_sdata_meta_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8dc7d671-0dfb-4673-aff8-faa5b1f54ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b2348fea-4b6f-4ea5-bc31-7f884cbf0ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_idx', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_data2ptr', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_data2ptr', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'pcat2lbl_idx', 'pcat2lbl_lbl2ptr', 'cat2lbl_idx', 'cat2lbl_lbl2ptr', 'cat2lbl_identifier', 'cat2lbl_input_text', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'cat2lbl_data2ptr', 'pcat2lbl_data2ptr'])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7de80-5789-4ec6-a6d3-955f7780e960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ac7b776-b6a3-42c0-9efe-52121236b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel\n",
    "m = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d7f4996-a9fa-40be-9f1c-6feefc9d188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = m(input_ids=batch['data_input_ids'], attention_mask=batch['data_attention_mask'])\n",
    "o = Pooling.mean_pooling(o.last_hidden_state, batch['data_attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70605e74-1b00-4560-9a5e-fbb17b6f9bbb",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "33c722db-2fd8-4507-9720-be77e90bb0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Parameters:\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_data_aug_meta_prefix_for_encoder(prefix:str, **kwargs):\n",
    "        inputs = {}\n",
    "        args = [arg for arg in kwargs if prefix is not None and re.match(f'^{prefix}.*_(input_ids|attention_mask|data2ptr|idx)$', arg)]\n",
    "        for arg in args:\n",
    "            meta,param = arg.split('_', maxsplit=1)\n",
    "            inputs.setdefault(meta, {})[param] = kwargs[arg]\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_aug_meta_prefix_for_feature(feat:str, prefix:str, **kwargs):\n",
    "        keys = ['attention_mask', 'input_ids', 'idx']        \n",
    "        inputs = {f'{prefix}_{k}': kwargs[f'{prefix}_{k}'] for k in keys if f'{prefix}_{k}' in kwargs}\n",
    "        if prefix is not None and f'{prefix}_{feat}2ptr' in kwargs:\n",
    "            inputs.update({f'{prefix}_data2ptr': kwargs[f'{prefix}_{feat}2ptr']})\n",
    "        return inputs\n",
    "\n",
    "    @staticmethod\n",
    "    def from_aug_meta_prefix_for_loss(feat:str, prefix:str, **kwargs):\n",
    "        keys = [f'{prefix}_idx', f'p{prefix}_idx']\n",
    "        args = {k: kwargs[k] for k in keys if k in kwargs}\n",
    "        if prefix is not None and f'{prefix}_{feat}2ptr' in kwargs:\n",
    "            args.update({f'{prefix}_data2ptr': kwargs[f'{prefix}_{feat}2ptr']})\n",
    "        if prefix is not None and f'p{prefix}_{feat}2ptr' in kwargs:\n",
    "            args.update({f'p{prefix}_data2ptr': kwargs[f'p{prefix}_{feat}2ptr']})\n",
    "\n",
    "        inputs = {}\n",
    "        for arg in args:\n",
    "            meta,param = arg.split('_', maxsplit=1)\n",
    "            inputs.setdefault(meta, {})[param] = args[arg]\n",
    "        return inputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6e746223-339d-44a7-8de0-7161636be755",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters.from_aug_meta_prefix_for_loss('lbl', 'cat2lbl', **batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "035419f7-01bf-4b51-88a6-d6adfcf38cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat2lbl': {'idx': tensor([ 87814,    656, 155406,   3056, 326685, 120394, 258077, 143634, 138944,\n",
       "          174633, 155467,   1228, 148694,  72242, 161845, 138151, 395355, 439024,\n",
       "          100619,  68113,  91529,  74225, 569108, 131690, 110921, 508118, 489998,\n",
       "          129962, 354599, 200014, 490420, 342971, 127050, 126452, 170818, 474981,\n",
       "          148836, 120396,  84773,  73276,  28131, 296564,  92821,  69899,  74828,\n",
       "          302326, 152673,  46822, 244562,  68249,  68123, 102584, 150784,  75601,\n",
       "           68691, 506612,  60180, 303594, 190220, 399247,  62666, 174024, 131647,\n",
       "          102518,  62592, 491957,  66439, 130779,  53106,  86585, 478961, 144409,\n",
       "          257443,  72352, 157102, 463424, 330411, 184623, 426850, 141850, 490081,\n",
       "          426908, 153510,  74217, 167418,  69981, 137586, 167418,  77661, 249965,\n",
       "          123368,  74827]),\n",
       "  'data2ptr': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "          1, 0, 1, 1])},\n",
       " 'pcat2lbl': {'idx': tensor([ 27146,  67082,  72817,  87814,  88559,  88560, 101646, 130668, 299633,\n",
       "             656,  49684,  56026,  72991,  75604,  79350, 129019, 165107, 165108,\n",
       "           70154,  75304,  76961,  81434, 100127, 101577, 104146, 112817, 131262,\n",
       "          131264, 131265, 131284, 131288, 138567, 140781, 144686, 155398, 155399,\n",
       "          155400, 155401, 155402, 155403, 155404, 155405, 155406, 155407, 155408,\n",
       "          155409, 155410, 155411, 155412, 155413, 155414, 155415, 155416, 155417,\n",
       "          155418, 155419,   3056,  10463,  46859,  56287,  71468,  71494,  71495,\n",
       "           71496,  71497,  71498,  52878,  78344, 326685, 120394, 120808, 303613,\n",
       "           71497, 135330, 258077, 258101, 143634,  47830, 138943, 138944, 138945,\n",
       "          138946, 100095, 174633,  88140, 111665, 155467,   1228,  73131, 148694,\n",
       "           49257,  49710,  72242, 161845, 439033, 491098, 138151, 107556, 395354,\n",
       "          395355, 490081, 102964, 439024,  84870,  84872,  95360, 100614, 100615,\n",
       "          100616, 100617, 100618, 100619, 100620, 100621, 100622, 100623, 100624,\n",
       "           68105,  68109,  68112,  68113,  79676,  84868,  84870,  84872,  84881,\n",
       "          100619, 100622, 100624, 157094, 157101, 157102, 161670, 178013, 178014,\n",
       "          178015,    656,  91528,  91529,  91530,  74225, 259765,  83239, 141642,\n",
       "          141644, 569108, 131690, 131691, 110921, 113592, 170004, 218588, 488572,\n",
       "          508118,  50937, 110847, 489997, 489998, 129961, 129962,  73238,  80103,\n",
       "           99971, 151909, 184098, 188309, 354599, 423863, 555039, 121618, 174525,\n",
       "          174597, 200013, 200014,  80129, 294502, 490420, 493245,  47085,  72240,\n",
       "          342971, 371773, 444784,  58873,  67166, 127050, 127053, 128784, 128785,\n",
       "          128786, 128787, 128788, 128789, 126452,  50423,  54304,  55903,  55905,\n",
       "           63794,  64711, 105823, 160065, 170812, 170813, 170814, 170815, 170816,\n",
       "          170817, 170818, 170819, 170820, 111060, 474981,   1205,  49275,  49276,\n",
       "           49373,  56406,  56729,  57630,  57631,  57647,  57711,  57712,  57714,\n",
       "           58406,  73074,  73076,  73079,  82451,  89766, 100208, 127346, 148834,\n",
       "          148835, 148836, 148837, 148838, 120396, 271133,  84773,  88956, 124867,\n",
       "          161606, 179316, 179319, 179409, 179778, 179786, 179791, 180406, 233429,\n",
       "           73276, 393192,  28131, 129302, 129303, 222417, 242721, 296564, 346047,\n",
       "           72673,  92821, 130669, 144003, 182160,  69899,  71434, 169723,   5926,\n",
       "           70044,  74825,  74826,  74827,  74828,  74829,  74830,  74831,  70044,\n",
       "           74829,  75622, 302326, 152673, 481488,  27327,  44103,  46816,  46822,\n",
       "           68170,  69981,  70144,  85885, 144093, 368575, 130517, 244562, 244563,\n",
       "           48312,  54290,  54378,  54413,  54414,  63247,  64055,  64470,  68249,\n",
       "           72893,  72894,  73382,  76517, 106664, 113098, 121366, 121367, 121368,\n",
       "          121369,  68123, 302731,    656,  53789,  53995,  54131,  54183,  65468,\n",
       "           80624,  80704,  80714,  80718,  80786, 101531, 101553, 102364, 102582,\n",
       "          102583, 102584, 102585, 102586, 102587, 102588, 102589, 102590, 102591,\n",
       "          102592, 131789, 131791, 150783, 150784,  75601, 445093,  68691, 141863,\n",
       "          506612,   2192,  35843,  56756,  56937,  60180,  70062,  72676, 246400,\n",
       "           52240,  52241,  64192, 113666, 303594, 304390, 304391, 318179, 517829,\n",
       "          190220, 229420, 375487, 131693, 318292, 399247,  62662,  62663,  62664,\n",
       "           62665,  62666,  62667,  62668, 114602, 174024, 581032, 131647,   4044,\n",
       "           53311,  64916,  71037,  77171,  80659,  80749,  80781,  81085, 101656,\n",
       "          101796, 101810, 101981, 102481, 102482, 102483, 102484, 102485, 102486,\n",
       "          102487, 102488, 102489, 102490, 102491, 102492, 102493, 102494, 102495,\n",
       "          102496, 102497, 102498, 102499, 102500, 102501, 102502, 102503, 102504,\n",
       "          102505, 102506, 102507, 102508, 102509, 102510, 102511, 102512, 102513,\n",
       "          102514, 102515, 102516, 102517, 102518, 102519, 102520, 102521, 102522,\n",
       "           62589,  62590,  62591,  62592,  62593,  62594,  62595,  62596, 170497,\n",
       "          491957,  54072,  54247,  62849,  66439,  68842,  80646,  94324, 101656,\n",
       "          101803, 107584, 109891, 109892, 109893, 109894, 109895,    656,  60701,\n",
       "          130779, 174880, 265986,  53106,  69656,  77965,  84134,  86585, 236085,\n",
       "          478961,  60299,  84872, 117344, 132100, 138294, 138295, 144409, 144410,\n",
       "          144440, 144441, 144442, 144443, 144444, 144445, 144446, 144447, 144448,\n",
       "          144449,   7279,  11185,  11198,  11245,  11246,  25597,  78219,  78245,\n",
       "           78267, 143864, 190019, 257443, 532191, 561039, 561040, 561041, 561042,\n",
       "          584534, 584535,  72352, 177845, 498229, 501242,  68105,  68109,  68112,\n",
       "           68113,  79676,  84868,  84870,  84872,  84881, 100619, 100622, 100624,\n",
       "          157094, 157101, 157102, 161670, 178013, 178014, 178015, 463424, 150235,\n",
       "          157434, 330411, 365591, 184623, 426850,  75176,  87372, 141850, 395354,\n",
       "          490081,  68235, 426908,  18473,  38642,  57132,  57133,  84398, 153510,\n",
       "          231497, 514162, 514163,  74217,  75400,  82548, 200450,  70022, 111647,\n",
       "          167418,  69981,  82308, 174243, 294506, 137586, 167418,  63350,  77661,\n",
       "          271201, 249965,  53296,  69944,  75316, 123368, 189026, 224421,  74217,\n",
       "           74827]),\n",
       "  'data2ptr': tensor([ 9,  9, 38, 10,  3,  3,  4,  1,  0,  5,  2,  3,  2,  1,  3,  3,  1,  4,\n",
       "           2,  0, 14, 19,  4,  2,  4,  2,  3,  3,  4,  2,  9,  5,  4,  5, 10,  1,\n",
       "          17,  2, 25,  2, 12,  2,  3,  4,  5,  3,  9,  4,  2, 10,  3, 19,  2, 25,\n",
       "           0,  4,  2,  2,  1,  8,  9,  3,  3,  7,  0,  3,  1, 55,  8,  2, 15,  5,\n",
       "           3,  3,  1, 18, 19,  4, 19,  1,  4,  0,  1,  1,  3,  2,  2,  0,  9,  4,\n",
       "           3,  4,  1,  0,  1,  3,  1,  0,  6,  2])}}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c0c820-ff1d-418d-9c7c-cd2ee4494020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "082f7adf-d3fb-41e8-afee-21095c7a3449",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d76164cf-718b-472e-9187-14f37c3c1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MemoryConfig(DistilBertConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        top_k_metadata:Optional[int] = 5,\n",
    "        num_metadata:Optional[int] = 100_000,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.top_k_metadata = top_k_metadata\n",
    "        self.num_metadata = num_metadata\n",
    "        super().__init__(**kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "31f0cdf3-583a-4cd9-9b45-5a970b5a2082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CachewConfig(MemoryConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_aug_meta_prefix:Optional[str] = None, \n",
    "        lbl2data_aug_meta_prefix:Optional[str] = None,\n",
    "\n",
    "        data_enrich:Optional[bool] = True,\n",
    "        lbl2data_enrich:Optional[bool] = True,\n",
    "        \n",
    "        num_batch_labels:Optional[int] = None,\n",
    "        batch_size:Optional[int] = None,\n",
    "        margin:Optional[float] = 0.3,\n",
    "        num_negatives:Optional[int] = 10,\n",
    "        tau:Optional[float] = 0.1,\n",
    "        apply_softmax:Optional[bool] = True,\n",
    "\n",
    "        calib_margin:Optional[float] = 0.05,\n",
    "        calib_num_negatives:Optional[int] = 10,\n",
    "        calib_tau:Optional[float] = 0.1,\n",
    "        calib_apply_softmax:Optional[bool] = False,\n",
    "        calib_loss_weight:Optional[float] = 0.1,\n",
    "        use_calib_loss:Optional[float] = False,\n",
    "        \n",
    "        use_query_loss:Optional[float] = True,\n",
    "\n",
    "        meta_loss_weight:Optional[float] = 0.1,\n",
    "        use_meta_loss:Optional[bool] = False,\n",
    "        \n",
    "        use_encoder_parallel:Optional[bool] = True,\n",
    "        \n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.data_aug_meta_prefix = data_aug_meta_prefix\n",
    "        self.lbl2data_aug_meta_prefix = lbl2data_aug_meta_prefix\n",
    "\n",
    "        self.data_enrich = data_enrich\n",
    "        self.lbl2data_enrich = lbl2data_enrich\n",
    "\n",
    "        self.num_batch_labels = num_batch_labels\n",
    "        self.batch_size = batch_size\n",
    "        self.margin = margin\n",
    "        self.num_negatives = num_negatives\n",
    "        self.tau = tau\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        self.calib_margin = calib_margin\n",
    "        self.calib_num_negatives = calib_num_negatives\n",
    "        self.calib_tau = calib_tau\n",
    "        self.calib_apply_softmax = calib_apply_softmax\n",
    "        self.calib_loss_weight = calib_loss_weight\n",
    "        self.use_calib_loss = use_calib_loss\n",
    "\n",
    "        self.use_query_loss = use_query_loss\n",
    "\n",
    "        self.meta_loss_weight = meta_loss_weight\n",
    "        self.use_meta_loss = use_meta_loss\n",
    "\n",
    "        self.use_encoder_parallel = use_encoder_parallel\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d085f55-8bb3-4ac8-b534-b7ed9e2d288f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0a56f8f-7de0-48c0-8ff5-5150f4934a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Memory(nn.Module):\n",
    "\n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__()\n",
    "        self.top_k_metadata = config.top_k_metadata\n",
    "        \n",
    "        self.memory_embeddings = nn.Embedding(config.num_metadata, config.dim)\n",
    "        \n",
    "        self.position_embeddings = nn.Embedding(config.num_metadata, config.dim)\n",
    "        if config.sinusoidal_pos_embds:\n",
    "            create_sinusoidal_embeddings(\n",
    "                n_pos=config.num_metadata, dim=config.dim, out=self.position_embeddings.weight\n",
    "            )\n",
    "        \n",
    "        self.LayerNorm = nn.LayerNorm(config.dim, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def set_memory_embeddings(self, embed:torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            self.memory_embeddings.weight.copy_(embed)\n",
    "\n",
    "    def align_embeddings(self, embeddings:torch.Tensor, group_lengths:torch.Tensor):\n",
    "        n, dim = embeddings.shape\n",
    "        num_groups, max_len = len(group_lengths), group_lengths.max()\n",
    "        group_ids = torch.repeat_interleave(torch.arange(num_groups, device=embeddings.device), group_lengths)\n",
    "\n",
    "        row_indices = torch.arange(n, device=embeddings.device)\n",
    "\n",
    "        group_start = torch.cat([torch.zeros(1, dtype=group_lengths.dtype, device=group_lengths.device), group_lengths.cumsum(0)[:-1]], dim=0)\n",
    "\n",
    "        within_idx = row_indices - group_start[group_ids]\n",
    "\n",
    "        output, mask = torch.zeros((num_groups, max_len, dim), device=embeddings.device), torch.zeros((num_groups, max_len), device=embeddings.device)\n",
    "        output[group_ids, within_idx] = embeddings\n",
    "        mask[group_ids, within_idx] = 1.0\n",
    "\n",
    "        return output, mask\n",
    "        \n",
    "    def forward(self, input_embeds:torch.Tensor, input_indices:Optional[torch.Tensor]=None, input_data2ptr:Optional[torch.Tensor]=None):\n",
    "        assert input_embeds.dim() == 2, f'Input embeddings should be 2-dimensional, but got dim:{input_embeds.dim()}'\n",
    "        \n",
    "        meta_norm = F.normalize(self.memory_embeddings.weight, dim=-1)\n",
    "        input_norm = F.normalize(input_embeds, dim=-1)\n",
    "        \n",
    "        scores = input_norm@meta_norm.T\n",
    "        values, indices = torch.topk(scores, self.top_k_metadata, dim=-1)\n",
    "        \n",
    "        pred_embeddings = self.memory_embeddings(indices) + self.position_embeddings(indices)\n",
    "        pred_embeddings = self.LayerNorm(pred_embeddings)\n",
    "        pred_embeddings = self.dropout(pred_embeddings)\n",
    "        pred_mask = torch.ones(pred_embeddings.shape[0], pred_embeddings.shape[1], device=pred_embeddings.device)\n",
    "\n",
    "        input_embeddings = input_mask = None\n",
    "        if input_indices is not None:\n",
    "            input_embeddings = self.memory_embeddings(input_indices) + self.position_embeddings(input_indices)\n",
    "            input_embeddings = self.LayerNorm(input_embeddings)\n",
    "            input_embeddings = self.dropout(input_embeddings)\n",
    "            input_embeddings, input_mask = self.align_embeddings(input_embeddings, input_data2ptr)\n",
    "\n",
    "        embeddings = pred_embeddings if input_embeddings is None else torch.cat([pred_embeddings, input_embeddings], dim=1)\n",
    "        mask = pred_mask if input_mask is None else torch.cat([pred_mask, input_mask], dim=1)\n",
    "        \n",
    "        return embeddings, mask, scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4eed69-154e-4c30-aa50-56ebe000144f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1c8252d-91fa-4e9c-8049-4a9f31261135",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MemoryConfig(num_metadata=block.train.dset.meta['cat_meta'].n_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70fbc632-ac55-45fb-8c4c-001f3e3dcda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Memory(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76b3ad56-d4e0-4758-abbf-d9fbb8b65620",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug_meta_prefix = 'cat2data'\n",
    "meta_kwargs = Parameters.from_data_aug_meta_prefix_for_encoder(data_aug_meta_prefix, **batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b30e01f-6263-42b1-8047-9f630614e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_repr = torch.randn(batch['data_input_ids'].shape[0], config.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28d597e4-fc01-4132-a314-b0f0509bb4e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings, mask, scores = m(data_repr, meta_kwargs[data_aug_meta_prefix]['idx'], meta_kwargs[data_aug_meta_prefix]['data2ptr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27ea702d-44e2-4ba5-8ca0-ec64955dff0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 8, 768]), torch.Size([100, 8]), torch.Size([100, 656086]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape, mask.shape, scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487dc644-2bfa-40dd-af8b-3fcafc949a14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Combiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d59f06d-f3aa-4cae-aff9-09fe682c3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrossCombinerBlock(TransformerBlock):\n",
    "\n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def post_init(self):\n",
    "        for module in self.modules(): self._init_weights(module)\n",
    "\n",
    "    def _init_weights(self, module: nn.Module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.eye_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        m: torch.Tensor,\n",
    "        attn_mask: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        output_attentions: bool = False,\n",
    "    ) -> Tuple[torch.Tensor, ...]:\n",
    "        \n",
    "        # Cross-Attention\n",
    "        ca_output = self.attention(\n",
    "            query=x,\n",
    "            key=m,\n",
    "            value=m,\n",
    "            mask=attn_mask,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        if output_attentions:\n",
    "            ca_output, ca_weights = ca_output  # (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\n",
    "        else:  # To handle these `output_attentions` or `output_hidden_states` cases returning tuples\n",
    "            if type(ca_output) is not tuple:\n",
    "                raise TypeError(f\"ca_output must be a tuple but it is {type(ca_output)} type\")\n",
    "\n",
    "            ca_output = ca_output[0]\n",
    "        ca_output = self.sa_layer_norm(ca_output + x)  # (bs, seq_length, dim)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        ffn_output = self.ffn(ca_output)  # (bs, seq_length, dim)\n",
    "        ffn_output: torch.Tensor = self.output_layer_norm(ffn_output + ca_output)  # (bs, seq_length, dim)\n",
    "\n",
    "        output = (ffn_output,)\n",
    "        if output_attentions:\n",
    "            output = (ca_weights,) + output\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b975a-9974-4e76-a832-0ac4633094e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4032f55d-88b8-40ff-bc6c-92868cd6e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class EncoderOutput(ModelOutput):\n",
    "    repr: Optional[torch.FloatTensor] = None\n",
    "    enriched_repr: Optional[torch.FloatTensor] = None\n",
    "    meta_scores: Optional[torch.FloatTensor] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "83ca2dcc-8f85-4127-b912-5d8d815bc19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder(DistilBertPreTrainedModel):\n",
    "    \n",
    "    config_class = MemoryConfig\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig, \n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.query_head = RepresentationHead(config)\n",
    "        self.combiner_head = CrossCombinerBlock(config)\n",
    "        self.enriched_query_head = RepresentationHead(config)\n",
    "\n",
    "        self.memory = Memory(config)\n",
    "        \n",
    "        self.post_init()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_heads_to_identity(self):\n",
    "        self.query_head.post_init()\n",
    "        self.combiner_head.post_init()\n",
    "        self.enriched_query_head.post_init()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_combiner_to_last_layer(self):\n",
    "        lsd = self.distilbert.transformer.layer[-1].state_dict()\n",
    "        lsd_keys = lsd.keys()        \n",
    "        csd = self.combiner_head.state_dict()\n",
    "        csd_keys = csd.keys()\n",
    "        \n",
    "        assert len(lsd_keys) == len(csd_keys), f'mismatched keys: {len(lsd_keys)} != {len(csd_keys)}'\n",
    "        \n",
    "        for k in csd_keys:\n",
    "            assert csd[k].shape == lsd[k].shape\n",
    "            csd[k].copy_(lsd[k])\n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def set_memory_embeddings(self, embed:torch.Tensor):\n",
    "        self.memory.set_memory_embeddings(embed)\n",
    "        \n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        return self.distilbert.get_position_embeddings()\n",
    "    \n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "        self.distilbert.resize_position_embeddings(new_num_position_embeddings)\n",
    "    \n",
    "    def encode(self, input_ids:torch.Tensor, attention_mask:torch.Tensor, **kwargs):\n",
    "        return self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def encode_query(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.query_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "\n",
    "    def encode_enriched_query(self, embed:torch.Tensor):\n",
    "        return F.normalize(self.enriched_query_head(embed), dim=1)\n",
    "\n",
    "    def enrich_query_representation(self, data_repr:torch.Tensor, meta_kwargs:Optional[Dict]=None):\n",
    "        meta_repr, meta_mask, meta_scores = self.memory(data_repr) if meta_kwargs is None else self.memory(data_repr, meta_kwargs['idx'], meta_kwargs['data2ptr'])\n",
    "        \n",
    "        meta_mask = meta_mask.view(len(meta_mask), 1, 1, -1).bool()\n",
    "        fusion_repr = self.combiner_head(x=data_repr.view(len(data_repr), 1, -1), m=meta_repr, attn_mask=meta_mask)\n",
    "        fusion_repr = fusion_repr[0].squeeze(dim=1)\n",
    "        \n",
    "        enriched_data_repr = self.encode_enriched_query(data_repr + fusion_repr)\n",
    "        return enriched_data_repr, meta_scores\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_enrich: Optional[bool]=True,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        data_repr = self.encode_query(data_o[0], data_attention_mask)\n",
    "        \n",
    "        enriched_data_repr = meta_scores = None\n",
    "        meta_kwargs = Parameters.from_data_aug_meta_prefix_for_encoder(data_aug_meta_prefix, **kwargs)\n",
    "        meta_kwargs = meta_kwargs.get(data_aug_meta_prefix, None)\n",
    "        \n",
    "        if data_enrich:\n",
    "            enriched_data_repr, meta_scores = self.enrich_query_representation(data_repr, meta_kwargs)\n",
    "            \n",
    "        return EncoderOutput(\n",
    "            repr=data_repr,\n",
    "            enriched_repr=enriched_data_repr,\n",
    "            meta_scores=meta_scores\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdac53b-6120-4598-b597-e4477045735d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "96ebd52b-436c-46e6-8ad3-3924738e1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MemoryConfig(num_metadata=block.train.dset.meta['cat_meta'].n_meta)\n",
    "m = Encoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "55a1c176-1373-4b32-8edc-e79e1ee817e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_idx', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_data2ptr', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_data2ptr', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'pcat2lbl_idx', 'pcat2lbl_lbl2ptr', 'cat2lbl_idx', 'cat2lbl_lbl2ptr', 'cat2lbl_identifier', 'cat2lbl_input_text', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'cat2lbl_data2ptr', 'pcat2lbl_data2ptr'])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "54afd1a2-4a9d-4f48-838a-b428cd7226d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_aug_meta_prefix='cat2data'\n",
    "output = m(**batch, data_aug_meta_prefix=data_aug_meta_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "be06da59-da28-43ea-bb10-c7b6309eb43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderOutput(repr=tensor([[-0.0538, -0.0170,  0.0591,  ..., -0.0791, -0.0830,  0.0450],\n",
       "        [-0.0295,  0.0319, -0.0031,  ..., -0.0622, -0.0621,  0.0216],\n",
       "        [-0.0148,  0.0062, -0.0024,  ..., -0.0583, -0.0546,  0.0029],\n",
       "        ...,\n",
       "        [ 0.0536, -0.0087, -0.0208,  ..., -0.0220, -0.0539,  0.0342],\n",
       "        [-0.0158,  0.0252,  0.0377,  ..., -0.0533, -0.0447,  0.0333],\n",
       "        [ 0.0298, -0.0146, -0.0188,  ..., -0.0568, -0.0479,  0.0317]],\n",
       "       grad_fn=<DivBackward0>), enriched_repr=tensor([[ 0.0427, -0.0454, -0.0224,  ..., -0.0174,  0.0331,  0.0002],\n",
       "        [ 0.0302, -0.0223,  0.0149,  ...,  0.0240, -0.0156,  0.0016],\n",
       "        [ 0.0192,  0.0120,  0.0273,  ..., -0.0221, -0.0642, -0.0499],\n",
       "        ...,\n",
       "        [ 0.0385,  0.0089,  0.0263,  ..., -0.0362,  0.0579, -0.0503],\n",
       "        [ 0.0260,  0.0138,  0.0007,  ..., -0.0468,  0.0162,  0.0187],\n",
       "        [-0.0065, -0.0112,  0.0086,  ..., -0.0254,  0.0095,  0.0348]],\n",
       "       grad_fn=<DivBackward0>), meta_scores=tensor([[ 0.0004, -0.0740, -0.1226,  ..., -0.0239, -0.0191, -0.0168],\n",
       "        [-0.0323,  0.0250, -0.0444,  ..., -0.0668, -0.0348, -0.0130],\n",
       "        [-0.0856, -0.0104, -0.0703,  ..., -0.0272, -0.0037, -0.0220],\n",
       "        ...,\n",
       "        [-0.0103, -0.0160, -0.0651,  ...,  0.0117, -0.0274,  0.0248],\n",
       "        [-0.0146, -0.0094, -0.0559,  ..., -0.0251, -0.0346,  0.0313],\n",
       "        [-0.0159, -0.0124, -0.0488,  ..., -0.0381,  0.0033, -0.0187]],\n",
       "       grad_fn=<MmBackward0>))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045dc821-df70-4d37-8961-86cdce86b4a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `CAW000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "70d26f79-06e1-4f0f-8010-5ab44fa286b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class CAWModelOutput(ModelOutput):\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    data_repr: Optional[torch.FloatTensor] = None\n",
    "    data_enriched_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_enriched_repr: Optional[torch.FloatTensor] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a2467815-5658-4ce0-a844-5c8542fcd09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CAW000(nn.Module):\n",
    "\n",
    "    config_class = CachewConfig\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config: CachewConfig,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.config, self.encoder = config, None\n",
    "        self.rep_loss_fn = MultiTriplet(margin=config.margin, n_negatives=config.num_negatives, tau=config.tau, \n",
    "                                        apply_softmax=config.apply_softmax, reduce='mean')\n",
    "        self.cab_loss_fn = Calibration(margin=config.calib_margin, tau=config.calib_tau, n_negatives=config.calib_num_negatives, \n",
    "                                       apply_softmax=config.calib_apply_softmax, reduce='mean')\n",
    "        \n",
    "    def init_heads_to_identity(self):\n",
    "        if self.encoder is None: raise ValueError('Encoder not initialized.')\n",
    "        self.encoder.init_heads_to_identity()\n",
    "\n",
    "    def init_combiner_to_last_layer(self):\n",
    "        if self.encoder is None: raise ValueError('Encoder not initialized.')\n",
    "        self.encoder.init_combiner_to_last_layer()\n",
    "\n",
    "    def set_memory_embeddings(self, embed:torch.Tensor):\n",
    "        if self.encoder is None: raise ValueError('Encoder not initialized.')\n",
    "        self.encoder.set_memory_embeddings(embed)\n",
    "        \n",
    "    def compute_loss(self, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.rep_loss_fn(inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "\n",
    "    def calibration_loss(self, einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.config.calib_loss_weight * self.cab_loss_fn(einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ): \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.config.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_aug_meta_prefix_for_feature('data', self.config.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.config.data_aug_meta_prefix, data_enrich=self.config.data_enrich, **data_meta_kwargs)\n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_aug_meta_prefix_for_feature('lbl', self.config.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.config.lbl2data_aug_meta_prefix, data_enrich=self.config.lbl2data_enrich, **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.enriched_repr, lbl2data_o.repr,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.config.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.repr, lbl2data_o.repr,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.config.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.enriched_repr, data_o.repr, lbl2data_o.repr,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.repr,data_o.enriched_repr,lbl2data_o.repr,lbl2data_o.enriched_repr)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        return CAWModelOutput(\n",
    "            loss=loss,\n",
    "            data_repr=data_o.repr,\n",
    "            data_enriched_repr=data_o.enriched_repr,\n",
    "            lbl2data_repr=lbl2data_o.repr,\n",
    "            lbl2data_enriched_repr=lbl2data_o.enriched_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760aa441-82a7-4e20-98f7-b71bf4ad58e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `CAW001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d0dc5719-c811-41cb-ab03-991daff2ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CAW001(CAW000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.encoder = Encoder(config)\n",
    "        \n",
    "        self.post_init()\n",
    "        self.remap_post_init()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e0f21-d6d0-40d1-a3b4-a1f57cd68577",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06dd341b-b4a7-416d-aca1-e7597a284a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CachewConfig(\n",
    "    top_k_metadata = 5,\n",
    "    num_metadata=block.train.dset.meta['cat_meta'].n_meta,\n",
    "\n",
    "    data_aug_meta_prefix='cat2data', \n",
    "    lbl2data_aug_meta_prefix=None,\n",
    "\n",
    "    data_enrich=True,\n",
    "    lbl2data_enrich=False,\n",
    "\n",
    "    batch_size=100, \n",
    "    num_batch_labels=5000, \n",
    "    margin=0.3,\n",
    "    num_negatives=5,\n",
    "    tau=0.1,\n",
    "    apply_softmax=True,\n",
    "\n",
    "    calib_margin=0.3,\n",
    "    calib_num_negatives=10,\n",
    "    calib_tau=0.1,\n",
    "    calib_apply_softmax=False,\n",
    "    calib_loss_weight=0.1,\n",
    "    use_calib_loss=True,\n",
    "\n",
    "    use_query_loss=True, \n",
    "    use_encoder_parallel=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c756da1-3064-4314-a9f6-a95e2e29c773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CAW001 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.combiner_head.attention.k_lin.bias', 'encoder.combiner_head.attention.k_lin.weight', 'encoder.combiner_head.attention.out_lin.bias', 'encoder.combiner_head.attention.out_lin.weight', 'encoder.combiner_head.attention.q_lin.bias', 'encoder.combiner_head.attention.q_lin.weight', 'encoder.combiner_head.attention.v_lin.bias', 'encoder.combiner_head.attention.v_lin.weight', 'encoder.combiner_head.ffn.lin1.bias', 'encoder.combiner_head.ffn.lin1.weight', 'encoder.combiner_head.ffn.lin2.bias', 'encoder.combiner_head.ffn.lin2.weight', 'encoder.combiner_head.output_layer_norm.bias', 'encoder.combiner_head.output_layer_norm.weight', 'encoder.combiner_head.sa_layer_norm.bias', 'encoder.combiner_head.sa_layer_norm.weight', 'encoder.enriched_query_head.layer_norm.bias', 'encoder.enriched_query_head.layer_norm.weight', 'encoder.enriched_query_head.projector.bias', 'encoder.enriched_query_head.projector.weight', 'encoder.enriched_query_head.transform.bias', 'encoder.enriched_query_head.transform.weight', 'encoder.memory.LayerNorm.bias', 'encoder.memory.LayerNorm.weight', 'encoder.memory.memory_embeddings.weight', 'encoder.memory.position_embeddings.weight', 'encoder.query_head.layer_norm.bias', 'encoder.query_head.layer_norm.weight', 'encoder.query_head.projector.bias', 'encoder.query_head.projector.weight', 'encoder.query_head.transform.bias', 'encoder.query_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = CAW001.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "e0834039-2ead-4a4e-82ce-27292001336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_heads_to_identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e7be5c2-14bf-4539-8162-7b45f0e39313",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_combiner_to_last_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c653176-5f81-43ee-93f8-6a0148834c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd76c0-fb42-421a-82bf-35cf2b3791cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "e0ebacf1-113d-4f89-b73e-fad4e03d6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    b = prepare_batch(model, batch, m_args=['cat2data_idx', 'cat2data_data2ptr'])\n",
    "    o = model(**b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57a54b76-627a-412d-b571-4013f082ae9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAWModelOutput(loss=tensor(0.1293, grad_fn=<AddBackward0>), data_repr=tensor([[-3.0410e-02, -3.0241e-02, -3.2113e-02,  ..., -3.5623e-02,\n",
       "         -2.5720e-02,  7.6438e-02],\n",
       "        [-2.5134e-02,  1.2242e-02, -2.8343e-02,  ...,  7.1558e-02,\n",
       "         -2.2071e-02, -1.9431e-02],\n",
       "        [-2.2176e-02, -1.7220e-02, -2.3142e-02,  ...,  4.7774e-02,\n",
       "         -2.0947e-03, -1.5657e-02],\n",
       "        ...,\n",
       "        [-6.7133e-03, -2.3140e-02,  1.3361e-04,  ..., -1.4936e-02,\n",
       "         -9.2534e-03, -8.7000e-04],\n",
       "        [-2.4098e-02,  2.2817e-02,  3.1067e-02,  ..., -4.0922e-03,\n",
       "         -1.7239e-02, -3.6599e-03],\n",
       "        [ 2.4830e-02,  4.8248e-02, -2.4326e-03,  ...,  1.3954e-01,\n",
       "          4.4811e-02, -2.6876e-02]], grad_fn=<DivBackward0>), data_enriched_repr=tensor([[-2.0211e-02, -5.9858e-03, -2.2439e-02,  ..., -2.1754e-02,\n",
       "         -2.2301e-02,  7.6863e-02],\n",
       "        [-9.8610e-03, -2.1608e-02,  1.0650e-02,  ...,  3.6301e-02,\n",
       "         -2.0757e-02,  2.3284e-02],\n",
       "        [ 2.1760e-02, -2.2429e-02, -1.9076e-02,  ..., -1.0963e-02,\n",
       "         -2.1555e-02, -1.3106e-02],\n",
       "        ...,\n",
       "        [-1.9716e-02,  6.5463e-03,  1.2907e-01,  ..., -2.2265e-02,\n",
       "         -1.0874e-03, -2.2274e-02],\n",
       "        [ 1.4945e-02, -2.3425e-02, -4.2892e-05,  ..., -1.8428e-02,\n",
       "         -2.3038e-02, -2.2960e-02],\n",
       "        [ 8.9404e-02, -1.0834e-02, -5.9670e-04,  ...,  7.2791e-02,\n",
       "         -2.3324e-02, -1.6468e-02]], grad_fn=<DivBackward0>), lbl2data_repr=tensor([[-0.0038,  0.0010, -0.0195,  ..., -0.0004, -0.0062,  0.0739],\n",
       "        [-0.0251,  0.0122, -0.0283,  ...,  0.0716, -0.0221, -0.0194],\n",
       "        [ 0.0206,  0.0271,  0.0714,  ..., -0.0170, -0.0405,  0.0291],\n",
       "        ...,\n",
       "        [ 0.0233, -0.0006, -0.0239,  ..., -0.0326, -0.0185, -0.0222],\n",
       "        [-0.0202, -0.0052,  0.0049,  ..., -0.0035, -0.0326,  0.0111],\n",
       "        [-0.0307, -0.0106,  0.0028,  ...,  0.1134, -0.0230, -0.0274]],\n",
       "       grad_fn=<DivBackward0>), lbl2data_enriched_repr=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc0f676-7252-4751-92a5-a48e8dc1e8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "77003275-7441-4673-8017-d2b329b02901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.core import *\n",
    "from xcai.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "53b16349-f546-4910-8060-1e08b570d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=['cat2data_idx', 'cat2data_data2ptr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "cfbc7164-e9ea-49e4-b590-8b75f5e5d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.to('cuda')\n",
    "b = b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e1563-4132-40dd-88c4-d572fa262acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = m(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "77eae000-d57e-4599-a0c8-de5b84761e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAWModelOutput(loss=tensor(0.1652, device='cuda:0', grad_fn=<AddBackward0>), data_repr=tensor([[-0.0091, -0.0404,  0.0069,  ..., -0.0133,  0.0293, -0.0296],\n",
       "        [ 0.0700, -0.0143, -0.0293,  ...,  0.0230, -0.0322,  0.0585],\n",
       "        [ 0.0543,  0.0195, -0.0226,  ...,  0.0164,  0.0351, -0.0225],\n",
       "        ...,\n",
       "        [ 0.0748, -0.0329, -0.0415,  ...,  0.0313,  0.0020,  0.0383],\n",
       "        [ 0.0754, -0.0068, -0.0007,  ..., -0.0117, -0.0502,  0.0220],\n",
       "        [-0.0040,  0.0592, -0.0239,  ..., -0.0101,  0.0522,  0.0024]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>), data_enriched_repr=tensor([[-0.0785, -0.0036,  0.1046,  ...,  0.0229,  0.0140, -0.0448],\n",
       "        [-0.0200,  0.0137, -0.0136,  ...,  0.0444,  0.0249, -0.0375],\n",
       "        [-0.0187, -0.0391,  0.0246,  ...,  0.0032,  0.0197,  0.0781],\n",
       "        ...,\n",
       "        [-0.0304,  0.0034,  0.0236,  ...,  0.0043,  0.0382, -0.0257],\n",
       "        [-0.0267, -0.0444, -0.0131,  ...,  0.0010, -0.0422,  0.0187],\n",
       "        [-0.0179, -0.0321, -0.0272,  ...,  0.0418,  0.0102, -0.0213]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>), lbl2data_repr=tensor([[ 0.0288, -0.0444,  0.0083,  ..., -0.0030,  0.0019,  0.0309],\n",
       "        [ 0.0700, -0.0143, -0.0293,  ...,  0.0230, -0.0322,  0.0585],\n",
       "        [ 0.0206, -0.0335, -0.0149,  ...,  0.0488, -0.0196,  0.0558],\n",
       "        ...,\n",
       "        [-0.0264,  0.0329, -0.0576,  ...,  0.0297,  0.0625,  0.0416],\n",
       "        [ 0.0594, -0.0246,  0.0539,  ..., -0.0014, -0.0064,  0.0334],\n",
       "        [-0.0055,  0.0686, -0.0204,  ...,  0.0074,  0.0330, -0.0363]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>), lbl2data_enriched_repr=None)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe0aed-15cb-42cc-8773-da36097a2d3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "source": [
    "## `New` MultiTriplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "174ea633-d37e-4d56-8cac-3a0a60985a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xcai.losses as xloss\n",
    "\n",
    "from xcai.losses import BaseLoss\n",
    "from xcai.core import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3dcaeb0-9575-4e2c-a670-70919d060cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseMultiTriplet(BaseLoss):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        margin:Optional[float]=0.8,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=False,\n",
    "        n_negatives:Optional[int]=5,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        store_attr('margin,tau,apply_softmax,n_negatives')\n",
    "\n",
    "    def align_indices(self, indices:torch.Tensor, group_lengths:torch.Tensor):\n",
    "        n, num_groups, max_len = len(indices), len(group_lengths), group_lengths.max()\n",
    "        group_ids = torch.repeat_interleave(torch.arange(num_groups, device=indices.device), group_lengths)\n",
    "    \n",
    "        row_indices = torch.arange(n, device=indices.device)\n",
    "    \n",
    "        group_start = torch.cat([torch.zeros(1, dtype=group_lengths.dtype, device=group_lengths.device), group_lengths.cumsum(0)[:-1]], dim=0)\n",
    "    \n",
    "        within_idx = row_indices - group_start[group_ids]\n",
    "    \n",
    "        output = torch.zeros((num_groups, max_len), dtype=indices.dtype, device=indices.device)\n",
    "        mask = torch.zeros((num_groups, max_len), device=indices.device)\n",
    "        output[group_ids, within_idx] = indices\n",
    "        mask[group_ids, within_idx] = 1.0\n",
    "    \n",
    "        return output, mask\n",
    "\n",
    "    def remove_redundant_indices(self, inp2targ_idx:torch.Tensor, n_inp2targ:torch.Tensor, pinp2targ_idx:torch.Tensor, n_pinp2targ:torch.Tensor):\n",
    "        mask = torch.isin(pinp2targ_idx, inp2targ_idx)\n",
    "        new_pinp2targ_idx = pinp2targ_idx[mask]\n",
    "    \n",
    "        num_groups = len(n_pinp2targ)\n",
    "        group_ids = torch.repeat_interleave(torch.arange(num_groups, device=n_pinp2targ.device), n_pinp2targ)\n",
    "        new_n_pinp2targ = torch.bincount(group_ids[mask], minlength=num_groups)\n",
    "    \n",
    "        return new_pinp2targ_idx, new_n_pinp2targ\n",
    "\n",
    "    def reset_indices(self, inp2targ_idx:torch.Tensor, n_inp2targ:torch.Tensor, pinp2targ_idx:torch.Tensor, n_pinp2targ:torch.Tensor):\n",
    "        _, reset_indices, counts = torch.unique(torch.cat([inp2targ_idx, pinp2targ_idx]), return_inverse=True, return_counts=True)\n",
    "    \n",
    "        _, idx_sorted = torch.sort(reset_indices, stable=True)\n",
    "        cum_sum = torch.cat((torch.zeros((1,), dtype=counts.dtype, device=counts.device), counts.cumsum(0)[:-1]))\n",
    "        indices = idx_sorted[cum_sum]\n",
    "    \n",
    "        inp2targ_idx = reset_indices[:len(inp2targ_idx)]\n",
    "        pinp2targ_idx = reset_indices[len(inp2targ_idx):]\n",
    "    \n",
    "        return inp2targ_idx, pinp2targ_idx, indices\n",
    "\n",
    "    def compute_scores(self, inp, targ, indices=None):\n",
    "        if indices is not None: targ = targ[indices]\n",
    "        return inp@targ.T\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        \n",
    "        n_inp2targ:torch.LongTensor,\n",
    "        inp2targ_idx:torch.LongTensor,\n",
    "        n_pinp2targ:torch.LongTensor,\n",
    "        pinp2targ_idx:torch.LongTensor,\n",
    "\n",
    "        inp:Optional[torch.FloatTensor]=None, \n",
    "        targ:Optional[torch.FloatTensor]=None,\n",
    "        scores:Optional[torch.FloatTensor]=None,\n",
    "        \n",
    "        margin:Optional[float]=None,\n",
    "        tau:Optional[float]=None,\n",
    "        apply_softmax:Optional[bool]=None,\n",
    "        n_negatives:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        store_attr('margin,tau,apply_softmax,n_negatives', is_none=False)\n",
    "\n",
    "        pinp2targ_idx, n_pinp2targ = self.remove_redundant_indices(inp2targ_idx, n_inp2targ, pinp2targ_idx, n_pinp2targ)\n",
    "        inp2targ_idx, pinp2targ_idx, indices = self.reset_indices(inp2targ_idx, n_inp2targ, pinp2targ_idx, n_pinp2targ)\n",
    "\n",
    "        scores = self.compute_scores(inp, targ, indices=indices) if scores is None else scores[:, indices]\n",
    "\n",
    "        pos_indices, pos_mask = self.align_indices(inp2targ_idx, n_inp2targ)\n",
    "        pos_scores = scores.gather(1, pos_indices)\n",
    "\n",
    "        pos_incidence = torch.zeros_like(scores)\n",
    "        ppos_indices, _ = self.align_indices(inp2targ_idx, n_inp2targ)\n",
    "        pos_incidence = pos_incidence.scatter(1, ppos_indices, 1)\n",
    "        neg_incidence = 1 - pos_incidence\n",
    "\n",
    "        loss = scores.unsqueeze(1) - pos_scores.unsqueeze(2) + self.margin\n",
    "        loss = F.relu(loss * neg_incidence.unsqueeze(1))\n",
    "\n",
    "        scores = scores.unsqueeze(1).expand_as(loss)\n",
    "        neg_incidence = neg_incidence.unsqueeze(1).expand_as(loss)\n",
    "\n",
    "        if self.n_negatives is not None:\n",
    "            loss, idx = torch.topk(loss, min(self.n_negatives, loss.shape[2]), dim=2, largest=True)\n",
    "            scores, neg_incidence = scores.gather(2, idx), neg_incidence.gather(2, idx)\n",
    "\n",
    "        if self.apply_softmax:\n",
    "            mask = loss != 0\n",
    "            penalty = scores / self.tau * mask\n",
    "            penalty[neg_incidence == 0] = torch.finfo(penalty.dtype).min\n",
    "            penalty = torch.softmax(penalty, dim=2)\n",
    "            loss = loss*penalty\n",
    "        \n",
    "        loss /= (neg_incidence.sum(dim=2, keepdim=True) + 1e-9)\n",
    "        loss = loss[pos_mask.bool()].sum(dim=1)\n",
    "\n",
    "        if self.reduction == 'mean': return loss.mean()\n",
    "        elif self.reduction == 'sum': return loss.sum()\n",
    "        else: raise ValueError(f'`reduction` cannot be `{self.reduction}`')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22ac8227-ff92-4da7-b31d-9e0902f8f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTriplet(BaseMultiTriplet):\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        inp:torch.FloatTensor, \n",
    "        targ:torch.FloatTensor, \n",
    "        n_inp2targ:torch.LongTensor,\n",
    "        inp2targ_idx:torch.LongTensor,\n",
    "        n_pinp2targ:torch.LongTensor,\n",
    "        pinp2targ_idx:torch.LongTensor,\n",
    "        margin:Optional[float]=None,\n",
    "        tau:Optional[float]=None,\n",
    "        apply_softmax:Optional[bool]=None,\n",
    "        n_negatives:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return super().forward(n_inp2targ, inp2targ_idx, n_pinp2targ, pinp2targ_idx, inp=inp, targ=targ, margin=margin, tau=tau, \n",
    "                               apply_softmax=apply_softmax, n_negatives=n_negatives, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "100bb802-bf72-427c-8322-81c835b1eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTripletFromScores(BaseMultiTriplet):\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        scores:torch.FloatTensor,  \n",
    "        n_inp2targ:torch.LongTensor,\n",
    "        inp2targ_idx:torch.LongTensor,\n",
    "        n_pinp2targ:torch.LongTensor,\n",
    "        pinp2targ_idx:torch.LongTensor,\n",
    "        margin:Optional[float]=None,\n",
    "        tau:Optional[float]=None,\n",
    "        apply_softmax:Optional[bool]=None,\n",
    "        n_negatives:Optional[int]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return super().forward(n_inp2targ, inp2targ_idx, n_pinp2targ, pinp2targ_idx, scores=scores, margin=margin, tau=tau, \n",
    "                               apply_softmax=apply_softmax, n_negatives=n_negatives, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e94b378d-57ed-4155-ac12-3eb052c09dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd.profiler as profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0bee1eae-39d7-454c-b3ef-67c8bb5b6639",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, targ = output.data_repr, output.lbl2data_repr\n",
    "\n",
    "inp2targ_idx, n_inp2targ = batch['lbl2data_idx'], batch['lbl2data_data2ptr']\n",
    "pinp2targ_idx, n_pinp2targ = batch['plbl2data_idx'], batch['plbl2data_data2ptr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c970b40c-8682-4b08-a354-a1e07c580397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 768]), torch.Size([1000, 768]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape, targ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "171377cc-3ec8-4688-9e3c-7674f5631d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin, tau = 0.3, 0.1\n",
    "apply_softmax = True\n",
    "n_negatives = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70c57f7a-c524-4870-a6aa-c42bbda9e806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0304, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_loss_fn = MultiTriplet(margin, tau, apply_softmax, n_negatives, reduce='mean')\n",
    "\n",
    "with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
    "    new_loss = new_loss_fn(inp, targ, n_inp2targ, inp2targ_idx, n_pinp2targ, pinp2targ_idx)\n",
    "    print(new_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c275385e-b8da-4e18-b7c1-50f5d67eb662",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::isin         0.29%      70.581us         3.05%     755.362us     755.362us       4.19 Kb    -206.17 Kb             1  \n",
      "                aten::_unique         0.20%      50.246us         1.38%     340.472us     340.472us      65.38 Kb     -67.06 Kb             1  \n",
      "                  aten::empty         0.02%       4.002us         0.02%       4.002us       4.002us           0 b           0 b             1  \n",
      "                  aten::empty         0.00%       0.425us         0.00%       0.425us       0.425us           0 b           0 b             1  \n",
      "                  aten::empty         0.00%       0.399us         0.00%       0.399us       0.399us           0 b           0 b             1  \n",
      "                  aten::empty         0.00%       0.429us         0.00%       0.429us       0.429us           0 b           0 b             1  \n",
      "                aten::flatten         0.00%       0.923us         0.00%       0.923us       0.923us           0 b           0 b             1  \n",
      "                   aten::sort         0.88%     217.435us         1.14%     281.247us     281.247us      67.06 Kb      33.53 Kb             1  \n",
      "                  aten::copy_         0.10%      24.094us         0.10%      24.094us      24.094us           0 b           0 b             1  \n",
      "                 aten::arange         0.02%       4.860us         0.09%      22.380us      22.380us      33.53 Kb           0 b             1  \n",
      "                  aten::empty         0.00%       0.586us         0.00%       0.586us       0.586us           0 b           0 b             1  \n",
      "                 aten::arange         0.06%      13.696us         0.07%      16.934us      16.934us      33.53 Kb           0 b             1  \n",
      "                aten::resize_         0.01%       3.238us         0.01%       3.238us       3.238us      33.53 Kb      33.53 Kb             1  \n",
      "             aten::as_strided         0.01%       3.005us         0.01%       3.005us       3.005us           0 b           0 b             1  \n",
      "                  aten::copy_         0.06%      14.333us         0.06%      14.333us      14.333us           0 b           0 b             1  \n",
      "                aten::resize_         0.01%       1.627us         0.01%       1.627us       1.627us      31.85 Kb      31.85 Kb             1  \n",
      "                aten::resize_         0.00%       1.174us         0.00%       1.174us       1.174us      33.53 Kb      33.53 Kb             1  \n",
      "                aten::_unique         0.06%      14.143us         0.32%      79.866us      79.866us       7.61 Kb     -15.62 Kb             1  \n",
      "                  aten::empty         0.00%       0.745us         0.00%       0.745us       0.745us           0 b           0 b             1  \n",
      "                  aten::empty         0.00%       0.446us         0.00%       0.446us       0.446us           0 b           0 b             1  \n",
      "                  aten::empty         0.00%       0.370us         0.00%       0.370us       0.370us           0 b           0 b             1  \n",
      "                  aten::empty         0.00%       0.367us         0.00%       0.367us       0.367us           0 b           0 b             1  \n",
      "                aten::flatten         0.00%       0.191us         0.00%       0.191us       0.191us           0 b           0 b             1  \n",
      "                   aten::sort         0.19%      48.253us         0.25%      62.331us      62.331us      15.62 Kb       7.81 Kb             1  \n",
      "                  aten::copy_         0.01%       3.477us         0.01%       3.477us       3.477us           0 b           0 b             1  \n",
      "                 aten::arange         0.01%       2.553us         0.03%       7.714us       7.714us       7.81 Kb           0 b             1  \n",
      "                  aten::empty         0.00%       0.632us         0.00%       0.632us       0.632us           0 b           0 b             1  \n",
      "                 aten::arange         0.01%       3.670us         0.02%       4.529us       4.529us       7.81 Kb           0 b             1  \n",
      "                aten::resize_         0.00%       0.859us         0.00%       0.859us       0.859us       7.81 Kb       7.81 Kb             1  \n",
      "             aten::as_strided         0.00%       0.751us         0.00%       0.751us       0.751us           0 b           0 b             1  \n",
      "                  aten::copy_         0.01%       2.136us         0.01%       2.136us       2.136us           0 b           0 b             1  \n",
      "                aten::resize_         0.01%       1.273us         0.01%       1.273us       1.273us       7.61 Kb       7.61 Kb             1  \n",
      "                    aten::cat         0.07%      16.126us         0.07%      16.126us      16.126us      39.46 Kb      39.46 Kb             1  \n",
      "                   aten::sort         0.47%     115.466us         0.55%     135.284us     135.284us      78.92 Kb      39.46 Kb             1  \n",
      "                  aten::copy_         0.01%       3.377us         0.01%       3.377us       3.377us           0 b           0 b             1  \n",
      "                 aten::arange         0.01%       2.292us         0.05%      11.570us      11.570us      39.46 Kb           0 b             1  \n",
      "                  aten::empty         0.00%       0.647us         0.00%       0.647us       0.647us           0 b           0 b             1  \n",
      "                 aten::arange         0.03%       7.569us         0.03%       8.631us       8.631us      39.46 Kb           0 b             1  \n",
      "                aten::resize_         0.00%       1.062us         0.00%       1.062us       1.062us      39.46 Kb      39.46 Kb             1  \n",
      "             aten::as_strided         0.00%       0.507us         0.00%       0.507us       0.507us           0 b           0 b             1  \n",
      "                  aten::copy_         0.02%       4.364us         0.02%       4.364us       4.364us           0 b           0 b             1  \n",
      "             aten::empty_like         0.02%       4.397us         0.03%       7.132us       7.132us       4.93 Kb           0 b             1  \n",
      "          aten::empty_strided         0.01%       2.735us         0.01%       2.735us       2.735us       4.93 Kb       4.93 Kb             1  \n",
      "                  aten::slice         0.02%       4.554us         0.02%       5.057us       5.057us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.503us         0.00%       0.503us       0.503us           0 b           0 b             1  \n",
      "                  aten::slice         0.01%       1.481us         0.01%       1.881us       1.881us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.400us         0.00%       0.400us       0.400us           0 b           0 b             1  \n",
      "                  aten::slice         0.01%       1.241us         0.01%       1.561us       1.561us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.320us         0.00%       0.320us       0.320us           0 b           0 b             1  \n",
      "                     aten::eq         0.05%      12.200us         0.05%      12.200us      12.200us       4.93 Kb       4.93 Kb             1  \n",
      "                  aten::copy_         0.01%       2.683us         0.01%       2.683us       2.683us           0 b           0 b             1  \n",
      "                 aten::select         0.03%       6.189us         0.03%       6.721us       6.721us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.532us         0.00%       0.532us       0.532us           0 b           0 b             1  \n",
      "                  aten::copy_         0.01%       1.596us         0.01%       1.596us       1.596us           0 b           0 b             1  \n",
      "             aten::empty_like         0.01%       1.312us         0.01%       3.039us       3.039us       4.93 Kb           0 b             1  \n",
      "          aten::empty_strided         0.01%       1.727us         0.01%       1.727us       1.727us       4.93 Kb       4.93 Kb             1  \n",
      "            aten::index_copy_         0.10%      24.853us         0.11%      26.403us      26.403us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.439us         0.00%       0.439us       0.439us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       1.111us         0.00%       1.111us       1.111us           0 b           0 b             1  \n",
      "                  aten::index         0.15%      38.003us         0.17%      42.934us      42.934us       4.19 Kb       4.19 Kb             1  \n",
      "             aten::as_strided         0.00%       0.415us         0.00%       0.415us       0.415us           0 b           0 b             1  \n",
      "                aten::reshape         0.01%       2.597us         0.02%       4.516us       4.516us           0 b           0 b             1  \n",
      "                   aten::view         0.01%       1.919us         0.01%       1.919us       1.919us           0 b           0 b             1  \n",
      "                  aten::copy_         0.01%       1.826us         0.01%       1.826us       1.826us           0 b           0 b             1  \n",
      "                  aten::index         0.10%      25.607us         0.35%      86.911us      86.911us       8.52 Kb           0 b             1  \n",
      "                aten::nonzero         0.20%      50.528us         0.23%      55.949us      55.949us       8.52 Kb       8.52 Kb             1  \n",
      "                  aten::empty         0.00%       0.994us         0.00%       0.994us       0.994us           0 b           0 b             1  \n",
      "            aten::as_strided_         0.02%       4.427us         0.02%       4.427us       4.427us           0 b           0 b             1  \n",
      "                 aten::select         0.01%       2.343us         0.01%       2.937us       2.937us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.594us         0.00%       0.594us       0.594us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.524us         0.00%       0.524us       0.524us           0 b           0 b             1  \n",
      "                aten::reshape         0.00%       1.095us         0.01%       1.894us       1.894us           0 b           0 b             1  \n",
      "                   aten::view         0.00%       0.799us         0.00%       0.799us       0.799us           0 b           0 b             1  \n",
      "                 aten::arange         0.02%       4.791us         0.05%      11.913us      11.913us       7.81 Kb           0 b             1  \n",
      "                  aten::empty         0.00%       0.951us         0.00%       0.951us       0.951us           0 b           0 b             1  \n",
      "                 aten::arange         0.02%       4.772us         0.02%       6.171us       6.171us       7.81 Kb           0 b             1  \n",
      "                aten::resize_         0.01%       1.399us         0.01%       1.399us       1.399us       7.81 Kb       7.81 Kb             1  \n",
      "      aten::repeat_interleave         0.04%       9.390us         0.46%     114.430us     114.430us      33.53 Kb     -33.53 Kb             1  \n",
      "                aten::flatten         0.00%       0.212us         0.00%       0.212us       0.212us           0 b           0 b             1  \n",
      "      aten::repeat_interleave         0.16%      40.052us         0.36%      89.959us      89.959us      33.53 Kb      -8.79 Kb             1  \n",
      "                 aten::cumsum         0.05%      12.462us         0.05%      13.358us      13.358us       7.81 Kb       7.81 Kb             1  \n",
      "                     aten::to         0.00%       0.896us         0.00%       0.896us       0.896us           0 b           0 b             1  \n",
      "                 aten::select         0.01%       2.534us         0.01%       3.268us       3.268us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.734us         0.00%       0.734us       0.734us           0 b           0 b             1  \n",
      "                   aten::item         0.01%       2.397us         0.01%       3.506us       3.506us           0 b           0 b             1  \n",
      "    aten::_local_scalar_dense         0.00%       1.109us         0.00%       1.109us       1.109us           0 b           0 b             1  \n",
      "                     aten::ge         0.04%      10.838us         0.04%      10.838us      10.838us        1000 b        1000 b             1  \n",
      "                    aten::all         0.06%      13.961us         0.06%      15.560us      15.560us           1 b           1 b             1  \n",
      "             aten::as_strided         0.00%       0.482us         0.00%       0.482us       0.482us           0 b           0 b             1  \n",
      "                  aten::fill_         0.00%       1.117us         0.00%       1.117us       1.117us           0 b           0 b             1  \n",
      "                   aten::item         0.00%       0.958us         0.01%       1.423us       1.423us           0 b           0 b             1  \n",
      "    aten::_local_scalar_dense         0.00%       0.465us         0.00%       0.465us       0.465us           0 b           0 b             1  \n",
      "                  aten::empty         0.01%       1.954us         0.01%       1.954us       1.954us      33.53 Kb      33.53 Kb             1  \n",
      "           aten::index_select         0.06%      14.288us         0.06%      14.869us      14.869us      33.53 Kb      33.53 Kb             1  \n",
      "                  aten::empty         0.00%       0.581us         0.00%       0.581us       0.581us           0 b           0 b             1  \n",
      "                     [memory]         0.00%       0.000us         0.00%       0.000us       0.000us      -7.81 Kb      -7.81 Kb             1  \n",
      "                  aten::index         0.11%      28.291us         0.33%      80.783us      80.783us       8.52 Kb           0 b             1  \n",
      "                aten::nonzero         0.18%      44.495us         0.19%      46.958us      46.958us       8.52 Kb       8.52 Kb             1  \n",
      "                  aten::empty         0.00%       0.617us         0.00%       0.617us       0.617us           0 b           0 b             1  \n",
      "            aten::as_strided_         0.01%       1.846us         0.01%       1.846us       1.846us           0 b           0 b             1  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 24.750ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e52b407-d48f-4258-99b1-4042ddef013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0304, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "scores = inp@targ.T\n",
    "new_loss_fn = MultiTripletFromScores(margin, tau, apply_softmax, n_negatives, reduce='mean')\n",
    "\n",
    "with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
    "    new_loss = new_loss_fn(scores, n_inp2targ, inp2targ_idx, n_pinp2targ, pinp2targ_idx)\n",
    "    print(new_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bfe7c878-1619-4305-94ee-2f445e6ae29f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::isin         0.40%      67.912us         4.37%     746.408us     746.408us       4.19 Kb    -206.17 Kb             1  \n",
      "                aten::_unique         0.29%      50.171us         1.92%     327.497us     327.497us      65.38 Kb     -67.06 Kb             1  \n",
      "                  aten::empty         0.03%       4.309us         0.03%       4.309us       4.309us           0 b           0 b             1  \n",
      "                  aten::empty         0.00%       0.504us         0.00%       0.504us       0.504us           0 b           0 b             1  \n",
      "                  aten::empty         0.00%       0.345us         0.00%       0.345us       0.345us           0 b           0 b             1  \n",
      "                  aten::empty         0.00%       0.439us         0.00%       0.439us       0.439us           0 b           0 b             1  \n",
      "                aten::flatten         0.00%       0.611us         0.00%       0.611us       0.611us           0 b           0 b             1  \n",
      "                   aten::sort         1.26%     215.431us         1.57%     268.045us     268.045us      67.06 Kb      33.53 Kb             1  \n",
      "                  aten::copy_         0.12%      21.192us         0.12%      21.192us      21.192us           0 b           0 b             1  \n",
      "                 aten::arange         0.03%       5.086us         0.14%      24.036us      24.036us      33.53 Kb           0 b             1  \n",
      "                  aten::empty         0.00%       0.737us         0.00%       0.737us       0.737us           0 b           0 b             1  \n",
      "                 aten::arange         0.09%      15.285us         0.11%      18.213us      18.213us      33.53 Kb           0 b             1  \n",
      "                aten::resize_         0.02%       2.928us         0.02%       2.928us       2.928us      33.53 Kb      33.53 Kb             1  \n",
      "             aten::as_strided         0.02%       2.696us         0.02%       2.696us       2.696us           0 b           0 b             1  \n",
      "                  aten::copy_         0.03%       4.690us         0.03%       4.690us       4.690us           0 b           0 b             1  \n",
      "                aten::resize_         0.01%       1.719us         0.01%       1.719us       1.719us      31.85 Kb      31.85 Kb             1  \n",
      "                aten::resize_         0.01%       1.354us         0.01%       1.354us       1.354us      33.53 Kb      33.53 Kb             1  \n",
      "                aten::_unique         0.08%      13.835us         0.47%      79.785us      79.785us       7.61 Kb     -15.62 Kb             1  \n",
      "                  aten::empty         0.00%       0.832us         0.00%       0.832us       0.832us           0 b           0 b             1  \n",
      "                  aten::empty         0.00%       0.486us         0.00%       0.486us       0.486us           0 b           0 b             1  \n",
      "                  aten::empty         0.00%       0.388us         0.00%       0.388us       0.388us           0 b           0 b             1  \n",
      "                  aten::empty         0.00%       0.384us         0.00%       0.384us       0.384us           0 b           0 b             1  \n",
      "                aten::flatten         0.00%       0.232us         0.00%       0.232us       0.232us           0 b           0 b             1  \n",
      "                   aten::sort         0.28%      48.263us         0.36%      62.223us      62.223us      15.62 Kb       7.81 Kb             1  \n",
      "                  aten::copy_         0.02%       3.051us         0.02%       3.051us       3.051us           0 b           0 b             1  \n",
      "                 aten::arange         0.02%       2.619us         0.05%       7.911us       7.911us       7.81 Kb           0 b             1  \n",
      "                  aten::empty         0.00%       0.666us         0.00%       0.666us       0.666us           0 b           0 b             1  \n",
      "                 aten::arange         0.02%       3.663us         0.03%       4.626us       4.626us       7.81 Kb           0 b             1  \n",
      "                aten::resize_         0.01%       0.963us         0.01%       0.963us       0.963us       7.81 Kb       7.81 Kb             1  \n",
      "             aten::as_strided         0.00%       0.816us         0.00%       0.816us       0.816us           0 b           0 b             1  \n",
      "                  aten::copy_         0.01%       2.182us         0.01%       2.182us       2.182us           0 b           0 b             1  \n",
      "                aten::resize_         0.01%       1.405us         0.01%       1.405us       1.405us       7.61 Kb       7.61 Kb             1  \n",
      "                    aten::cat         0.10%      16.936us         0.10%      16.936us      16.936us      39.46 Kb      39.46 Kb             1  \n",
      "                   aten::sort         0.65%     111.566us         0.78%     133.886us     133.886us      78.92 Kb      39.46 Kb             1  \n",
      "                  aten::copy_         0.03%       4.759us         0.03%       4.759us       4.759us           0 b           0 b             1  \n",
      "                 aten::arange         0.01%       2.344us         0.07%      11.117us      11.117us      39.46 Kb           0 b             1  \n",
      "                  aten::empty         0.00%       0.662us         0.00%       0.662us       0.662us           0 b           0 b             1  \n",
      "                 aten::arange         0.04%       7.030us         0.05%       8.111us       8.111us      39.46 Kb           0 b             1  \n",
      "                aten::resize_         0.01%       1.081us         0.01%       1.081us       1.081us      39.46 Kb      39.46 Kb             1  \n",
      "             aten::as_strided         0.00%       0.587us         0.00%       0.587us       0.587us           0 b           0 b             1  \n",
      "                  aten::copy_         0.03%       5.857us         0.03%       5.857us       5.857us           0 b           0 b             1  \n",
      "             aten::empty_like         0.02%       4.180us         0.04%       7.007us       7.007us       4.93 Kb           0 b             1  \n",
      "          aten::empty_strided         0.02%       2.827us         0.02%       2.827us       2.827us       4.93 Kb       4.93 Kb             1  \n",
      "                  aten::slice         0.02%       4.051us         0.03%       4.616us       4.616us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.565us         0.00%       0.565us       0.565us           0 b           0 b             1  \n",
      "                  aten::slice         0.01%       1.517us         0.01%       1.999us       1.999us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.482us         0.00%       0.482us       0.482us           0 b           0 b             1  \n",
      "                  aten::slice         0.01%       1.180us         0.01%       1.568us       1.568us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.388us         0.00%       0.388us       0.388us           0 b           0 b             1  \n",
      "                     aten::eq         0.07%      11.868us         0.07%      11.868us      11.868us       4.93 Kb       4.93 Kb             1  \n",
      "                  aten::copy_         0.01%       2.278us         0.01%       2.278us       2.278us           0 b           0 b             1  \n",
      "                 aten::select         0.04%       6.279us         0.04%       6.883us       6.883us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.604us         0.00%       0.604us       0.604us           0 b           0 b             1  \n",
      "                  aten::copy_         0.01%       1.606us         0.01%       1.606us       1.606us           0 b           0 b             1  \n",
      "             aten::empty_like         0.01%       1.391us         0.02%       3.264us       3.264us       4.93 Kb           0 b             1  \n",
      "          aten::empty_strided         0.01%       1.873us         0.01%       1.873us       1.873us       4.93 Kb       4.93 Kb             1  \n",
      "            aten::index_copy_         0.19%      31.889us         0.19%      33.210us      33.210us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.536us         0.00%       0.536us       0.536us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.785us         0.00%       0.785us       0.785us           0 b           0 b             1  \n",
      "                  aten::index         0.23%      38.666us         0.26%      43.879us      43.879us       4.19 Kb       4.19 Kb             1  \n",
      "             aten::as_strided         0.00%       0.506us         0.00%       0.506us       0.506us           0 b           0 b             1  \n",
      "                aten::reshape         0.02%       2.731us         0.03%       4.707us       4.707us           0 b           0 b             1  \n",
      "                   aten::view         0.01%       1.976us         0.01%       1.976us       1.976us           0 b           0 b             1  \n",
      "                  aten::copy_         0.01%       2.214us         0.01%       2.214us       2.214us           0 b           0 b             1  \n",
      "                  aten::index         0.15%      24.875us         0.50%      85.459us      85.459us       8.52 Kb           0 b             1  \n",
      "                aten::nonzero         0.29%      49.457us         0.32%      54.991us      54.991us       8.52 Kb       8.52 Kb             1  \n",
      "                  aten::empty         0.01%       0.955us         0.01%       0.955us       0.955us           0 b           0 b             1  \n",
      "            aten::as_strided_         0.03%       4.579us         0.03%       4.579us       4.579us           0 b           0 b             1  \n",
      "                 aten::select         0.01%       2.555us         0.02%       3.146us       3.146us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.591us         0.00%       0.591us       0.591us           0 b           0 b             1  \n",
      "             aten::as_strided         0.00%       0.450us         0.00%       0.450us       0.450us           0 b           0 b             1  \n",
      "                aten::reshape         0.01%       1.234us         0.01%       1.997us       1.997us           0 b           0 b             1  \n",
      "                   aten::view         0.00%       0.763us         0.00%       0.763us       0.763us           0 b           0 b             1  \n",
      "                 aten::arange         0.03%       4.752us         0.07%      12.264us      12.264us       7.81 Kb           0 b             1  \n",
      "                  aten::empty         0.00%       0.844us         0.00%       0.844us       0.844us           0 b           0 b             1  \n",
      "                 aten::arange         0.03%       5.287us         0.04%       6.668us       6.668us       7.81 Kb           0 b             1  \n",
      "                aten::resize_         0.01%       1.381us         0.01%       1.381us       1.381us       7.81 Kb       7.81 Kb             1  \n",
      "      aten::repeat_interleave         0.06%       9.399us         0.66%     113.266us     113.266us      33.53 Kb     -33.53 Kb             1  \n",
      "                aten::flatten         0.00%       0.248us         0.00%       0.248us       0.248us           0 b           0 b             1  \n",
      "      aten::repeat_interleave         0.23%      39.909us         0.52%      89.237us      89.237us      33.53 Kb      -8.79 Kb             1  \n",
      "                 aten::cumsum         0.07%      12.333us         0.08%      13.255us      13.255us       7.81 Kb       7.81 Kb             1  \n",
      "                     aten::to         0.01%       0.922us         0.01%       0.922us       0.922us           0 b           0 b             1  \n",
      "                 aten::select         0.02%       2.604us         0.02%       3.683us       3.683us           0 b           0 b             1  \n",
      "             aten::as_strided         0.01%       1.079us         0.01%       1.079us       1.079us           0 b           0 b             1  \n",
      "                   aten::item         0.02%       2.885us         0.02%       3.805us       3.805us           0 b           0 b             1  \n",
      "    aten::_local_scalar_dense         0.01%       0.920us         0.01%       0.920us       0.920us           0 b           0 b             1  \n",
      "                     aten::ge         0.06%      10.002us         0.06%      10.002us      10.002us        1000 b        1000 b             1  \n",
      "                    aten::all         0.08%      13.208us         0.09%      14.929us      14.929us           1 b           1 b             1  \n",
      "             aten::as_strided         0.00%       0.560us         0.00%       0.560us       0.560us           0 b           0 b             1  \n",
      "                  aten::fill_         0.01%       1.161us         0.01%       1.161us       1.161us           0 b           0 b             1  \n",
      "                   aten::item         0.01%       1.173us         0.01%       1.638us       1.638us           0 b           0 b             1  \n",
      "    aten::_local_scalar_dense         0.00%       0.465us         0.00%       0.465us       0.465us           0 b           0 b             1  \n",
      "                  aten::empty         0.01%       2.016us         0.01%       2.016us       2.016us      33.53 Kb      33.53 Kb             1  \n",
      "           aten::index_select         0.08%      13.814us         0.08%      14.382us      14.382us      33.53 Kb      33.53 Kb             1  \n",
      "                  aten::empty         0.00%       0.568us         0.00%       0.568us       0.568us           0 b           0 b             1  \n",
      "                     [memory]         0.00%       0.000us         0.00%       0.000us       0.000us      -7.81 Kb      -7.81 Kb             1  \n",
      "                  aten::index         0.11%      18.699us         0.42%      71.744us      71.744us       8.52 Kb           0 b             1  \n",
      "                aten::nonzero         0.26%      44.398us         0.28%      47.343us      47.343us       8.52 Kb       8.52 Kb             1  \n",
      "                  aten::empty         0.00%       0.646us         0.00%       0.646us       0.646us           0 b           0 b             1  \n",
      "            aten::as_strided_         0.01%       2.299us         0.01%       2.299us       2.299us           0 b           0 b             1  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 17.077ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "949d8c25-c45e-45d4-a3b4-d2ae58ef80e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0300, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "old_loss_fn = xloss.MultiTriplet(bsz=1000, tn_targ=1000, margin=margin, tau=tau, apply_softmax=apply_softmax, \n",
    "                                 n_negatives=n_negatives, reduce='mean')\n",
    "\n",
    "with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
    "    old_loss = old_loss_fn(inp, targ, n_inp2targ, inp2targ_idx, n_pinp2targ, pinp2targ_idx)\n",
    "    print(old_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2890d814-a919-46b8-9946-8f9712191d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                      Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                  aten::to         0.01%       2.103us         0.01%       2.103us       2.103us           0 b           0 b             1  \n",
      "                                  aten::to         0.00%       0.148us         0.00%       0.148us       0.148us           0 b           0 b             1  \n",
      "                                 aten::max         0.05%      18.833us         0.08%      31.685us      31.685us           8 b           0 b             1  \n",
      "                               aten::empty         0.03%      11.313us         0.03%      11.313us      11.313us           8 b           8 b             1  \n",
      "                               aten::fill_         0.00%       1.539us         0.00%       1.539us       1.539us           0 b           0 b             1  \n",
      "                               aten::slice         0.04%      16.840us         0.05%      20.413us      20.413us           0 b           0 b             1  \n",
      "                          aten::as_strided         0.01%       3.573us         0.01%       3.573us       3.573us           0 b           0 b             1  \n",
      "                               aten::slice         0.01%       2.493us         0.01%       2.944us       2.944us           0 b           0 b             1  \n",
      "                          aten::as_strided         0.00%       0.451us         0.00%       0.451us       0.451us           0 b           0 b             1  \n",
      "                   aten::repeat_interleave         0.03%      12.284us         0.30%     119.064us     119.064us       7.81 Kb      -7.81 Kb             1  \n",
      "                             aten::flatten         0.00%       0.548us         0.00%       0.548us       0.548us           0 b           0 b             1  \n",
      "                   aten::repeat_interleave         0.08%      29.629us         0.24%      94.486us      94.486us       7.81 Kb      -8.79 Kb             1  \n",
      "                              aten::cumsum         0.05%      20.334us         0.05%      20.665us      20.665us       7.81 Kb       7.81 Kb             1  \n",
      "                                  aten::to         0.00%       0.331us         0.00%       0.331us       0.331us           0 b           0 b             1  \n",
      "                              aten::select         0.02%       7.013us         0.02%       7.707us       7.707us           0 b           0 b             1  \n",
      "                          aten::as_strided         0.00%       0.694us         0.00%       0.694us       0.694us           0 b           0 b             1  \n",
      "                                aten::item         0.01%       2.599us         0.01%       3.537us       3.537us           0 b           0 b             1  \n",
      "                 aten::_local_scalar_dense         0.00%       0.938us         0.00%       0.938us       0.938us           0 b           0 b             1  \n",
      "                                  aten::ge         0.04%      14.196us         0.04%      14.196us      14.196us        1000 b        1000 b             1  \n",
      "                                 aten::all         0.04%      13.951us         0.04%      14.910us      14.910us           1 b           1 b             1  \n",
      "                          aten::as_strided         0.00%       0.534us         0.00%       0.534us       0.534us           0 b           0 b             1  \n",
      "                               aten::fill_         0.00%       0.425us         0.00%       0.425us       0.425us           0 b           0 b             1  \n",
      "                                aten::item         0.00%       0.976us         0.00%       1.454us       1.454us           0 b           0 b             1  \n",
      "                 aten::_local_scalar_dense         0.00%       0.478us         0.00%       0.478us       0.478us           0 b           0 b             1  \n",
      "                               aten::empty         0.01%       2.388us         0.01%       2.388us       2.388us       7.81 Kb       7.81 Kb             1  \n",
      "                        aten::index_select         0.03%      11.124us         0.03%      11.746us      11.746us       7.81 Kb       7.81 Kb             1  \n",
      "                               aten::empty         0.00%       0.622us         0.00%       0.622us       0.622us           0 b           0 b             1  \n",
      "                             aten::numpy_T         0.01%       2.539us         0.05%      18.325us      18.325us           0 b           0 b             1  \n",
      "                             aten::permute         0.04%      14.087us         0.04%      15.786us      15.786us           0 b           0 b             1  \n",
      "                          aten::as_strided         0.00%       1.699us         0.00%       1.699us       1.699us           0 b           0 b             1  \n",
      "                              aten::matmul         0.02%       7.430us        29.33%      11.458ms      11.458ms       3.81 Mb           0 b             1  \n",
      "                                  aten::mm        29.31%      11.450ms        29.31%      11.451ms      11.451ms       3.81 Mb       3.81 Mb             1  \n",
      "                        aten::resolve_conj         0.00%       0.809us         0.00%       0.809us       0.809us           0 b           0 b             1  \n",
      "                        aten::resolve_conj         0.00%       0.063us         0.00%       0.063us       0.063us           0 b           0 b             1  \n",
      "                                aten::view         0.03%      10.072us         0.03%      10.072us      10.072us           0 b           0 b             1  \n",
      "                              aten::gather         0.10%      39.684us         0.10%      39.684us      39.684us       3.91 Kb       3.91 Kb             1  \n",
      "                                 aten::cat         0.06%      22.061us         0.06%      22.061us      22.061us      41.34 Kb      41.34 Kb             1  \n",
      "                            aten::_unique2         0.19%      74.957us         1.09%     424.238us     424.238us      73.20 Kb     -82.69 Kb             1  \n",
      "                               aten::empty         0.01%       2.147us         0.01%       2.147us       2.147us           0 b           0 b             1  \n",
      "                               aten::empty         0.00%       0.492us         0.00%       0.492us       0.492us           0 b           0 b             1  \n",
      "                               aten::empty         0.00%       0.530us         0.00%       0.530us       0.530us           0 b           0 b             1  \n",
      "                               aten::empty         0.00%       0.495us         0.00%       0.495us       0.495us           0 b           0 b             1  \n",
      "                             aten::flatten         0.00%       0.321us         0.00%       0.321us       0.321us           0 b           0 b             1  \n",
      "                                aten::sort         0.75%     294.951us         0.88%     342.573us     342.573us      82.69 Kb      41.34 Kb             1  \n",
      "                               aten::copy_         0.05%      20.165us         0.05%      20.165us      20.165us           0 b           0 b             1  \n",
      "                              aten::arange         0.01%       4.622us         0.05%      20.192us      20.192us      41.34 Kb           0 b             1  \n",
      "                               aten::empty         0.00%       0.706us         0.00%       0.706us       0.706us           0 b           0 b             1  \n",
      "                              aten::arange         0.03%      12.642us         0.04%      14.864us      14.864us      41.34 Kb           0 b             1  \n",
      "                             aten::resize_         0.01%       2.222us         0.01%       2.222us       2.222us      41.34 Kb      41.34 Kb             1  \n",
      "                          aten::as_strided         0.00%       1.942us         0.00%       1.942us       1.942us           0 b           0 b             1  \n",
      "                               aten::copy_         0.01%       5.323us         0.01%       5.323us       5.323us           0 b           0 b             1  \n",
      "                             aten::resize_         0.00%       1.633us         0.00%       1.633us       1.633us      31.85 Kb      31.85 Kb             1  \n",
      "                             aten::resize_         0.00%       1.090us         0.00%       1.090us       1.090us      41.34 Kb      41.34 Kb             1  \n",
      "                                  [memory]         0.00%       0.000us         0.00%       0.000us       0.000us     -41.34 Kb     -41.34 Kb             1  \n",
      "                               aten::slice         0.02%       8.317us         0.03%       9.884us       9.884us           0 b           0 b             1  \n",
      "                          aten::as_strided         0.00%       1.567us         0.00%       1.567us       1.567us           0 b           0 b             1  \n",
      "                               aten::zeros         0.01%       5.783us         0.02%       8.503us       8.503us           8 b           0 b             1  \n",
      "                               aten::empty         0.01%       2.037us         0.01%       2.037us       2.037us           8 b           8 b             1  \n",
      "                               aten::zero_         0.00%       0.683us         0.00%       0.683us       0.683us           0 b           0 b             1  \n",
      "                              aten::cumsum         0.04%      14.762us         0.04%      15.380us      15.380us       7.81 Kb       7.81 Kb             1  \n",
      "                                  aten::to         0.00%       0.618us         0.00%       0.618us       0.618us           0 b           0 b             1  \n",
      "                                 aten::cat         0.02%       8.469us         0.02%       8.469us       8.469us       7.82 Kb       7.82 Kb             1  \n",
      "                                  [memory]         0.00%       0.000us         0.00%       0.000us       0.000us      -7.81 Kb      -7.81 Kb             1  \n",
      "                                  [memory]         0.00%       0.000us         0.00%       0.000us       0.000us          -8 b          -8 b             1  \n",
      "                           aten::ones_like         0.01%       4.684us         0.05%      18.356us      18.356us      33.53 Kb           0 b             1  \n",
      "                          aten::empty_like         0.01%       4.098us         0.02%       7.725us       7.725us      33.53 Kb           0 b             1  \n",
      "                       aten::empty_strided         0.01%       3.627us         0.01%       3.627us       3.627us      33.53 Kb      33.53 Kb             1  \n",
      "                               aten::fill_         0.02%       5.947us         0.02%       5.947us       5.947us           0 b           0 b             1  \n",
      "                                  aten::to         0.00%       0.670us         0.00%       0.670us       0.670us           0 b           0 b             1  \n",
      "                                  aten::to         0.00%       0.119us         0.00%       0.119us       0.119us           0 b           0 b             1  \n",
      "                                  aten::to         0.00%       0.082us         0.00%       0.082us       0.082us           0 b           0 b             1  \n",
      "            aten::sparse_compressed_tensor         0.05%      20.191us         0.11%      42.141us      42.141us           0 b          -8 b             1  \n",
      "                                 aten::max         0.02%       6.355us         0.02%       8.459us       8.459us           8 b           0 b             1  \n",
      "                               aten::empty         0.00%       1.644us         0.00%       1.644us       1.644us           8 b           8 b             1  \n",
      "                               aten::fill_         0.00%       0.460us         0.00%       0.460us       0.460us           0 b           0 b             1  \n",
      "                                aten::item         0.01%       2.183us         0.01%       2.753us       2.753us           0 b           0 b             1  \n",
      "                 aten::_local_scalar_dense         0.00%       0.570us         0.00%       0.570us       0.570us           0 b           0 b             1  \n",
      "    aten::_sparse_compressed_tensor_unsafe         0.02%       9.163us         0.03%      10.738us      10.738us           0 b           0 b             1  \n",
      "                               aten::empty         0.00%       0.706us         0.00%       0.706us       0.706us           0 b           0 b             1  \n",
      "                               aten::empty         0.00%       0.476us         0.00%       0.476us       0.476us           0 b           0 b             1  \n",
      "                               aten::empty         0.00%       0.393us         0.00%       0.393us       0.393us           0 b           0 b             1  \n",
      "                            aten::to_dense         0.01%       3.611us        15.73%       6.147ms       6.147ms      31.11 Mb           0 b             1  \n",
      "                           aten::_to_dense         0.22%      86.773us        15.73%       6.144ms       6.144ms      31.11 Mb    -333.07 Kb             1  \n",
      "                        aten::crow_indices         0.01%       2.687us         0.01%       4.959us       4.959us           0 b           0 b             1  \n",
      "                               aten::alias         0.01%       2.272us         0.01%       2.272us       2.272us           0 b           0 b             1  \n",
      "                         aten::col_indices         0.00%       1.220us         0.00%       1.605us       1.605us           0 b           0 b             1  \n",
      "                               aten::alias         0.00%       0.385us         0.00%       0.385us       0.385us           0 b           0 b             1  \n",
      "                        aten::crow_indices         0.00%       0.892us         0.00%       1.298us       1.298us           0 b           0 b             1  \n",
      "                               aten::alias         0.00%       0.406us         0.00%       0.406us       0.406us           0 b           0 b             1  \n",
      "                              aten::values         0.00%       1.141us         0.00%       1.501us       1.501us           0 b           0 b             1  \n",
      "                               aten::alias         0.00%       0.360us         0.00%       0.360us       0.360us           0 b           0 b             1  \n",
      "                               aten::zeros         0.01%       3.933us        14.53%       5.677ms       5.677ms      31.11 Mb           0 b             1  \n",
      "                               aten::empty         0.05%      19.612us         0.05%      19.612us      19.612us      31.11 Mb      31.11 Mb             1  \n",
      "                               aten::zero_         0.01%       4.629us        14.47%       5.653ms       5.653ms           0 b           0 b             1  \n",
      "                               aten::fill_        14.46%       5.648ms        14.46%       5.648ms       5.648ms           0 b           0 b             1  \n",
      "                          aten::unsqueeze_         0.01%       5.518us         0.03%      12.977us      12.977us           0 b           0 b             1  \n",
      "                         aten::as_strided_         0.02%       7.459us         0.02%       7.459us       7.459us           0 b           0 b             1  \n",
      "                          aten::unsqueeze_         0.00%       1.017us         0.00%       1.735us       1.735us           0 b           0 b             1  \n",
      "                         aten::as_strided_         0.00%       0.718us         0.00%       0.718us       0.718us           0 b           0 b             1  \n",
      "                          aten::unsqueeze_         0.00%       1.221us         0.00%       1.937us       1.937us           0 b           0 b             1  \n",
      "------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 39.068ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f9288-41cf-419e-b8ee-facddbc9881b",
   "metadata": {},
   "source": [
    "## `CAW002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe6da0-4e5d-4080-9616-719f1c1bda96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CAW002(CAW000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.encoder = Encoder(config)\n",
    "        self.meta_loss_fn = MultiTripletFromScores(margin=config.margin, n_negatives=config.num_negatives, tau=config.tau, \n",
    "                                                  apply_softmax=config.apply_softmax, reduce='mean')\n",
    "        self.post_init()\n",
    "        self.remap_post_init()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "\n",
    "    def compute_meta_loss(self, scores, feat, prefix, **kwargs):\n",
    "        loss = 0.0\n",
    "        meta_kwargs = Parameters.from_aug_meta_prefix_for_loss(feat, prefix, **kwargs)\n",
    "        if len(meta_kwargs):\n",
    "            args, pargs = meta_kwargs[prefix], meta_kwargs[f'p{prefix}']\n",
    "            loss = self.config.meta_loss_weight * self.meta_loss_fn(scores[:, args['idx']], args['data2ptr'], args['idx'], \n",
    "                                                                    pargs['data2ptr'], pargs['idx'])\n",
    "        return loss\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ): \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.config.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_aug_meta_prefix_for_feature('data', self.config.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.config.data_aug_meta_prefix, data_enrich=self.config.data_enrich, **data_meta_kwargs)\n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_aug_meta_prefix_for_feature('lbl', self.config.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.config.lbl2data_aug_meta_prefix, data_enrich=self.config.lbl2data_enrich, **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.enriched_repr, lbl2data_o.repr,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            if self.config.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.repr, lbl2data_o.repr,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "                \n",
    "            if self.config.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.enriched_repr, data_o.repr, lbl2data_o.repr,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.config.use_meta_loss:\n",
    "                loss += self.compute_meta_loss(data_o.meta_scores, 'data', self.config.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_meta_loss(lbl2data_o.meta_scores, 'lbl', self.config.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.repr,data_o.enriched_repr,lbl2data_o.repr,lbl2data_o.enriched_repr)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        return CAWModelOutput(\n",
    "            loss=loss,\n",
    "            data_repr=data_o.repr,\n",
    "            data_enriched_repr=data_o.enriched_repr,\n",
    "            lbl2data_repr=lbl2data_o.repr,\n",
    "            lbl2data_enriched_repr=lbl2data_o.enriched_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087dc979-7660-4900-8ce3-17c47a8bebc9",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d4474850-6dbb-4e51-8eb9-3e3325a2b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CachewConfig(\n",
    "    top_k_metadata = 5,\n",
    "    num_metadata=block.train.dset.meta['cat_meta'].n_meta,\n",
    "\n",
    "    data_aug_meta_prefix='cat2data', \n",
    "    lbl2data_aug_meta_prefix=None,\n",
    "\n",
    "    data_enrich=True,\n",
    "    lbl2data_enrich=False,\n",
    "\n",
    "    batch_size=100, \n",
    "    num_batch_labels=5000, \n",
    "    margin=0.3,\n",
    "    num_negatives=10,\n",
    "    tau=0.1,\n",
    "    apply_softmax=True,\n",
    "\n",
    "    calib_margin=0.3,\n",
    "    calib_num_negatives=10,\n",
    "    calib_tau=0.1,\n",
    "    calib_apply_softmax=False,\n",
    "    calib_loss_weight=0.1,\n",
    "    use_calib_loss=True,\n",
    "\n",
    "    meta_loss_weight=0.1,\n",
    "    use_meta_loss=True,\n",
    "    \n",
    "    use_query_loss=True, \n",
    "    use_encoder_parallel=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e821b94a-39c4-4173-9cf8-b6ee225adcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CAW002 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.combiner_head.attention.k_lin.bias', 'encoder.combiner_head.attention.k_lin.weight', 'encoder.combiner_head.attention.out_lin.bias', 'encoder.combiner_head.attention.out_lin.weight', 'encoder.combiner_head.attention.q_lin.bias', 'encoder.combiner_head.attention.q_lin.weight', 'encoder.combiner_head.attention.v_lin.bias', 'encoder.combiner_head.attention.v_lin.weight', 'encoder.combiner_head.ffn.lin1.bias', 'encoder.combiner_head.ffn.lin1.weight', 'encoder.combiner_head.ffn.lin2.bias', 'encoder.combiner_head.ffn.lin2.weight', 'encoder.combiner_head.output_layer_norm.bias', 'encoder.combiner_head.output_layer_norm.weight', 'encoder.combiner_head.sa_layer_norm.bias', 'encoder.combiner_head.sa_layer_norm.weight', 'encoder.enriched_query_head.layer_norm.bias', 'encoder.enriched_query_head.layer_norm.weight', 'encoder.enriched_query_head.projector.bias', 'encoder.enriched_query_head.projector.weight', 'encoder.enriched_query_head.transform.bias', 'encoder.enriched_query_head.transform.weight', 'encoder.memory.LayerNorm.bias', 'encoder.memory.LayerNorm.weight', 'encoder.memory.memory_embeddings.weight', 'encoder.memory.position_embeddings.weight', 'encoder.query_head.layer_norm.bias', 'encoder.query_head.layer_norm.weight', 'encoder.query_head.projector.bias', 'encoder.query_head.projector.weight', 'encoder.query_head.transform.bias', 'encoder.query_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = CAW002.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "aa974231-775c-4332-a734-3af459056b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_combiner_to_last_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "12f8d0b4-ce43-4f7e-82ad-cb5d58738b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b324eac8-7a2b-4271-a72f-3f35904a0c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAWModelOutput(loss=tensor(0.1707, grad_fn=<AddBackward0>), data_repr=tensor([[-0.0214, -0.0066,  0.0303,  ...,  0.0182, -0.0135, -0.0793],\n",
       "        [ 0.0273,  0.0134, -0.0062,  ...,  0.0202,  0.0661,  0.0051],\n",
       "        [-0.0364,  0.0412,  0.0306,  ...,  0.0285, -0.0069, -0.0259],\n",
       "        ...,\n",
       "        [-0.0645,  0.0458, -0.0585,  ...,  0.0032,  0.0341, -0.0968],\n",
       "        [ 0.0521, -0.0134, -0.0446,  ...,  0.0345, -0.0384, -0.0503],\n",
       "        [ 0.0612, -0.0032,  0.0068,  ...,  0.0308,  0.0379,  0.0087]],\n",
       "       grad_fn=<DivBackward0>), data_enriched_repr=tensor([[ 0.0099,  0.0407,  0.0103,  ...,  0.0601, -0.0036, -0.0469],\n",
       "        [ 0.0121, -0.0055, -0.0352,  ...,  0.0269, -0.0329,  0.0282],\n",
       "        [ 0.0361,  0.0599, -0.0128,  ..., -0.0444,  0.0144, -0.0105],\n",
       "        ...,\n",
       "        [ 0.0085,  0.0783,  0.0237,  ...,  0.0411, -0.0147, -0.0539],\n",
       "        [ 0.0198,  0.0504, -0.0206,  ..., -0.0257,  0.0670,  0.0072],\n",
       "        [ 0.1197,  0.0223,  0.0419,  ...,  0.0094, -0.0042,  0.0105]],\n",
       "       grad_fn=<DivBackward0>), lbl2data_repr=tensor([[ 0.0466,  0.0200, -0.0254,  ..., -0.0217,  0.0787,  0.0471],\n",
       "        [ 0.0273,  0.0134, -0.0062,  ...,  0.0202,  0.0661,  0.0051],\n",
       "        [-0.0364,  0.0412,  0.0306,  ...,  0.0285, -0.0069, -0.0259],\n",
       "        ...,\n",
       "        [ 0.0081, -0.0228, -0.0618,  ..., -0.0061,  0.0700, -0.0538],\n",
       "        [-0.0199,  0.0347, -0.0152,  ...,  0.0174, -0.0880, -0.0705],\n",
       "        [ 0.0343,  0.0327, -0.0233,  ..., -0.0052,  0.0079,  0.0162]],\n",
       "       grad_fn=<DivBackward0>), lbl2data_enriched_repr=None)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8050b7db-9b8e-4664-9070-26ffcf0fad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    output = model(**batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb4c93-0d3b-4453-9bb4-9668dd81f6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb13d7c-dbb8-4370-ad88-c39475ef2158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
