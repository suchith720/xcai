{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b84d227-6f70-4060-82c0-40648d681f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.cachew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a33728-6828-4b79-a40e-4054c830d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8dcb50-00fe-4d0b-b2f2-fbb6b09049dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "290df3ff-0ce1-4791-ae32-c758f12d67e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, torch.nn as nn, torch.nn.functional as F, re\n",
    "from typing import Optional, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from transformers.utils.generic import ModelOutput\n",
    "from transformers import PretrainedConfig, DistilBertConfig, DistilBertPreTrainedModel, DistilBertModel\n",
    "from transformers.models.distilbert.modeling_distilbert import create_sinusoidal_embeddings, TransformerBlock\n",
    "\n",
    "from xcai.losses import *\n",
    "from xcai.learner import XCDataParallel\n",
    "from xcai.models.modeling_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76abb7-8560-490d-8cb5-a8ee46299b44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb535de-64ed-4430-8fcb-35eaead49eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08dd4c65-aaa1-44eb-9fb9-039d6807de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/scratch/scai/phd/aiz218323/outputs/mogicX/03_ngame-for-wikiseealsotitles'\n",
    "\n",
    "data_dir = '/home/scai/phd/aiz218323/scratch/datasets/benchmarks/'\n",
    "config_file = 'wikiseealsotitles'\n",
    "config_key = 'data_meta'\n",
    "\n",
    "mname = 'sentence-transformers/msmarco-distilbert-base-v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b9fe27-0065-4a54-a70a-f867a45c6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/scratch/scai/phd/aiz218323/datasets/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9867f45-61e8-466c-b015-afb4c68d1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = f'{pkl_dir}/mogicX/wikiseealsotitles_data-meta_distilbert-base-uncased_sxc.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55640a26-6348-4644-917d-f7779092b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = build_block(pkl_file, config_file, True, config_key, data_dir=data_dir, n_sdata_meta_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dc7d671-0dfb-4673-aff8-faa5b1f54ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2348fea-4b6f-4ea5-bc31-7f884cbf0ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_idx', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_data2ptr', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_data2ptr', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'pcat2lbl_idx', 'pcat2lbl_lbl2ptr', 'cat2lbl_idx', 'cat2lbl_lbl2ptr', 'cat2lbl_identifier', 'cat2lbl_input_text', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'cat2lbl_data2ptr', 'pcat2lbl_data2ptr'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7de80-5789-4ec6-a6d3-955f7780e960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ac7b776-b6a3-42c0-9efe-52121236b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel\n",
    "m = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d7f4996-a9fa-40be-9f1c-6feefc9d188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = m(input_ids=batch['data_input_ids'], attention_mask=batch['data_attention_mask'])\n",
    "o = Pooling.mean_pooling(o.last_hidden_state, batch['data_attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70605e74-1b00-4560-9a5e-fbb17b6f9bbb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "33c722db-2fd8-4507-9720-be77e90bb0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Parameters:\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_data_aug_meta_prefix_for_encoder(prefix:str, **kwargs):\n",
    "        inputs = {}\n",
    "        args = [arg for arg in kwargs if prefix is not None and re.match(f'^{prefix}.*_(input_ids|attention_mask|data2ptr|idx)$', arg)]\n",
    "        for arg in args:\n",
    "            meta,param = arg.split('_', maxsplit=1)\n",
    "            inputs.setdefault(meta, {})[param] = kwargs[arg]\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_data_aug_meta_prefix_for_feature(feat:str, prefix:str, **kwargs):\n",
    "        keys = ['attention_mask', 'input_ids', 'idx']        \n",
    "        inputs = {f'{prefix}_{k}': kwargs[f'{prefix}_{k}'] for k in keys if f'{prefix}_{k}' in kwargs}\n",
    "        if prefix is not None and f'{prefix}_{feat}2ptr' in kwargs:\n",
    "            inputs.update({f'{prefix}_data2ptr': kwargs[f'{prefix}_{feat}2ptr']})\n",
    "        return inputs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082f7adf-d3fb-41e8-afee-21095c7a3449",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "d76164cf-718b-472e-9187-14f37c3c1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MemoryConfig(DistilBertConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        top_k_metadata:Optional[int] = 5,\n",
    "        num_metadata:Optional[int] = 100_000,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.top_k_metadata = top_k_metadata\n",
    "        self.num_metadata = num_metadata\n",
    "        super().__init__(**kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "31f0cdf3-583a-4cd9-9b45-5a970b5a2082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CachewConfig(MemoryConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_aug_meta_prefix:Optional[str] = None, \n",
    "        lbl2data_aug_meta_prefix:Optional[str] = None, \n",
    "        \n",
    "        num_batch_labels:Optional[int] = None,\n",
    "        batch_size:Optional[int] = None,\n",
    "        margin:Optional[float] = 0.3,\n",
    "        num_negatives:Optional[int] = 10,\n",
    "        tau:Optional[float] = 0.1,\n",
    "        apply_softmax:Optional[bool] = True,\n",
    "\n",
    "        calib_margin:Optional[float] = 0.05,\n",
    "        calib_num_negatives:Optional[int] = 10,\n",
    "        calib_tau:Optional[float] = 0.1,\n",
    "        calib_apply_softmax:Optional[bool] = False,\n",
    "        calib_loss_weight:Optional[float] = 0.1,\n",
    "        use_calib_loss:Optional[float] = False,\n",
    "        \n",
    "        use_query_loss:Optional[float] = True,\n",
    "        \n",
    "        use_encoder_parallel:Optional[bool] = True,\n",
    "        \n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.data_aug_meta_prefix = data_aug_meta_prefix\n",
    "        self.lbl2data_aug_meta_prefix = lbl2data_aug_meta_prefix\n",
    "\n",
    "        self.num_batch_labels = num_batch_labels\n",
    "        self.batch_size = batch_size\n",
    "        self.margin = margin\n",
    "        self.num_negatives = num_negatives\n",
    "        self.tau = tau\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        self.calib_margin = calib_margin\n",
    "        self.calib_num_negatives = calib_num_negatives\n",
    "        self.calib_tau = calib_tau\n",
    "        self.calib_apply_softmax = calib_apply_softmax\n",
    "        self.calib_loss_weight = calib_loss_weight\n",
    "        self.use_calib_loss = use_calib_loss\n",
    "\n",
    "        self.use_query_loss = use_query_loss\n",
    "\n",
    "        self.use_encoder_parallel = use_encoder_parallel\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d085f55-8bb3-4ac8-b534-b7ed9e2d288f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "d0a56f8f-7de0-48c0-8ff5-5150f4934a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Memory(nn.Module):\n",
    "\n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__()\n",
    "        self.top_k_metadata = config.top_k_metadata\n",
    "        \n",
    "        self.memory_embeddings = nn.Embedding(config.num_metadata, config.dim)\n",
    "        \n",
    "        self.position_embeddings = nn.Embedding(config.num_metadata, config.dim)\n",
    "        if config.sinusoidal_pos_embds:\n",
    "            create_sinusoidal_embeddings(\n",
    "                n_pos=config.num_metadata, dim=config.dim, out=self.position_embeddings.weight\n",
    "            )\n",
    "        \n",
    "        self.LayerNorm = nn.LayerNorm(config.dim, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def set_memory_embeddings(self, embed:torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            self.memory_embeddings.weight.copy_(embed)\n",
    "\n",
    "    def align_embeddings(self, embeddings:torch.Tensor, group_lengths:torch.Tensor):\n",
    "        n, dim = embeddings.shape\n",
    "        num_groups, max_len = len(group_lengths), group_lengths.max()\n",
    "        group_ids = torch.repeat_interleave(torch.arange(num_groups, device=embeddings.device), group_lengths)\n",
    "\n",
    "        row_indices = torch.arange(n, device=embeddings.device)\n",
    "\n",
    "        group_start = torch.cat([torch.zeros(1, dtype=group_lengths.dtype, device=group_lengths.device), group_lengths.cumsum(0)[:-1]], dim=0)\n",
    "\n",
    "        within_idx = row_indices - group_start[group_ids]\n",
    "\n",
    "        output, mask = torch.zeros((num_groups, max_len, dim), device=embeddings.device), torch.zeros((num_groups, max_len), device=embeddings.device)\n",
    "        output[group_ids, within_idx] = embeddings\n",
    "        mask[group_ids, within_idx] = 1.0\n",
    "\n",
    "        return output, mask\n",
    "        \n",
    "    def forward(self, input_embeds:torch.Tensor, input_indices:Optional[torch.Tensor]=None, input_data2ptr:Optional[torch.Tensor]=None):\n",
    "        assert input_embeds.dim() == 2, f'Input embeddings should be 2-dimensional, but got dim:{input_embeds.dim()}'\n",
    "        \n",
    "        meta_norm = F.normalize(self.memory_embeddings.weight, dim=-1)\n",
    "        input_norm = F.normalize(input_embeds, dim=-1)\n",
    "        \n",
    "        scores = input_norm@meta_norm.T\n",
    "        values, indices = torch.topk(scores, self.top_k_metadata, dim=-1)\n",
    "        \n",
    "        pred_embeddings = self.memory_embeddings(indices) + self.position_embeddings(indices)\n",
    "        pred_embeddings = self.LayerNorm(pred_embeddings)\n",
    "        pred_embeddings = self.dropout(pred_embeddings)\n",
    "        pred_mask = torch.ones(pred_embeddings.shape[0], pred_embeddings.shape[1], device=pred_embeddings.device)\n",
    "\n",
    "        input_embeddings = input_mask = None\n",
    "        if input_indices is not None:\n",
    "            input_embeddings = self.memory_embeddings(input_indices) + self.position_embeddings(input_indices)\n",
    "            input_embeddings = self.LayerNorm(input_embeddings)\n",
    "            input_embeddings = self.dropout(input_embeddings)\n",
    "            input_embeddings, input_mask = self.align_embeddings(input_embeddings, input_data2ptr)\n",
    "\n",
    "        embeddings = pred_embeddings if input_embeddings is None else torch.cat([pred_embeddings, input_embeddings], dim=1)\n",
    "        mask = pred_mask if pred_mask is None else torch.cat([pred_mask, input_mask], dim=1)\n",
    "        \n",
    "        return embeddings, mask, scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4eed69-154e-4c30-aa50-56ebe000144f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1c8252d-91fa-4e9c-8049-4a9f31261135",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MemoryConfig(num_metadata=block.train.dset.meta['cat_meta'].n_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70fbc632-ac55-45fb-8c4c-001f3e3dcda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Memory(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76b3ad56-d4e0-4758-abbf-d9fbb8b65620",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug_meta_prefix = 'cat2data'\n",
    "meta_kwargs = Parameters.from_data_aug_meta_prefix_for_encoder(data_aug_meta_prefix, **batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b30e01f-6263-42b1-8047-9f630614e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_repr = torch.randn(batch['data_input_ids'].shape[0], config.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28d597e4-fc01-4132-a314-b0f0509bb4e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings, mask, scores = m(data_repr, meta_kwargs[data_aug_meta_prefix]['idx'], meta_kwargs[data_aug_meta_prefix]['data2ptr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27ea702d-44e2-4ba5-8ca0-ec64955dff0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 8, 768]), torch.Size([100, 8]), torch.Size([100, 656086]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape, mask.shape, scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487dc644-2bfa-40dd-af8b-3fcafc949a14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Combiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "0d59f06d-f3aa-4cae-aff9-09fe682c3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrossCombinerBlock(TransformerBlock):\n",
    "\n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def post_init(self):\n",
    "        for module in self.modules(): self._init_weights(module)\n",
    "\n",
    "    def _init_weights(self, module: nn.Module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.eye_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        m: torch.Tensor,\n",
    "        attn_mask: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        output_attentions: bool = False,\n",
    "    ) -> Tuple[torch.Tensor, ...]:\n",
    "        \n",
    "        # Cross-Attention\n",
    "        ca_output = self.attention(\n",
    "            query=x,\n",
    "            key=m,\n",
    "            value=m,\n",
    "            mask=attn_mask,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        if output_attentions:\n",
    "            ca_output, ca_weights = ca_output  # (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\n",
    "        else:  # To handle these `output_attentions` or `output_hidden_states` cases returning tuples\n",
    "            if type(ca_output) is not tuple:\n",
    "                raise TypeError(f\"ca_output must be a tuple but it is {type(ca_output)} type\")\n",
    "\n",
    "            ca_output = ca_output[0]\n",
    "        ca_output = self.sa_layer_norm(ca_output + x)  # (bs, seq_length, dim)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        ffn_output = self.ffn(ca_output)  # (bs, seq_length, dim)\n",
    "        ffn_output: torch.Tensor = self.output_layer_norm(ffn_output + ca_output)  # (bs, seq_length, dim)\n",
    "\n",
    "        output = (ffn_output,)\n",
    "        if output_attentions:\n",
    "            output = (ca_weights,) + output\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b975a-9974-4e76-a832-0ac4633094e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "4032f55d-88b8-40ff-bc6c-92868cd6e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class EncoderOutput(ModelOutput):\n",
    "    repr: Optional[torch.FloatTensor] = None\n",
    "    enriched_repr: Optional[torch.FloatTensor] = None\n",
    "    meta_scores: Optional[torch.FloatTensor] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "83ca2dcc-8f85-4127-b912-5d8d815bc19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder(DistilBertPreTrainedModel):\n",
    "    \n",
    "    config_class = MemoryConfig\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig, \n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.query_head = RepresentationHead(config)\n",
    "        self.combiner_head = CrossCombinerBlock(config)\n",
    "        self.enriched_query_head = RepresentationHead(config)\n",
    "\n",
    "        self.memory = Memory(config)\n",
    "        \n",
    "        self.post_init()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_heads_to_identity(self):\n",
    "        self.query_head.post_init()\n",
    "        self.combiner_head.post_init()\n",
    "        self.enriched_query_head.post_init()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_combiner_to_last_layer(self):\n",
    "        lsd = self.distilbert.transformer.layer[-1].state_dict()\n",
    "        lsd_keys = lsd.keys()        \n",
    "        csd = self.combiner_head.state_dict()\n",
    "        csd_keys = csd.keys()\n",
    "        \n",
    "        assert len(lsd_keys) == len(csd_keys), f'mismatched keys: {len(lsd_keys)} != {len(csd_keys)}'\n",
    "        \n",
    "        for k in csd_keys:\n",
    "            assert csd[k].shape == lsd[k].shape\n",
    "            csd[k].copy_(lsd[k])\n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def set_memory_embeddings(self, embed:torch.Tensor):\n",
    "        self.memory.set_memory_embeddings(embed)\n",
    "        \n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        return self.distilbert.get_position_embeddings()\n",
    "    \n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "        self.distilbert.resize_position_embeddings(new_num_position_embeddings)\n",
    "    \n",
    "    def encode(self, input_ids:torch.Tensor, attention_mask:torch.Tensor, **kwargs):\n",
    "        return self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def encode_query(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.query_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "\n",
    "    def encode_enriched_query(self, embed:torch.Tensor):\n",
    "        return F.normalize(self.enriched_query_head(embed), dim=1)\n",
    "\n",
    "    def enrich_query_representation(self, data_repr:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr, meta_mask, meta_scores = self.memory(data_repr, meta_kwargs['idx'], meta_kwargs['data2ptr'])\n",
    "        \n",
    "        meta_mask = meta_mask.view(len(meta_mask), 1, 1, -1).bool()\n",
    "        fusion_repr = self.combiner_head(x=data_repr.view(len(data_repr), 1, -1), m=meta_repr, attn_mask=meta_mask)\n",
    "        fusion_repr = fusion_repr[0].squeeze(dim=1)\n",
    "        \n",
    "        enriched_data_repr = self.encode_enriched_query(data_repr + fusion_repr)\n",
    "        return enriched_data_repr, meta_scores\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        data_repr = self.encode_query(data_o[0], data_attention_mask)\n",
    "        \n",
    "        enriched_data_repr = meta_scores = None\n",
    "        meta_kwargs = Parameters.from_data_aug_meta_prefix_for_encoder(data_aug_meta_prefix, **kwargs)\n",
    "        if len(meta_kwargs): \n",
    "            enriched_data_repr, meta_scores = self.enrich_query_representation(data_repr, meta_kwargs[data_aug_meta_prefix])\n",
    "            \n",
    "        return EncoderOutput(\n",
    "            repr=data_repr,\n",
    "            enriched_repr=enriched_data_repr,\n",
    "            meta_scores=meta_scores\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdac53b-6120-4598-b597-e4477045735d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "96ebd52b-436c-46e6-8ad3-3924738e1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MemoryConfig(num_metadata=block.train.dset.meta['cat_meta'].n_meta)\n",
    "m = Encoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "55a1c176-1373-4b32-8edc-e79e1ee817e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_idx', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_data2ptr', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_data2ptr', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'pcat2lbl_idx', 'pcat2lbl_lbl2ptr', 'cat2lbl_idx', 'cat2lbl_lbl2ptr', 'cat2lbl_identifier', 'cat2lbl_input_text', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'cat2lbl_data2ptr', 'pcat2lbl_data2ptr'])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "54afd1a2-4a9d-4f48-838a-b428cd7226d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_aug_meta_prefix='cat2data'\n",
    "output = m(**batch, data_aug_meta_prefix=data_aug_meta_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "be06da59-da28-43ea-bb10-c7b6309eb43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderOutput(repr=tensor([[-0.0538, -0.0170,  0.0591,  ..., -0.0791, -0.0830,  0.0450],\n",
       "        [-0.0295,  0.0319, -0.0031,  ..., -0.0622, -0.0621,  0.0216],\n",
       "        [-0.0148,  0.0062, -0.0024,  ..., -0.0583, -0.0546,  0.0029],\n",
       "        ...,\n",
       "        [ 0.0536, -0.0087, -0.0208,  ..., -0.0220, -0.0539,  0.0342],\n",
       "        [-0.0158,  0.0252,  0.0377,  ..., -0.0533, -0.0447,  0.0333],\n",
       "        [ 0.0298, -0.0146, -0.0188,  ..., -0.0568, -0.0479,  0.0317]],\n",
       "       grad_fn=<DivBackward0>), enriched_repr=tensor([[ 0.0427, -0.0454, -0.0224,  ..., -0.0174,  0.0331,  0.0002],\n",
       "        [ 0.0302, -0.0223,  0.0149,  ...,  0.0240, -0.0156,  0.0016],\n",
       "        [ 0.0192,  0.0120,  0.0273,  ..., -0.0221, -0.0642, -0.0499],\n",
       "        ...,\n",
       "        [ 0.0385,  0.0089,  0.0263,  ..., -0.0362,  0.0579, -0.0503],\n",
       "        [ 0.0260,  0.0138,  0.0007,  ..., -0.0468,  0.0162,  0.0187],\n",
       "        [-0.0065, -0.0112,  0.0086,  ..., -0.0254,  0.0095,  0.0348]],\n",
       "       grad_fn=<DivBackward0>), meta_scores=tensor([[ 0.0004, -0.0740, -0.1226,  ..., -0.0239, -0.0191, -0.0168],\n",
       "        [-0.0323,  0.0250, -0.0444,  ..., -0.0668, -0.0348, -0.0130],\n",
       "        [-0.0856, -0.0104, -0.0703,  ..., -0.0272, -0.0037, -0.0220],\n",
       "        ...,\n",
       "        [-0.0103, -0.0160, -0.0651,  ...,  0.0117, -0.0274,  0.0248],\n",
       "        [-0.0146, -0.0094, -0.0559,  ..., -0.0251, -0.0346,  0.0313],\n",
       "        [-0.0159, -0.0124, -0.0488,  ..., -0.0381,  0.0033, -0.0187]],\n",
       "       grad_fn=<MmBackward0>))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045dc821-df70-4d37-8961-86cdce86b4a3",
   "metadata": {},
   "source": [
    "## `CAW000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "70d26f79-06e1-4f0f-8010-5ab44fa286b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class CAWModelOutput(ModelOutput):\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    data_repr: Optional[torch.FloatTensor] = None\n",
    "    data_enriched_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_enriched_repr: Optional[torch.FloatTensor] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "a2467815-5658-4ce0-a844-5c8542fcd09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CAW000(nn.Module):\n",
    "\n",
    "    config_class = CachewConfig\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config: CachewConfig,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.config, self.encoder = config, None\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=config.batch_size, tn_targ=config.num_batch_labels, margin=config.margin, \n",
    "                                        n_negatives=config.num_negatives, tau=config.tau, apply_softmax=config.apply_softmax, \n",
    "                                        reduce='mean')\n",
    "        self.cab_loss_fn = Calibration(margin=config.calib_margin, tau=config.calib_tau, n_negatives=config.calib_num_negatives, \n",
    "                                       apply_softmax=config.calib_apply_softmax, reduce='mean')\n",
    "        \n",
    "    def init_heads_to_identity(self):\n",
    "        if self.encoder is None: raise ValueError('Encoder not initialized.')\n",
    "        self.encoder.init_heads_to_identity()\n",
    "\n",
    "    def init_combiner_to_last_layer(self):\n",
    "        if self.encoder is None: raise ValueError('Encoder not initialized.')\n",
    "        self.encoder.init_combiner_to_last_layer()\n",
    "\n",
    "    def set_memory_embeddings(self, embed:torch.Tensor):\n",
    "        if self.encoder is None: raise ValueError('Encoder not initialized.')\n",
    "        self.encoder.set_memory_embeddings(embed)\n",
    "        \n",
    "    def compute_loss(self, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.rep_loss_fn(inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "\n",
    "    def calibration_loss(self, einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.config.calib_loss_weight * self.cab_loss_fn(einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ): \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.config.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_data_aug_meta_prefix_for_feature('data', self.config.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.config.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_data_aug_meta_prefix_for_feature('lbl2data', self.config.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.config.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.enriched_repr, lbl2data_o.repr,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.config.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.repr, lbl2data_o.repr,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.config.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.enriched_repr, data_o.repr, lbl2data_o.repr,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.repr,data_o.enriched_repr,lbl2data_o.repr,lbl2data_o.enriched_repr)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        return CAWModelOutput(\n",
    "            loss=loss,\n",
    "            data_repr=data_o.repr,\n",
    "            data_enriched_repr=data_o.enriched_repr,\n",
    "            lbl2data_repr=lbl2data_o.repr,\n",
    "            lbl2data_enriched_repr=lbl2data_o.enriched_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760aa441-82a7-4e20-98f7-b71bf4ad58e2",
   "metadata": {},
   "source": [
    "## `CAW001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "d0dc5719-c811-41cb-ab03-991daff2ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CAW001(CAW000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.encoder = Encoder(config)\n",
    "        \n",
    "        self.post_init()\n",
    "        self.remap_post_init()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e0f21-d6d0-40d1-a3b4-a1f57cd68577",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "06dd341b-b4a7-416d-aca1-e7597a284a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CachewConfig(\n",
    "    top_k_metadata = 5,\n",
    "    num_metadata=block.train.dset.meta['cat_meta'].n_meta,\n",
    "\n",
    "    data_aug_meta_prefix='cat2data', \n",
    "    lbl2data_aug_meta_prefix=None,\n",
    "\n",
    "    batch_size=100, \n",
    "    num_batch_labels=5000, \n",
    "    margin=0.3,\n",
    "    num_negatives=5,\n",
    "    tau=0.1,\n",
    "    apply_softmax=True,\n",
    "\n",
    "    calib_margin=0.3,\n",
    "    calib_num_negatives=10,\n",
    "    calib_tau=0.1,\n",
    "    calib_apply_softmax=False,\n",
    "    calib_loss_weight=0.1,\n",
    "    use_calib_loss=True,\n",
    "\n",
    "    use_query_loss=True, \n",
    "    use_encoder_parallel=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "5c756da1-3064-4314-a9f6-a95e2e29c773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CAW001 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.combiner_head.attention.k_lin.bias', 'encoder.combiner_head.attention.k_lin.weight', 'encoder.combiner_head.attention.out_lin.bias', 'encoder.combiner_head.attention.out_lin.weight', 'encoder.combiner_head.attention.q_lin.bias', 'encoder.combiner_head.attention.q_lin.weight', 'encoder.combiner_head.attention.v_lin.bias', 'encoder.combiner_head.attention.v_lin.weight', 'encoder.combiner_head.ffn.lin1.bias', 'encoder.combiner_head.ffn.lin1.weight', 'encoder.combiner_head.ffn.lin2.bias', 'encoder.combiner_head.ffn.lin2.weight', 'encoder.combiner_head.output_layer_norm.bias', 'encoder.combiner_head.output_layer_norm.weight', 'encoder.combiner_head.sa_layer_norm.bias', 'encoder.combiner_head.sa_layer_norm.weight', 'encoder.enriched_query_head.layer_norm.bias', 'encoder.enriched_query_head.layer_norm.weight', 'encoder.enriched_query_head.projector.bias', 'encoder.enriched_query_head.projector.weight', 'encoder.enriched_query_head.transform.bias', 'encoder.enriched_query_head.transform.weight', 'encoder.memory.LayerNorm.bias', 'encoder.memory.LayerNorm.weight', 'encoder.memory.memory_embeddings.weight', 'encoder.memory.position_embeddings.weight', 'encoder.query_head.layer_norm.bias', 'encoder.query_head.layer_norm.weight', 'encoder.query_head.projector.bias', 'encoder.query_head.projector.weight', 'encoder.query_head.transform.bias', 'encoder.query_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = CAW001.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "e0834039-2ead-4a4e-82ce-27292001336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_heads_to_identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "5e7be5c2-14bf-4539-8162-7b45f0e39313",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_combiner_to_last_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "0c653176-5f81-43ee-93f8-6a0148834c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "77eae000-d57e-4599-a0c8-de5b84761e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAWModelOutput(loss=tensor(0.1652, grad_fn=<AddBackward0>), data_repr=tensor([[-0.0091, -0.0404,  0.0069,  ..., -0.0133,  0.0293, -0.0296],\n",
       "        [ 0.0700, -0.0143, -0.0293,  ...,  0.0230, -0.0322,  0.0585],\n",
       "        [ 0.0543,  0.0195, -0.0226,  ...,  0.0164,  0.0351, -0.0225],\n",
       "        ...,\n",
       "        [ 0.0748, -0.0329, -0.0415,  ...,  0.0313,  0.0020,  0.0383],\n",
       "        [ 0.0754, -0.0068, -0.0007,  ..., -0.0117, -0.0502,  0.0220],\n",
       "        [-0.0040,  0.0592, -0.0239,  ..., -0.0101,  0.0522,  0.0024]],\n",
       "       grad_fn=<DivBackward0>), data_enriched_repr=tensor([[-0.0785, -0.0036,  0.1046,  ...,  0.0229,  0.0140, -0.0448],\n",
       "        [-0.0200,  0.0137, -0.0136,  ...,  0.0444,  0.0249, -0.0375],\n",
       "        [-0.0187, -0.0391,  0.0246,  ...,  0.0032,  0.0197,  0.0781],\n",
       "        ...,\n",
       "        [-0.0304,  0.0034,  0.0236,  ...,  0.0043,  0.0382, -0.0257],\n",
       "        [-0.0267, -0.0444, -0.0131,  ...,  0.0010, -0.0422,  0.0187],\n",
       "        [-0.0179, -0.0321, -0.0272,  ...,  0.0418,  0.0102, -0.0213]],\n",
       "       grad_fn=<DivBackward0>), lbl2data_repr=tensor([[ 0.0288, -0.0444,  0.0083,  ..., -0.0030,  0.0019,  0.0309],\n",
       "        [ 0.0700, -0.0143, -0.0293,  ...,  0.0230, -0.0322,  0.0585],\n",
       "        [ 0.0206, -0.0335, -0.0149,  ...,  0.0488, -0.0196,  0.0558],\n",
       "        ...,\n",
       "        [-0.0264,  0.0329, -0.0576,  ...,  0.0297,  0.0625,  0.0416],\n",
       "        [ 0.0594, -0.0246,  0.0539,  ..., -0.0014, -0.0064,  0.0334],\n",
       "        [-0.0055,  0.0686, -0.0204,  ...,  0.0074,  0.0330, -0.0363]],\n",
       "       grad_fn=<DivBackward0>), lbl2data_enriched_repr=None)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "7c7f5130-1665-40d7-9e51-ff76553b9914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_idx', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_data2ptr', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_data2ptr', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'pcat2lbl_idx', 'pcat2lbl_lbl2ptr', 'cat2lbl_idx', 'cat2lbl_lbl2ptr', 'cat2lbl_identifier', 'cat2lbl_input_text', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'cat2lbl_data2ptr', 'pcat2lbl_data2ptr'])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe0aed-15cb-42cc-8773-da36097a2d3a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## `CAW002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "2749b6a6-3879-4f83-9148-316a6c715277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_indices(indices:torch.Tensor, group_lengths:torch.Tensor):\n",
    "    n, num_groups, max_len = len(indices), len(group_lengths), group_lengths.max()\n",
    "    group_ids = torch.repeat_interleave(torch.arange(num_groups, device=embeddings.device), group_lengths)\n",
    "\n",
    "    row_indices = torch.arange(n, device=embeddings.device)\n",
    "\n",
    "    group_start = torch.cat([torch.zeros(1, dtype=group_lengths.dtype, device=group_lengths.device), group_lengths.cumsum(0)[:-1]], dim=0)\n",
    "\n",
    "    within_idx = row_indices - group_start[group_ids]\n",
    "\n",
    "    output = torch.zeros((num_groups, max_len), dtype=indices.dtype, device=embeddings.device)\n",
    "    mask = torch.zeros((num_groups, max_len), device=embeddings.device)\n",
    "    output[group_ids, within_idx] = indices\n",
    "    mask[group_ids, within_idx] = 1.0\n",
    "\n",
    "    return output, mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "1d1aaabb-9d57-4bf7-9d5d-b1341120cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_indices, pos_mask = align_indices(batch['pcat2data_idx'], batch['pcat2data_data2ptr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "47191400-85ba-49da-af8e-0982eb8b598a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0248, -0.0620,  0.0081,  ..., -0.0392, -0.0392, -0.0392],\n",
       "        [-0.0060,  0.0322,  0.0235,  ..., -0.0391, -0.0391, -0.0391],\n",
       "        [ 0.0424,  0.0510, -0.0347,  ..., -0.0060, -0.0060, -0.0060],\n",
       "        ...,\n",
       "        [-0.0385,  0.0220,  0.0220,  ...,  0.0220,  0.0220,  0.0220],\n",
       "        [ 0.0434, -0.0090, -0.0090,  ..., -0.0090, -0.0090, -0.0090],\n",
       "        [ 0.0067,  0.0091, -0.0174,  ..., -0.0174, -0.0174, -0.0174]],\n",
       "       grad_fn=<GatherBackward0>)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.gather(1, pos_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee1eae-39d7-454c-b3ef-67c8bb5b6639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfdae56-7e51-4ab9-a861-779eba2b82e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "dcc86a97-043e-4e8e-87ab-a57b31424b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Loss(torch.nn.Module):\n",
    "    def __init__(self, reduction='mean', pad_ind=None):\n",
    "        super(_Loss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.pad_ind = pad_ind\n",
    "\n",
    "    def _reduce(self, loss):\n",
    "        if self.reduction == 'none':\n",
    "            return loss\n",
    "        elif self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'custom':\n",
    "            return loss.sum(dim=1).mean()\n",
    "        else:\n",
    "            return loss.sum()\n",
    "\n",
    "    def _mask_at_pad(self, loss):\n",
    "        \"\"\"\n",
    "        Mask the loss at padding index, i.e., make it zero\n",
    "        \"\"\"\n",
    "        if self.pad_ind is not None:\n",
    "            loss[:, self.pad_ind] = 0.0\n",
    "        return loss\n",
    "\n",
    "    def _mask(self, loss, mask=None):\n",
    "        \"\"\"\n",
    "        Mask the loss at padding index, i.e., make it zero\n",
    "        * Mask should be a boolean array with 1 where loss needs\n",
    "        to be considered.\n",
    "        * it'll make it zero where value is 0\n",
    "        \"\"\"\n",
    "        if mask is not None:\n",
    "            loss = loss.masked_fill(~mask, 0.0)\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "3f9e0a26-373d-44e6-b808-2f7664585794",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletMarginLoss(_Loss):\n",
    "\n",
    "    def __init__(self, margin=1.0, eps=1.0e-6, reduction='mean',\n",
    "                 num_positives=3, num_negatives=10,\n",
    "                 num_violators=False, alpha=0.9):\n",
    "        super(TripletMarginLossOHNMMulti, self).__init__(reduction)\n",
    "        self.mx_lim = 100\n",
    "        self.mn_lim = -100\n",
    "        self.alpha = alpha\n",
    "        self._eps = eps\n",
    "        self._margin = margin\n",
    "        self._reduction = reduction\n",
    "        self.num_positives = num_positives\n",
    "        self.num_negatives = num_negatives\n",
    "        self.num_violators = num_violators\n",
    "\n",
    "    def forward(self, output, target, *args):\n",
    "        B = target.size(0)\n",
    "        if target.size(0) != target.size(1):\n",
    "            MX_LIM = torch.full_like(output, self.mx_lim)\n",
    "            sim_p = output.where(target == 1, MX_LIM)\n",
    "            indices = sim_p.topk(largest=False, dim=1, k=self.num_positives)[1]\n",
    "            sim_p = sim_p.gather(1, indices)\n",
    "        else:\n",
    "            sim_p = output.diagonal().view(B, 1)\n",
    "        \n",
    "        MN_LIM = torch.full_like(output, self.mn_lim)\n",
    "        target = target.to(output.device)\n",
    "\n",
    "        _, num_p = sim_p.size()\n",
    "        sim_p = sim_p.view(B, num_p, 1)\n",
    "        sim_m = MN_LIM.where(target == 1, output)\n",
    "        indices = sim_m.topk(largest=True, dim=1, k=self.num_negatives)[1]\n",
    "        sim_n = output.gather(1, indices)\n",
    "        sim_n = sim_n.unsqueeze(1).repeat_interleave(num_p, dim=1)\n",
    "        loss = F.relu(sim_n - sim_p + self._margin)\n",
    "        prob = loss.clone()\n",
    "        prob.masked_fill_(prob == 0, self.mn_lim)\n",
    "        loss = F.softmax(prob, dim=-1)*loss\n",
    "        if (self._reduction == \"mean\"):\n",
    "            reduced_loss = loss.mean()\n",
    "        else:\n",
    "            reduced_loss = loss.sum()\n",
    "        if self.num_violators:\n",
    "            nnz = torch.sum((loss > 0), axis=1).float().mean()\n",
    "            return reduced_loss, nnz\n",
    "        else:\n",
    "            return reduced_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f88b27-cafd-4831-b1d4-8b5f1abdca42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
