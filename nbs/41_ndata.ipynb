{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9210a1b2-d1cc-41a7-8067-a8b9090198c4",
   "metadata": {},
   "source": [
    "# NData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850b98cc-4a9d-4797-996c-61e3ecfdc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e75ed5fc-72a5-4443-88a1-53a80782323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ff3617f-3c42-4302-bbf7-7fb6ade1b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, inspect, numpy as np, scipy.sparse as sp\n",
    "from typing import Callable, Optional, Union, Dict\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BatchEncoding\n",
    "\n",
    "from xcai.core import Filterer, Info\n",
    "from xcai.data import _read_sparse_file\n",
    "from xcai.sdata import identity_collate_fn\n",
    "from xcai.sdata import SMainXCDataset, SXCDataset\n",
    "from xcai.sdata import SBaseXCDataBlock, SXCDataBlock\n",
    "\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import *\n",
    "from plum import dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "973ec7a4-af26-46da-b3df-1f2b013db1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4958fd31-77c0-429f-b32a-c7d10780d753",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dcef4a8-09e7-4879-b9bb-b60bf626cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20111c0d-892f-4757-b8cd-b4ed9295bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/Users/suchith720/Projects/data/processed/mogicX'\n",
    "pkl_file = f'{pkl_dir}/wikiseealsotitles_data_distilbert-base-uncased_sxc.joblib'\n",
    "\n",
    "data_dir = '/home/scai/phd/aiz218323/scratch/datasets/benchmarks/'\n",
    "config_file = 'wikiseealsotitles'\n",
    "config_key = 'data_meta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6cfc0e7-421d-4382-a08d-32e3c6ccd87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = build_block(pkl_file, config_file, True, config_key, data_dir=data_dir, n_slbl_samples=2, do_build=False, \n",
    "                    main_oversample=True, meta_oversample=True, return_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c3d7f-0e85-4666-98bb-9af4e66dbf33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8c5a39a-b20d-4ae6-9a38-5df912490b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {\n",
    "    'data_lbl': block.train.dset.data.data_lbl,\n",
    "    'data_neg': block.train.dset.data.data_lbl,\n",
    "    'data_info': block.train.dset.data.data_info,\n",
    "    'lbl_info': block.train.dset.data.lbl_info,\n",
    "    'data_lbl_filterer': block.train.dset.data.data_lbl_filterer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "495cbd4e-1bb1-49b1-b8b5-7693f78345c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = block.train.dset.meta['cat_meta']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd4430d-cec8-42af-a40f-492af3c40431",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d095fb-abcd-43f9-8929-b27fa697acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NMainXCData:\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls, data_info:str, lbl_info:str, data_lbl:Optional[str]=None, data_neg:Optional[str]=None, \n",
    "                  data_lbl_filterer:Optional[str]=None, main_max_data_sequence_length:Optional[int]=None, \n",
    "                  main_max_lbl_sequence_length:Optional[int]=None, **kwargs):\n",
    "        return {\n",
    "            'data_lbl': _read_sparse_file(data_lbl),\n",
    "            'data_neg': _read_sparse_file(data_neg),\n",
    "            'data_info': Info.from_txt(data_info, max_sequence_length=main_max_data_sequence_length, **kwargs),\n",
    "            'lbl_info': Info.from_txt(lbl_info, max_sequence_length=main_max_lbl_sequence_length, **kwargs),\n",
    "            'data_lbl_filterer': Filterer.load_filter(data_lbl_filterer),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6b61b8-6211-4b35-9a99-82a18176fb72",
   "metadata": {},
   "source": [
    "## NDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c14617-b016-4735-8267-99917e04933b",
   "metadata": {},
   "source": [
    "### `SMainWithNegativesXCDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fdf818c-9599-4426-bb04-73ce3ff9e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NMainXCDataset(SMainXCDataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_neg:Optional[sp.csr_matrix]=None,\n",
    "        n_neg_samples:Optional[int]=None,\n",
    "        n_sneg_samples:Optional[int]=1,\n",
    "        neg_oversample:Optional[int]=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        store_attr('data_neg,n_neg_samples,n_sneg_samples,neg_oversample')\n",
    "        self.curr_data_neg, self.data_neg_scores = None, None\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def _store_indices(self):\n",
    "        super()._store_indices()\n",
    "        if self.data_neg is not None: self.curr_data_neg = [o.indices.tolist() for o in self.data_neg]\n",
    "\n",
    "    def _verify_inputs(self):\n",
    "        super()._verify_inputs()\n",
    "        if self.data_neg is not None and self.data_lbl is not None:\n",
    "            if self.data_neg.shape != self.data_lbl.shape:\n",
    "                raise ValueError(f\"Shape mismatch: `self.data_lbl`({self.data_lbl.shape}) and `self.data_neg`({self.data_neg.shape})\")\n",
    "\n",
    "    def _store_scores(self):\n",
    "        super()._store_scores()\n",
    "        if self.data_neg is not None:\n",
    "            if self.use_main_distribution:\n",
    "                data_neg = self.data_neg / (self.data_neg.sum(axis=1) + 1e-9)\n",
    "                data_neg = data_neg.tocsr()\n",
    "            else:\n",
    "                data_neg = self.data_neg\n",
    "            self.data_neg_scores = [o.data.tolist() for o in data_neg]\n",
    "            \n",
    "    def __getitems__(self, idxs:List):\n",
    "        x = {'data_idx': torch.tensor(idxs, dtype=torch.int64)}\n",
    "        x.update(self.get_info('data', idxs, self.data_info, self.data_info_keys))\n",
    "        if self.data_lbl is not None:\n",
    "            prefix = 'lbl2data'\n",
    "            o = self.extract_items(prefix, self.curr_data_lbl, idxs, self.n_lbl_samples, self.n_slbl_samples, self.main_oversample, \n",
    "                                   self.lbl_info, self.lbl_info_keys, self.use_main_distribution, self.data_lbl_scores, \n",
    "                                   return_scores=self.return_scores)\n",
    "            x.update(o)\n",
    "            \n",
    "        if self.data_neg is not None:\n",
    "            prefix = 'neg2data'\n",
    "            o = self.extract_items(prefix, self.curr_data_neg, idxs, self.n_neg_samples, self.n_sneg_samples, self.neg_oversample, \n",
    "                                   self.lbl_info, self.lbl_info_keys, self.use_main_distribution, self.data_neg_scores, \n",
    "                                   return_scores=self.return_scores)\n",
    "            x.update(o)\n",
    "            \n",
    "        return x\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(NMainXCData.from_file)\n",
    "    def from_file(\n",
    "        cls, \n",
    "        n_lbl_samples:Optional[int]=None,\n",
    "        data_info_keys:Optional[List]=None,\n",
    "        lbl_info_keys:Optional[List]=None,\n",
    "        n_slbl_samples:Optional[int]=1,\n",
    "        main_oversample:Optional[bool]=False,\n",
    "\n",
    "        n_neg_samples:Optional[int]=None,\n",
    "        n_sneg_samples:Optional[int]=1,\n",
    "        neg_oversample:Optional[int]=False,\n",
    "        \n",
    "        use_main_distribution:Optional[bool]=False,\n",
    "        return_scores:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return cls(**NMainXCData.from_file(**kwargs), n_lbl_samples=n_lbl_samples, data_info_keys=data_info_keys,\n",
    "                   lbl_info_keys=lbl_info_keys, n_slbl_samples=n_slbl_samples, main_oversample=main_oversample, \n",
    "                   use_main_distribution=use_main_distribution, return_scores=return_scores, n_neg_samples=n_neg_samples,\n",
    "                   n_sneg_samples=n_sneg_samples, neg_oversample=neg_oversample)\n",
    "\n",
    "    def _getitems(cls, idxs:List):\n",
    "        raise NotImplementedError('Function should be implemented in the subclass.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d5d68d-1a31-4689-b4df-f680ea3bd26e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80d687c6-5824-4da6-943e-0cf6ccc0a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_main = NMainXCDataset(**train_data, n_slbl_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4aebef83-e943-469c-8262-ebed46796118",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_idx': tensor([10, 20]),\n",
       " 'data_identifier': ['Austroasiatic_languages', 'Albania'],\n",
       " 'data_input_text': ['Austroasiatic languages', 'Albania'],\n",
       " 'data_input_ids': tensor([[  101, 16951, 15396,  4588,  4155,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 10407,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'data_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'plbl2data_idx': tensor([   109, 195485,    309,    310]),\n",
       " 'plbl2data_data2ptr': tensor([2, 2]),\n",
       " 'lbl2data_idx': tensor([   109, 195485,    309,    310]),\n",
       " 'lbl2data_data2ptr': tensor([2, 2]),\n",
       " 'lbl2data_identifier': ['Austric_languages',\n",
       "  'Austroasiatic_languages',\n",
       "  'Index_of_Albania-related_articles',\n",
       "  'Albania'],\n",
       " 'lbl2data_input_text': ['Austric languages',\n",
       "  'Austroasiatic languages',\n",
       "  'Index of Albania-related articles',\n",
       "  'Albania'],\n",
       " 'lbl2data_input_ids': tensor([[  101, 17151, 12412,  4155,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 16951, 15396,  4588,  4155,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  5950,  1997, 10407,  1011,  3141,  4790,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 10407,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'lbl2data_attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'pneg2data_idx': tensor([   109, 195485,    309,    310]),\n",
       " 'pneg2data_data2ptr': tensor([2, 2]),\n",
       " 'neg2data_idx': tensor([   109, 195485,    310,    309]),\n",
       " 'neg2data_data2ptr': tensor([2, 2]),\n",
       " 'neg2data_identifier': ['Austric_languages',\n",
       "  'Austroasiatic_languages',\n",
       "  'Albania',\n",
       "  'Index_of_Albania-related_articles'],\n",
       " 'neg2data_input_text': ['Austric languages',\n",
       "  'Austroasiatic languages',\n",
       "  'Albania',\n",
       "  'Index of Albania-related articles'],\n",
       " 'neg2data_input_ids': tensor([[  101, 17151, 12412,  4155,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 16951, 15396,  4588,  4155,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 10407,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  5950,  1997, 10407,  1011,  3141,  4790,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'neg2data_attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_main.__getitems__([10, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720bb509-7468-4750-a1aa-0b5fdfbf1ae4",
   "metadata": {},
   "source": [
    "### `NXCDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aff04cf5-090d-44b2-8c97-811e4b26099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NXCDataset(SXCDataset):\n",
    "\n",
    "    def __init__(self, data:NMainXCDataset, **kwargs):\n",
    "        super().__init__(data, **kwargs)\n",
    "        \n",
    "    @classmethod\n",
    "    @delegates(SMainXCDataset.from_file)\n",
    "    def from_file(cls, **kwargs):\n",
    "        data = NMainXCDataset.from_file(**kwargs)\n",
    "        meta_kwargs = {o:kwargs.pop(o) for o in cls.get_meta_args(**kwargs)}\n",
    "        meta = {k:SMetaXCDataset.from_file(**v, **kwargs) for k,v in meta_kwargs.items()}\n",
    "        return cls(data, **meta)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b1215-1386-43ec-bcfc-860e90fba905",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50b95c4a-ee7f-4ba3-b0ed-1a2b7f6721d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = NXCDataset(train_main, hlk_meta=train_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1351a1f2-5c30-4011-bf6f-8ee838e99a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = train_dset.__getitems__([100, 200, 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c66f0ac-0f81-49bc-89e0-277b97d093d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_idx': tensor([100, 200, 500]),\n",
       " 'data_identifier': ['Applet',\n",
       "  'Geography_of_Africa',\n",
       "  'National_League_Championship_Series'],\n",
       " 'data_input_text': ['Applet',\n",
       "  'Geography of Africa',\n",
       "  'National League Championship Series'],\n",
       " 'data_input_ids': tensor([[  101,  6207,  2102,   102,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 10505,  1997,  3088,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  2120,  2223,  2528,  2186,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'data_attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'plbl2data_idx': tensor([  927,   928,   929,   930, 23961,  1470,  1471, 27329,  3411,  3412,\n",
       "          3413,  3414,  3418]),\n",
       " 'plbl2data_data2ptr': tensor([5, 3, 5]),\n",
       " 'lbl2data_idx': tensor([ 929,  927, 1470, 1471, 3411, 3413]),\n",
       " 'lbl2data_data2ptr': tensor([2, 2, 2]),\n",
       " 'lbl2data_identifier': ['Widget_engine',\n",
       "  'Application_posture',\n",
       "  'List_of_national_parks_in_Africa',\n",
       "  'Outline_of_Africa',\n",
       "  'List_of_National_League_pennant_winners',\n",
       "  'National_League_Division_Series'],\n",
       " 'lbl2data_input_text': ['Widget engine',\n",
       "  'Application posture',\n",
       "  'List of national parks in Africa',\n",
       "  'Outline of Africa',\n",
       "  'List of National League pennant winners',\n",
       "  'National League Division Series'],\n",
       " 'lbl2data_input_ids': tensor([[  101, 15536, 24291,  3194,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  4646, 16819,   102,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  2862,  1997,  2120,  6328,  1999,  3088,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 12685,  1997,  3088,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  2862,  1997,  2120,  2223, 22690,  4791,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  2120,  2223,  2407,  2186,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'lbl2data_attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'pneg2data_idx': tensor([  927,   928,   929,   930, 23961,  1470,  1471, 27329,  3411,  3412,\n",
       "          3413,  3414,  3418]),\n",
       " 'pneg2data_data2ptr': tensor([5, 3, 5]),\n",
       " 'neg2data_idx': tensor([23961,   929,  1470,  1471,  3413,  3418]),\n",
       " 'neg2data_data2ptr': tensor([2, 2, 2]),\n",
       " 'neg2data_identifier': ['Applet',\n",
       "  'Widget_engine',\n",
       "  'List_of_national_parks_in_Africa',\n",
       "  'Outline_of_Africa',\n",
       "  'National_League_Division_Series',\n",
       "  'National_League_Championship_Series'],\n",
       " 'neg2data_input_text': ['Applet',\n",
       "  'Widget engine',\n",
       "  'List of national parks in Africa',\n",
       "  'Outline of Africa',\n",
       "  'National League Division Series',\n",
       "  'National League Championship Series'],\n",
       " 'neg2data_input_ids': tensor([[  101,  6207,  2102,   102,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 15536, 24291,  3194,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  2862,  1997,  2120,  6328,  1999,  3088,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 12685,  1997,  3088,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  2120,  2223,  2407,  2186,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  2120,  2223,  2528,  2186,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'neg2data_attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'pcat2data_idx': tensor([  1058, 147261, 149012,  85726,  43699,  67384]),\n",
       " 'pcat2data_data2ptr': tensor([3, 1, 2]),\n",
       " 'cat2data_idx': tensor([147261,  85726,  43699]),\n",
       " 'cat2data_scores': tensor([1., 1., 1.]),\n",
       " 'cat2data_data2ptr': tensor([1, 1, 1]),\n",
       " 'cat2data_identifier': ['Category:Java_(programming_language)_libraries',\n",
       "  'Category:Geography_of_Africa',\n",
       "  'Category:National_League_Championship_Series'],\n",
       " 'cat2data_input_text': ['Java (programming language) libraries',\n",
       "  'Geography of Africa',\n",
       "  'National League Championship Series'],\n",
       " 'cat2data_input_ids': tensor([[  101,  9262,  1006,  4730,  2653,  1007,  8860,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101, 10505,  1997,  3088,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  2120,  2223,  2528,  2186,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'cat2data_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]]),\n",
       " 'pcat2lbl_idx': tensor([ 68318, 119891, 304851, 305876, 497919,  85145, 304851, 562618, 181005,\n",
       "         495100]),\n",
       " 'pcat2lbl_lbl2ptr': tensor([0, 2, 3, 3, 1, 1]),\n",
       " 'cat2lbl_idx': tensor([ 68318, 497919, 304851, 181005, 495100]),\n",
       " 'cat2lbl_scores': tensor([1., 1., 1., 1., 1.]),\n",
       " 'cat2lbl_lbl2ptr': tensor([0, 1, 1, 1, 1, 1]),\n",
       " 'cat2lbl_identifier': ['Category:Computing_terminology',\n",
       "  'Category:Lists_of_tourist_attractions_in_Africa',\n",
       "  'Category:Africa-related_lists',\n",
       "  'Category:Major_League_Baseball_playoffs_and_champions',\n",
       "  'Category:National_League_Division_Series'],\n",
       " 'cat2lbl_input_text': ['Computing terminology',\n",
       "  'Lists of tourist attractions in Africa',\n",
       "  'Africa-related lists',\n",
       "  'Major League Baseball playoffs and champions',\n",
       "  'National League Division Series'],\n",
       " 'cat2lbl_input_ids': tensor([[  101,  9798, 18444,   102,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  7201,  1997,  7538, 13051,  1999,  3088,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  3088,  1011,  3141,  7201,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  2350,  2223,  3598,  7555,  1998,  3966,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  2120,  2223,  2407,  2186,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'cat2lbl_attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]]),\n",
       " 'cat2lbl_data2ptr': tensor([1, 2, 2]),\n",
       " 'pcat2lbl_data2ptr': tensor([2, 6, 2])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1276856-555f-48dc-b33e-f6dc2c8e3078",
   "metadata": {},
   "source": [
    "### `NBaseXCDataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c4fe897-b306-486b-a83f-71532ef20768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NBaseXCDataBlock(SBaseXCDataBlock):\n",
    "\n",
    "    @delegates(DataLoader.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        dset:NXCDataset, \n",
    "        collate_fn:Optional[Callable]=identity_collate_fn,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.dset, self.dl_kwargs, self.collate_fn = dset, self._get_dl_kwargs(**kwargs), collate_fn\n",
    "        self.dl = DataLoader(dset, collate_fn=collate_fn, **self.dl_kwargs) if collate_fn is not None else None\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(NXCDataset.from_file)\n",
    "    def from_file(cls, collate_fn:Callable=identity_collate_fn, **kwargs):\n",
    "        return NBaseXCDataBlock(NXCDataset.from_file(**kwargs), collate_fn, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17116fa3-1a26-455e-9dd4-d24fc8927b65",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc3a7966-e7d0-4ef6-8cd0-aab3f438ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_block = SBaseXCDataBlock(train_dset, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393cb71-6335-49e4-a8ca-2ad49d9ff40b",
   "metadata": {},
   "source": [
    "### `NXCDataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1279c494-5a05-41ad-97db-94e15abb3996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NXCDataBlock(SXCDataBlock):\n",
    "\n",
    "    @classmethod\n",
    "    def from_cfg(\n",
    "        cls, \n",
    "        cfg:Union[str,Dict],\n",
    "        collate_fn:Optional[Callable]=identity_collate_fn,\n",
    "        valid_pct:Optional[float]=0.2,\n",
    "        seed=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if isinstance(cfg, str): cfg = cls.load_cfg(cfg)\n",
    "\n",
    "        blocks = dict()\n",
    "        for o in ['train', 'valid', 'test']:\n",
    "            if o in cfg['path']:\n",
    "                params = cfg['parameters'].copy()\n",
    "                params.update(kwargs)\n",
    "                if o != 'train': \n",
    "                    params['meta_dropout_remove'], params['meta_dropout_replace'] = None, None\n",
    "                blocks[o] = NBaseXCDataBlock.from_file(**cfg['path'][o], **params, collate_fn=collate_fn)\n",
    "                \n",
    "        return cls(**blocks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd70f12d-37d4-418e-8e1e-9be5fa9212d2",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bc02ad1-1327-4d17-8269-fface748df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = SXCDataBlock(train=train_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2ac3d-1998-4007-bbbf-05b80794c80a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
