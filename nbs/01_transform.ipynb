{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa5fb1d-1a6d-4e46-9250-6f8c6d958e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0571d3e-ed11-49da-be66-f9c19862bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a99bc8-8184-4059-b79b-56cd4b9f05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tqdm.auto import tqdm\n",
    "from scipy import sparse\n",
    "import torch, numpy as np\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import *\n",
    "from fastcore.dispatch import *\n",
    "from transformers import AutoTokenizer, BatchEncoding\n",
    "from itertools import chain\n",
    "\n",
    "from xcai.core import *\n",
    "from xcai.generation.trie import *\n",
    "from xcai.data import XCDataBlock, BaseXCDataBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb3972-8916-4275-8ed0-f65433d6e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b387629-65fb-4e67-a85a-bb32f0765905",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c69be4-db73-4980-abe8-0a7fdf39caab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/xclib-0.97-py3.9-linux-x86_64.egg/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n",
      "/scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "from xcai.test_utils import *\n",
    "block = Test.from_cfg('data_meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a596b8f4-483a-4fd9-80c5-2e05d5aa9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM = {\n",
    "    'cols': ['identifier', 'input_text'],\n",
    "    'use_tokz': True,\n",
    "    'tokz': 'bert-base-uncased',\n",
    "    'max_len': 32,\n",
    "    'prefix': 'lbl',\n",
    "    'pad_side': 'right',\n",
    "    'inp': 'data',\n",
    "    'targ': 'lbl2data',\n",
    "    'ptr': 'lbl2data_data2ptr',\n",
    "    'drop': True,\n",
    "    'ret_t': True,\n",
    "    'in_place': True,\n",
    "    'collapse': True,\n",
    "    'device': 'cpu',\n",
    "}\n",
    "tokz = AutoTokenizer.from_pretrained(PARAM['tokz'])\n",
    "PARAM['sep_tok'] = tokz.sep_token_id\n",
    "PARAM['pad_tok'] = tokz.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6390acfa-0c7d-4f6b-9769-612f6502dd7d",
   "metadata": {},
   "source": [
    "## Batch transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e0a9a9-fb0b-400f-9943-39d0a57679f5",
   "metadata": {},
   "source": [
    "### `PadTfm`: PAD FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1eb46d-047f-4948-89d3-0e1de15d8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PadTfm:\n",
    "\n",
    "    def __init__(self, \n",
    "                 pad_tok:Optional[int]=None, \n",
    "                 pad_side:Optional[str]='right', \n",
    "                 ret_t:Optional[bool]=True,\n",
    "                 in_place:Optional[bool]=True,\n",
    "                 **kwargs):\n",
    "        store_attr('pad_tok,pad_side,ret_t,in_place')\n",
    "\n",
    "    def _sz_help(self, x:List, sz:List, lev:int):\n",
    "        if isinstance(x[0], list):\n",
    "            l = max(len(o) for o in x)\n",
    "            if len(sz) > lev: sz[lev] = max(sz[lev], l)\n",
    "            else: sz.append(l)\n",
    "            for o in x: self._sz_help(o, sz, lev+1)\n",
    "\n",
    "    def get_sz(self, x:List):\n",
    "        sz = [len(x)]\n",
    "        self._sz_help(x, sz, len(sz))\n",
    "        return sz\n",
    "\n",
    "    def _pad_help(self, x:List, sz:List, pads:List, lev:int):\n",
    "        if len(x) and isinstance(x[0], list):\n",
    "            for i,o in enumerate(x): x[i] = self._pad_help(o, sz, pads, lev+1)\n",
    "        rem = [pads[lev]]*(sz[lev] - len(x))\n",
    "        return x+rem if self.pad_side == 'right' else rem+x\n",
    "\n",
    "    def __call__(self, \n",
    "                 x:List, \n",
    "                 pad_tok:Optional[int]=None, \n",
    "                 pad_side:Optional[str]=None, \n",
    "                 ret_t:Optional[bool]=None, \n",
    "                 in_place:Optional[bool]=None):\n",
    "        store_attr('pad_tok,pad_side,ret_t,in_place', is_none=False)\n",
    "        if self.pad_tok is None: raise ValueError('`pad_tok` cannot be None.')\n",
    "        \n",
    "        sz = self.get_sz(x)\n",
    "        pads = [self.pad_tok]\n",
    "        for s in sz[:0:-1]: pads.insert(0, [pads[0]]*s)\n",
    "        if not self.in_place: x = x.copy()\n",
    "        x = self._pad_help(x, sz, pads, 0)\n",
    "        try: return torch.tensor(x) if self.ret_t else x\n",
    "        except: return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b25ff2f-44e1-43e8-b973-4c174f61595f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  1,   2,   3],\n",
      "         [  1,   2, 100]],\n",
      "\n",
      "        [[  1, 100, 100],\n",
      "         [100, 100, 100]]])\n"
     ]
    }
   ],
   "source": [
    "tfm = PadTfm(0, 'right')\n",
    "\n",
    "arr = [[[1, 2, 3], [1, 2]], [[1]]]\n",
    "o = tfm(arr, 100)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1994ff-84e1-45ee-a37c-16ee99649a13",
   "metadata": {},
   "source": [
    "### `CollapseTfm`: COLLAPSE FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6781295a-f4ab-4c60-a6dd-f475beeb65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CollapseTfm:\n",
    "\n",
    "    def __init__(self, lev:int=0, use_ptr:int=True):\n",
    "        store_attr('lev,use_ptr')\n",
    "\n",
    "    def collapse(self, x:List, ptr:Dict, lev:int):\n",
    "        if not isinstance(x, list): raise ValueError(f'`x` should be a list, check the `lev`({self.lev}).')\n",
    "        if self.lev == lev:\n",
    "            if lev in ptr: ptr[lev].append(len(x))\n",
    "            else: ptr[lev] = [len(x)]\n",
    "            return x\n",
    "        x = list(chain(*[self.collapse(o, ptr, lev+1) for o in x]))\n",
    "        if lev in ptr: ptr[lev].append(len(x))\n",
    "        else: ptr[lev] = [len(x)]\n",
    "        return x\n",
    "\n",
    "    def _get_ptr(self, ptr):\n",
    "        for v in ptr.values():\n",
    "            for p,q in enumerate(v[1:]): v[p+1] = v[p] + q\n",
    "        \n",
    "    def __call__(self, x:List, lev:int=None, use_ptr:Optional[int]=None):\n",
    "        store_attr('lev,use_ptr', is_none=False)\n",
    "        \n",
    "        ptr = dict()\n",
    "        x = self.collapse(x, ptr, 0)\n",
    "        if self.use_ptr: self._get_ptr(ptr)\n",
    "        return x, ptr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12511429-742f-48b2-b247-4957f305de96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 2, 3],\n",
       "  [4, 5, 6],\n",
       "  [7, 8, 9],\n",
       "  [1, 2, 3],\n",
       "  [4, 5, 6],\n",
       "  [7, 8, 9],\n",
       "  [1, 2, 3],\n",
       "  [4, 5, 6],\n",
       "  [7, 8, 9],\n",
       "  [1, 2, 3],\n",
       "  [4, 5, 6],\n",
       "  [7, 8, 9]],\n",
       " {2: [3, 6, 9, 12], 1: [6, 12], 0: [12]})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm = CollapseTfm()\n",
    "x = [[[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]],\n",
    "     [[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]]]\n",
    "tfm(x, lev=2, use_ptr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3c9f7-7604-44bf-b587-641485a9ae8d",
   "metadata": {},
   "source": [
    "### `PadFeatTfm`: PAD BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b719c-2c48-4209-933d-37dffab9afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PadFeatTfm:\n",
    "\n",
    "    def __init__(self,\n",
    "                 prefix:Optional[str]=None, \n",
    "                 drop:Optional[bool]=True, \n",
    "                 pad_tok:Optional[int]=0, \n",
    "                 pad_side:Optional[str]='right', \n",
    "                 ret_t:Optional[bool]=True,\n",
    "                 in_place:Optional[bool]=True,\n",
    "                 lev:Optional[int]=0,\n",
    "                 **kwargs):\n",
    "        store_attr('prefix,drop,pad_tok,pad_side,ret_t,in_place,lev')\n",
    "        self.pad_proc, self.colps_proc = PadTfm(), CollapseTfm(lev, use_ptr=False)\n",
    "\n",
    "    def get_feat(self, \n",
    "                 x:Union[Dict, List], \n",
    "                 prefix:Optional[str]=None, \n",
    "                 drop:Optional[bool]=True, \n",
    "                 lev:Optional[int]=0):\n",
    "        if isinstance(x, list):\n",
    "            name = [k for k in x[0] if prefix is None or re.match(f'^{prefix}',k)]\n",
    "            feat = {k: [o.pop(k) if drop else o[k] for o in x] for k in name}\n",
    "            if lev > 0:\n",
    "                for k in name: \n",
    "                    feat[k], ptr = self.colps_proc(feat[k], lev)\n",
    "                    for p,q in ptr.items(): \n",
    "                        if p != 0: feat[f'{k}_ptr-{p}'] = q\n",
    "        elif isinstance(x, dict):\n",
    "            name = [k for k in x if prefix is None or re.match(f'^{prefix}',k)]\n",
    "            feat = {k: x.pop(k) if drop else x[k] for k in name}\n",
    "        return feat\n",
    "        \n",
    "    def __call__(self, x:Union[Dict, List], \n",
    "                 prefix:Optional[str]=None, \n",
    "                 drop:Optional[bool]=None, \n",
    "                 pad_tok:Optional[int]=None, \n",
    "                 pad_side:Optional[str]=None, \n",
    "                 ret_t:Optional[bool]=None, \n",
    "                 in_place:Optional[bool]=None,\n",
    "                 lev:Optional[int]=0):\n",
    "        store_attr('prefix,drop,pad_tok,pad_side,ret_t,in_place,lev', is_none=False)\n",
    "        \n",
    "        feat = self.get_feat(x, self.prefix, self.drop, self.lev)\n",
    "        return BatchEncoding({k:self.pad_proc(v, self.pad_tok, self.pad_side, self.ret_t, self.in_place) for k,v in feat.items()})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac165a05-06a1-460d-87f5-45889ed1fdca",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e6c48-ef51-4e43-b557-6fa6224eb185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a :\n",
      "tensor([[[1, 2, 3, 0, 0],\n",
      "         [1, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 2, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0, 0],\n",
      "         [1, 2, 3, 4, 5]]])\n",
      "b :\n",
      "tensor([[1, 2, 3, 0],\n",
      "        [1, 0, 0, 0],\n",
      "        [1, 2, 0, 0],\n",
      "        [1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "tfm = PadFeatTfm(pad_tok=0)\n",
    "\n",
    "obj = [{'a':[[1, 2, 3], [1]], 'b':[1, 2, 3]}, \n",
    "       {'a':[[1, 2]], 'b':[1]},\n",
    "       {'a':[[1]], 'b':[1, 2]},\n",
    "       {'a':[[1], [1, 2, 3, 4, 5]], 'b':[1, 2, 3, 4]}]\n",
    "\n",
    "o = tfm(obj)\n",
    "for k,v in o.items(): print(k, ':'); print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ceecd5-e069-4b31-af42-61df0388954b",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5322b8ad-2d14-4811-8ee0-9d58ab030b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_identifier', 'data_input_text', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = block.train.dset.one_batch()\n",
    "batch[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371cfe89-dd6c-43c1-be35-ea7b425b9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = (PadFeatTfm(**PARAM))(batch, prefix='lbl2data', lev=1, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6eb574-35dc-4377-b11d-8cabfe3d38b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbl2data_idx :  torch.Size([33])\n",
      "lbl2data_identifier :  33\n",
      "lbl2data_input_text :  33\n",
      "lbl2data_input_ids :  torch.Size([33, 12])\n",
      "lbl2data_token_type_ids :  torch.Size([33, 12])\n",
      "lbl2data_attention_mask :  torch.Size([33, 12])\n",
      "lbl2data_idx_ptr-1 :  torch.Size([10])\n",
      "lbl2data_identifier_ptr-1 :  torch.Size([10])\n",
      "lbl2data_input_text_ptr-1 :  torch.Size([10])\n",
      "lbl2data_input_ids_ptr-1 :  torch.Size([10])\n",
      "lbl2data_token_type_ids_ptr-1 :  torch.Size([10])\n",
      "lbl2data_attention_mask_ptr-1 :  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for k,v in o.items(): \n",
    "    if hasattr(v, 'shape'): print(k, ': ', v.shape)\n",
    "    else: print(k, ': ', len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58613f09-01d4-4f7d-8514-31131cf324dd",
   "metadata": {},
   "source": [
    "### `AlignInputIdsTfm`: ALIGN TOKEN SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d34d5-8558-44c6-809e-874c0932e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AlignInputIdsTfm:\n",
    "\n",
    "    def __init__(self,\n",
    "                 inp:Optional[str]='data',\n",
    "                 targ:Optional[str]='lbl2data',\n",
    "                 ptr:Optional[str]='lbl2data_data2ptr',\n",
    "                 sep_tok:Optional[int]=0, \n",
    "                 pad_tok:Optional[int]=0,\n",
    "                 device:Union[str,torch.device]='cpu', \n",
    "                 **kwargs):\n",
    "        store_attr('inp,targ,ptr,sep_tok,pad_tok,device')\n",
    "\n",
    "    @typedispatch\n",
    "    def encode(self, inp_ids:List, targ_ids:List, sep_tok:int, targ_mask:Optional[List]=None, targ_tok:Optional[List]=None, **kwargs):\n",
    "        for i,ids in enumerate(inp_ids):\n",
    "            inp_len = len(ids)\n",
    "            for j,t in enumerate(targ_ids[i]):\n",
    "                if len(t) > inp_len: \n",
    "                    targ_ids[i][j] = t[:inp_len-1]+[self.sep_tok]\n",
    "                    if targ_mask is not None: targ_mask[i][j] = targ_mask[i][j][:inp_len]\n",
    "                    if targ_tok is not None: targ_tok[i][j] = targ_tok[i][j][:inp_len] \n",
    "        return targ_ids, targ_mask, targ_tok\n",
    "\n",
    "    @typedispatch\n",
    "    def encode(self, inp_ids:torch.Tensor, targ_ids:torch.Tensor, ptr:torch.Tensor, sep_tok:int, pad_tok:int,\n",
    "               targ_mask:Optional[torch.Tensor]=None, targ_tok:Optional[torch.Tensor]=None):\n",
    "        inp_len = torch.where(inp_ids == sep_tok)[1] + 1\n",
    "        inp_len = torch.repeat_interleave(inp_len, ptr)\n",
    "        targ_len = torch.where(targ_ids == sep_tok)[1] + 1\n",
    "        seq_len = torch.where(inp_len < targ_len, inp_len, targ_len)\n",
    "        \n",
    "        for i,(p,q) in enumerate(zip(seq_len, targ_len)):\n",
    "            targ_ids[i,p-1] = sep_tok\n",
    "            targ_ids[i,p:q] = pad_tok \n",
    "            if targ_mask is not None: targ_mask[i,p:q] = 0\n",
    "            if targ_tok is not None: targ_tok[i,p:q] = 0\n",
    "        return targ_ids, targ_mask, targ_tok\n",
    "        \n",
    "    def __call__(self, x:Dict, \n",
    "                 inp:Optional[str]=None, \n",
    "                 targ:Optional[str]=None,\n",
    "                 ptr:Optional[str]=None, \n",
    "                 sep_tok:Optional[int]=None, \n",
    "                 pad_tok:Optional[int]=None):\n",
    "        store_attr('inp,targ,ptr,sep_tok,pad_tok', is_none=False)\n",
    "\n",
    "        def get_attr(x, keys, required=False):\n",
    "            attr = []\n",
    "            for k in keys.split(','):\n",
    "                if k not in x: \n",
    "                    if required: raise ValueError(f'\"{k}\" not in `x`')\n",
    "                    else: attr.append(None)\n",
    "                else: attr.append(x[k])\n",
    "            return attr\n",
    "            \n",
    "        inp_ids, targ_ids = get_attr(x, f'{self.inp}_input_ids,{self.targ}_input_ids', required=True) \n",
    "        targ_mask, targ_tok = get_attr(x, f'{self.targ}_attention_mask,{self.targ}_token_type_ids') \n",
    "        ptr = None if self.ptr is None else x[self.ptr]\n",
    "        \n",
    "        targ_ids, targ_mask, targ_tok = self.encode(inp_ids, targ_ids, ptr=ptr, targ_mask=targ_mask, targ_tok=targ_tok, \n",
    "                                                    sep_tok=self.sep_tok, pad_tok=self.pad_tok)\n",
    "        def set_attr(x, keys, vals):\n",
    "            for i,(k,v) in enumerate(zip(keys.split(','),vals)):\n",
    "                if v is not None: x[k] = v\n",
    "                    \n",
    "        set_attr(x, f'{self.targ}_input_ids,{self.targ}_attention_mask,{self.targ}_token_type_ids', [targ_ids,targ_mask,targ_tok])\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf066915-66bf-44b2-887a-c8cdcf999fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typedispatch\n",
    "def verify_align(p:torch.Tensor, q:torch.Tensor, r:torch.Tensor, tok:int):\n",
    "    p_len = torch.where(p == tok)[1]+1\n",
    "    p_len = p_len.repeat_interleave(r)\n",
    "    q_len = torch.where(q == tok)[1]+1\n",
    "    for p,q in zip(p_len, q_len):\n",
    "        p,q = p.item(),q.item()\n",
    "        if p < q: print(p,' < ',q)\n",
    "        else: print(p,' > ',q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c0f1d-c594-4f41-84d2-f0b2dc739d76",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5bc351-4b0d-404f-92a3-981131dc4cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_input_ids :\n",
      "tensor([[ 1,  2, 11,  0,  0,  0],\n",
      "        [11,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5, 11]])\n",
      "lbl2data_input_ids :\n",
      "tensor([[ 1,  2, 11],\n",
      "        [ 5, 11,  0],\n",
      "        [ 5, 11,  0],\n",
      "        [ 5, 11,  0],\n",
      "        [ 5,  6, 11],\n",
      "        [13,  4, 11]])\n",
      "lbl2data_data2ptr :\n",
      "tensor([1, 2, 3])\n",
      "lbl2data_attention_mask :\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "lbl2data_token_type_ids :\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "pad_tfm = PadFeatTfm(pad_tok=0)\n",
    "obj = {\n",
    "    'data_input_ids':[[1, 2, 11], [11], [1, 2, 3, 4, 5, 11]], \n",
    "    'lbl2data_input_ids':[[1, 2, 11], [5, 11], [5, 11], [5, 11], [5, 6, 11], [13, 4, 11]],\n",
    "    'lbl2data_data2ptr':[1, 2, 3],\n",
    "    'lbl2data_attention_mask':[[1, 1, 1], [1, 1], [1, 1], [1, 1], [1, 1, 1], [1, 1, 1]],\n",
    "    'lbl2data_token_type_ids':[[0, 0, 0], [0, 0], [0, 0], [0, 0], [0, 0, 0], [0, 0, 0]],\n",
    "}\n",
    "\n",
    "o = pad_tfm(obj)\n",
    "for k,v in o.items(): print(k,':'); print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af2ce9-459b-4e0c-a7d8-7617788fd5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_input_ids :\n",
      "tensor([[ 1,  2, 11,  0,  0,  0],\n",
      "        [11,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5, 11]])\n",
      "lbl2data_input_ids :\n",
      "tensor([[ 1,  2, 11],\n",
      "        [11,  0,  0],\n",
      "        [11,  0,  0],\n",
      "        [ 5, 11,  0],\n",
      "        [ 5,  6, 11],\n",
      "        [13,  4, 11]])\n",
      "lbl2data_data2ptr :\n",
      "tensor([1, 2, 3])\n",
      "lbl2data_attention_mask :\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "lbl2data_token_type_ids :\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "align_tfm = AlignInputIdsTfm(bsz=4, pad_tok=0, sep_tok=11, inp='data', \n",
    "                             targ='lbl2data', ptr='lbl2data_data2ptr')\n",
    "o = align_tfm(o)\n",
    "for k,v in o.items(): print(k,':'); print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2cb375-3c38-4acd-931c-19f56c6f3186",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f89b4-2428-44b5-9101-f4adb9ea66f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch()\n",
    "pad_tfm, alg_tfm = PadFeatTfm(**PARAM), AlignInputIdsTfm(**PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea98af-1685-4605-a393-f8d98be2a38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_identifier', 'data_input_text', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4b95a-a820-4e74-98ce-e652283a034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = pad_tfm(batch, prefix='data', lev=0, in_place=True, drop=True)\n",
    "o.update(pad_tfm(batch, prefix='lbl2data', lev=1, in_place=True, drop=True))\n",
    "o['lbl2data_data2ptr'] = o['lbl2data_idx_ptr-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e182b95-12fc-4352-bcd3-9c3db72535da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  >  5\n",
      "7  >  7\n",
      "7  <  9\n",
      "7  >  4\n",
      "7  <  8\n",
      "10  >  3\n",
      "10  >  3\n",
      "10  >  4\n",
      "10  >  6\n",
      "4  <  5\n",
      "4  >  4\n",
      "4  <  5\n",
      "7  >  7\n",
      "6  >  4\n",
      "6  >  4\n",
      "6  >  4\n",
      "13  >  8\n",
      "13  <  14\n",
      "13  >  8\n",
      "5  <  9\n",
      "5  <  14\n",
      "5  >  5\n",
      "5  <  11\n",
      "5  <  6\n"
     ]
    }
   ],
   "source": [
    "verify_align(o['data_input_ids'], o['lbl2data_input_ids'], o['lbl2data_data2ptr'], PARAM['sep_tok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6b557-7e31-412c-a8dc-e63915bb58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = alg_tfm(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502ba49-4563-4b9b-972e-030c5e135197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  >  5\n",
      "7  >  7\n",
      "7  >  7\n",
      "7  >  4\n",
      "7  >  7\n",
      "10  >  3\n",
      "10  >  3\n",
      "10  >  4\n",
      "10  >  6\n",
      "4  >  4\n",
      "4  >  4\n",
      "4  >  4\n",
      "7  >  7\n",
      "6  >  4\n",
      "6  >  4\n",
      "6  >  4\n",
      "13  >  8\n",
      "13  >  13\n",
      "13  >  8\n",
      "5  >  5\n",
      "5  >  5\n",
      "5  >  5\n",
      "5  >  5\n",
      "5  >  5\n"
     ]
    }
   ],
   "source": [
    "verify_align(o['data_input_ids'], o['lbl2data_input_ids'], o['lbl2data_data2ptr'], PARAM['sep_tok'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aec367-cbb3-4977-9618-300fe396b030",
   "metadata": {},
   "source": [
    "### `XCPadFeatTfm`: PAD XC BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e99119-8dfe-4936-95d3-bd45cbfee30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCPadFeatTfm:\n",
    "\n",
    "    @delegates(PadFeatTfm.__init__)\n",
    "    def __init__(self, **kwargs):\n",
    "        self.tfm = PadFeatTfm(**kwargs)\n",
    "\n",
    "    def extract_ptr(self, x:Dict, suffix:str):\n",
    "        ptr_name = [k for k in x if re.match(f'.*{suffix}$',k)]\n",
    "        return [x.pop(k) for k in ptr_name][0]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        meta_name = set([k.split('_',maxsplit=1)[0].split('2')[0] for k in x[0]]).difference(['lbl', 'data'])\n",
    "        out = self.tfm(x, prefix='lbl2data', lev=1, in_place=True, drop=True)\n",
    "        out['lbl2data_data2ptr'] = self.extract_ptr(out, 'ptr-1')\n",
    "        out.update(self.tfm(x, prefix='data', lev=0, in_place=True, drop=True))\n",
    "        for k in meta_name:\n",
    "            o = self.tfm(x, prefix=f'{k}2lbl2data', lev=2, in_place=True, drop=True)\n",
    "            o[f'{k}2lbl2data_data2ptr'] = self.extract_ptr(o, 'ptr-1')\n",
    "            o[f'{k}2lbl2data_lbl2ptr'] = self.extract_ptr(o, 'ptr-2')\n",
    "            out.update(o)\n",
    "            o = self.tfm(x, prefix=f'{k}2data', lev=1, in_place=True, drop=True)\n",
    "            o[f'{k}2data_data2ptr'] = self.extract_ptr(o, 'ptr-1')\n",
    "            out.update(o)\n",
    "            \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdde4ef-c383-47e3-8dc3-0b498109c195",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c19f62-537f-4e91-b5d3-4118051a3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch()\n",
    "pad_tfm, align_tfm = XCPadFeatTfm(**PARAM), AlignInputIdsTfm(**PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334d1d4f-ef85-435a-8fd2-b204085eb57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = pad_tfm(batch)\n",
    "o = align_tfm(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27353d37-2323-472c-8b97-40f499273979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  >  4\n",
      "16  >  14\n",
      "8  >  5\n",
      "8  >  3\n",
      "8  >  8\n",
      "8  >  8\n",
      "8  >  8\n",
      "8  >  8\n",
      "5  >  5\n",
      "10  >  10\n",
      "10  >  9\n",
      "10  >  10\n",
      "11  >  10\n",
      "7  >  7\n",
      "7  >  7\n",
      "7  >  7\n",
      "7  >  7\n",
      "6  >  6\n",
      "6  >  6\n",
      "4  >  4\n",
      "4  >  4\n",
      "4  >  4\n",
      "4  >  4\n"
     ]
    }
   ],
   "source": [
    "verify_align(o['data_input_ids'], o['lbl2data_input_ids'], o['lbl2data_data2ptr'], PARAM['sep_tok'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7ca80-47a9-47bb-bb63-d7149b306cd9",
   "metadata": {},
   "source": [
    "### `XCPadOutputTfm`: PAD XC OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59fa453-7c26-4851-a3dd-3eb4762f29d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCPadOutputTfm:\n",
    "\n",
    "    @delegates(PadFeatTfm.__init__)\n",
    "    def __init__(self, **kwargs):\n",
    "        self.tfm = PadFeatTfm(**kwargs)\n",
    "\n",
    "    def extract_ptr(self, x:Dict, suffix:str):\n",
    "        ptr_name = [k for k in x if re.match(f'.*{suffix}$',k)]\n",
    "        return [x.pop(k) for k in ptr_name][0]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = self.tfm(x, prefix='info2seq', lev=0, in_place=True, drop=True)\n",
    "        out.update(self.tfm(x, prefix='seq', lev=0, in_place=True, drop=True))\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376362e-496c-4d56-98fa-ac1991c07327",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3706562d-9dc2-40d8-9f24-78041c029208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info2seq_idx :\n",
      "tensor([ 1,  2, 11,  5, 11, 13])\n",
      "info2seq_seq2ptr :\n",
      "tensor([1, 2, 3])\n",
      "seq_output_ids :\n",
      "tensor([[ 1,  2, 11,  0,  0,  0],\n",
      "        [11,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5, 11]])\n",
      "seq_score :\n",
      "tensor([1.2000, 3.3000, 4.5000])\n"
     ]
    }
   ],
   "source": [
    "pad_tfm = XCPadOutputTfm(pad_tok=0)\n",
    "obj = {\n",
    "    'seq_output_ids':[[1, 2, 11], [11], [1, 2, 3, 4, 5, 11]],\n",
    "    'seq_score':[1.2, 3.3, 4.5],\n",
    "    'info2seq_idx':[1, 2, 11, 5, 11, 13],\n",
    "    'info2seq_seq2ptr':[1, 2, 3],\n",
    "}\n",
    "\n",
    "o = pad_tfm(obj)\n",
    "for k,v in o.items(): print(k,':'); print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0c4ea5-3b45-4102-88b8-ffaa496124f1",
   "metadata": {},
   "source": [
    "### `TfmPipeline`: APPLY TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0055cc-d49b-4097-a16d-6120ccf0d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TfmPipeline:\n",
    "\n",
    "    def __init__(self, tfms:List):\n",
    "        self.tfms = tfms\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for tfm in self.tfms: x = tfm(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a6a7c4-5326-4021-9dff-2567010919ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [XCPadFeatTfm(**PARAM), AlignInputIdsTfm(**PARAM)]\n",
    "\n",
    "tfm = TfmPipeline(tfms)\n",
    "batch = block.train.dset.one_batch()\n",
    "\n",
    "o = tfm(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb70a2f-4bec-40f4-9ba5-63a71cc90465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f75de4-963f-4a13-85c3-a73ca65fcc1b",
   "metadata": {},
   "source": [
    "## Item transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae2cd94-b6f9-4885-8545-8d017ee95ee4",
   "metadata": {},
   "source": [
    "### `AlignInputIdsTfm`: ALIGN TOKEN SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402929de-496b-45f9-a72e-5e85f249246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typedispatch\n",
    "def verify_align(src_ids:List, targ_ids:List):\n",
    "    for p,qs in zip(src_ids, targ_ids):\n",
    "        for q in qs: \n",
    "            if len(p)<len(q): print(len(p),' < ', len(q))\n",
    "            else: print(len(p),' > ', len(q))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563fe3c-fe62-4c5f-aed6-825a0dad248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch()\n",
    "batch = {k:[o[k] for o in batch] for k,v in batch[0].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc04a66-ffd9-45d0-aee0-485aacc87eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_identifier', 'data_input_text', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925109c9-57ec-43f4-80cc-fe09ee564fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM['ptr'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567b25a-a7e8-4a94-9c48-c18e038568ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = AlignInputIdsTfm(**PARAM)\n",
    "o = tfm(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5d370-848c-431d-aad4-b2dca02b3b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  >  5\n",
      "5  >  4\n",
      "11  >  7\n",
      "11  >  5\n",
      "11  >  5\n",
      "11  >  6\n",
      "11  >  5\n",
      "6  >  6\n",
      "7  >  7\n",
      "16  >  9\n",
      "4  >  4\n",
      "6  >  6\n",
      "7  >  7\n",
      "4  >  4\n"
     ]
    }
   ],
   "source": [
    "verify_align(o['data_input_ids'], o['lbl2data_input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88344ad-ea20-4c83-8b25-55fbe5162345",
   "metadata": {},
   "source": [
    "### `TriePruneInputIdsTfm`: PRUNE TOKEN SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e1437-32fe-41d2-9d97-a67c0e859897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TriePruneInputIdsTfm:\n",
    "\n",
    "    def __init__(self, prefix:str='lbl2data'):\n",
    "        self.prefix = prefix\n",
    "\n",
    "    @staticmethod\n",
    "    def _flatten(x:List, o:List):\n",
    "        if not isinstance(x[0], list): o.append(x)\n",
    "        else: \n",
    "            for i in x: TriePruneInputIdsTfm._flatten(i, o)\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten(x:List):\n",
    "        flat_x = []\n",
    "        TriePruneInputIdsTfm._flatten(x, flat_x)\n",
    "        return flat_x\n",
    "        \n",
    "    @staticmethod\n",
    "    def _prune_feature(x:List, trie:Trie):\n",
    "        if not isinstance(x[0], list): return trie.prefix(x)\n",
    "        return [TriePruneInputIdsTfm._prune_feature(o, trie) for o in x]\n",
    "\n",
    "    def prune_feature(self, x:Dict, fld:str):\n",
    "        if fld not in x: raise ValueError(f'`{fld}` not in `x`')\n",
    "        v = self.flatten(x[fld])\n",
    "        trie = Trie.from_list(v)\n",
    "        trie.prune()\n",
    "        x[fld] = self._prune_feature(x[fld], trie)\n",
    "\n",
    "    @staticmethod\n",
    "    def _align_feature(inp:List, targ:List):\n",
    "        if not isinstance(inp[0], list): return targ[:len(inp)]\n",
    "        for i,(p,q) in enumerate(zip(inp, targ)): targ[i] = TriePruneInputIdsTfm._align_feature(p,q)\n",
    "        return targ\n",
    "\n",
    "    def align_feature(self, x:Dict, inp:str, targ:str):\n",
    "        if targ not in x: return\n",
    "        self._align_feature(x[inp], x[targ])\n",
    "        \n",
    "    def __call__(self, x:Dict, \n",
    "                 prefix:Optional[str]=None):\n",
    "        self.prefix = self.prefix if prefix is None else prefix\n",
    "        \n",
    "        self.prune_feature(x, f'{self.prefix}_input_ids')\n",
    "        self.align_feature(x, f'{self.prefix}_input_ids', f'{self.prefix}_attention_mask')\n",
    "        self.align_feature(x, f'{self.prefix}_input_ids', f'{self.prefix}_token_type_ids')\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdcb183-721e-42ad-a7b8-da0c560347df",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538407e0-a254-4a6b-9b3c-b0ee074de323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbl2data_input_ids :\n",
      "[[[101, 100, 200, 300, 102], [101, 200, 100, 100, 109, 102]], [[101, 200, 100, 100, 301, 102], [101, 300, 301, 200, 400, 500, 102], [101, 300, 301, 102]], [[101, 200, 100, 222, 301, 401, 501, 444, 102]]]\n",
      "lbl2data_attention_mask :\n",
      "[[[1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]], [[1, 1, 1, 1, 1, 1, 1, 1, 1]]]\n"
     ]
    }
   ],
   "source": [
    "lbl = [[[101, 100, 200, 300, 102],\n",
    "        [101, 200, 100, 100, 109, 102]],\n",
    "       [[101, 200, 100, 100, 301, 102],\n",
    "        [101, 300, 301, 200, 400, 500, 102],\n",
    "        [101, 300, 301, 102]],\n",
    "       [[101, 200, 100, 222, 301, 401, 501, 444, 102]]]\n",
    "\n",
    "mask = [[[1, 1, 1, 1, 1],\n",
    "         [1, 1, 1, 1, 1, 1]],\n",
    "        [[1, 1, 1, 1, 1, 1],\n",
    "         [1, 1, 1, 1],\n",
    "         [1, 1, 1, 1]],\n",
    "        [[1, 1, 1, 1, 1, 1, 1, 1, 1]]]\n",
    "\n",
    "x = {'lbl2data_input_ids': lbl, 'lbl2data_attention_mask': mask}\n",
    "for k,v in x.items(): print(k, ':'); print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48adbaa3-9bf8-44d0-8b47-a767a0f9caa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ff3d138b064d92a62930bfd53ae2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbl2data_input_ids :\n",
      "[[[101, 100, 102], [101, 200, 100, 100, 109, 102]], [[101, 200, 100, 100, 301, 102], [101, 300, 301, 200, 102], [101, 300, 301, 102]], [[101, 200, 100, 222, 102]]]\n",
      "lbl2data_attention_mask :\n",
      "[[[1, 1, 1], [1, 1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]], [[1, 1, 1, 1, 1]]]\n"
     ]
    }
   ],
   "source": [
    "tfm = TriePruneInputIdsTfm(prefix='lbl2data')\n",
    "o = tfm(x)\n",
    "for k,v in o.items(): \n",
    "    print(k, ':'); print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83eb190-3b5d-4432-aba5-9efc7ef332b0",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3bfca5-7527-46b7-86a6-4e3c85380d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch()\n",
    "batch = {k:[o[k] for o in batch] for k,v in batch[0].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a6e07-182c-4f18-abf2-31f3b1c7ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl2data_input_ids = batch['lbl2data_input_ids'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25659e1-c2d4-4fbb-b30c-c852cd369d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_identifier', 'data_input_text', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cba03c-3568-4c46-bdeb-a5d7c09ae992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404e621ab8ec41f9ae128ffb93763769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfm = TriePruneInputIdsTfm(prefix='lbl2data')\n",
    "o = tfm(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca365a0f-7bac-4f7c-af3b-add83f80efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_prune(x:List, y:List):\n",
    "    x = TriePruneInputIdsTfm.flatten(x)\n",
    "    y = TriePruneInputIdsTfm.flatten(y)\n",
    "    for p,q in zip(x,y):\n",
    "        if len(p) < len(q): print(len(p),' < ',len(q))\n",
    "        else: print(len(p),' > ',len(q))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da26cd-d134-45f9-9758-1403efe6dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_alignment(x:List, y:List):\n",
    "    x = TriePruneInputIdsTfm.flatten(x)\n",
    "    y = TriePruneInputIdsTfm.flatten(y)\n",
    "    return np.all([len(p)==len(q) for p,q in zip(x,y)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d906db5-73e3-4238-ad5a-f5ff4a2cdb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_alignment(batch['lbl2data_input_ids'], batch['lbl2data_attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b62ebc0-d90a-40a5-9cdf-3a4d110d084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  >  3\n",
      "10  >  5\n",
      "13  >  5\n",
      "8  >  3\n",
      "8  >  3\n",
      "4  >  3\n",
      "7  >  3\n",
      "6  >  3\n",
      "3  >  3\n",
      "11  >  5\n",
      "7  >  5\n",
      "5  >  3\n",
      "7  >  7\n",
      "7  >  7\n"
     ]
    }
   ],
   "source": [
    "verify_prune(lbl2data_input_ids, batch['lbl2data_input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c9c47-8494-4159-9050-e9d0ff1511cd",
   "metadata": {},
   "source": [
    "### `AugmentMetaInputIdsTfm`: AUGMENT INPUT TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe7c4a-fd0e-4291-b5fa-65b70ab0a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AugmentMetaInputIdsTfm:\n",
    "\n",
    "    def __init__(self, meta:str, max_len:Optional[int]=None):\n",
    "        self.meta, self.max_len = meta, max_len\n",
    "    \n",
    "    def proc(self, data_ids:List, data_meta:sparse.csr_matrix, meta_ids:List):\n",
    "        meta2data_ids = []\n",
    "        for d_ids, d_meta in tqdm(zip(data_ids, data_meta), total=len(data_ids)):\n",
    "            m2d_ids = d_ids.copy()\n",
    "            for o in d_meta.indices:\n",
    "                m2d_ids.extend(meta_ids[o][1:])\n",
    "                if len(m2d_ids)>self.max_len and self.max_len is not None: m2d_ids = m2d_ids[:self.max_len-1] + m2d_ids[-1:]; break\n",
    "            meta2data_ids.append(m2d_ids)\n",
    "        return meta2data_ids\n",
    "\n",
    "    def feature(self, block:BaseXCDataBlock, fld:str):\n",
    "        if fld in block.dset.data.data_info:\n",
    "            data_ids = block.dset.data.data_info[fld]\n",
    "            meta_ids = block.dset.meta[self.meta].meta_info[fld]\n",
    "            data_meta = block.dset.meta[self.meta].data_meta\n",
    "            block.dset.data.data_info[fld] = self.proc(data_ids, data_meta, meta_ids)\n",
    "\n",
    "    def split(self, block:XCDataBlock, split:str):\n",
    "        split = getattr(block, split)\n",
    "        if split is None: return\n",
    "        if self.meta is None or self.meta not in split.dset.meta: raise ValueError(f'`{self.meta}` not in `block`')\n",
    "        for fld in ['input_ids', 'attention_mask', 'token_type_ids']: self.feature(split, fld)\n",
    "\n",
    "    @classmethod\n",
    "    def apply(cls, block:XCDataBlock, meta:str, max_len:Optional[int]=None):\n",
    "        self = cls(f'{meta}_meta', max_len)\n",
    "        for split in ['train', 'valid', 'test']: self.split(block, split)\n",
    "        return block\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37c9ca-ad0d-48dd-99b9-53c1725e4c05",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e885bdb-ba5b-4aec-be28-aab2bbcfad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "aug_block = copy.deepcopy(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f394b-9273-495d-8a79-86c9534e9067",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4de5b-f56d-4751-ab00-0a7af288cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids = aug_block.train.dset.data.data_info['input_ids']\n",
    "meta_ids = aug_block.train.dset.meta['hlk_meta'].meta_info['input_ids']\n",
    "data_meta = aug_block.train.dset.meta['hlk_meta'].data_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031bcda6-86d8-42c5-b63a-13ee7bd93a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = AugmentMetaInputIdsTfm('hlk', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7da9c7-8256-47bd-8b35-387bb4181d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c178d80a7874bf9bb700a52791b029f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/554466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta2data_ids = tfm.proc(data_ids, data_meta, meta_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510ff43-00c5-4f69-a315-e21543b2eedf",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f20a7b-dd35-4b63-9597-420b17883606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc895d6a09d54c1d8ad66ee12f66c448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/554466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfd0bef6a56492380328bfb0363662b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/554466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f68717291a494388cb54f779a6c270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/554466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd380af8b6234f8a9e541f641056df1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137554 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616fdb45e67d4372baeae7169faec8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137554 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9396a1c31a7d4632803dfdc64d24a7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137554 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3012b2f608d149c99c42033f60fba9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40550917a40f4d5f909bc275aeba2514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f533c160d2e46f0bc0872b0c8530a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "o = AugmentMetaInputIdsTfm.apply(aug_block, 'hlk', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292e4af-2ab0-4ec2-a8b1-2cd2762da607",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = block.train.dset.data.data_info['token_type_ids']\n",
    "q = aug_block.train.dset.data.data_info['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71567f-722b-4815-9d12-8a2fcff85d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 15\n",
      "4 15\n",
      "7 15\n",
      "6 15\n",
      "8 15\n",
      "8 15\n",
      "4 4\n",
      "9 15\n",
      "5 15\n",
      "6 15\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.permutation(len(p))[:10]: print(len(p[i]), len(q[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35289ce3-b8dd-4387-89b6-45a2c131d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = aug_block.train.dset.data.data_info['input_ids']\n",
    "q = aug_block.train.dset.data.data_info['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d7ad6-1db3-45dc-99fa-5062e4d56a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15\n",
      "15 15\n",
      "15 15\n",
      "16 16\n",
      "15 15\n",
      "15 15\n",
      "15 15\n",
      "15 15\n",
      "15 15\n",
      "9 9\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.permutation(len(p))[:10]: print(len(p[i]), len(q[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46de22f-165f-467c-8f85-7372bb49a3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 23544, 12809, 11428, 1204, 12143, 102, 1498, 102, 1203, 1365, 1392, 102, 3559, 102]\n"
     ]
    }
   ],
   "source": [
    "print(p[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd87a63-b9fd-4b85-9fe3-acf1e29f9541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
