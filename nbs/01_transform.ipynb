{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa5fb1d-1a6d-4e46-9250-6f8c6d958e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0571d3e-ed11-49da-be66-f9c19862bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a99bc8-8184-4059-b79b-56cd4b9f05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, numpy as np, re, pickle\n",
    "from tqdm.auto import tqdm\n",
    "from scipy import sparse\n",
    "from transformers import AutoTokenizer, BatchEncoding\n",
    "from itertools import chain\n",
    "\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import *\n",
    "from fastcore.dispatch import *\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "\n",
    "from xcai.core import *\n",
    "from xcai.generation.trie import *\n",
    "from xcai.data import XCDataBlock, BaseXCDataBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb3972-8916-4275-8ed0-f65433d6e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b387629-65fb-4e67-a85a-bb32f0765905",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c69be4-db73-4980-abe8-0a7fdf39caab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/xclib-0.97-py3.9-linux-x86_64.egg/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n"
     ]
    }
   ],
   "source": [
    "from xcai.block import *\n",
    "block = XCBlock.from_cfg('/home/scai/phd/aiz218323/Projects/XC/data', 'train_meta', tokenizer='distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3280b51-91d5-446f-96d8-e00b5024c57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e76494-5717-4b20-8b57-f4bf86fd9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets/processed/'\n",
    "pkl_file = f'{pkl_dir}/wikiseealso_data-meta_distilbert-base-uncased_rm_ramen-cat.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4575b973-9a18-44d9-87eb-fa8d30c8aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f255783-53d0-411c-92d9-6a49bf906006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a596b8f4-483a-4fd9-80c5-2e05d5aa9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM = {\n",
    "    \n",
    "    # Collator arguements\n",
    "    #-------------------------\n",
    "    'transform_type': 'xc', \n",
    "    'smp_features': [('lbl2data',1,2), ('hlk2data',1,1), ('hlk2lbl2data',2,1)],\n",
    "    'sampling_features': [('lbl2data',2), ('hlk2data',1), ('hlk2lbl2data',1)],\n",
    "    \n",
    "    # Arguements for Info class\n",
    "    #-------------------------\n",
    "    'info_column_names': ['identifier', 'input_text'], \n",
    "    'use_tokenizer': True, \n",
    "    'tokenizer': 'bert-base-cased',\n",
    "    'tokenization_column': 'input_text',\n",
    "    'max_sequence_length': 32,\n",
    "    \n",
    "    # PadFeatTfm arguements\n",
    "    #-------------------------\n",
    "    'pad_side': 'right', 'drop': True, 'ret_t': True, 'in_place': True, 'collapse': True, 'device': 'cpu',\n",
    "    \n",
    "    # AlignInputIdsTfm arguements\n",
    "    #-------------------------\n",
    "    'inp': 'data', 'targ': 'lbl2data', 'ptr': 'lbl2data_data2ptr',\n",
    "    \n",
    "    # Data arguements\n",
    "    #-------------------------\n",
    "    'n_data_meta_samples': None,\n",
    "    'n_lbl_meta_samples': None,\n",
    "    'n_lbl_samples': None,\n",
    "    \n",
    "}\n",
    "\n",
    "tokz = AutoTokenizer.from_pretrained(PARAM['tokenizer'])\n",
    "PARAM['sep_tok'] = tokz.sep_token_id\n",
    "PARAM['pad_tok'] = tokz.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6390acfa-0c7d-4f6b-9769-612f6502dd7d",
   "metadata": {},
   "source": [
    "## Batch transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e0a9a9-fb0b-400f-9943-39d0a57679f5",
   "metadata": {},
   "source": [
    "### `PadTfm`: PAD FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1eb46d-047f-4948-89d3-0e1de15d8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PadTfm:\n",
    "\n",
    "    def __init__(self, \n",
    "                 pad_tok:Optional[int]=None, \n",
    "                 pad_side:Optional[str]='right', \n",
    "                 ret_t:Optional[bool]=True,\n",
    "                 in_place:Optional[bool]=True,\n",
    "                 **kwargs):\n",
    "        store_attr('pad_tok,pad_side,ret_t,in_place')\n",
    "\n",
    "    def _sz_help(self, x:List, sz:List, lev:int):\n",
    "        if len(x) and isinstance(x[0], list):\n",
    "            l = max(len(o) for o in x)\n",
    "            if len(sz) > lev: sz[lev] = max(sz[lev], l)\n",
    "            else: sz.append(l)\n",
    "            for o in x: self._sz_help(o, sz, lev+1)\n",
    "\n",
    "    def get_sz(self, x:List):\n",
    "        sz = [len(x)]\n",
    "        self._sz_help(x, sz, len(sz))\n",
    "        return sz\n",
    "\n",
    "    def _pad_help(self, x:List, sz:List, pads:List, lev:int):\n",
    "        if len(x) and isinstance(x[0], list):\n",
    "            for i,o in enumerate(x): x[i] = self._pad_help(o, sz, pads, lev+1)\n",
    "        rem = [pads[lev]]*(sz[lev] - len(x))\n",
    "        return x+rem if self.pad_side == 'right' else rem+x\n",
    "\n",
    "    def __call__(self, \n",
    "                 x:List, \n",
    "                 pad_tok:Optional[int]=None, \n",
    "                 pad_side:Optional[str]=None, \n",
    "                 ret_t:Optional[bool]=None, \n",
    "                 in_place:Optional[bool]=None):\n",
    "        store_attr('pad_tok,pad_side,ret_t,in_place', is_none=False)\n",
    "        if self.pad_tok is None: raise ValueError('`pad_tok` cannot be None.')\n",
    "        \n",
    "        sz = self.get_sz(x)\n",
    "        pads = [self.pad_tok]\n",
    "        for s in sz[:0:-1]: pads.insert(0, [pads[0]]*s)\n",
    "        if not self.in_place: x = x.copy()\n",
    "        x = self._pad_help(x, sz, pads, 0)\n",
    "        try: return torch.tensor(x) if self.ret_t else x\n",
    "        except: return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba86ffc-15eb-4e60-924b-003d837f4408",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b25ff2f-44e1-43e8-b973-4c174f61595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = PadTfm(0, 'right')\n",
    "\n",
    "arr = [[[1, 2, 3], [1, 2]], [[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24a7a7-c913-4c4c-81d5-b9d33eac401a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [1, 2, 0]],\n",
      "\n",
      "        [[1, 0, 0],\n",
      "         [0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "o = tfm(arr, 0)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccefc195-44af-4eb1-869b-1346753f977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokz = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0921950-339c-41bc-a695-809d7d73747c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[[1, 2, 3], [1, 2]], [[1], 0]], 'attention_mask': [[1, 1], [1, 0]]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.pad({'input_ids':[[[1, 2, 3], [1, 2]], [[1]]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2f6129-6896-499f-b1a5-64b2272fd91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[1, 2, 3], [1, 0, 0]], 'attention_mask': [[1, 1, 1], [1, 0, 0]]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.pad({'input_ids':[[1, 2, 3], [1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266dc822-4886-4b80-b5d2-a456ec4cdc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b1994ff-84e1-45ee-a37c-16ee99649a13",
   "metadata": {},
   "source": [
    "### `CollapseTfm`: COLLAPSE FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6781295a-f4ab-4c60-a6dd-f475beeb65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CollapseTfm:\n",
    "\n",
    "    def __init__(self, lev:int=0, use_ptr:int=True, **kwargs):\n",
    "        store_attr('lev,use_ptr')\n",
    "\n",
    "    def collapse(self, x:List, ptr:Dict, lev:int):\n",
    "        if not isinstance(x, list): raise ValueError(f'`x` should be a list, check the `lev`({self.lev}).')\n",
    "        if self.lev == lev:\n",
    "            if lev in ptr: ptr[lev].append(len(x))\n",
    "            else: ptr[lev] = [len(x)]\n",
    "            return x\n",
    "        x = list(chain(*[self.collapse(o, ptr, lev+1) for o in x]))\n",
    "        if lev in ptr: ptr[lev].append(len(x))\n",
    "        else: ptr[lev] = [len(x)]\n",
    "        return x\n",
    "\n",
    "    def _get_ptr(self, ptr):\n",
    "        for v in ptr.values():\n",
    "            for p,q in enumerate(v[1:]): v[p+1] = v[p] + q\n",
    "        \n",
    "    def __call__(self, x:List, lev:int=None, use_ptr:Optional[int]=None):\n",
    "        store_attr('lev,use_ptr', is_none=False)\n",
    "        \n",
    "        ptr = dict()\n",
    "        x = self.collapse(x, ptr, 0)\n",
    "        if self.use_ptr: self._get_ptr(ptr)\n",
    "        return x, ptr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c079609-3c97-40c5-b083-947462b5990c",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12511429-742f-48b2-b247-4957f305de96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 2, 3],\n",
       "  [4, 5, 6],\n",
       "  [7, 8, 9],\n",
       "  [1, 2, 3],\n",
       "  [4, 5, 6],\n",
       "  [7, 8, 9],\n",
       "  [1, 2, 3],\n",
       "  [4, 5, 6],\n",
       "  [7, 8, 9],\n",
       "  [1, 2, 3],\n",
       "  [4, 5, 6],\n",
       "  [7, 8, 9]],\n",
       " {2: [3, 6, 9, 12], 1: [6, 12], 0: [12]})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm = CollapseTfm()\n",
    "x = [[[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]],\n",
    "     [[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]]]\n",
    "tfm(x, lev=2, use_ptr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62244877-51c1-4fad-8e95-9d4999b0f9e0",
   "metadata": {},
   "source": [
    "### `CollateFeatTfm`: COLLATE FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6367f9-e63d-4ba1-acde-ed831e7e3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CollateFeatTfm:\n",
    "\n",
    "    def __init__(self, prefix:Optional[str]=None, drop:Optional[bool]=True, lev:Optional[int]=0, **kwargs):\n",
    "        store_attr('prefix,drop,lev')\n",
    "        self.colps_proc = CollapseTfm(lev, use_ptr=False)\n",
    "\n",
    "    def proc(self, x:Union[Dict, List], prefix:Optional[str]=None, drop:Optional[bool]=True, lev:Optional[int]=0):\n",
    "        if isinstance(x, list):\n",
    "            name = [k for k in x[0] if prefix is None or re.match(f'^{prefix}',k)]\n",
    "            feat = {k: [o.pop(k) if drop else o[k] for o in x] for k in name}\n",
    "            if lev > 0:\n",
    "                for k in name: \n",
    "                    feat[k], ptr = self.colps_proc(feat[k], lev)\n",
    "                    for p,q in ptr.items(): \n",
    "                        if p != 0: feat[f'{k}_ptr-{p}'] = q\n",
    "        elif isinstance(x, dict):\n",
    "            name = [k for k in x if prefix is None or re.match(f'^{prefix}',k)]\n",
    "            feat = {k: x.pop(k) if drop else x[k] for k in name}\n",
    "        return feat\n",
    "\n",
    "    def __call__(self, x:Union[Dict, List], prefix:Optional[str]=None, drop:Optional[bool]=None, lev:Optional[int]=None):\n",
    "        store_attr('prefix,drop,lev', is_none=False)\n",
    "        return self.proc(x, self.prefix, self.drop, self.lev)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5f7fbf-be55-47a0-9d48-41848a6b3c11",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3377ebc-9679-4474-8777-28465382c2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a :\n",
      "[1, 2, 3, 1, 1, 2, 1, 1, 1, 2, 3, 4, 5]\n",
      "a_ptr-2 :\n",
      "[3, 1, 2, 1, 1, 5]\n",
      "a_ptr-1 :\n",
      "[4, 2, 1, 6]\n"
     ]
    }
   ],
   "source": [
    "tfm = CollateFeatTfm(prefix='a', drop=False)\n",
    "obj = [{'a':[[1, 2, 3], [1]], 'b':[1, 2, 3]}, \n",
    "       {'a':[[1, 2]], 'b':[1]},\n",
    "       {'a':[[1]], 'b':[1, 2]},\n",
    "       {'a':[[1], [1, 2, 3, 4, 5]], 'b':[1, 2, 3, 4]}]\n",
    "\n",
    "o = tfm(obj, lev=2)\n",
    "for k,v in o.items(): print(k, ':'); print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3c9f7-7604-44bf-b587-641485a9ae8d",
   "metadata": {},
   "source": [
    "### `PadFeatTfm`: PAD BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b719c-2c48-4209-933d-37dffab9afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PadFeatTfm:\n",
    "\n",
    "    def __init__(self,\n",
    "                 prefix:Optional[str]=None, \n",
    "                 drop:Optional[bool]=True, \n",
    "                 pad_tok:Optional[int]=0, \n",
    "                 pad_side:Optional[str]='right', \n",
    "                 ret_t:Optional[bool]=True,\n",
    "                 in_place:Optional[bool]=True,\n",
    "                 lev:Optional[int]=0,\n",
    "                 **kwargs):\n",
    "        store_attr('prefix,drop,pad_tok,pad_side,ret_t,in_place,lev')\n",
    "        self.pad_proc, self.coll_proc = PadTfm(), CollateFeatTfm(prefix=prefix, drop=drop, lev=lev)\n",
    "\n",
    "    def get_feat(self, \n",
    "                 x:Union[Dict, List], \n",
    "                 prefix:Optional[str]=None, \n",
    "                 drop:Optional[bool]=True, \n",
    "                 lev:Optional[int]=0):\n",
    "        if isinstance(x, list):\n",
    "            name = [k for k in x[0] if prefix is None or re.match(f'^{prefix}',k)]\n",
    "            feat = {k: [o.pop(k) if drop else o[k] for o in x] for k in name}\n",
    "            if lev > 0:\n",
    "                for k in name: \n",
    "                    feat[k], ptr = self.coll_proc(feat[k], lev)\n",
    "                    for p,q in ptr.items(): \n",
    "                        if p != 0: feat[f'{k}_ptr-{p}'] = q\n",
    "        elif isinstance(x, dict):\n",
    "            name = [k for k in x if prefix is None or re.match(f'^{prefix}',k)]\n",
    "            feat = {k: x.pop(k) if drop else x[k] for k in name}\n",
    "        return feat\n",
    "\n",
    "    def proc(self, x):\n",
    "        return BatchEncoding({\n",
    "            k: (self.pad_proc(v, 0, self.pad_side, self.ret_t, self.in_place) \n",
    "                if re.match('(.*_attention_mask|.*_token_type_ids)', k) else \n",
    "                self.pad_proc(v, self.pad_tok, self.pad_side, self.ret_t, self.in_place)) \n",
    "            for k,v in x.items()\n",
    "        })\n",
    "        \n",
    "    def __call__(self, x:Union[Dict, List], \n",
    "                 prefix:Optional[str]=None, \n",
    "                 drop:Optional[bool]=None, \n",
    "                 pad_tok:Optional[int]=None, \n",
    "                 pad_side:Optional[str]=None, \n",
    "                 ret_t:Optional[bool]=None, \n",
    "                 in_place:Optional[bool]=None,\n",
    "                 lev:Optional[int]=0):\n",
    "        store_attr('prefix,drop,pad_tok,pad_side,ret_t,in_place,lev', is_none=False)\n",
    "        feat = self.coll_proc(x, self.prefix, self.drop, self.lev)\n",
    "        return self.proc(feat)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac165a05-06a1-460d-87f5-45889ed1fdca",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e6c48-ef51-4e43-b557-6fa6224eb185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a :\n",
      "tensor([[[1, 2, 3, 0, 0],\n",
      "         [1, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 2, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0, 0],\n",
      "         [1, 2, 3, 4, 5]]])\n"
     ]
    }
   ],
   "source": [
    "tfm = PadFeatTfm(pad_tok=0)\n",
    "\n",
    "obj = [{'a':[[1, 2, 3], [1]], 'b':[1, 2, 3]}, \n",
    "       {'a':[[1, 2]], 'b':[1]},\n",
    "       {'a':[[1]], 'b':[1, 2]},\n",
    "       {'a':[[1], [1, 2, 3, 4, 5]], 'b':[1, 2, 3, 4]}]\n",
    "\n",
    "o = tfm(obj, prefix='a')\n",
    "for k,v in o.items(): print(k, ':'); print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ceecd5-e069-4b31-af42-61df0388954b",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5322b8ad-2d14-4811-8ee0-9d58ab030b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_identifier', 'data_input_text', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = block.train.dset.one_batch()\n",
    "batch[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371cfe89-dd6c-43c1-be35-ea7b425b9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = (PadFeatTfm(**PARAM))(batch, prefix='lbl2data', lev=1, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6eb574-35dc-4377-b11d-8cabfe3d38b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbl2data_idx :  torch.Size([16])\n",
      "lbl2data_identifier :  16\n",
      "lbl2data_input_text :  16\n",
      "lbl2data_input_ids :  torch.Size([16, 16])\n",
      "lbl2data_token_type_ids :  torch.Size([16, 16])\n",
      "lbl2data_attention_mask :  torch.Size([16, 16])\n",
      "lbl2data_idx_ptr-1 :  torch.Size([10])\n",
      "lbl2data_identifier_ptr-1 :  torch.Size([10])\n",
      "lbl2data_input_text_ptr-1 :  torch.Size([10])\n",
      "lbl2data_input_ids_ptr-1 :  torch.Size([10])\n",
      "lbl2data_token_type_ids_ptr-1 :  torch.Size([10])\n",
      "lbl2data_attention_mask_ptr-1 :  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for k,v in o.items(): \n",
    "    if hasattr(v, 'shape'): print(k, ': ', v.shape)\n",
    "    else: print(k, ': ', len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58613f09-01d4-4f7d-8514-31131cf324dd",
   "metadata": {},
   "source": [
    "### `AlignInputIdsTfm`: ALIGN TOKEN SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d34d5-8558-44c6-809e-874c0932e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AlignInputIdsTfm:\n",
    "\n",
    "    def __init__(self,\n",
    "                 inp:Optional[str]='data',\n",
    "                 targ:Optional[str]='lbl2data',\n",
    "                 ptr:Optional[str]='lbl2data_data2ptr',\n",
    "                 sep_tok:Optional[int]=0, \n",
    "                 pad_tok:Optional[int]=0,\n",
    "                 device:Union[str,torch.device]='cpu', \n",
    "                 **kwargs):\n",
    "        store_attr('inp,targ,ptr,sep_tok,pad_tok,device')\n",
    "\n",
    "    @typedispatch\n",
    "    def proc(self, inp_ids:List, targ_ids:List, sep_tok:int, targ_mask:Optional[List]=None, targ_tok:Optional[List]=None, **kwargs):\n",
    "        for i,ids in enumerate(inp_ids):\n",
    "            inp_len = len(ids)\n",
    "            for j,t in enumerate(targ_ids[i]):\n",
    "                if len(t) > inp_len: \n",
    "                    targ_ids[i][j] = t[:inp_len-1]+[self.sep_tok]\n",
    "                    if targ_mask is not None: targ_mask[i][j] = targ_mask[i][j][:inp_len]\n",
    "                    if targ_tok is not None: targ_tok[i][j] = targ_tok[i][j][:inp_len] \n",
    "        return targ_ids, targ_mask, targ_tok\n",
    "\n",
    "    @typedispatch\n",
    "    def proc(self, inp_ids:torch.Tensor, targ_ids:torch.Tensor, ptr:torch.Tensor, sep_tok:int, pad_tok:int,\n",
    "             targ_mask:Optional[torch.Tensor]=None, targ_tok:Optional[torch.Tensor]=None):\n",
    "        inp_len = (inp_ids == sep_tok).cumsum(1).argmax(1) + 1\n",
    "        inp_len = torch.repeat_interleave(inp_len, ptr)\n",
    "        targ_len = (targ_ids == sep_tok).cumsum(1).argmax(1) + 1\n",
    "        seq_len = torch.where(inp_len < targ_len, inp_len, targ_len)\n",
    "        \n",
    "        for i,(p,q) in enumerate(zip(seq_len, targ_len)):\n",
    "            targ_ids[i,p-1] = sep_tok\n",
    "            targ_ids[i,p:q] = pad_tok \n",
    "            if targ_mask is not None: targ_mask[i,p:q] = 0\n",
    "            if targ_tok is not None: targ_tok[i,p:q] = 0\n",
    "        return targ_ids, targ_mask, targ_tok\n",
    "        \n",
    "    def __call__(self, x:Dict, \n",
    "                 inp:Optional[str]=None, \n",
    "                 targ:Optional[str]=None,\n",
    "                 ptr:Optional[str]=None, \n",
    "                 sep_tok:Optional[int]=None, \n",
    "                 pad_tok:Optional[int]=None):\n",
    "        store_attr('inp,targ,ptr,sep_tok,pad_tok', is_none=False)\n",
    "\n",
    "        def get_attr(x, keys, required=False):\n",
    "            attr = []\n",
    "            for k in keys.split(','):\n",
    "                if k not in x: \n",
    "                    if required: raise ValueError(f'\"{k}\" not in `x`')\n",
    "                    else: attr.append(None)\n",
    "                else: attr.append(x[k])\n",
    "            return attr\n",
    "            \n",
    "        inp_ids, targ_ids = get_attr(x, f'{self.inp}_input_ids,{self.targ}_input_ids')\n",
    "        if inp_ids is None or targ_ids is None: return x\n",
    "        targ_mask, targ_tok = get_attr(x, f'{self.targ}_attention_mask,{self.targ}_token_type_ids') \n",
    "        ptr = None if self.ptr is None else x[self.ptr]\n",
    "        \n",
    "        targ_ids, targ_mask, targ_tok = self.proc(inp_ids, targ_ids, ptr=ptr, targ_mask=targ_mask, targ_tok=targ_tok, \n",
    "                                                  sep_tok=self.sep_tok, pad_tok=self.pad_tok)\n",
    "        def set_attr(x, keys, vals):\n",
    "            for i,(k,v) in enumerate(zip(keys.split(','),vals)):\n",
    "                if v is not None: x[k] = v\n",
    "                    \n",
    "        set_attr(x, f'{self.targ}_input_ids,{self.targ}_attention_mask,{self.targ}_token_type_ids', [targ_ids,targ_mask,targ_tok])\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf066915-66bf-44b2-887a-c8cdcf999fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typedispatch\n",
    "def verify_align(p:torch.Tensor, q:torch.Tensor, r:torch.Tensor, tok:int):\n",
    "    p_len = torch.where(p == tok)[1]+1\n",
    "    p_len = p_len.repeat_interleave(r)\n",
    "    q_len = torch.where(q == tok)[1]+1\n",
    "    for p,q in zip(p_len, q_len):\n",
    "        p,q = p.item(),q.item()\n",
    "        if p < q: print(p,' < ',q)\n",
    "        else: print(p,' > ',q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c0f1d-c594-4f41-84d2-f0b2dc739d76",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5bc351-4b0d-404f-92a3-981131dc4cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_input_ids :\n",
      "tensor([[ 1,  2, 11,  0,  0,  0],\n",
      "        [11,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5, 11]])\n",
      "lbl2data_input_ids :\n",
      "tensor([[ 1,  2, 11],\n",
      "        [ 5, 11,  0],\n",
      "        [ 5, 11,  0],\n",
      "        [ 5, 11,  0],\n",
      "        [ 5,  6, 11],\n",
      "        [13,  4, 11]])\n",
      "lbl2data_data2ptr :\n",
      "tensor([1, 2, 3])\n",
      "lbl2data_attention_mask :\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "lbl2data_token_type_ids :\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "pad_tfm = PadFeatTfm(pad_tok=0)\n",
    "obj = {\n",
    "    'data_input_ids':[[1, 2, 11], [11], [1, 2, 3, 4, 5, 11]], \n",
    "    'lbl2data_input_ids':[[1, 2, 11], [5, 11], [5, 11], [5, 11], [5, 6, 11], [13, 4, 11]],\n",
    "    'lbl2data_data2ptr':[1, 2, 3],\n",
    "    'lbl2data_attention_mask':[[1, 1, 1], [1, 1], [1, 1], [1, 1], [1, 1, 1], [1, 1, 1]],\n",
    "    'lbl2data_token_type_ids':[[0, 0, 0], [0, 0], [0, 0], [0, 0], [0, 0, 0], [0, 0, 0]],\n",
    "}\n",
    "\n",
    "o = pad_tfm(obj)\n",
    "for k,v in o.items(): print(k,':'); print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af2ce9-459b-4e0c-a7d8-7617788fd5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_input_ids :\n",
      "tensor([[ 1,  2, 11,  0,  0,  0],\n",
      "        [11,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5, 11]])\n",
      "lbl2data_input_ids :\n",
      "tensor([[ 1,  2, 11],\n",
      "        [11,  0,  0],\n",
      "        [11,  0,  0],\n",
      "        [ 5, 11,  0],\n",
      "        [ 5,  6, 11],\n",
      "        [13,  4, 11]])\n",
      "lbl2data_data2ptr :\n",
      "tensor([1, 2, 3])\n",
      "lbl2data_attention_mask :\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "lbl2data_token_type_ids :\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "align_tfm = AlignInputIdsTfm(bsz=4, pad_tok=0, sep_tok=11, inp='data', \n",
    "                             targ='lbl2data', ptr='lbl2data_data2ptr')\n",
    "o = align_tfm(o)\n",
    "for k,v in o.items(): print(k,':'); print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2cb375-3c38-4acd-931c-19f56c6f3186",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f89b4-2428-44b5-9101-f4adb9ea66f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch()\n",
    "pad_tfm, alg_tfm = PadFeatTfm(**PARAM), AlignInputIdsTfm(**PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea98af-1685-4605-a393-f8d98be2a38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_identifier', 'data_input_text', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4b95a-a820-4e74-98ce-e652283a034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = pad_tfm(batch, prefix='data', lev=0, in_place=True, drop=True)\n",
    "o.update(pad_tfm(batch, prefix='lbl2data', lev=1, in_place=True, drop=True))\n",
    "o['lbl2data_data2ptr'] = o['lbl2data_idx_ptr-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e182b95-12fc-4352-bcd3-9c3db72535da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  >  7\n",
      "4  <  5\n",
      "4  <  9\n",
      "4  <  5\n",
      "4  <  8\n",
      "9  >  7\n",
      "7  <  11\n",
      "5  >  4\n",
      "5  >  4\n",
      "5  <  8\n",
      "6  <  9\n",
      "6  >  4\n",
      "6  <  8\n",
      "6  >  5\n",
      "7  >  7\n",
      "7  >  7\n",
      "6  >  3\n",
      "11  >  3\n",
      "11  >  6\n"
     ]
    }
   ],
   "source": [
    "verify_align(o['data_input_ids'], o['lbl2data_input_ids'], o['lbl2data_data2ptr'], PARAM['sep_tok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6b557-7e31-412c-a8dc-e63915bb58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = alg_tfm(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502ba49-4563-4b9b-972e-030c5e135197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  >  7\n",
      "4  >  4\n",
      "4  >  4\n",
      "4  >  4\n",
      "4  >  4\n",
      "9  >  7\n",
      "7  >  7\n",
      "5  >  4\n",
      "5  >  4\n",
      "5  >  5\n",
      "6  >  6\n",
      "6  >  4\n",
      "6  >  6\n",
      "6  >  5\n",
      "7  >  7\n",
      "7  >  7\n",
      "6  >  3\n",
      "11  >  3\n",
      "11  >  6\n"
     ]
    }
   ],
   "source": [
    "verify_align(o['data_input_ids'], o['lbl2data_input_ids'], o['lbl2data_data2ptr'], PARAM['sep_tok'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aec367-cbb3-4977-9618-300fe396b030",
   "metadata": {},
   "source": [
    "### `XCPadFeatTfm`: PAD XC BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e99119-8dfe-4936-95d3-bd45cbfee30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCPadFeatTfm:\n",
    "\n",
    "    @delegates(PadFeatTfm.__init__)\n",
    "    def __init__(self, **kwargs):\n",
    "        self.tfm = PadFeatTfm(**kwargs)\n",
    "\n",
    "    def extract_ptr(self, x:Dict, suffix:str):\n",
    "        ptr_name = [k for k in x if re.match(f'.*{suffix}$',k)]\n",
    "        ptr = [x.pop(k) for k in ptr_name]\n",
    "        return ptr[0] if len(ptr) else None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        meta_name = set([k.split('_',maxsplit=1)[0].split('2')[0] for k in x[0]]).difference(['lbl', 'data'])\n",
    "        out = self.tfm(x, prefix='lbl2data', lev=1, in_place=True, drop=True)\n",
    "        lbl2data_data2ptr = self.extract_ptr(out, 'ptr-1')\n",
    "        if lbl2data_data2ptr is not None: out['lbl2data_data2ptr'] = lbl2data_data2ptr\n",
    "        out.update(self.tfm(x, prefix='data', lev=0, in_place=True, drop=True))\n",
    "        for k in meta_name:\n",
    "            o = self.tfm(x, prefix=f'{k}2lbl2data', lev=2, in_place=True, drop=True)\n",
    "            o[f'{k}2lbl2data_data2ptr'] = self.extract_ptr(o, 'ptr-1')\n",
    "            o[f'{k}2lbl2data_lbl2ptr'] = self.extract_ptr(o, 'ptr-2')\n",
    "            out.update(o)\n",
    "            o = self.tfm(x, prefix=f'{k}2data', lev=1, in_place=True, drop=True)\n",
    "            o[f'{k}2data_data2ptr'] = self.extract_ptr(o, 'ptr-1')\n",
    "            out.update(o)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdde4ef-c383-47e3-8dc3-0b498109c195",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c19f62-537f-4e91-b5d3-4118051a3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch()\n",
    "pad_tfm, align_tfm = XCPadFeatTfm(**PARAM), AlignInputIdsTfm(**PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334d1d4f-ef85-435a-8fd2-b204085eb57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = pad_tfm(batch)\n",
    "o = align_tfm(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27353d37-2323-472c-8b97-40f499273979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  >  6\n",
      "7  >  7\n",
      "5  >  5\n",
      "7  >  7\n",
      "7  >  7\n",
      "10  >  7\n",
      "6  >  5\n",
      "6  >  6\n",
      "16  >  16\n",
      "16  >  6\n",
      "16  >  7\n",
      "16  >  6\n",
      "16  >  5\n",
      "16  >  4\n",
      "16  >  5\n",
      "5  >  4\n",
      "5  >  5\n",
      "5  >  5\n",
      "5  >  5\n",
      "5  >  5\n",
      "5  >  5\n",
      "7  >  5\n"
     ]
    }
   ],
   "source": [
    "verify_align(o['data_input_ids'], o['lbl2data_input_ids'], o['lbl2data_data2ptr'], PARAM['sep_tok'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7ca80-47a9-47bb-bb63-d7149b306cd9",
   "metadata": {},
   "source": [
    "### `XCPadOutputTfm`: PAD XC OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59fa453-7c26-4851-a3dd-3eb4762f29d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCPadOutputTfm:\n",
    "\n",
    "    @delegates(PadFeatTfm.__init__)\n",
    "    def __init__(self, **kwargs):\n",
    "        self.tfm = PadFeatTfm(**kwargs)\n",
    "\n",
    "    def extract_ptr(self, x:Dict, suffix:str):\n",
    "        ptr_name = [k for k in x if re.match(f'.*{suffix}$',k)]\n",
    "        return [x.pop(k) for k in ptr_name][0]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = self.tfm(x, prefix='info2seq', lev=0, in_place=True, drop=True)\n",
    "        out.update(self.tfm(x, prefix='seq', lev=0, in_place=True, drop=True))\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376362e-496c-4d56-98fa-ac1991c07327",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3706562d-9dc2-40d8-9f24-78041c029208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info2seq_idx :\n",
      "tensor([ 1,  2, 11,  5, 11, 13])\n",
      "info2seq_seq2ptr :\n",
      "tensor([1, 2, 3])\n",
      "seq_output_ids :\n",
      "tensor([[ 1,  2, 11,  0,  0,  0],\n",
      "        [11,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5, 11]])\n",
      "seq_score :\n",
      "tensor([1.2000, 3.3000, 4.5000])\n"
     ]
    }
   ],
   "source": [
    "pad_tfm = XCPadOutputTfm(pad_tok=0)\n",
    "obj = {\n",
    "    'seq_output_ids':[[1, 2, 11], [11], [1, 2, 3, 4, 5, 11]],\n",
    "    'seq_score':[1.2, 3.3, 4.5],\n",
    "    'info2seq_idx':[1, 2, 11, 5, 11, 13],\n",
    "    'info2seq_seq2ptr':[1, 2, 3],\n",
    "}\n",
    "\n",
    "o = pad_tfm(obj)\n",
    "for k,v in o.items(): print(k,':'); print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa8c6c8-aabf-49f2-a66b-764d1ec72297",
   "metadata": {},
   "source": [
    "### `SampleFeatTfm`: SAMPLE LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd5c653-00bb-4f2e-9495-b9fda7da731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SampleFeatTfm:\n",
    "\n",
    "    def __init__(self, feat_type:Optional[str]=None, smp_prefix:Optional[str]='', **kwargs):\n",
    "        store_attr('feat_type,smp_prefix')\n",
    "\n",
    "    def _get_feat(self, x:Dict):\n",
    "        if self.feat_type is None: raise ValueError('`feat_type` is None.')\n",
    "        return [o for o in x if re.match(f'^({self.feat_type})_.*', o)]\n",
    "\n",
    "    def proc(self, x:List, lev:int, n_samples:Optional[int]=1):\n",
    "        feat = self._get_feat(x[0])\n",
    "        out, coll_proc = {}, CollapseTfm()\n",
    "        \n",
    "        if len(feat) > 0:\n",
    "            smp_prefix = self.smp_prefix if self.smp_prefix == '' else f'{self.smp_prefix}2'\n",
    "            def _size(o, l): return len(coll_proc(o[feat[0]],l)[0])\n",
    "            rnd_idx = [np.random.permutation(_size(o,lev))[:n_samples] if _size(o,lev) else [] for o in x]\n",
    "            \n",
    "            out = []\n",
    "            for idx,o in zip(rnd_idx, x):\n",
    "                d = {}\n",
    "                for k in feat: c = coll_proc(o[k],lev)[0]; d.update({smp_prefix+k:[c[i] for i in idx] if len(idx) >= 0 else []})\n",
    "                out.append(d) \n",
    "        return out\n",
    "\n",
    "    def __call__(self, x:[List,Dict,BatchEncoding], lev:int, n_samples:Optional[int]=1, \n",
    "                 feat_type:Optional[str]=None, smp_prefix:Optional[str]=None, **kwargs):\n",
    "        store_attr('feat_type,smp_prefix', is_none=False)\n",
    "        return self.proc(x, lev, n_samples)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ec8d4-9e79-4e95-8ae4-19eb0139cc64",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a237e-d599-4808-ae8a-fe04d5a424af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5932a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'hlk2data_idx', 'hlk2data_identifier', 'hlk2data_input_text', 'hlk2data_input_ids', 'hlk2data_attention_mask', 'hlk2lbl2data_idx', 'hlk2lbl2data_identifier', 'hlk2lbl2data_input_text', 'hlk2lbl2data_input_ids', 'hlk2lbl2data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1027ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_type = '(hlk2lbl2data|lbl2data)'\n",
    "smp_tfm = SampleFeatTfm(feat_type=feat_type, ptr_type='data', smp_prefix='smp')\n",
    "out = smp_tfm(batch, lev=0, n_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127581e-6a55-4fc2-9c8e-78215a817609",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(o, b) in enumerate(zip(out, batch)): \n",
    "    k='data_input_text'; print(f'{i+1}.{k} ',': ', b[k])\n",
    "    k=f'smp2{feat_type}_input_text'; print(f'  {k}', ': ', o[k])\n",
    "    k=f'{feat_type}_input_text'; print(f'  {k}', ': ', b[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c02b1",
   "metadata": {},
   "source": [
    "### `XCSamplePadFeatTfm`: SAMPLE AND THEN PAD BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af771dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCSamplePadFeatTfm:\n",
    "\n",
    "    def __init__(self, smp_features:Optional[List]=None, **kwargs):\n",
    "        store_attr('smp_features')\n",
    "        self.smp_proc, self.pad_proc = SampleFeatTfm(**kwargs), PadFeatTfm(**kwargs)\n",
    "        \n",
    "    def extract_ptr(self, x:Dict, suffix:str):\n",
    "        ptr_name = [k for k in x if re.match(f'.*{suffix}$',k)]\n",
    "        ptr = [x.pop(k) for k in ptr_name]\n",
    "        return ptr[0] if len(ptr) else None\n",
    "        \n",
    "    def sample_feat(self, x:List, feat:str, lev:int, n_samples:Optional[int]=1):\n",
    "        out = self.pad_proc(x, prefix=f'{feat}_idx', lev=lev, in_place=False, drop=False)\n",
    "        \n",
    "        if f'{feat}_idx' in out:\n",
    "            \n",
    "            out[f'p{feat}_idx'] = out.pop(f'{feat}_idx')\n",
    "            out[f'p{feat}_data2ptr'] = out.pop(f'{feat}_idx_ptr-1')\n",
    "            if f'{feat}_idx_ptr-2' in out: out.pop(f'{feat}_idx_ptr-2')\n",
    "                \n",
    "            o = self.pad_proc(self.smp_proc(x, lev=lev-1, n_samples=n_samples, feat_type=feat), \n",
    "                              prefix=feat, lev=1, in_place=True, drop=True)\n",
    "            o[f'{feat}_data2ptr'] = self.extract_ptr(o, 'ptr-1')\n",
    "            self.extract_ptr(o, 'ptr-2')\n",
    "            \n",
    "            out.update(o)\n",
    "        return out\n",
    "\n",
    "    def __call__(self, x:List, smp_features:Optional[List]=None):\n",
    "        store_attr('smp_features', is_none=False)\n",
    "        \n",
    "        out, smp_features = BatchEncoding({}), () \n",
    "        if self.smp_features is not None:\n",
    "            for feat,lev,n in self.smp_features: out.update(self.sample_feat(x, feat, lev, n))\n",
    "            smp_features = list(zip(*self.smp_features))[0]\n",
    "            \n",
    "        out.update(self.pad_proc(x, prefix='data', lev=0, in_place=True, drop=True))\n",
    "        \n",
    "        meta_names = set([o.split('_',maxsplit=1)[0] for o in x[0]]).difference(smp_features+('data',))\n",
    "        if 'lbl2data' in meta_names:\n",
    "            out.update(self.pad_proc(x, prefix='lbl2data', lev=1, in_place=True, drop=True))\n",
    "            out['lbl2data_data2ptr'] = self.extract_ptr(out, 'ptr-1')\n",
    "        \n",
    "        for k in meta_names.difference(['lbl2data']):\n",
    "            if k.endswith('2lbl2data'): \n",
    "                o = self.pad_proc(x, prefix=k, lev=2, in_place=True, drop=True)\n",
    "                o[f'{k}_data2ptr'] = self.extract_ptr(o, 'ptr-1')\n",
    "                if 'lbl2data' in meta_names: o[f'{k}_lbl2data2ptr'] = self.extract_ptr(o, 'ptr-2')\n",
    "                else: o[f'{k}_plbl2data2ptr'] = self.extract_ptr(o, 'ptr-2')\n",
    "            elif k.endswith('2data'): \n",
    "                o = self.pad_proc(x, prefix=k, lev=1, in_place=True, drop=True)\n",
    "                o[f'{k}_data2ptr'] = self.extract_ptr(o, 'ptr-1')\n",
    "            else: raise ValueError(f'Invalid metadata name ({k})')\n",
    "            out.update(o)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98536bba",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e4faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1ca0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'hlk2data_idx', 'hlk2data_identifier', 'hlk2data_input_text', 'hlk2data_input_ids', 'hlk2data_attention_mask', 'hlk2lbl2data_idx', 'hlk2lbl2data_identifier', 'hlk2lbl2data_input_text', 'hlk2lbl2data_input_ids', 'hlk2lbl2data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c1259c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aab740",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = XCSamplePadFeatTfm(**PARAM)\n",
    "o = tfm(batch, smp_features=[('lbl2data',1, 2), ('hlk2data',1, 1), ('hlk2lbl2data',2, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec08445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbl2data_idx:  torch.Size([5])\n",
      "lbl2data_identifier:  5\n",
      "lbl2data_input_text:  5\n",
      "lbl2data_input_ids:  torch.Size([5, 12])\n",
      "lbl2data_attention_mask:  torch.Size([5, 12])\n",
      "lbl2data_data2ptr:  torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for k,v in o.items():\n",
    "    if k.startswith(r'lbl2data_'):\n",
    "        if isinstance(v, torch.Tensor): print(f'{k}: ', v.shape)\n",
    "        else: print(f'{k}: ', len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1270e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hlk2data_idx:  torch.Size([3])\n",
      "hlk2data_identifier 3\n",
      "hlk2data_input_text 3\n",
      "hlk2data_input_ids:  torch.Size([3, 8])\n",
      "hlk2data_attention_mask:  torch.Size([3, 8])\n",
      "hlk2data_data2ptr:  torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for k,v in o.items():\n",
    "    if k.startswith(r'hlk2data_'):\n",
    "        if isinstance(v, torch.Tensor): print(f'{k}: ', v.shape)\n",
    "        else: print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hlk2lbl2data_idx:  torch.Size([3])\n",
      "hlk2lbl2data_identifier 3\n",
      "hlk2lbl2data_input_text 3\n",
      "hlk2lbl2data_input_ids:  torch.Size([3, 8])\n",
      "hlk2lbl2data_attention_mask:  torch.Size([3, 8])\n",
      "hlk2lbl2data_data2ptr:  torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for k,v in o.items():\n",
    "    if k.startswith(r'hlk2lbl2data_'):\n",
    "        if isinstance(v, torch.Tensor): print(f'{k}: ', v.shape)\n",
    "        else: print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b56c294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'phlk2data_idx', 'phlk2data_data2ptr', 'hlk2data_idx', 'hlk2data_identifier', 'hlk2data_input_text', 'hlk2data_input_ids', 'hlk2data_attention_mask', 'hlk2data_data2ptr', 'phlk2lbl2data_idx', 'phlk2lbl2data_data2ptr', 'hlk2lbl2data_idx', 'hlk2lbl2data_identifier', 'hlk2lbl2data_input_text', 'hlk2lbl2data_input_ids', 'hlk2lbl2data_attention_mask', 'hlk2lbl2data_data2ptr', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d716f1fc",
   "metadata": {},
   "source": [
    "### `RamenPadFeatTfm`: SAMPLE AND THEN PAD BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a74ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RamenPadFeatTfm:\n",
    "\n",
    "    def __init__(self, smp_features:Optional[List]=None, **kwargs):\n",
    "        store_attr('smp_features')\n",
    "        self.smp_proc, self.pad_proc = SampleFeatTfm(**kwargs), PadFeatTfm(**kwargs)\n",
    "        \n",
    "    def extract_ptr(self, x:Dict, suffix:str):\n",
    "        ptr_name = [k for k in x if re.match(f'.*{suffix}$',k)]\n",
    "        ptr = [x.pop(k) for k in ptr_name]\n",
    "        return ptr[0] if len(ptr) else None\n",
    "    \n",
    "    def get_feat(self, x, feat_type): return [o for o in x[0] if o.startswith(f'{feat_type}_')]\n",
    "\n",
    "    def smp_feat(self, x:List, feat_type:str, n_samples:Optional[int]=1):\n",
    "        feat = self.get_feat(x, feat_type)\n",
    "        rnd_idx = [[np.random.permutation(len(v))[:n_samples] if len(v) else [-1] for v in o[feat[0]]] for o in x]\n",
    "\n",
    "        out = []\n",
    "        for o,idx in zip(x, rnd_idx):\n",
    "            out.append({k:[[v[i] for i in ii if i >= 0] for v,ii in zip(o[k], idx)] for k in feat})\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def sample_feat(self, x:List, feat:str, lev:int, n_samples:Optional[Union[int,List]]=1):\n",
    "        f = feat.split(\"|\")\n",
    "        \n",
    "        if isinstance(n_samples, int):\n",
    "            n_samples = (n_samples,)*len(f)\n",
    "        else:\n",
    "            if len(n_samples) != len(f): \n",
    "                raise ValueError(f\"Size of `n_samples`({len(n_samples)}) should be equal to number of features.\")\n",
    "        \n",
    "        f,of = f[0], f[1:]\n",
    "        n_sample, n_samples = n_samples[0], n_samples[1:]\n",
    "        \n",
    "        out = self.pad_proc(x, prefix=f'{f}_idx', lev=1, in_place=False, drop=False)\n",
    "        if f'{f}_idx' in out:\n",
    "            out[f'p{f}_idx'],out[f'p{f}_{f.split(\"2\")[-1]}2ptr'] = out.pop(f'{f}_idx'), self.extract_ptr(out, 'ptr-1')\n",
    "            self.extract_ptr(out, 'ptr-2')\n",
    "\n",
    "            smp_out = self.smp_proc(x, lev=0, n_samples=n_sample, feat_type=feat)\n",
    "\n",
    "            o = self.pad_proc(smp_out, prefix=f, lev=1, in_place=True, drop=True)\n",
    "            o[f'{f}_{f.split(\"2\")[-1]}2ptr'] = self.extract_ptr(o, 'ptr-1')\n",
    "            self.extract_ptr(o, 'ptr-2')\n",
    "            out.update(o)\n",
    "\n",
    "            for f,n_sample in zip(of,n_samples):\n",
    "                o = self.pad_proc(smp_out, prefix=f'{f}_idx', lev=2, in_place=False, drop=False)\n",
    "                if f'{f}_idx' in o:\n",
    "                    o[f'p{\"2\".join(f.split(\"2\")[:-1])}_idx'] = o.pop(f'{f}_idx')\n",
    "                    o[f'p{\"2\".join(f.split(\"2\")[:-1])}_{\"2\".join(f.split(\"2\")[-2:])}2ptr'] = self.extract_ptr(o, 'ptr-2')\n",
    "                    o[f'p{\"2\".join(f.split(\"2\")[:-1])}_{f.split(\"2\")[-1]}2ptr'] = self.extract_ptr(o, 'ptr-1')\n",
    "                    out.update(o)\n",
    "\n",
    "                    o = self.pad_proc(self.smp_feat(smp_out, f, n_sample), prefix=f, lev=2, in_place=True, drop=True)\n",
    "                    feat = list(o.keys())\n",
    "                    for k in feat:\n",
    "                        p,q = k.split('_', maxsplit=1)\n",
    "                        o[\"_\".join([\"2\".join(p.split(\"2\")[:-1]),q])] = o.pop(k)\n",
    "                    o[f'{\"2\".join(p.split(\"2\")[:-1])}_{\"2\".join(f.split(\"2\")[-2:])}2ptr'] = self.extract_ptr(o, 'ptr-2')\n",
    "                    o[f'{\"2\".join(p.split(\"2\")[:-1])}_{f.split(\"2\")[-1]}2ptr'] = self.extract_ptr(o, 'ptr-1')\n",
    "                    out.update(o)\n",
    "        return out\n",
    "    \n",
    "\n",
    "    def __call__(self, x:List, smp_features:Optional[List]=None):\n",
    "        store_attr('smp_features', is_none=False)\n",
    "        \n",
    "        out, smp_features = BatchEncoding({}), () \n",
    "        if self.smp_features is not None:\n",
    "            for feat,lev,n in self.smp_features: out.update(self.sample_feat(x, feat, lev, n))\n",
    "            smp_features = list(chain(*[o[0].split('|') for o in self.smp_features]))\n",
    "            \n",
    "        out.update(self.pad_proc(x, prefix='data', lev=0, in_place=True, drop=True))\n",
    "        \n",
    "        meta_names = set([o.split('_',maxsplit=1)[0] for o in x[0]]).difference(smp_features+['data'])\n",
    "        if 'lbl2data' in meta_names:\n",
    "            out.update(self.pad_proc(x, prefix='lbl2data', lev=1, in_place=True, drop=True))\n",
    "            out['lbl2data_data2ptr'] = self.extract_ptr(out, 'ptr-1')\n",
    "        \n",
    "        for k in meta_names.difference(['lbl2data']):\n",
    "            if k.endswith('2lbl2data'): \n",
    "                o = self.pad_proc(x, prefix=k, lev=2, in_place=True, drop=True)\n",
    "                o[f'{k}_data2ptr'] = self.extract_ptr(o, 'ptr-1')\n",
    "                if 'lbl2data' in meta_names: o[f'{k}_lbl2data2ptr'] = self.extract_ptr(o, 'ptr-2')\n",
    "                else: o[f'{k}_plbl2data2ptr'] = self.extract_ptr(o, 'ptr-2')\n",
    "            elif k.endswith('2data'): \n",
    "                o = self.pad_proc(x, prefix=k, lev=1, in_place=True, drop=True)\n",
    "                o[f'{k}_data2ptr'] = self.extract_ptr(o, 'ptr-1')\n",
    "            else: raise ValueError(f'Invalid metadata name ({k})')\n",
    "            out.update(o)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f464e",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a29f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb0191",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = RamenPadFeatTfm(**PARAM)\n",
    "o = tfm(batch, smp_features=[('lbl2data|cat2lbl2data',1, (1,1)), ('cat2data',1, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf2f0b-c208-48e4-be28-5dd3dccab513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1275968-bf6e-4afa-aa36-b37e88458548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 11412,  31970,  31971,  89688, 100218, 193510, 223526, 230797, 115246,\n",
       "        219431, 219547, 229016, 237079])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o['plbl2data_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df095c5-d076-42b9-bfce-8bb8d1a6e177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 2, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o['pcat2lbl_lbl2data2ptr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f51416-fe13-4561-bdaf-23eab46ccf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 31970, 100218, 223526, 115246])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o['lbl2data_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c632a08d-d7e5-42dc-9613-80002ebf7182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 98820, 149008,  91424, 157547])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o['cat2lbl_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d641f4-d368-4eb9-a477-83c5544b527c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf1aa5-f48d-4c52-ba61-f610deeb712a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ffe7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plbl2data_idx :  torch.Size([13])\n",
      "plbl2data_data2ptr :  torch.Size([4])\n",
      "lbl2data_idx :  torch.Size([4])\n",
      "lbl2data_identifier :  4\n",
      "lbl2data_input_text :  4\n",
      "lbl2data_input_ids :  torch.Size([4, 11])\n",
      "lbl2data_attention_mask :  torch.Size([4, 11])\n",
      "lbl2data_data2ptr :  torch.Size([4])\n",
      "pcat2lbl_idx :  torch.Size([10])\n",
      "pcat2lbl_lbl2data2ptr :  torch.Size([4])\n",
      "pcat2lbl_data2ptr :  torch.Size([4])\n",
      "cat2lbl_idx :  torch.Size([4])\n",
      "cat2lbl_identifier :  4\n",
      "cat2lbl_input_text :  4\n",
      "cat2lbl_input_ids :  torch.Size([4, 9])\n",
      "cat2lbl_attention_mask :  torch.Size([4, 9])\n",
      "cat2lbl_lbl2data2ptr :  torch.Size([4])\n",
      "cat2lbl_data2ptr :  torch.Size([4])\n",
      "pcat2data_idx :  torch.Size([11])\n",
      "pcat2data_data2ptr :  torch.Size([4])\n",
      "cat2data_idx :  torch.Size([7])\n",
      "cat2data_identifier :  7\n",
      "cat2data_input_text :  7\n",
      "cat2data_input_ids :  torch.Size([7, 10])\n",
      "cat2data_attention_mask :  torch.Size([7, 10])\n",
      "cat2data_data2ptr :  torch.Size([4])\n",
      "data_identifier :  4\n",
      "data_input_text :  4\n",
      "data_input_ids :  torch.Size([4, 7])\n",
      "data_attention_mask :  torch.Size([4, 7])\n"
     ]
    }
   ],
   "source": [
    "for k,v in o.items():\n",
    "    if isinstance(v, torch.Tensor): print(k, ': ', v.shape)\n",
    "    else: print(k, ': ', len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0660cb",
   "metadata": {},
   "source": [
    "### `RemoveColumnsTfm`: REMOVE COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be832d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RemoveColumnTfm:\n",
    "    \n",
    "    def __init__(self, column:List, **kwargs):\n",
    "        self.column = column\n",
    "    \n",
    "    def __call__(self, x:Dict):\n",
    "        for k in self.column: \n",
    "            if k in x: x.pop(k)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86475d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86cfdd16-7c8a-4dd8-8ece-bf79f158ff9d",
   "metadata": {},
   "source": [
    "### `NGPadFeatTfm`: PAD NGAME BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01985c01-1014-49a8-a415-cf6d5a6ae88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NGPadFeatTfm:\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.smp_proc, self.pad_proc = SampleFeatTfm(**kwargs), PadFeatTfm(**kwargs)\n",
    "\n",
    "    def __call__(self, x:Dict):\n",
    "        out = self.pad_proc(x, prefix='lbl2data_idx', lev=1, in_place=False, drop=False)\n",
    "        if 'lbl2data_idx' in out:\n",
    "            out['plbl2data_idx'] = out['lbl2data_idx']\n",
    "            out['plbl2data_data2ptr'] = out.pop('lbl2data_idx_ptr-1')\n",
    "            out.update(self.pad_proc(self.smp_proc(x, lev=0, feat_type='lbl2data', ptr_type='data'), \n",
    "                                     prefix='lbl2data', lev=1, in_place=True, drop=True))\n",
    "        out.update(self.pad_proc(x, prefix='data', lev=0, in_place=True, drop=True))\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e953e52-6433-46c2-8e9f-939433b9eb01",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f851c-d81e-4acd-9ff2-d250ec9640b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch()\n",
    "tfm = NGPadFeatTfm(**PARAM)\n",
    "\n",
    "o = tfm(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679358cb-2b4b-4a37-a828-7bcb554b339b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lbl2data_idx', 'plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_idx_ptr-1', 'lbl2data_identifier_ptr-1', 'lbl2data_input_text_ptr-1', 'lbl2data_input_ids_ptr-1', 'lbl2data_attention_mask_ptr-1', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff3e350-b1b7-4ea5-81fd-304e56d236ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbl2data_idx :  torch.Size([10])\n",
      "lbl2data_identifier :  10\n",
      "lbl2data_input_text :  10\n",
      "lbl2data_input_ids :  torch.Size([10, 13])\n",
      "lbl2data_attention_mask :  torch.Size([10, 13])\n",
      "lbl2data_idx_ptr-1 :  torch.Size([10])\n",
      "lbl2data_identifier_ptr-1 :  torch.Size([10])\n",
      "lbl2data_input_text_ptr-1 :  torch.Size([10])\n",
      "lbl2data_input_ids_ptr-1 :  torch.Size([10])\n",
      "lbl2data_attention_mask_ptr-1 :  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "prefix = 'lbl2data'\n",
    "for k,v in o.items():\n",
    "    if re.match(f'^{prefix}_.*',k): print(k, ': ', v.shape if isinstance(v, torch.Tensor) else len(v))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304edcef-ccc6-40c4-a5e1-60f6414b1459",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dcd74d-c997-49ee-845f-814809609ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [{k:v for k,v in o.items() if re.match(r'^data_*',k)} for o in block.train.dset.one_batch()]\n",
    "tfm = NGPadFeatTfm(**PARAM)\n",
    "\n",
    "o = tfm(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ff2d2-a8cd-4427-9d28-2b0434bf71ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0c4ea5-3b45-4102-88b8-ffaa496124f1",
   "metadata": {},
   "source": [
    "### `TfmPipeline`: APPLY TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0055cc-d49b-4097-a16d-6120ccf0d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TfmPipeline:\n",
    "\n",
    "    def __init__(self, tfms:List):\n",
    "        self.tfms = tfms\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for tfm in self.tfms: x = tfm(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02006bc-7b82-4589-81f5-b95c1e28dc2b",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a6a7c4-5326-4021-9dff-2567010919ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [XCPadFeatTfm(**PARAM), AlignInputIdsTfm(**PARAM)]\n",
    "\n",
    "tfm = TfmPipeline(tfms)\n",
    "batch = block.train.dset.one_batch()\n",
    "\n",
    "o = tfm(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb70a2f-4bec-40f4-9ba5-63a71cc90465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f75de4-963f-4a13-85c3-a73ca65fcc1b",
   "metadata": {},
   "source": [
    "## Mid transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae2cd94-b6f9-4885-8545-8d017ee95ee4",
   "metadata": {},
   "source": [
    "### `AlignInputIdsTfm`: ALIGN TOKEN SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402929de-496b-45f9-a72e-5e85f249246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typedispatch\n",
    "def verify_align(src_ids:List, targ_ids:List):\n",
    "    for p,qs in zip(src_ids, targ_ids):\n",
    "        for q in qs: \n",
    "            if len(p)<len(q): print(len(p),' < ', len(q))\n",
    "            else: print(len(p),' > ', len(q))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563fe3c-fe62-4c5f-aed6-825a0dad248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch()\n",
    "batch = {k:[o[k] for o in batch] for k,v in batch[0].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc04a66-ffd9-45d0-aee0-485aacc87eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_identifier', 'data_input_text', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925109c9-57ec-43f4-80cc-fe09ee564fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM['ptr'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567b25a-a7e8-4a94-9c48-c18e038568ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = AlignInputIdsTfm(**PARAM)\n",
    "o = tfm(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5d370-848c-431d-aad4-b2dca02b3b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  >  5\n",
      "5  >  4\n",
      "11  >  7\n",
      "11  >  5\n",
      "11  >  5\n",
      "11  >  6\n",
      "11  >  5\n",
      "6  >  6\n",
      "7  >  7\n",
      "16  >  9\n",
      "4  >  4\n",
      "6  >  6\n",
      "7  >  7\n",
      "4  >  4\n"
     ]
    }
   ],
   "source": [
    "verify_align(o['data_input_ids'], o['lbl2data_input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88344ad-ea20-4c83-8b25-55fbe5162345",
   "metadata": {},
   "source": [
    "### `TriePruneInputIdsTfm`: PRUNE TOKEN SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e1437-32fe-41d2-9d97-a67c0e859897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriePruneInputIdsTfm:\n",
    "\n",
    "    def __init__(self, prefix:str='lbl2data'):\n",
    "        self.prefix = prefix\n",
    "\n",
    "    @staticmethod\n",
    "    def _flatten(x:List, o:List):\n",
    "        if not isinstance(x[0], list): o.append(x)\n",
    "        else: \n",
    "            for i in x: TriePruneInputIdsTfm._flatten(i, o)\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten(x:List):\n",
    "        flat_x = []\n",
    "        TriePruneInputIdsTfm._flatten(x, flat_x)\n",
    "        return flat_x\n",
    "        \n",
    "    @staticmethod\n",
    "    def _prune_feature(x:List, trie:Trie):\n",
    "        if not isinstance(x[0], list): return trie.prefix(x)\n",
    "        return [TriePruneInputIdsTfm._prune_feature(o, trie) for o in x]\n",
    "\n",
    "    def prune_feature(self, x:Dict, fld:str):\n",
    "        if fld not in x: raise ValueError(f'`{fld}` not in `x`')\n",
    "        v = self.flatten(x[fld])\n",
    "        trie = Trie.from_list(v)\n",
    "        trie.prune()\n",
    "        x[fld] = self._prune_feature(x[fld], trie)\n",
    "\n",
    "    @staticmethod\n",
    "    def _align_feature(inp:List, targ:List):\n",
    "        if not isinstance(inp[0], list): return targ[:len(inp)]\n",
    "        for i,(p,q) in enumerate(zip(inp, targ)): targ[i] = TriePruneInputIdsTfm._align_feature(p,q)\n",
    "        return targ\n",
    "\n",
    "    def align_feature(self, x:Dict, inp:str, targ:str):\n",
    "        if targ not in x: return\n",
    "        self._align_feature(x[inp], x[targ])\n",
    "        \n",
    "    def __call__(self, x:Dict, \n",
    "                 prefix:Optional[str]=None):\n",
    "        self.prefix = self.prefix if prefix is None else prefix\n",
    "        \n",
    "        self.prune_feature(x, f'{self.prefix}_input_ids')\n",
    "        self.align_feature(x, f'{self.prefix}_input_ids', f'{self.prefix}_attention_mask')\n",
    "        self.align_feature(x, f'{self.prefix}_input_ids', f'{self.prefix}_token_type_ids')\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdcb183-721e-42ad-a7b8-da0c560347df",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538407e0-a254-4a6b-9b3c-b0ee074de323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbl2data_input_ids :\n",
      "[[[101, 100, 200, 300, 102], [101, 200, 100, 100, 109, 102]], [[101, 200, 100, 100, 301, 102], [101, 300, 301, 200, 400, 500, 102], [101, 300, 301, 102]], [[101, 200, 100, 222, 301, 401, 501, 444, 102]]]\n",
      "lbl2data_attention_mask :\n",
      "[[[1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]], [[1, 1, 1, 1, 1, 1, 1, 1, 1]]]\n"
     ]
    }
   ],
   "source": [
    "lbl = [[[101, 100, 200, 300, 102],\n",
    "        [101, 200, 100, 100, 109, 102]],\n",
    "       [[101, 200, 100, 100, 301, 102],\n",
    "        [101, 300, 301, 200, 400, 500, 102],\n",
    "        [101, 300, 301, 102]],\n",
    "       [[101, 200, 100, 222, 301, 401, 501, 444, 102]]]\n",
    "\n",
    "mask = [[[1, 1, 1, 1, 1],\n",
    "         [1, 1, 1, 1, 1, 1]],\n",
    "        [[1, 1, 1, 1, 1, 1],\n",
    "         [1, 1, 1, 1],\n",
    "         [1, 1, 1, 1]],\n",
    "        [[1, 1, 1, 1, 1, 1, 1, 1, 1]]]\n",
    "\n",
    "x = {'lbl2data_input_ids': lbl, 'lbl2data_attention_mask': mask}\n",
    "for k,v in x.items(): print(k, ':'); print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48adbaa3-9bf8-44d0-8b47-a767a0f9caa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ff3d138b064d92a62930bfd53ae2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbl2data_input_ids :\n",
      "[[[101, 100, 102], [101, 200, 100, 100, 109, 102]], [[101, 200, 100, 100, 301, 102], [101, 300, 301, 200, 102], [101, 300, 301, 102]], [[101, 200, 100, 222, 102]]]\n",
      "lbl2data_attention_mask :\n",
      "[[[1, 1, 1], [1, 1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]], [[1, 1, 1, 1, 1]]]\n"
     ]
    }
   ],
   "source": [
    "tfm = TriePruneInputIdsTfm(prefix='lbl2data')\n",
    "o = tfm(x)\n",
    "for k,v in o.items(): \n",
    "    print(k, ':'); print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83eb190-3b5d-4432-aba5-9efc7ef332b0",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3bfca5-7527-46b7-86a6-4e3c85380d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch()\n",
    "batch = {k:[o[k] for o in batch] for k,v in batch[0].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a6e07-182c-4f18-abf2-31f3b1c7ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl2data_input_ids = batch['lbl2data_input_ids'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25659e1-c2d4-4fbb-b30c-c852cd369d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_identifier', 'data_input_text', 'data_input_ids', 'data_token_type_ids', 'data_attention_mask', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_token_type_ids', 'lbl2data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cba03c-3568-4c46-bdeb-a5d7c09ae992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404e621ab8ec41f9ae128ffb93763769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfm = TriePruneInputIdsTfm(prefix='lbl2data')\n",
    "o = tfm(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca365a0f-7bac-4f7c-af3b-add83f80efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_prune(x:List, y:List):\n",
    "    x = TriePruneInputIdsTfm.flatten(x)\n",
    "    y = TriePruneInputIdsTfm.flatten(y)\n",
    "    for p,q in zip(x,y):\n",
    "        if len(p) < len(q): print(len(p),' < ',len(q))\n",
    "        else: print(len(p),' > ',len(q))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da26cd-d134-45f9-9758-1403efe6dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_alignment(x:List, y:List):\n",
    "    x = TriePruneInputIdsTfm.flatten(x)\n",
    "    y = TriePruneInputIdsTfm.flatten(y)\n",
    "    return np.all([len(p)==len(q) for p,q in zip(x,y)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d906db5-73e3-4238-ad5a-f5ff4a2cdb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_alignment(batch['lbl2data_input_ids'], batch['lbl2data_attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b62ebc0-d90a-40a5-9cdf-3a4d110d084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  >  3\n",
      "10  >  5\n",
      "13  >  5\n",
      "8  >  3\n",
      "8  >  3\n",
      "4  >  3\n",
      "7  >  3\n",
      "6  >  3\n",
      "3  >  3\n",
      "11  >  5\n",
      "7  >  5\n",
      "5  >  3\n",
      "7  >  7\n",
      "7  >  7\n"
     ]
    }
   ],
   "source": [
    "verify_prune(lbl2data_input_ids, batch['lbl2data_input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710be008-8d34-413c-a194-5a4cc3195c0f",
   "metadata": {},
   "source": [
    "## Item transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c9c47-8494-4159-9050-e9d0ff1511cd",
   "metadata": {},
   "source": [
    "### `AugmentMetaInputIdsTfm`: AUGMENT INPUT TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe7c4a-fd0e-4291-b5fa-65b70ab0a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AugmentMetaInputIdsTfm:\n",
    "\n",
    "    def __init__(self, meta:str, max_len:Optional[int]=None, exclude_sep:Optional[bool]=False):\n",
    "        self.meta, self.max_len, self.exclude_sep = meta, max_len, exclude_sep\n",
    "    \n",
    "    def augment(self, data_ids:List, data_meta:sparse.csr_matrix, meta_ids:List):\n",
    "        meta2data_ids = []\n",
    "        for d_ids, d_meta in progress_bar(zip(data_ids, data_meta), total=len(data_ids)):\n",
    "            m2d_ids, sep_tok = d_ids[:-1].copy() if self.exclude_sep else d_ids.copy(), d_ids[-1:]\n",
    "            for o in d_meta.indices[np.random.permutation(len(d_meta.indices))]:\n",
    "                if self.exclude_sep: m2d_ids.extend(meta_ids[o][1:-1])\n",
    "                else: m2d_ids.extend(meta_ids[o][1:])\n",
    "                if self.max_len is not None and len(m2d_ids)>=self.max_len: m2d_ids = m2d_ids[:self.max_len-1]; break\n",
    "            meta2data_ids.append(m2d_ids+sep_tok)\n",
    "        return meta2data_ids\n",
    "\n",
    "    def proc(self, block:XCDataBlock, split:str, fld:str, side:Optional[str]='data'):\n",
    "        if side not in ['data', 'lbl']: \n",
    "            raise ValueError(\"Invalid `side`, it should be in ['data','lbl']\")\n",
    "            \n",
    "        if fld in get_attr(block, f'{split}.dset.data.{side}_info'):\n",
    "            data_ids = get_attr(block, f'{split}.dset.data.{side}_info')[fld]\n",
    "            meta_ids = get_attr(block, f'{split}.dset.meta.{self.meta}.meta_info')[fld]\n",
    "            data_meta = get_attr(block, f'{split}.dset.meta.{self.meta}.{side}_meta')\n",
    "            get_attr(block, f'{split}.dset.data.{side}_info')[f'{fld}_aug_{self.meta.split(\"_\")[0]}'] = self.augment(data_ids, data_meta, meta_ids)\n",
    "\n",
    "    def __call__(self, block:XCDataBlock, meta:str, side:Optional[str]='data', max_len:Optional[int]=None, \n",
    "                 exclude_sep:Optional[bool]=None):\n",
    "        store_attr('meta,max_len,exclude_sep', is_none=False)\n",
    "        for split in master_bar(['train', 'valid', 'test']):\n",
    "            if hasattr(block, split) and get_attr(block, split) is not None: \n",
    "                for fld in ['input_ids', 'attention_mask', 'token_type_ids']: self.proc(block, split, fld, side)\n",
    "        return block\n",
    "        \n",
    "    @classmethod\n",
    "    def apply(cls, block:XCDataBlock, meta:str, side:Optional[str]='data', max_len:Optional[int]=None, exclude_sep:Optional[bool]=False):\n",
    "        self = cls(meta, max_len, exclude_sep)\n",
    "        return self(block, meta, side, max_len, exclude_sep)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37c9ca-ad0d-48dd-99b9-53c1725e4c05",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510ff43-00c5-4f69-a315-e21543b2eedf",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f20a7b-dd35-4b63-9597-420b17883606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='554466' class='' max='554466' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [554466/554466 00:44&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='554466' class='' max='554466' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [554466/554466 00:40&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='137548' class='' max='137548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [137548/137548 00:11&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='137548' class='' max='137548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [137548/137548 00:09&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "o = AugmentMetaInputIdsTfm.apply(block, 'hlk_meta', 15, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da2d9e-4e34-4671-b1c8-583dea717119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['identifier', 'input_text', 'input_ids', 'attention_mask', 'input_ids_aug_hlk', 'attention_mask_aug_hlk'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.train.dset.data.data_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292e4af-2ab0-4ec2-a8b1-2cd2762da607",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = block.train.dset.data.data_info['attention_mask']\n",
    "q = block.train.dset.data.data_info['attention_mask_aug_hlk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71567f-722b-4815-9d12-8a2fcff85d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 15\n",
      "13 15\n",
      "9 15\n",
      "10 15\n",
      "4 15\n",
      "9 15\n",
      "8 15\n",
      "6 15\n",
      "9 15\n",
      "4 15\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.permutation(len(p))[:10]: print(len(p[i]), len(q[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35289ce3-b8dd-4387-89b6-45a2c131d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = block.train.dset.data.data_info['input_ids_aug_hlk']\n",
    "q = block.train.dset.data.data_info['attention_mask_aug_hlk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d7ad6-1db3-45dc-99fa-5062e4d56a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15\n",
      "15 15\n",
      "15 15\n",
      "15 15\n",
      "15 15\n",
      "15 15\n",
      "15 15\n",
      "13 13\n",
      "15 15\n",
      "15 15\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.permutation(len(p))[:10]: print(len(p[i]), len(q[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3c8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2522, 17040, 2239, 16569, 1997, 2605, 1996, 17830, 2063, 16944, 2099, 2605, 7640, 102]\n",
      "Length:  15\n",
      "[CLS] couzon communes of france thermae allier france departments [SEP]\n"
     ]
    }
   ],
   "source": [
    "tokz = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "n = 1000\n",
    "print(p[n])\n",
    "print(\"Length: \", len(p[n]))\n",
    "print(tokz.decode(p[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbca5d-9baa-4370-a880-5ad09587c140",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14d78e2-06c7-4a2b-8740-298e6e557db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = AugmentMetaInputIdsTfm('hlk_meta', 512, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550f22b-8349-4c14-b167-31fac0d74e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='693082' class='' max='693082' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [693082/693082 00:39&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='693082' class='' max='693082' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [693082/693082 00:35&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='177515' class='' max='177515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [177515/177515 00:09&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='177515' class='' max='177515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [177515/177515 00:09&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "o = AugmentMetaInputIdsTfm.apply(block, 'hlk_meta', 'data', 15, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130f2cd-e4e5-4d65-af13-a880cfec6a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d700f7-0e2c-433c-97fb-3d8750fb4613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='312330' class='' max='312330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [312330/312330 00:17&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='312330' class='' max='312330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [312330/312330 00:16&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='312330' class='' max='312330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [312330/312330 00:17&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='312330' class='' max='312330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [312330/312330 00:22&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "o = AugmentMetaInputIdsTfm.apply(block, 'hlk_meta', 'lbl', 32, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90cd8ce-705c-4a8b-96f2-b67166380cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49220089-2672-4b30-90ac-506b1aac3710",
   "metadata": {},
   "source": [
    "### `TriePruneInputIdsTfm`: PRUNE TOKEN SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcef461-de16-4425-aa68-cd6a3d8348f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TriePruneInputIdsTfm:\n",
    "\n",
    "    def prune(self, block:XCDataBlock, loc:str, fld:str):\n",
    "        x = get_attr(block, loc)\n",
    "        if fld in x:\n",
    "            trie = Trie.from_list(x[fld], None)\n",
    "            trie.prune()\n",
    "            x[f'{fld}_prn_tre'] = [trie.prefix(o) for o in x[fld]]\n",
    "\n",
    "    def align(self, block:XCDataBlock, loc:str, inp:str, targ:str):\n",
    "        x = get_attr(block, loc)\n",
    "        if inp in x and targ in x:\n",
    "            x[f'{targ}_prn_tre'] = [q[:len(p)] for i,(p,q) in enumerate(zip(x[inp],x[targ]))]\n",
    "        \n",
    "    def proc(self, block:XCDataBlock, loc:str):\n",
    "        self.prune(block, loc, 'input_ids')\n",
    "        self.align(block, loc, 'input_ids_prn_tre', 'attention_mask')\n",
    "        self.align(block, loc, 'input_ids_prn_tre', 'token_type_ids')\n",
    "        return block\n",
    "\n",
    "    def __call__(self, block:XCDataBlock, loc:str):\n",
    "        return self.proc(block, loc)\n",
    "\n",
    "    @classmethod\n",
    "    def apply(cls, block:XCDataBlock, loc:str):\n",
    "        self = cls()\n",
    "        return self(block, loc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd57cf1-458b-4ccf-81c7-d5b91b5534a4",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f42e547-6b42-4a23-9e41-ed8ed49b819e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60323008f7441168742d9e39c3b560d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "block = TriePruneInputIdsTfm.apply(block, 'train.dset.data.lbl_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f4de3f-dcd3-4905-aa1e-a7e298ab5527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['identifier', 'input_text', 'input_ids', 'attention_mask', 'input_ids_prn_tre', 'attention_mask_prn_tre'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.train.dset.data.lbl_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878650aa-ba49-4bb7-a0f2-1dbf44a29352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2293, 2818, 102]: 4 ; [101, 2293, 2818, 102]: 4\n",
      "[101, 16359, 102]: 3 ; [101, 16359, 102]: 3\n",
      "[101, 4794, 7120, 102]: 4 ; [101, 4794, 7120, 102]: 4\n",
      "[101, 2697, 1059, 102]: 4 ; [101, 2697, 1059, 16584, 9286, 7952, 102]: 7\n",
      "[101, 10067, 19948, 102]: 4 ; [101, 10067, 19948, 102]: 4\n",
      "[101, 25353, 4571, 13592, 22498, 2015, 102]: 7 ; [101, 25353, 4571, 13592, 22498, 2015, 102]: 7\n",
      "[101, 16215, 10735, 102]: 4 ; [101, 16215, 10735, 21007, 3686, 102]: 6\n",
      "[101, 1060, 22540, 102]: 4 ; [101, 1060, 22540, 9099, 3401, 16402, 102]: 7\n",
      "[101, 2862, 1997, 4291, 4290, 3152, 1997, 2901, 102]: 9 ; [101, 2862, 1997, 4291, 4290, 3152, 1997, 2901, 102]: 9\n",
      "[101, 13873, 8316, 102]: 4 ; [101, 13873, 8316, 1006, 4623, 1007, 102]: 7\n"
     ]
    }
   ],
   "source": [
    "x = block.train.dset.data.lbl_info\n",
    "rnd_idx = np.random.permutation(len(x['input_ids_prn_tre']))[:10]\n",
    "p,q = x['input_ids_prn_tre'],x['input_ids']\n",
    "for idx in rnd_idx: print(f'{p[idx]}: {len(p[idx])} ; {q[idx]}: {len(q[idx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c604a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce71f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b7f847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
