{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "483ee0f1-49bb-4794-9612-9e8182da0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.upma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "563da750-7f38-4597-948c-236a7ca27667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "464ed0be-1ad4-4722-96e7-791081a9abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "52a38dda-cc60-48e0-8528-a896969d33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, torch.nn as nn, re\n",
    "from dataclasses import dataclass\n",
    "from torch.nn.parallel import DataParallel\n",
    "from typing import Optional, Union, Tuple, Any, Dict, Sequence\n",
    "\n",
    "from transformers import DistilBertConfig, DistilBertModel, PretrainedConfig, PreTrainedModel\n",
    "from transformers.modeling_outputs import BaseModelOutput, ModelOutput\n",
    "from transformers.models.distilbert.modeling_distilbert import Embeddings, TransformerBlock\n",
    "from transformers.activations import get_activation\n",
    "\n",
    "from xcai.core import *\n",
    "from xcai.losses import *\n",
    "from xcai.learner import XCDataParallel\n",
    "from xcai.models.modeling_utils import Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1724c0fa-2829-42dc-bb53-1fed8107a973",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc73605-f2b1-4e69-9780-c1932fc9f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7558da2e-090d-4b47-81bc-d43c00854412",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/suchith720/Projects/data'\n",
    "config_file = 'wikiseealsotitles'\n",
    "config_key = 'data_meta'\n",
    "\n",
    "mname = 'sentence-transformers/msmarco-distilbert-base-v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dba6c85c-111e-4496-b9c0-66de3ac303b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = f'{data_dir}/processed/mogicX/'\n",
    "pkl_file = f'{pkl_dir}/wikiseealsotitles_data-meta_distilbert-base-uncased_sxc.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "072f908a-9942-4ccb-af2d-dfb3b624bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = build_block(pkl_file, config_file, True, config_key, data_dir=data_dir, \n",
    "                    n_sdata_meta_samples=3, do_build=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d1bba-3b4e-4f99-ab30-d3ac855edd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d61f91ea-52b0-428e-aaea-90352cbae018",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.__getitems__([10, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8ba99d74-faae-4d3e-bac2-0c088267a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_idx', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_data2ptr', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_data2ptr', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'pcat2lbl_idx', 'pcat2lbl_lbl2ptr', 'cat2lbl_idx', 'cat2lbl_lbl2ptr', 'cat2lbl_identifier', 'cat2lbl_input_text', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'cat2lbl_data2ptr', 'pcat2lbl_data2ptr'])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65120292-4da4-4316-81b0-d49942e92661",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "61fc143b-bd04-4d10-a838-728c10ed9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UPMAConfig(DistilBertConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_total_metadata: Optional[int] = None,\n",
    "        num_input_metadata: Optional[int] = 3,\n",
    "        pad_metadata_idx: Optional[int] = None,\n",
    "        metadata_dropout: Optional[float] = 0.1,\n",
    "        memory_injection_layer: Optional[int] = None,\n",
    "        memory_module_name: Optional[str] = \"embeddings\",\n",
    "        \n",
    "        data_aug_meta_prefix: Optional[str] = None, \n",
    "        lbl2data_aug_meta_prefix: Optional[str] = None,\n",
    "\n",
    "        data_enrich: Optional[bool] = True,\n",
    "        lbl2data_enrich: Optional[bool] = True,\n",
    "\n",
    "        margin: Optional[float] = 0.3,\n",
    "        num_negatives: Optional[int] = 10,\n",
    "        tau: Optional[float] = 0.1,\n",
    "        apply_softmax: Optional[bool] = True,\n",
    "\n",
    "        calib_margin: Optional[float] = 0.05,\n",
    "        calib_num_negatives: Optional[int] = 10,\n",
    "        calib_tau: Optional[float] = 0.1,\n",
    "        calib_apply_softmax: Optional[bool] = False,\n",
    "        \n",
    "        calib_loss_weight: Optional[float] = 0.1,\n",
    "        use_calib_loss: Optional[bool] = False,\n",
    "\n",
    "        use_encoder_parallel: Optional[bool] = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        store_attr('num_total_metadata,num_input_metadata,pad_metadata_idx,metadata_dropout,memory_module_name')\n",
    "        store_attr('data_aug_meta_prefix,lbl2data_aug_meta_prefix,data_enrich,lbl2data_enrich')\n",
    "        store_attr('margin,num_negatives,tau,apply_softmax')\n",
    "        store_attr('calib_margin,calib_num_negatives,calib_tau,calib_apply_softmax')\n",
    "        store_attr('calib_loss_weight,use_calib_loss')\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        if memory_injection_layer is None: self.memory_injection_layer = self.n_layers\n",
    "            \n",
    "        assert self.memory_injection_layer <= self.n_layers, (\n",
    "            f\"Invalid memory injection layer: {self.memory_injection_layer}. \"\n",
    "            f\"it must be less than the total number of layers ({self.n_layers}).\"\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19777e6-d47c-4903-a417-7031c5fe29d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d83bebd2-6fb8-4277-870c-304cf440af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_memory_module(name: str):\n",
    "    if name == \"embeddings\": return UPMAEmbeddingMemory\n",
    "    else: raise ValueError(f\"Invalid memory module: {name}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8a6af7-70b6-408c-ab89-40293db3ecea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "488154eb-8e12-41e0-8987-b98b0a44d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class UPMAEncoderOutput(BaseModelOutput):\n",
    "    repr: Optional[torch.FloatTensor] = None\n",
    "    \n",
    "@dataclass\n",
    "class UPMAModelOutput(ModelOutput):\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    data_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_repr: Optional[torch.FloatTensor] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d2580-d5b1-4e0a-b297-bf54218a534f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f3cb9f-2449-4ba3-90c4-26914e26771a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `FFN`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f8bab1-ce05-4092-9868-6279819f1e9d",
   "metadata": {},
   "source": [
    "* $\\hat{x} = dropout(W_2 * max(0, W_1 * x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "352e0cbc-95ff-4d17-985e-f38305c0f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FFN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig,\n",
    "        input_dim:int,\n",
    "        hidden_dim:int,\n",
    "        output_dim:int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=config.dropout)\n",
    "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
    "        self.seq_len_dim = 1\n",
    "        self.lin1 = nn.Linear(in_features=input_dim, out_features=hidden_dim)\n",
    "        self.lin2 = nn.Linear(in_features=hidden_dim, out_features=output_dim)\n",
    "        self.activation = get_activation(config.activation)\n",
    "        \n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return apply_chunking_to_forward(self.ff_chunk, self.chunk_size_feed_forward, self.seq_len_dim, input)\n",
    "\n",
    "    def ff_chunk(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.lin1(input)\n",
    "        x = self.activation(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937df2a6-0c22-417d-adcc-f0a97a65192a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `Embedding Memory`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c45035-daf4-4d72-800c-97389048673f",
   "metadata": {},
   "source": [
    "* $\\hat{\\mathcal{A}} = \\{a_1, a_2, a_3, \\dots a_n\\}$ be relevant metadata predicted by the linker.\n",
    "\n",
    "* $\\hat{\\mathcal{S}} = \\{s_1, s_2, s_3, \\dots s_n\\}$ be scores of the predicted metadata.\n",
    "\n",
    "* $\\hat{\\mathcal{R}} = \\{1, 2, 3, \\dots n\\}$ be rank for the predicted metadata.\n",
    "\n",
    "* $\\mathcal{K} \\in R^{M \\times D}$ be the $M$ memory items for each metadata.\n",
    "\n",
    "* $\\mathcal{P} \\in R^{N \\times D}$ be the $N$ positional embeddings.\n",
    "\n",
    "* Rank and score aware metadata representation: $x_m = \\mathcal{K}(\\hat{\\mathcal{A}}) + MLP(\\hat{\\mathcal{S}}) + \\mathcal{P}(\\hat{\\mathcal{R}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9aec34b2-9d4c-4fc2-9bfd-a8644e780b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UPMAEmbeddingMemory(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config: PretrainedConfig\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.metadata_embeddings = nn.Embedding(config.num_total_metadata, config.dim, padding_idx=config.pad_metadata_idx)\n",
    "        self.rank_embeddings = nn.Embedding(config.num_input_metadata, config.dim)\n",
    "        \n",
    "        self.score_ffn = FFN(config, input_dim=1, hidden_dim=config.hidden_dim, output_dim=config.dim)\n",
    "        self.out_ffn = FFN(config, input_dim=config.dim, hidden_dim=config.hidden_dim, output_dim=config.dim)\n",
    "\n",
    "        self.LayerNorm = nn.LayerNorm(config.dim, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.metadata_dropout)\n",
    "        self.register_buffer(\n",
    "            \"position_ids\", torch.arange(config.num_input_metadata).expand((1, -1)), persistent=False\n",
    "        )\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_idx: torch.Tensor,\n",
    "        input_embeds: Optional[torch.Tensor] = None,\n",
    "        input_scores: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        **kwargs,\n",
    "    ) -> torch.Tensor:\n",
    "        # `input_idx`: (bs, num_input_metadata)\n",
    "        # `input_scores`: (bs, num_input_metadata)\n",
    "        \n",
    "        if input_ids is not None:\n",
    "            input_embeds = self.metadata_embeddings(input_idx) # (bs, num_input_metadata, dim)\n",
    "            \n",
    "        if input_embeds.size(1) != self.num_input_metadata:\n",
    "            raise ValueError(\n",
    "                f\"Invalid input: expected {self.num_input_metadata} metadata items, \"\n",
    "                f\"but got {input_embeds.size(1)}.\"\n",
    "            )\n",
    "            \n",
    "        if position_ids is None:\n",
    "            position_ids = (\n",
    "                self.position_ids[:, :self.num_input_metadata]\n",
    "                if input_scores is None else \n",
    "                torch.argsort(scores, dim=1, descending=True)\n",
    "            )\n",
    "            \n",
    "        rank_embeddings = self.rank_embeddings(position_ids) # (bs, num_input_metadata, dim) or (1, num_input_metadata, dim)\n",
    "\n",
    "        embeddings = input_embeds + rank_embeddings\n",
    "\n",
    "        if input_scores is not None:\n",
    "            score_embeddings = self.score_ffn(input_scores) # (bs, num_input_metadata, dim)\n",
    "            embeddings = embeddings + score_embeddings\n",
    "            \n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return self.out_ffn(embeddings)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb42de0e-b03b-469c-af20-609dfa387f08",
   "metadata": {},
   "source": [
    "## `UPMA Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "45836e79-26b9-4315-a206-a0cfc292eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UPMAModel(PreTrainedModel):\n",
    "    config: UPMAConfig\n",
    "    load_tf_weights = None\n",
    "    base_model_prefix = \"distilbert\"\n",
    "    supports_gradient_checkpointing = True\n",
    "    _supports_flash_attn = True\n",
    "    _supports_sdpa = True\n",
    "    \n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__(config)\n",
    "        self.embeddings = Embeddings(config)\n",
    "        self.memory_module = get_memory_module(config.memory_module_name)(config)\n",
    "        \n",
    "        self.n_layers = config.n_layers\n",
    "        self.layer = nn.ModuleList([TransformerBlock(config) for _ in range(config.n_layers)])\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "        self._use_flash_attention_2 = config._attn_implementation == \"flash_attention_2\"\n",
    "        self._use_sdpa = config._attn_implementation == \"sdpa\"\n",
    "\n",
    "    def _init_weights(self, module: nn.Module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        elif isinstance(module, Embeddings) and self.config.sinusoidal_pos_embds:\n",
    "            create_sinusoidal_embeddings(\n",
    "                self.config.max_position_embeddings, self.config.dim, module.position_embeddings.weight\n",
    "            )\n",
    "        elif isinstance(module, UPMAEmbeddingMemory) and self.config.sinusoidal_pos_embds:\n",
    "            create_sinusoidal_embeddings(\n",
    "                self.config.num_input_metadata, self.config.dim, module.rank_embeddings.weight\n",
    "            )\n",
    "            \n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        return self.embeddings.position_embeddings\n",
    "\n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "        num_position_embeds_diff = new_num_position_embeddings - self.config.max_position_embeddings\n",
    "\n",
    "        # no resizing needs to be done if the length stays the same\n",
    "        if num_position_embeds_diff == 0:\n",
    "            return\n",
    "\n",
    "        logger.info(f\"Setting `config.max_position_embeddings={new_num_position_embeddings}`...\")\n",
    "        self.config.max_position_embeddings = new_num_position_embeddings\n",
    "\n",
    "        old_position_embeddings_weight = self.embeddings.position_embeddings.weight.clone()\n",
    "\n",
    "        self.embeddings.position_embeddings = nn.Embedding(self.config.max_position_embeddings, self.config.dim)\n",
    "\n",
    "        if self.config.sinusoidal_pos_embds:\n",
    "            create_sinusoidal_embeddings(\n",
    "                n_pos=self.config.max_position_embeddings, dim=self.config.dim, out=self.position_embeddings.weight\n",
    "            )\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                if num_position_embeds_diff > 0:\n",
    "                    self.embeddings.position_embeddings.weight[:-num_position_embeds_diff] = nn.Parameter(\n",
    "                        old_position_embeddings_weight\n",
    "                    )\n",
    "                else:\n",
    "                    self.embeddings.position_embeddings.weight = nn.Parameter(\n",
    "                        old_position_embeddings_weight[:num_position_embeds_diff]\n",
    "                    )\n",
    "        # move position_embeddings to correct device\n",
    "        self.embeddings.position_embeddings.to(self.device)\n",
    "\n",
    "    def get_input_embeddings(self) -> nn.Embedding:\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings: nn.Embedding):\n",
    "        self.embeddings.word_embeddings = new_embeddings\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune: dict[int, list[list[int]]]):\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.transformer.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        \n",
    "        metadata_idx: Optional[torch.Tensor] = None,\n",
    "        metadata_ids: Optional[torch.Tensor] = None,\n",
    "        metadata_attention_mask: Optional[torch.Tensor] = None,\n",
    "        metadata_scores: Optional[torch.Tensor] = None,\n",
    "        inject_memory: Optional[bool] = True,\n",
    "        \n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[BaseModelOutput, tuple[torch.Tensor, ...]]:\n",
    "         \n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            self.warn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        head_mask_is_none = head_mask is None\n",
    "        # Prepare head mask if needed\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
    "\n",
    "        embeddings = self.embeddings(input_ids, inputs_embeds)  # (bs, seq_length, dim)\n",
    "        if inject_memory:\n",
    "            memory_embeddings = self.memory_module(\n",
    "                input_idx=metadata_idx,\n",
    "                input_ids=metadata_ids,\n",
    "                input_attention_mask=metadata_attention_mask,\n",
    "                input_scores=metadata_scores\n",
    "            ) # (bs, num_input_metadata, dim)\n",
    "\n",
    "        if self._use_flash_attention_2:\n",
    "            attention_mask = attention_mask if (attention_mask is not None and 0 in attention_mask) else None\n",
    "        else:\n",
    "            if attention_mask is None:\n",
    "                attention_mask = torch.ones(input_shape, device=device)  # (bs, seq_length)\n",
    "\n",
    "            if self._use_sdpa and head_mask_is_none and not output_attentions:\n",
    "                attention_mask = _prepare_4d_attention_mask_for_sdpa(\n",
    "                    attention_mask, embeddings.dtype, tgt_len=input_shape[1]\n",
    "                )\n",
    "                \n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_attentions = () if output_attentions else None\n",
    "\n",
    "        hidden_state = embeddings\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_state,)\n",
    "\n",
    "            if inject_memory and i+1 == self.config.memory_injection_layer:\n",
    "                hidden_state = torch.cat([hidden_state, memory_embeddings], dim=1)\n",
    "                # modify the attention mask here.\n",
    "                \n",
    "            layer_outputs = layer_module(\n",
    "                hidden_state,\n",
    "                attention_mask,\n",
    "                head_mask[i],\n",
    "                output_attentions,\n",
    "            )\n",
    "\n",
    "            hidden_state = layer_outputs[-1]\n",
    "\n",
    "            if output_attentions:\n",
    "                if len(layer_outputs) != 2:\n",
    "                    raise ValueError(f\"The length of the layer_outputs should be 2, but it is {len(layer_outputs)}\")\n",
    "\n",
    "                attentions = layer_outputs[0]\n",
    "                all_attentions = all_attentions + (attentions,)\n",
    "            else:\n",
    "                if len(layer_outputs) != 1:\n",
    "                    raise ValueError(f\"The length of the layer_outputs should be 1, but it is {len(layer_outputs)}\")\n",
    "\n",
    "        # Add last layer\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_state,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(v for v in [hidden_state, all_hidden_states, all_attentions] if v is not None)\n",
    "            \n",
    "        return BaseModelOutput(\n",
    "            last_hidden_state=hidden_state, hidden_states=all_hidden_states, attentions=all_attentions\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27149f80-5d75-4664-9e4d-3efd4059c193",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "99fb3eac-ce1d-4125-a6dc-52411a85e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Parameters:\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_data_aug_meta_prefix_for_encoder(prefix:str, **kwargs):\n",
    "        inputs = {}\n",
    "        args = [arg for arg in kwargs if prefix is not None and re.match(f'^{prefix}.*_(input_ids|attention_mask|data2ptr|idx)$', arg)]\n",
    "        for arg in args:\n",
    "            meta,param = arg.split('_', maxsplit=1)\n",
    "            inputs.setdefault(meta, {})[f\"metadata_{param}\"] = kwargs[arg]\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_aug_meta_prefix_for_feature(feat:str, prefix:str, **kwargs):\n",
    "        keys = ['attention_mask', 'input_ids', 'idx']        \n",
    "        inputs = {f'{prefix}_{k}': kwargs[f'{prefix}_{k}'] for k in keys if f'{prefix}_{k}' in kwargs}\n",
    "        if prefix is not None and f'{prefix}_{feat}2ptr' in kwargs:\n",
    "            inputs.update({f'{prefix}_data2ptr': kwargs[f'{prefix}_{feat}2ptr']})\n",
    "        return inputs\n",
    "\n",
    "    @staticmethod\n",
    "    def from_aug_meta_prefix_for_loss(feat:str, prefix:str, **kwargs):\n",
    "        keys = [f'{prefix}_idx', f'p{prefix}_idx']\n",
    "        args = {k: kwargs[k] for k in keys if k in kwargs}\n",
    "        if prefix is not None and f'{prefix}_{feat}2ptr' in kwargs:\n",
    "            args.update({f'{prefix}_data2ptr': kwargs[f'{prefix}_{feat}2ptr']})\n",
    "        if prefix is not None and f'p{prefix}_{feat}2ptr' in kwargs:\n",
    "            args.update({f'p{prefix}_data2ptr': kwargs[f'p{prefix}_{feat}2ptr']})\n",
    "\n",
    "        inputs = {}\n",
    "        for arg in args:\n",
    "            meta,param = arg.split('_', maxsplit=1)\n",
    "            inputs.setdefault(meta, {})[param] = args[arg]\n",
    "        return inputs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585329e-3eef-4e65-a11b-840d2a1d1732",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b848a619-2e1b-498c-8502-19370b71e69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cat2lbl_attention_mask', 'cat2lbl_input_ids', 'cat2lbl_idx', 'cat2lbl_data2ptr'])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = Parameters.from_aug_meta_prefix_for_feature('lbl', 'cat2lbl', **batch)\n",
    "kwargs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "1c90c9a8-92f1-4e26-a309-93736130afca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat2lbl': {'metadata_attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0]]),\n",
       "  'metadata_input_ids': tensor([[  101, 17151, 12412,  4155,   102,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "          [  101, 12943, 23296, 21823, 19833,  3512,  4155,   102,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "          [  101,  7939,  2050, 29652,  4710, 18595, 20240,  2319,  4155,   102,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       "  'metadata_idx': tensor([174633,  53220, 331408]),\n",
       "  'metadata_data2ptr': tensor([1, 1, 1, 0])}}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parameters.from_data_aug_meta_prefix_for_encoder('cat2lbl', **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b3a20-713f-4e95-bfd7-b56a61723a1e",
   "metadata": {},
   "source": [
    "## `UPMAEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "3f23c229-1bd6-453a-a754-da743661f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UPMAEncoder(UPMAModel):\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls):\n",
    "        src_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        targ_model = cls(config)\n",
    "\n",
    "        src_sd, targ_sd = src_model.state_dict(), targ_model.state_dict()\n",
    "        src_keys, targ_keys = set(src_sd.keys()), set(targ_sd.keys())\n",
    "        \n",
    "        for k in src_keys.intersection(targ_keys):\n",
    "            assert targ_sd[k].shape == src_sd[k].shape, (\n",
    "                f\"Shape mismatch at key '{k}'. \"\n",
    "                f\"Expected {targ_sd[k].shape}, but got {src_sd[k].shape} in source state_dict.\"\n",
    "            )\n",
    "            targ_sd[k].copy_(src_sd[k])\n",
    "\n",
    "        diff_keys = targ_keys.difference(src_keys)\n",
    "        transformer_keys = [k for k in src_keys if k.startswith(\"transformer\")]\n",
    "        for k in transformer_keys:\n",
    "            targ_k = k.split('.', maxsplit=1)[1]\n",
    "            \n",
    "            assert targ_k in targ_sd, (\n",
    "                f\"Unexpected key '{targ_k}' encountered, not found in target state_dict.\"\n",
    "            )\n",
    "            \n",
    "            assert targ_sd[targ_k].shape == src_sd[k].shape, (\n",
    "                f\"Shape mismatch at key '{k}'. \"\n",
    "                f\"Expected {targ_sd[targ_k].shape}, but got {src_sd[k].shape} in source state_dict.\"\n",
    "            )\n",
    "            \n",
    "            targ_sd[targ_k].copy_(src_sd[k])\n",
    "            diff_keys.remove(targ_k)\n",
    "        return targ_model, diff_keys\n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_inject_memory: Optional[bool]=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        meta_kwargs = Parameters.from_data_aug_meta_prefix_for_encoder(data_aug_meta_prefix, **kwargs)\n",
    "        meta_kwargs = meta_kwargs.get(data_aug_meta_prefix, dict())\n",
    "        \n",
    "        output = super().forward(\n",
    "            input_ids=data_input_ids, \n",
    "            attention_mask=data_attention_mask,\n",
    "            inject_memory=data_inject_memory,\n",
    "            **meta_kwargs\n",
    "        )\n",
    "        \n",
    "        # NOTE: Pooling can be done according to modified attention mask.\n",
    "        data_repr = Pooling.mean_pooling(output[0], data_attention_mask)\n",
    "        return UPMAEncoderOutput(repr=data_repr, **output)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b4e74f-9080-4b21-a44d-dc2b2cf62177",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "c1e401e9-6a52-4592-a2c9-171ea872be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = UPMAConfig(\n",
    "    num_total_metadata=block.train.dset.meta['cat_meta'].n_meta,\n",
    "    num_input_metadata = 5,\n",
    "    pad_metadata_idx=None,\n",
    "    metadata_dropout=0.1,\n",
    "    memory_injection_layer=None,\n",
    "    memory_module_name=\"embeddings\",\n",
    "\n",
    "    data_aug_meta_prefix=\"cat2data\",\n",
    "    lbl2data_aug_meta_prefix=\"cat2lbl\",\n",
    "\n",
    "    data_enrich=True,\n",
    "    lbl2data_enrich=False,\n",
    "\n",
    "    margin=0.3,\n",
    "    num_negatives=5,\n",
    "    tau=0.1,\n",
    "    apply_softmax=True,\n",
    "\n",
    "    calib_margin=0.3,\n",
    "    calib_num_negatives=10,\n",
    "    calib_tau=0.1,\n",
    "    calib_apply_softmax=False,\n",
    "    \n",
    "    calib_loss_weight=0.1,\n",
    "    use_calib_loss=True,\n",
    "    \n",
    "    use_encoder_parallel=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "baecd2c8-1871-4caa-8fd3-8055fe2aeeb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/suchith720/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/suchith720/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model, new_keys = UPMAEncoder.from_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8619b56-30d5-4321-bca9-598ad973733f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "fc91d6e1-af0e-434f-b628-42bd3fb3fedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory_module.LayerNorm.bias',\n",
       " 'memory_module.LayerNorm.weight',\n",
       " 'memory_module.metadata_embeddings.weight',\n",
       " 'memory_module.out_ffn.lin1.bias',\n",
       " 'memory_module.out_ffn.lin1.weight',\n",
       " 'memory_module.out_ffn.lin2.bias',\n",
       " 'memory_module.out_ffn.lin2.weight',\n",
       " 'memory_module.rank_embeddings.weight',\n",
       " 'memory_module.score_ffn.lin1.bias',\n",
       " 'memory_module.score_ffn.lin1.weight',\n",
       " 'memory_module.score_ffn.lin2.bias',\n",
       " 'memory_module.score_ffn.lin2.weight'}"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "fffd29e8-101b-4a72-83da-5367ed52eacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(656086, 768)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.memory_module.metadata_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "4f20ac44-b8d8-4e47-979e-690272fd8b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker_dset = block.linker_dset('cat_meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b3916-aaf6-4ea3-8a1e-2316e9e09f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "e24587fb-2867-474d-b46c-30fb0c5850dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xcai.sdata.SMainXCDataset at 0x16872ae40>"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "b672f453-7927-4410-9875-d88e52f31d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = block.train.dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288ea28-9975-49e4-8b8c-0f80da7e7f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "ac3d0fca-1e87-402e-b714-3e07dd402b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_keys_to_ignore = [\"data_info\", \"data_lbl\", \"lbl_info\", \"data_lbl_filterer\", \"curr_data_lbl\", \"data_lbl_scores\"]\n",
    "args = [o for o in vars(dset.data).keys() if not o.startswith('__') and o not in _keys_to_ignore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "5c4a1ea8-5e3f-4ae3-b81e-298a746d5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {k: kwargs.get(k, getattr(dset.data, k)) for k in args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "881e6929-54f9-48c5-81ef-bae6976574f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_dset = type(dset.data)(data_info=dset.meta['cat_meta'].meta_info, **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3fcc54-c4bd-40a1-92b6-647ee0961c70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63af36f-dea7-437d-b30f-bcbcfd1796f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e0de6c7-5e05-4354-ae76-2fac1241aa70",
   "metadata": {},
   "source": [
    "## `UPA000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "b7d28224-725c-4349-8b7f-aa2df23b1635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UPA000(PreTrainedModel):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config: UPMAConfig,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.config, self.encoder = config, UPMAEncoder(config)\n",
    "        self.rep_loss_fn = MultiTriplet(margin=config.margin, n_negatives=config.num_negatives, tau=config.tau, \n",
    "                                        apply_softmax=config.apply_softmax, reduce='mean')\n",
    "        self.cab_loss_fn = Calibration(margin=config.calib_margin, tau=config.calib_tau, n_negatives=config.calib_num_negatives, \n",
    "                                       apply_softmax=config.calib_apply_softmax, reduce='mean')\n",
    "        \n",
    "    def init_heads_to_identity(self):\n",
    "        if self.encoder is None: raise ValueError('Encoder not initialized.')\n",
    "        self.encoder.init_heads_to_identity()\n",
    "\n",
    "    def init_combiner_to_last_layer(self):\n",
    "        if self.encoder is None: raise ValueError('Encoder not initialized.')\n",
    "        self.encoder.init_combiner_to_last_layer()\n",
    "\n",
    "    def set_memory_embeddings(self, embed:torch.Tensor):\n",
    "        if self.encoder is None: raise ValueError('Encoder not initialized.')\n",
    "        self.encoder.set_memory_embeddings(embed)\n",
    "        \n",
    "    def compute_loss(\n",
    "        self, \n",
    "        inp_repr: Optional[torch.Tensor] = None, \n",
    "        targ_repr: Optional[torch.Tensor] = None,\n",
    "        targ_ptr: Optional[torch.Tensor] = None, \n",
    "        targ_idx: Optional[torch.Tensor] = None,\n",
    "        ptarg_ptr: Optional[torch.Tensor] = None,\n",
    "        ptarg_idx: Optional[torch.Tensor] = None\n",
    "    ):\n",
    "        return self.rep_loss_fn(inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "\n",
    "    def calibration_loss(\n",
    "        self, \n",
    "        einp_repr: Optional[torch.Tensor] = None, \n",
    "        inp_repr: Optional[torch.Tensor] = None,\n",
    "        targ_repr: Optional[torch.Tensor] = None,\n",
    "        targ_ptr: Optional[torch.Tensor] = None,\n",
    "        targ_idx: Optional[torch.Tensor] = None,\n",
    "        ptarg_ptr: Optional[torch.Tensor] = None,\n",
    "        ptarg_idx: Optional[torch.Tensor] = None\n",
    "    ):\n",
    "        return self.config.calib_loss_weight * self.cab_loss_fn(einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids: Optional[torch.Tensor] = None,\n",
    "        data_attention_mask: Optional[torch.Tensor] = None,\n",
    "        lbl2data_data2ptr: Optional[torch.Tensor] = None,\n",
    "        lbl2data_idx: Optional[torch.Tensor] = None,\n",
    "        lbl2data_input_ids: Optional[torch.Tensor] = None,\n",
    "        lbl2data_attention_mask: Optional[torch.Tensor] = None,\n",
    "        plbl2data_data2ptr: Optional[torch.Tensor] = None,\n",
    "        plbl2data_idx: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        encoder = XCDataParallel(module=self.encoder) if self.config.use_encoder_parallel else self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_aug_meta_prefix_for_feature('data', self.config.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.config.data_aug_meta_prefix, data_enrich=self.config.data_enrich, **data_meta_kwargs)\n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_aug_meta_prefix_for_feature('lbl', self.config.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.config.lbl2data_aug_meta_prefix, data_enrich=self.config.lbl2data_enrich, **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.enriched_repr, lbl2data_o.repr,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.repr,lbl2data_o.repr)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "\n",
    "        return UPAModelOutput(\n",
    "            loss=loss,\n",
    "            data_repr=data_o.repr,\n",
    "            lbl2data_repr=lbl2data_o.repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc769de-9935-4078-8233-75d436021d46",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "053952ab-b015-418f-9af0-0eff9ad79268",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = UPMAConfig(\n",
    "    num_total_metadata=block.train.dset.meta['cat_meta'].n_meta,\n",
    "    num_input_metadata = 5,\n",
    "    pad_metadata_idx=None,\n",
    "    metadata_dropout=0.1,\n",
    "    memory_injection_layer=None,\n",
    "    memory_module_name=\"embeddings\",\n",
    "\n",
    "    data_aug_meta_prefix=\"cat2data\",\n",
    "    lbl2data_aug_meta_prefix=\"cat2lbl\",\n",
    "\n",
    "    data_enrich=True,\n",
    "    lbl2data_enrich=False,\n",
    "\n",
    "    margin=0.3,\n",
    "    num_negatives=5,\n",
    "    tau=0.1,\n",
    "    apply_softmax=True,\n",
    "\n",
    "    calib_margin=0.3,\n",
    "    calib_num_negatives=10,\n",
    "    calib_tau=0.1,\n",
    "    calib_apply_softmax=False,\n",
    "    \n",
    "    calib_loss_weight=0.1,\n",
    "    use_calib_loss=True,\n",
    "    \n",
    "    use_encoder_parallel=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "6c5041df-fd0f-46f1-9acf-f94a0026e2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UPA000(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e76436-578f-4462-824f-b6557282c654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
