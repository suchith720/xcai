{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd48060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.radga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc4a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import torch, re, inspect, pickle, os, torch.nn as nn, math\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Tuple, Mapping, Any, Union\n",
    "from transformers import (\n",
    "    PretrainedConfig,\n",
    "    DistilBertForMaskedLM,\n",
    "    DistilBertModel,\n",
    "    DistilBertPreTrainedModel,\n",
    ")\n",
    "from transformers.utils.generic import ModelOutput\n",
    "from transformers.activations import get_activation\n",
    "\n",
    "from fastcore.meta import *\n",
    "from fastcore.utils import *\n",
    "\n",
    "from xcai.losses import *\n",
    "from xcai.core import store_attr\n",
    "from xcai.learner import XCDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee9b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c00009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from xcai.block import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ede14",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc269b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/scai/phd/aiz218323/Projects/XC/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb671af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/xclib-0.97-py3.9-linux-x86_64.egg/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n"
     ]
    }
   ],
   "source": [
    "block = XCBlock.from_cfg(data_dir, 'data_metas', tfm='rm', tokenizer='distilbert-base-uncased', \n",
    "                         smp_features=[('lbl2data|cat2lbl2data',1,(1,3)), ('cat2data',1,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f3da90-d45a-40eb-bfeb-de65aa6cde4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c1d105-6978-44b6-a9c9-851220d03e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealso_data-meta_distilbert-base-uncased_rm_radga-cat.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843bd7a-d18c-4f44-bd4b-c56064ee937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'wb') as file: pickle.dump(block, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(5)\n",
    "for i,batch in enumerate(block.train.dl):\n",
    "    if i > 2: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63666b5",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class RADOutput(ModelOutput):\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    logits: Optional[torch.FloatTensor] = None\n",
    "    data_repr: Optional[torch.FloatTensor] = None\n",
    "    data_fused_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_repr: Optional[torch.FloatTensor] = None\n",
    "    lbl2data_fused_repr: Optional[torch.FloatTensor] = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc40c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class EncoderOutput(ModelOutput):\n",
    "    rep: Optional[torch.FloatTensor] = None\n",
    "    fused_rep: Optional[torch.FloatTensor] = None\n",
    "    logits: Optional[torch.FloatTensor] = None\n",
    "    fusion_weights: Optional[torch.FloatTensor] = None\n",
    "    meta_repr: Optional[torch.FloatTensor] = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Pooling:\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_pooling(data_embeds:torch.FloatTensor, data_attention_mask:torch.LongTensor):\n",
    "        data_attention_mask = data_attention_mask.unsqueeze(2).expand(data_embeds.size()).float()\n",
    "        return torch.sum(data_embeds * data_attention_mask, 1) / torch.clamp(data_attention_mask.sum(1), min=1e-9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f97b11c",
   "metadata": {},
   "source": [
    "## CrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a92acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CrossAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__()\n",
    "        self.config, self.n_h, self.dim = config, config.n_heads, config.dim\n",
    "        self.dropout = nn.Dropout(p=config.attention_dropout)\n",
    "\n",
    "        if self.dim % self.n_h != 0:\n",
    "            raise ValueError(f\"self.n_heads: {self.n_h} must divide self.dim: {self.dim} evenly.\")\n",
    "            \n",
    "        self.q = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.k = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.v = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.o = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "\n",
    "    def post_init(self):\n",
    "        self.q.weight.data = torch.eye(self.q.out_features, self.q.in_features, dtype=self.q.weight.dtype)\n",
    "        self.k.weight.data = torch.eye(self.k.out_features, self.k.in_features, dtype=self.k.weight.dtype)\n",
    "        self.v.weight.data = torch.eye(self.v.out_features, self.v.in_features, dtype=self.v.weight.dtype)\n",
    "        self.o.weight.data = torch.eye(self.o.out_features, self.o.in_features, dtype=self.o.weight.dtype)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        q: torch.Tensor,\n",
    "        q_m: torch.Tensor,\n",
    "        k: torch.Tensor, \n",
    "        k_m: torch.Tensor,\n",
    "        output_attentions:Optional[bool] = False,\n",
    "    ):\n",
    "        bs, q_len, dim = q.size()\n",
    "        v, k_len = k, k.size(1) \n",
    "\n",
    "        h_dim = self.dim//self.n_h\n",
    "\n",
    "        def shape(x: torch.Tensor): return x.view(bs, -1, self.n_h, h_dim).transpose(1, 2)\n",
    "\n",
    "        def unshape(x: torch.Tensor): return x.transpose(1, 2).contiguous().view(bs, -1, self.n_h * h_dim)\n",
    "\n",
    "        q = shape(self.q(q))  # (bs, n_h, q_len, h_dim)\n",
    "        k = shape(self.k(k))  # (bs, n_h, k_len, h_dim)\n",
    "        v = shape(self.v(v))  # (bs, n_h, k_len, h_dim)\n",
    "\n",
    "        q = q / math.sqrt(h_dim)  # (bs, n_h, q_len, h_dim)\n",
    "        sc = torch.matmul(q, k.transpose(2, 3))  # (bs, n_h, q_len, k_len)\n",
    "        \n",
    "        q_m, k_m = q_m.view(bs, 1, -1, 1).to(q.dtype), k_m.view(bs, 1, 1, -1).to(q.dtype)\n",
    "        mask = torch.matmul(q_m, k_m).expand_as(sc)  # (bs, n_h, q_len, k_len)\n",
    "        \n",
    "        sc = sc.masked_fill(mask == 0, torch.tensor(torch.finfo(sc.dtype).min))  # (bs, n_h, q_len, k_len)\n",
    "\n",
    "        w = nn.functional.softmax(sc, dim=-1)  # (bs, n_h, q_len, k_len)\n",
    "        w = self.dropout(w)  # (bs, n_h, q_len, k_len)\n",
    "\n",
    "        o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
    "        \n",
    "        if output_attentions: return (o, w)\n",
    "        else: return (o,)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258a231",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('distilbert-base-uncased')\n",
    "fuser = CrossAttention(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec047a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz, data_seq_len, n_meta, dim, dtype = 2, 3, 2, config.dim, torch.float32\n",
    "data, meta = torch.randn(bsz, data_seq_len, dim, dtype=dtype), torch.randn(bsz, n_meta, dim, dtype=dtype)\n",
    "data_mask = torch.randint(0, 2, size=(bsz,data_seq_len), dtype=dtype)\n",
    "meta_mask = torch.randint(0, 2, size=(bsz,n_meta), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = fuser(data, data_mask, meta, meta_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d426e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936fdbda-95ff-4531-ad45-09f0f5793534",
   "metadata": {},
   "source": [
    "## GatedCrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8691b3-0fdd-4e04-a1f7-a9442fcc3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GatedCrossAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, config: PretrainedConfig, margin:Optional[float]=0.3, tau:Optional[float]=0.1):\n",
    "        super().__init__()\n",
    "        store_attr('margin,tau')\n",
    "        self.config, self.n_h, self.dim = config, config.n_heads, config.dim\n",
    "        self.dropout = nn.Dropout(p=config.attention_dropout)\n",
    "\n",
    "        if self.dim % self.n_h != 0:\n",
    "            raise ValueError(f\"self.n_heads: {self.n_h} must divide self.dim: {self.dim} evenly.\")\n",
    "            \n",
    "        self.q = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.k = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.v = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.o = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "\n",
    "    def post_init(self):\n",
    "        self.q.weight.data = torch.eye(self.q.out_features, self.q.in_features, dtype=self.q.weight.dtype)\n",
    "        self.k.weight.data = torch.eye(self.k.out_features, self.k.in_features, dtype=self.k.weight.dtype)\n",
    "        self.v.weight.data = torch.eye(self.v.out_features, self.v.in_features, dtype=self.v.weight.dtype)\n",
    "        self.o.weight.data = torch.eye(self.o.out_features, self.o.in_features, dtype=self.o.weight.dtype)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        q: torch.Tensor,\n",
    "        q_m: torch.Tensor,\n",
    "        k: torch.Tensor, \n",
    "        k_m: torch.Tensor,\n",
    "        output_attentions:Optional[bool] = False,\n",
    "    ):\n",
    "        bs, q_len, dim = q.size()\n",
    "        v, k_len = k, k.size(1) \n",
    "\n",
    "        h_dim = self.dim//self.n_h\n",
    "\n",
    "        def shape(x: torch.Tensor): return x.view(bs, -1, self.n_h, h_dim).transpose(1, 2)\n",
    "\n",
    "        def unshape(x: torch.Tensor): return x.transpose(1, 2).contiguous().view(bs, -1, self.n_h * h_dim)\n",
    "\n",
    "        q = shape(self.q(q))  # (bs, n_h, q_len, h_dim)\n",
    "        k = shape(self.k(k))  # (bs, n_h, k_len, h_dim)\n",
    "        v = shape(self.v(v))  # (bs, n_h, k_len, h_dim)\n",
    "\n",
    "        q = q / math.sqrt(h_dim)  # (bs, n_h, q_len, h_dim)\n",
    "        sc = torch.matmul(q, k.transpose(2, 3))  # (bs, n_h, q_len, k_len)\n",
    "        sc = sc / self.tau\n",
    "\n",
    "        q_m, k_m = q_m.view(bs, 1, -1, 1).to(q.dtype), k_m.view(bs, 1, 1, -1).to(q.dtype)\n",
    "        mask = torch.matmul(q_m, k_m).expand_as(sc)  # (bs, n_h, q_len, k_len)\n",
    "        sc = sc.masked_fill(mask == 0, torch.tensor(torch.finfo(sc.dtype).min))  # (bs, n_h, q_len, k_len)\n",
    "\n",
    "        q_norm, k_norm = F.normalize(q, dim=-1), F.normalize(k, dim=-1)\n",
    "        gated_sc = torch.matmul(q_norm, k_norm.transpose(2, 3))\n",
    "        gated_sc = F.relu(gated_sc)\n",
    "        gated_mask = gated_sc != 0 \n",
    "        sc = sc.masked_fill(gated_mask == 0, torch.tensor(torch.finfo(sc.dtype).min))\n",
    "\n",
    "        w = nn.functional.softmax(sc, dim=-1)  # (bs, n_h, q_len, k_len)\n",
    "        w = w * mask * gated_mask\n",
    "        w = self.dropout(w)  # (bs, n_h, q_len, k_len)\n",
    "\n",
    "        o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
    "        \n",
    "        if output_attentions: return (o, w)\n",
    "        else: return (o,)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c937d-803e-419b-91a2-3002edd103b9",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a282707-094c-429c-97db-f0080d44c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('distilbert-base-uncased')\n",
    "fuser = GatedCrossAttention(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61a60e-c6e4-4822-9f7e-f29c52fd7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz, data_seq_len, n_meta, dim, dtype = 2, 3, 2, config.dim, torch.float32\n",
    "\n",
    "data, meta = torch.randn(bsz, data_seq_len, dim, dtype=dtype), torch.randn(bsz, n_meta, dim, dtype=dtype)\n",
    "data_mask = torch.randint(0, 2, size=(bsz,data_seq_len), dtype=dtype)\n",
    "meta_mask = torch.randint(0, 2, size=(bsz,n_meta), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb2581-f3c5-4635-a9e3-943074ba7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = fuser(data, data_mask, meta, meta_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9419a3bc-5e8f-46b9-b98f-95d07076b09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b46912f-df33-408d-8840-b9d18e723707",
   "metadata": {},
   "source": [
    "## GatedCrossAttention2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd457460-affa-4c21-b1ce-bcc3fdbe728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GatedCrossAttention2(nn.Module):\n",
    "    \n",
    "    def __init__(self, config: PretrainedConfig, margin:Optional[float]=0.3, tau:Optional[float]=0.1, dropout:Optional[float]=0.1):\n",
    "        super().__init__()\n",
    "        self.margin = nn.Parameter(torch.tensor(margin, dtype=torch.float32))\n",
    "        self.tau = nn.Parameter(torch.tensor(tau, dtype=torch.float32))\n",
    "        \n",
    "        self.config, self.n_h, self.dim = config, config.n_heads, config.dim\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        if self.dim % self.n_h != 0:\n",
    "            raise ValueError(f\"self.n_heads: {self.n_h} must divide self.dim: {self.dim} evenly.\")\n",
    "            \n",
    "        self.q = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.k = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.v = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.o = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "\n",
    "    def post_init(self):\n",
    "        self.q.weight.data = torch.eye(self.q.out_features, self.q.in_features, dtype=self.q.weight.dtype)\n",
    "        self.k.weight.data = torch.eye(self.k.out_features, self.k.in_features, dtype=self.k.weight.dtype)\n",
    "        self.v.weight.data = torch.eye(self.v.out_features, self.v.in_features, dtype=self.v.weight.dtype)\n",
    "        self.o.weight.data = torch.eye(self.o.out_features, self.o.in_features, dtype=self.o.weight.dtype)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        q: torch.Tensor,\n",
    "        q_m: torch.Tensor,\n",
    "        k: torch.Tensor, \n",
    "        k_m: torch.Tensor,\n",
    "        output_attentions:Optional[bool] = False,\n",
    "    ):\n",
    "        bs, q_len, dim = q.size()\n",
    "        v, k_len = k, k.size(1) \n",
    "\n",
    "        h_dim = self.dim//self.n_h\n",
    "\n",
    "        def shape(x: torch.Tensor): return x.view(bs, -1, self.n_h, h_dim).transpose(1, 2)\n",
    "\n",
    "        def unshape(x: torch.Tensor): return x.transpose(1, 2).contiguous().view(bs, -1, self.n_h * h_dim)\n",
    "\n",
    "        q = shape(self.q(q))  # (bs, n_h, q_len, h_dim)\n",
    "        k = shape(self.k(k))  # (bs, n_h, k_len, h_dim)\n",
    "        v = shape(self.v(v))  # (bs, n_h, k_len, h_dim)\n",
    "\n",
    "        q,k = F.normalize(q, dim=-1),F.normalize(k, dim=-1)\n",
    "        sc = torch.matmul(q, k.transpose(2, 3))  # (bs, n_h, q_len, k_len)\n",
    "        sc = F.relu(sc - self.margin)\n",
    "\n",
    "        sc = sc / self.tau\n",
    "        \n",
    "        q_m, k_m = q_m.view(bs, 1, -1, 1).to(q.dtype), k_m.view(bs, 1, 1, -1).to(q.dtype)\n",
    "        mask1 = torch.matmul(q_m, k_m).expand_as(sc)  # (bs, n_h, q_len, k_len)\n",
    "        sc = sc.masked_fill(mask1 == 0, torch.tensor(torch.finfo(sc.dtype).min))  # (bs, n_h, q_len, k_len)\n",
    "        mask2 = sc != 0\n",
    "        sc = sc.masked_fill(mask2 == 0, torch.tensor(torch.finfo(sc.dtype).min))\n",
    "        \n",
    "        w = nn.functional.softmax(sc, dim=-1)  # (bs, n_h, q_len, k_len)\n",
    "        w = self.dropout(w * mask1 * mask2)  # (bs, n_h, q_len, k_len)\n",
    "\n",
    "        o = self.o(unshape(torch.matmul(w, v))) # (bs, q_len, dim)\n",
    "        \n",
    "        if output_attentions: return (o, w)\n",
    "        else: return (o,)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46746ae-a119-4515-b582-93cd6a0d0e96",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5440729-1b64-40a1-b13c-dee28b0ba905",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('distilbert-base-uncased')\n",
    "fuser = GatedCrossAttention2(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d980489b-c299-47b5-8ee4-35919f52754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz, data_seq_len, n_meta, dim, dtype = 2, 3, 2, config.dim, torch.float32\n",
    "\n",
    "data, meta = torch.randn(bsz, data_seq_len, dim, dtype=dtype), torch.randn(bsz, n_meta, dim, dtype=dtype)\n",
    "data_mask = torch.randint(0, 2, size=(bsz,data_seq_len), dtype=dtype)\n",
    "meta_mask = torch.randint(0, 2, size=(bsz,n_meta), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6e6fa2-b5d2-4e09-aac1-a22713db3cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = fuser(data, data_mask, meta, meta_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1f1e7-1bb2-45f9-aaa9-e1a9df0282b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46f75c9",
   "metadata": {},
   "source": [
    "## Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e25a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RepresentationHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.transform = nn.Linear(config.dim, config.dim)\n",
    "        self.layer_norm = nn.LayerNorm(config.dim, eps=1e-12)\n",
    "        self.projector = nn.Linear(config.dim, config.dim)\n",
    "        self.activation = get_activation(config.activation)\n",
    "        \n",
    "        self.post_init()\n",
    "        \n",
    "    def post_init(self):\n",
    "        self.transform.weight.data = torch.eye(self.transform.out_features, self.transform.in_features, \n",
    "                                               dtype=self.transform.weight.dtype)\n",
    "        self.projector.weight.data = torch.eye(self.projector.out_features, self.projector.in_features, \n",
    "                                               dtype=self.projector.weight.dtype)\n",
    "        \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.transform(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.projector(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GenerationHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.transform = nn.Linear(config.dim, config.dim)\n",
    "        self.layer_norm = nn.LayerNorm(config.dim, eps=1e-12)\n",
    "        self.projector = nn.Linear(config.dim, config.vocab_size)\n",
    "        self.activation = get_activation(config.activation)\n",
    "        \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.transform(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.projector(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa14f380",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bd2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('distilbert-base-uncased')\n",
    "x = torch.randn(10, 20, config.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76321c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RepresentationHead(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ea52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = GenerationHead(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9224630",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ca951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Parameters:\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_meta_aug_prefix(prefix:str, **kwargs):\n",
    "        inputs = {}\n",
    "        args = [arg for arg in kwargs if prefix is not None and re.match(f'^{prefix}.*_(input_ids|attention_mask|data2ptr|meta_repr|idx)$', arg)]\n",
    "        for arg in args:\n",
    "            meta,param = arg.split('_', maxsplit=1)\n",
    "            inputs.setdefault(meta, {})[param] = kwargs[arg]\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_feat_meta_aug_prefix(feat:str, prefix:str, **kwargs):\n",
    "        keys = ['attention_mask', 'input_ids', 'meta_repr', 'idx']\n",
    "        \n",
    "        inputs = {f'{prefix}_{k}': kwargs[f'{prefix}_{k}'] for k in keys if f'{prefix}_{k}' in kwargs}\n",
    "        if prefix is not None and f'{prefix}_{feat}2ptr' in kwargs:\n",
    "            inputs.update({f'{prefix}_data2ptr': kwargs[f'{prefix}_{feat}2ptr']})\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_meta_pred_prefix(prefix:str, **kwargs):\n",
    "        inputs = {}\n",
    "        args = [arg for arg in kwargs if prefix is not None and re.match(f'^[p]?{prefix}.*', arg)]\n",
    "        for arg in args:\n",
    "            meta,param = arg.split('_', maxsplit=1)\n",
    "            if arg[0] == 'p': \n",
    "                inputs.setdefault(meta[1:], {})[f'p{param}'] = kwargs[arg]\n",
    "            else: \n",
    "                inputs.setdefault(meta, {})[param] = kwargs[arg]\n",
    "        return inputs\n",
    "\n",
    "    @staticmethod\n",
    "    def get_meta_loss_weights(lw:Union[float,List], n_meta:int):\n",
    "        if isinstance(lw, float):\n",
    "            lw = lw/n_meta if n_meta else None\n",
    "            return [lw] * n_meta\n",
    "        else:\n",
    "            if len(lw) != n_meta: raise ValueError(f'length of `lw` should be equal to number of metadata.')\n",
    "            return lw\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c76edd-7068-43c8-b661-5cbb185e788c",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2517ed38-5df8-40e5-8587-a09aca55fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(block.train.dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5429b9a1-8f1f-44b1-ba3f-e7c01e04b1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cat2lbl', 'cat2data'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Parameters.from_meta_aug_prefix('cat', **b); p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668bf4d9-4748-422b-a6a1-a0b502dcfcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cat2lbl_attention_mask', 'cat2lbl_input_ids', 'cat2lbl_data2ptr'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Parameters.from_feat_meta_aug_prefix('data', 'cat2lbl', **b); p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58af55d5-31aa-4b4a-8ea5-23e88d9770d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cat2lbl', 'cat2data'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Parameters.from_meta_pred_prefix('cat', **b); p.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a8737b",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder(DistilBertPreTrainedModel):\n",
    "    \n",
    "    def __init__(self, config:PretrainedConfig, use_noise:Optional[bool]=True, noise_pct:Optional[float]=0.5, resize_length:Optional[int]=None):\n",
    "        super().__init__(config)\n",
    "        store_attr('use_noise,noise_pct')\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        \n",
    "        self.dr_head = RepresentationHead(config)\n",
    "        self.dr_fused_head =  RepresentationHead(config)\n",
    "        self.meta_head = RepresentationHead(config)\n",
    "        self.cross_head = CrossAttention(config)\n",
    "         \n",
    "        self.ones = torch.ones(resize_length, dtype=torch.long, device=self.device) if resize_length is not None else None\n",
    "        self.post_init()\n",
    "        \n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        return self.distilbert.get_position_embeddings()\n",
    "    \n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "        self.distilbert.resize_position_embeddings(new_num_position_embeddings)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def resize(self, inputs:torch.Tensor, mask:torch.Tensor, num_inputs:torch.Tensor):\n",
    "        if torch.any(num_inputs == 0): raise ValueError(\"`num_inputs` should be non-zero positive integer.\")\n",
    "        bsz, dim, total_num_inputs = num_inputs.shape[0], inputs.shape[-1], inputs.shape[0]\n",
    "        \n",
    "        self.ones = self.ones.to(inputs.device)\n",
    "        ones = (\n",
    "            torch.ones(total_num_inputs, dtype=torch.long, device=inputs.device) \n",
    "            if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
    "        )\n",
    "\n",
    "        max_num_inputs = num_inputs.max()\n",
    "        xnum_inputs = max_num_inputs-num_inputs+1\n",
    "\n",
    "        inputs_ptr = num_inputs.cumsum(dim=0)-1\n",
    "        repeat_inputs = ones.scatter(0, inputs_ptr, xnum_inputs)\n",
    "        \n",
    "        resized_inputs = inputs.repeat_interleave(repeat_inputs, dim=0)\n",
    "        resized_mask = mask.repeat_interleave(repeat_inputs, dim=0)\n",
    "        \n",
    "        ignore_mask_idx = ones.scatter(0, inputs_ptr, 0).repeat_interleave(repeat_inputs, dim=0).view(bsz, -1)\n",
    "        ignore_mask_idx[:, -1] = 1; ignore_mask_idx = ignore_mask_idx.view(-1, 1)\n",
    "        \n",
    "        resized_mask *= ignore_mask_idx\n",
    "        \n",
    "        return resized_inputs,resized_mask\n",
    "        \n",
    "    def add_noise(self, input_ids:torch.Tensor, attention_mask:torch.Tensor, n_meta:int):\n",
    "        n_data, dim = input_ids.shape[0]//n_meta, input_ids.shape[1]\n",
    "        noise_mask = torch.rand(n_meta, n_data, device=input_ids.device) < self.noise_pct\n",
    "        \n",
    "        input_ids, attention_mask = input_ids.view(n_data, n_meta, -1), attention_mask.view(n_data, n_meta, -1)\n",
    "        for i,mask in enumerate(noise_mask):\n",
    "            rnd_idx = torch.randperm(mask.sum())\n",
    "            input_ids[:,i][mask] = input_ids[:,i][mask][rnd_idx]\n",
    "            attention_mask[:,i][mask] = attention_mask[:,i][mask][rnd_idx]\n",
    "        return input_ids.view(-1, dim), attention_mask.view(-1, dim)\n",
    "        \n",
    "\n",
    "    \n",
    "    def encode(self, input_ids:torch.Tensor, attention_mask:torch.Tensor, **kwargs):\n",
    "        return self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    def dr(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.dr_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "\n",
    "    def dr_fused(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.dr_fused_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "\n",
    "    def meta(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.meta_head(embed)\n",
    "        return F.normalize(Pooling.mean_pooling(embed, attention_mask), dim=1)\n",
    "    \n",
    "    def meta_unnormalized(self, embed:torch.Tensor, attention_mask:torch.Tensor):\n",
    "        embed = self.meta_head(embed)\n",
    "        return Pooling.mean_pooling(embed, attention_mask)\n",
    "\n",
    "\n",
    "    \n",
    "    def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
    "            \n",
    "            if len(idx):\n",
    "                if 'meta_repr' in m_args:\n",
    "                    m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
    "                    m_repr,m_repr_mask = self.resize(m_repr, m_repr_mask, m_args['data2ptr'][idx])\n",
    "                    m_repr_mask = m_repr_mask.bool()\n",
    "                else:\n",
    "                    m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
    "                                                                m_args['data2ptr'][idx])\n",
    "                    n_meta = m_args['data2ptr'].max()\n",
    "                    \n",
    "                    if self.use_noise:\n",
    "                        m_input_ids, m_attention_mask = self.add_noise(m_input_ids, m_attention_mask, n_meta)\n",
    "\n",
    "                    m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
    "\n",
    "                    m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
    "                    m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
    "                    \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
    "                \n",
    "                meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
    "                \n",
    "                fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                embed[idx] += fused_embed\n",
    "                \n",
    "        return embed, meta_repr\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_type:Optional[str]=None,\n",
    "        data_unnormalized:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        \n",
    "        if data_type is not None and data_type == \"meta\":\n",
    "            data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
    "        else: \n",
    "            data_repr = self.dr(data_o[0], data_attention_mask)\n",
    "        \n",
    "        data_fused_repr = meta_repr = None\n",
    "        if data_aug_meta_prefix is not None:\n",
    "            meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
    "            if len(meta_kwargs):\n",
    "                data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
    "                                                                             data_attention_mask, \n",
    "                                                                             meta_kwargs)\n",
    "                data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
    "        \n",
    "        return EncoderOutput(\n",
    "            rep=data_repr,\n",
    "            fused_rep=data_fused_repr,\n",
    "            meta_repr=meta_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba618800-3966-4b2a-b887-96faa1cda5b5",
   "metadata": {},
   "source": [
    "## `RAD000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51c610-41c8-4752-b2e6-5ac4cd5492ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RAD000(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, config,\n",
    "        \n",
    "        num_batch_labels:Optional[int]=None, \n",
    "        batch_size:Optional[int]=None,\n",
    "        margin:Optional[float]=0.3,\n",
    "        num_negatives:Optional[int]=5,\n",
    "        tau:Optional[float]=0.1,\n",
    "        apply_softmax:Optional[bool]=True,\n",
    "        \n",
    "        data_aug_meta_prefix:Optional[str]=None, \n",
    "        lbl2data_aug_meta_prefix:Optional[str]=None, \n",
    "\n",
    "        data_pred_meta_prefix:Optional[str]=None,\n",
    "        lbl2data_pred_meta_prefix:Optional[str]=None,\n",
    "        \n",
    "        meta_loss_weight:Optional[Union[List,float]]=0.3,\n",
    "        use_fusion_loss:Optional[bool]=False,\n",
    "        fusion_loss_weight:Optional[float]=0.15,\n",
    "        \n",
    "        use_encoder_parallel:Optional[bool]=True,\n",
    "    ):\n",
    "        super().__init__(config)\n",
    "        self.m_lw, self.f_lw = meta_loss_weight, fusion_loss_weight\n",
    "        store_attr('data_pred_meta_prefix,lbl2data_pred_meta_prefix')\n",
    "        store_attr('data_aug_meta_prefix,lbl2data_aug_meta_prefix')\n",
    "        store_attr('use_fusion_loss,use_encoder_parallel')\n",
    "        \n",
    "        self.encoder = None\n",
    "        self.rep_loss_fn = MultiTriplet(bsz=batch_size, tn_targ=num_batch_labels, margin=margin, n_negatives=num_negatives, \n",
    "                                        tau=tau, apply_softmax=apply_softmax, reduce='mean')\n",
    "        \n",
    "    def init_retrieval_head(self):\n",
    "        if self.encoder is None: raise ValueError('`self.encoder` is not initialized.')\n",
    "        self.encoder.dr_head.post_init()\n",
    "        self.encoder.dr_fused_head.post_init()\n",
    "        self.encoder.meta_head.post_init()\n",
    "\n",
    "    def init_cross_head(self):\n",
    "        if self.encoder is None: raise ValueError('`self.encoder` is not initialized.')\n",
    "        self.encoder.cross_head.post_init()\n",
    "        \n",
    "    \n",
    "    def disable_noise(self):\n",
    "        if self.encoder is None: raise ValueError('`self.encoder` is not initialized.')\n",
    "        use_noise = self.encoder.module.use_noise if isinstance(self.encoder, XCDataParallel) else self.encoder.use_noise\n",
    "        if isinstance(self.encoder, XCDataParallel): self.encoder.module.use_noise = False\n",
    "        else: self.encoder.use_noise = False\n",
    "        return use_noise\n",
    "    \n",
    "    def set_noise(self, use_noise):\n",
    "        if self.encoder is None: raise ValueError('`self.encoder` is not initialized.')\n",
    "        if isinstance(self.encoder, XCDataParallel): self.encoder.module.use_noise = use_noise\n",
    "        else: self.encoder.use_noise = use_noise\n",
    "            \n",
    "    def get_noise(self):\n",
    "        if self.encoder is None: raise ValueError('`self.encoder` is not initialized.')\n",
    "        return self.encoder.module.use_noise if isinstance(self.encoder, XCDataParallel) else self.encoder.use_noise\n",
    "\n",
    "    \n",
    "\n",
    "    def compute_loss(self, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.rep_loss_fn(inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "    \n",
    "    def compute_meta_loss(self, data_repr, lbl2data_repr, **kwargs):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "            \n",
    "        data_meta_inputs = Parameters.from_meta_pred_prefix(self.data_pred_meta_prefix, **kwargs)\n",
    "        lbl2data_meta_inputs = Parameters.from_meta_pred_prefix(self.lbl2data_pred_meta_prefix, **kwargs)\n",
    "        meta_inputs = {**data_meta_inputs, **lbl2data_meta_inputs}\n",
    "\n",
    "        m_lw = Parameters.get_meta_loss_weights(self.m_lw, len(meta_inputs)) if len(meta_inputs) else []\n",
    "        \n",
    "        loss = 0.0\n",
    "        for inputs,lw in zip(meta_inputs.values(), m_lw):\n",
    "            if 'lbl2data2ptr' in inputs:\n",
    "                idx = torch.where(inputs['lbl2data2ptr'])[0]\n",
    "                if len(idx) > 0:\n",
    "                    inputs_o = encoder(data_input_ids=inputs['input_ids'], data_attention_mask=inputs['attention_mask'], \n",
    "                                       data_type=\"meta\")\n",
    "                    m_loss = self.rep_loss_fn(lbl2data_repr[idx], inputs_o.rep, inputs['lbl2data2ptr'][idx],\n",
    "                                              inputs['idx'], inputs['plbl2data2ptr'][idx], inputs['pidx'])\n",
    "                    loss += lw * m_loss\n",
    "\n",
    "            elif 'data2ptr' in inputs:\n",
    "                idx = torch.where(inputs['data2ptr'])[0]\n",
    "                if len(idx) > 0:\n",
    "                    inputs_o = encoder(data_input_ids=inputs['input_ids'], data_attention_mask=inputs['attention_mask'], \n",
    "                                       data_type=\"meta\")\n",
    "                    m_loss = self.rep_loss_fn(data_repr[idx], inputs_o.rep, inputs['data2ptr'][idx], inputs['idx'], \n",
    "                                              inputs['pdata2ptr'][idx], inputs['pidx'])\n",
    "                    loss += lw * m_loss       \n",
    "\n",
    "            else: raise ValueError('Invalid metadata input arguments.')\n",
    "        return loss\n",
    "\n",
    "    def compute_fusion_loss(self, data_repr, meta_repr:Dict, prefix:str, **kwargs):\n",
    "        meta_inputs = Parameters.from_meta_pred_prefix(prefix, **kwargs)\n",
    "        \n",
    "        loss = 0.0\n",
    "        if meta_repr is not None:\n",
    "            for key,input_repr in meta_repr.items():\n",
    "                inputs = meta_inputs[key]\n",
    "                if 'lbl2data2ptr' in inputs:\n",
    "                    idx = torch.where(inputs['lbl2data2ptr'])[0]\n",
    "                    if len(idx) > 0:\n",
    "                        m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['lbl2data2ptr'][idx],\n",
    "                                                  inputs['idx'], inputs['plbl2data2ptr'][idx], inputs['pidx'])\n",
    "                        loss += self.f_lw * m_loss\n",
    "    \n",
    "                elif 'data2ptr' in inputs:\n",
    "                    idx = torch.where(inputs['data2ptr'])[0]\n",
    "                    if len(idx) > 0:\n",
    "                        m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['data2ptr'][idx], inputs['idx'], \n",
    "                                                  inputs['pdata2ptr'][idx], inputs['pidx'])\n",
    "                        loss += self.f_lw * m_loss       \n",
    "    \n",
    "                else: raise ValueError('Invalid metadata input arguments.')\n",
    "        return loss\n",
    "\n",
    "\n",
    "    \n",
    "    def get_meta_representation(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "            \n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_unnormalized=True, data_type=\"meta\")\n",
    "        return RADOutput(\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "        )\n",
    "\n",
    "    \n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c613ba79",
   "metadata": {},
   "source": [
    "## `RAD001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f4f42-9489-4c8b-9e7f-2304e07ba42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RAD001Encoder(Encoder):\n",
    "\n",
    "    def __init__(self, config:PretrainedConfig, use_noise:Optional[bool]=True, noise_pct:Optional[float]=0.5, resize_length:Optional[int]=None):\n",
    "        super().__init__(config, use_noise, noise_pct, resize_length)        \n",
    "        self.gen_head = GenerationHead(config)\n",
    "        \n",
    "        \n",
    "    def get_output_embeddings(self) -> nn.Module:\n",
    "        return self.gen_head.projector\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings: nn.Module):\n",
    "        self.gen_head.projector = new_embeddings\n",
    "\n",
    "    \n",
    "    \n",
    "    def gen(self, x:torch.Tensor):\n",
    "        return self.gen_head(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_gen_idx:Optional[torch.Tensor]=None,\n",
    "        data_type:Optional[str]=None,\n",
    "        data_unnormalized:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        \n",
    "        if data_type is not None and data_type == \"meta\":\n",
    "            data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
    "        else: \n",
    "            data_repr = self.dr(data_o[0], data_attention_mask)\n",
    "            \n",
    "        data_embed = data_o[0]\n",
    "        data_fused_repr = data_logits = meta_repr = None\n",
    "        if data_aug_meta_prefix is not None:\n",
    "            meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
    "            if len(meta_kwargs):\n",
    "                data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
    "                                                                             data_attention_mask, \n",
    "                                                                             meta_kwargs)\n",
    "                data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
    "                data_logits = self.gen(data_fused_embed if data_gen_idx is None else data_fused_embed[data_gen_idx])\n",
    "                \n",
    "        if data_logits is None:\n",
    "            data_fused_repr = data_repr\n",
    "            data_logits = self.gen(data_embed if data_gen_idx is None else data_embed[data_gen_idx])    \n",
    "        \n",
    "        return EncoderOutput(\n",
    "            rep=data_repr,\n",
    "            fused_rep=data_fused_repr,\n",
    "            \n",
    "            logits=data_logits,\n",
    "            \n",
    "            meta_repr=meta_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9073dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RAD001(RAD000, DistilBertForMaskedLM):\n",
    "    use_generation,use_representation = True,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\", \"encoder.gen_head.transform\", \"encoder.gen_head.layer_norm\", \n",
    "                          \"encoder.gen_head.projector\"]\n",
    "    \n",
    "    @delegates(RAD000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,\n",
    "        \n",
    "        num_batch_labels:Optional[int]=None, \n",
    "        ignore_token:Optional[int]=0,\n",
    "        gen_loss_weight:Optional[float]=0.01,\n",
    "\n",
    "        resize_length:Optional[int]=None,\n",
    "        use_noise:Optional[bool]=False,\n",
    "        noise_percent:Optional[float]=0.7,\n",
    "        \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, num_batch_labels=num_batch_labels, **kwargs)\n",
    "        self.lw = gen_loss_weight\n",
    "        \n",
    "        self.encoder = RAD001Encoder(config, use_noise=use_noise, noise_pct=noise_percent, resize_length=resize_length)\n",
    "        self.gen_loss_fn = MultiCrossEntropy(tn_targ=num_batch_labels, ig_tok=ignore_token, reduce='mean')\n",
    "        \n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_generation_head()\n",
    "\n",
    "\n",
    "    \n",
    "    def init_generation_head(self):\n",
    "        self.encoder.gen_head.projector.weight.data = self.get_input_embeddings().weight.data.clone()\n",
    "        \n",
    "    def remap_post_init(self):\n",
    "        self.encoder.distilbert = self.distilbert \n",
    "        self.encoder.gen_head.transform = self.vocab_transform\n",
    "        self.encoder.gen_head.layer_norm = self.vocab_layer_norm\n",
    "        self.encoder.gen_head.projector = self.vocab_projector\n",
    "        \n",
    "\n",
    "    \n",
    "    def compute_loss(self, inp_logits, inp_repr, targ_logits, targ_repr, \n",
    "                     inp_input_ids, targ_input_ids, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        \n",
    "        gen_loss = self.gen_loss_fn(inp_logits, targ_input_ids, targ_ptr) + self.gen_loss_fn(targ_logits, inp_input_ids)\n",
    "        rep_loss = self.rep_loss_fn(inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "        return rep_loss + self.lw * gen_loss\n",
    "        \n",
    "        \n",
    "    def get_last_item_mask(self, num_input:torch.Tensor, input_sz:int):\n",
    "        idx = torch.where(num_input > 0)[0]\n",
    "        input_ptr = num_input[idx].cumsum(dim=0)-1\n",
    "        return torch.zeros(input_sz, dtype=torch.bool, device=num_input.device).scatter(0, input_ptr, 1)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_gen_idx = self.get_last_item_mask(lbl2data_data2ptr, len(lbl2data_idx))\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, data_gen_idx=lbl2data_gen_idx,\n",
    "                                 **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.logits, data_o.fused_rep, lbl2data_o.logits, lbl2data_o.fused_rep, \n",
    "                                     data_input_ids,lbl2data_input_ids,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.fused_rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.fused_rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            logits=data_o.logits,\n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6473ad96",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c8fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RAD001 were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.gen_head.projector.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight', 'vocab_projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RAD001.from_pretrained('distilbert-base-uncased', num_batch_labels=5000, ignore_token=0, batch_size=100,\n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='hlk2data', lbl2data_aug_meta_prefix='hlk2lbl', \n",
    "                               data_pred_meta_prefix='cat2data', lbl2data_pred_meta_prefix='cat2lbl',\n",
    "                               \n",
    "                               resize_length=5000, use_noise=True, noise_percent=0.3,\n",
    "                               \n",
    "                               gen_loss_weight=0.001, meta_loss_weight=0.3, fusion_loss_weight=0.1,\n",
    "                               \n",
    "                               tie_word_embeddings=False, use_fusion_loss=False,  use_encoder_parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_retrieval_head()\n",
    "model.init_generation_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816aa8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49343f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "    'pcat2lbl_idx', 'pcat2lbl_lbl2data2ptr', 'pcat2lbl_data2ptr', 'cat2lbl_idx', 'cat2lbl_input_ids', \n",
    "    'cat2lbl_attention_mask', 'cat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr',\n",
    "    \n",
    "    'phlk2data_idx', 'phlk2data_data2ptr', 'hlk2data_idx', 'hlk2data_input_ids', 'hlk2data_attention_mask', \n",
    "    'hlk2data_data2ptr',\n",
    "    'phlk2lbl_idx', 'phlk2lbl_lbl2data2ptr', 'phlk2lbl_data2ptr', 'hlk2lbl_idx', 'hlk2lbl_input_ids', \n",
    "    'hlk2lbl_attention_mask', 'hlk2lbl_lbl2data2ptr', 'hlk2lbl_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25867c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1000, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77498614-dc2c-4502-810c-7ec4d89d9447",
   "metadata": {},
   "source": [
    "## `RAD002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca974424-8b53-4c3c-94f0-53bca3373924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RAD002(RAD000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(RAD000.__init__)\n",
    "    def __init__(\n",
    "        self, \n",
    "        config,  \n",
    "        resize_length:Optional[int]=None,\n",
    "        use_noise:Optional[bool]=False,\n",
    "        noise_percent:Optional[float]=0.5,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder(config, use_noise=use_noise, noise_pct=noise_percent, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "\n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad29670-b8a1-4c4a-9ed1-688cf1688942",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c3368-2fa0-4de1-9f08-af5457072ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RAD002 were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RAD002.from_pretrained('distilbert-base-uncased', num_batch_labels=5000, batch_size=100,\n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix='cat2lbl', \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "                               \n",
    "                               resize_length=5000, use_noise=True, noise_percent=0.5,\n",
    "                               \n",
    "                               meta_loss_weight=0.3, fusion_loss_weight=0.1, \n",
    "                               use_fusion_loss=True,  use_encoder_parallel=False)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7597bab-4125-48b5-8c7e-411ec4b8af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ccf90-490a-484c-b163-92094f37632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "    'pcat2lbl_idx', 'pcat2lbl_lbl2data2ptr', 'pcat2lbl_data2ptr', 'cat2lbl_idx', 'cat2lbl_input_ids', \n",
    "    'cat2lbl_attention_mask', 'cat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr',\n",
    "    \n",
    "    'phlk2data_idx', 'phlk2data_data2ptr', 'hlk2data_idx', 'hlk2data_input_ids', 'hlk2data_attention_mask', \n",
    "    'hlk2data_data2ptr',\n",
    "    'phlk2lbl_idx', 'phlk2lbl_lbl2data2ptr', 'phlk2lbl_data2ptr', 'hlk2lbl_idx', 'hlk2lbl_input_ids', \n",
    "    'hlk2lbl_attention_mask', 'hlk2lbl_lbl2data2ptr', 'hlk2lbl_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7739b8c-6990-46e8-92a7-3e798638f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "    'pcat2lbl_idx', 'pcat2lbl_lbl2data2ptr', 'pcat2lbl_data2ptr', 'cat2lbl_idx', 'cat2lbl_input_ids', \n",
    "    'cat2lbl_attention_mask', 'cat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be5291-396b-461a-ba4a-31b02a2dd394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(164)forward()\n",
      "    162         #debug\n",
      "    163 \n",
      "--> 164         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "    165 \n",
      "    166         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(166)forward()\n",
      "    164         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "    165 \n",
      "--> 166         if self.use_encoder_parallel:\n",
      "    167             encoder = XCDataParallel(module=self.encoder)\n",
      "    168         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(168)forward()\n",
      "    166         if self.use_encoder_parallel:\n",
      "    167             encoder = XCDataParallel(module=self.encoder)\n",
      "--> 168         else: encoder = self.encoder\n",
      "    169 \n",
      "    170         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(170)forward()\n",
      "    168         else: encoder = self.encoder\n",
      "    169 \n",
      "--> 170         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "    171         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "    172                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(171)forward()\n",
      "    169 \n",
      "    170         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "--> 171         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "    172                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    173 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(172)forward()\n",
      "    170         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "    171         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "--> 172                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    173 \n",
      "    174 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(171)forward()\n",
      "    169 \n",
      "    170         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "--> 171         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "    172                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    173 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(172)forward()\n",
      "    170         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "    171         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "--> 172                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    173 \n",
      "    174 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(171)forward()\n",
      "    169 \n",
      "    170         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "--> 171         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "    172                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "    173 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(130)forward()\n",
      "    128         import pdb; pdb.set_trace()\n",
      "    129         #debug\n",
      "--> 130         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    131 \n",
      "    132         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(132)forward()\n",
      "    130         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    131 \n",
      "--> 132         if data_type is not None and data_type == \"meta\":\n",
      "    133             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    134         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(135)forward()\n",
      "    133             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    134         else:\n",
      "--> 135             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    136 \n",
      "    137         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(137)forward()\n",
      "    135             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    136 \n",
      "--> 137         data_fused_repr = meta_repr = None\n",
      "    138         if data_aug_meta_prefix is not None:\n",
      "    139             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(138)forward()\n",
      "    136 \n",
      "    137         data_fused_repr = meta_repr = None\n",
      "--> 138         if data_aug_meta_prefix is not None:\n",
      "    139             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    140             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(139)forward()\n",
      "    137         data_fused_repr = meta_repr = None\n",
      "    138         if data_aug_meta_prefix is not None:\n",
      "--> 139             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    140             if len(meta_kwargs):\n",
      "    141                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(140)forward()\n",
      "    138         if data_aug_meta_prefix is not None:\n",
      "    139             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "--> 140             if len(meta_kwargs):\n",
      "    141                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    142                                                                              data_attention_mask,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cat2data'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(141)forward()\n",
      "    139             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    140             if len(meta_kwargs):\n",
      "--> 141                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    142                                                                              data_attention_mask,\n",
      "    143                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(142)forward()\n",
      "    140             if len(meta_kwargs):\n",
      "    141                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "--> 142                                                                              data_attention_mask,\n",
      "    143                                                                              meta_kwargs)\n",
      "    144                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(143)forward()\n",
      "    141                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    142                                                                              data_attention_mask,\n",
      "--> 143                                                                              meta_kwargs)\n",
      "    144                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    145 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(141)forward()\n",
      "    139             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    140             if len(meta_kwargs):\n",
      "--> 141                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    142                                                                              data_attention_mask,\n",
      "    143                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_7476/658384959.py(84)fuse_meta_into_embeddings()\n",
      "     82 \n",
      "     83 \n",
      "---> 84     def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "     85         meta_repr = {}\n",
      "     86 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(85)fuse_meta_into_embeddings()\n",
      "     83 \n",
      "     84     def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "---> 85         meta_repr = {}\n",
      "     86 \n",
      "     87         for m_key, m_args in meta_kwargs.items():\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(87)fuse_meta_into_embeddings()\n",
      "     85         meta_repr = {}\n",
      "     86 \n",
      "---> 87         for m_key, m_args in meta_kwargs.items():\n",
      "     88             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     89             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(88)fuse_meta_into_embeddings()\n",
      "     86 \n",
      "     87         for m_key, m_args in meta_kwargs.items():\n",
      "---> 88             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     89             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "     90 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(89)fuse_meta_into_embeddings()\n",
      "     87         for m_key, m_args in meta_kwargs.items():\n",
      "     88             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "---> 89             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "     90 \n",
      "     91             if len(idx):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(91)fuse_meta_into_embeddings()\n",
      "     89             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "     90 \n",
      "---> 91             if len(idx):\n",
      "     92                 if 'meta_repr' in m_args:\n",
      "     93                     m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(92)fuse_meta_into_embeddings()\n",
      "     90 \n",
      "     91             if len(idx):\n",
      "---> 92                 if 'meta_repr' in m_args:\n",
      "     93                     m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
      "     94                     m_repr,m_repr_mask = self.resize(m_repr, m_repr_mask, m_args['data2ptr'][idx])\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(97)fuse_meta_into_embeddings()\n",
      "     95                     m_repr_mask = m_repr_mask.bool()\n",
      "     96                 else:\n",
      "---> 97                     m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
      "     98                                                                 m_args['data2ptr'][idx])\n",
      "     99                     n_meta = m_args['data2ptr'].max()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(98)fuse_meta_into_embeddings()\n",
      "     96                 else:\n",
      "     97                     m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
      "---> 98                                                                 m_args['data2ptr'][idx])\n",
      "     99                     n_meta = m_args['data2ptr'].max()\n",
      "    100 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(97)fuse_meta_into_embeddings()\n",
      "     95                     m_repr_mask = m_repr_mask.bool()\n",
      "     96                 else:\n",
      "---> 97                     m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
      "     98                                                                 m_args['data2ptr'][idx])\n",
      "     99                     n_meta = m_args['data2ptr'].max()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(99)fuse_meta_into_embeddings()\n",
      "     97                     m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
      "     98                                                                 m_args['data2ptr'][idx])\n",
      "---> 99                     n_meta = m_args['data2ptr'].max()\n",
      "    100 \n",
      "    101                     if self.use_noise:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(101)fuse_meta_into_embeddings()\n",
      "     99                     n_meta = m_args['data2ptr'].max()\n",
      "    100 \n",
      "--> 101                     if self.use_noise:\n",
      "    102                         m_input_ids, m_attention_mask = self.add_noise(m_input_ids, m_attention_mask, n_meta)\n",
      "    103 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(102)fuse_meta_into_embeddings()\n",
      "    100 \n",
      "    101                     if self.use_noise:\n",
      "--> 102                         m_input_ids, m_attention_mask = self.add_noise(m_input_ids, m_attention_mask, n_meta)\n",
      "    103 \n",
      "    104                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(104)fuse_meta_into_embeddings()\n",
      "    102                         m_input_ids, m_attention_mask = self.add_noise(m_input_ids, m_attention_mask, n_meta)\n",
      "    103 \n",
      "--> 104                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "    105 \n",
      "    106                     m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(106)fuse_meta_into_embeddings()\n",
      "    104                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "    105 \n",
      "--> 106                     m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
      "    107                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "    108 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(107)fuse_meta_into_embeddings()\n",
      "    105 \n",
      "    106                     m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
      "--> 107                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "    108 \n",
      "    109                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(109)fuse_meta_into_embeddings()\n",
      "    107                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "    108 \n",
      "--> 109                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "    110 \n",
      "    111                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(111)fuse_meta_into_embeddings()\n",
      "    109                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "    110 \n",
      "--> 111                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "    112 \n",
      "    113                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr_mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(113)fuse_meta_into_embeddings()\n",
      "    111                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "    112 \n",
      "--> 113                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "    114                 embed[idx] += fused_embed\n",
      "    115 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_repr[m_key].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  embed[idx].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  attention_mask[idx].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr_mask.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(114)fuse_meta_into_embeddings()\n",
      "    112 \n",
      "    113                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "--> 114                 embed[idx] += fused_embed\n",
      "    115 \n",
      "    116         return embed, meta_repr\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  fused_embed.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(87)fuse_meta_into_embeddings()\n",
      "     85         meta_repr = {}\n",
      "     86 \n",
      "---> 87         for m_key, m_args in meta_kwargs.items():\n",
      "     88             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     89             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(116)fuse_meta_into_embeddings()\n",
      "    114                 embed[idx] += fused_embed\n",
      "    115 \n",
      "--> 116         return embed, meta_repr\n",
      "    117 \n",
      "    118     def forward(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[[-0....PutBackward0>), {'cat2data': tensor([[-0.0...DivBackward0>)})\n",
      "> /tmp/ipykernel_7476/658384959.py(116)fuse_meta_into_embeddings()\n",
      "    114                 embed[idx] += fused_embed\n",
      "    115 \n",
      "--> 116         return embed, meta_repr\n",
      "    117 \n",
      "    118     def forward(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(144)forward()\n",
      "    142                                                                              data_attention_mask,\n",
      "    143                                                                              meta_kwargs)\n",
      "--> 144                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    145 \n",
      "    146         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(146)forward()\n",
      "    144                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    145 \n",
      "--> 146         return EncoderOutput(\n",
      "    147             rep=data_repr,\n",
      "    148             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(147)forward()\n",
      "    145 \n",
      "    146         return EncoderOutput(\n",
      "--> 147             rep=data_repr,\n",
      "    148             fused_rep=data_fused_repr,\n",
      "    149             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(148)forward()\n",
      "    146         return EncoderOutput(\n",
      "    147             rep=data_repr,\n",
      "--> 148             fused_rep=data_fused_repr,\n",
      "    149             meta_repr=meta_repr,\n",
      "    150         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(149)forward()\n",
      "    147             rep=data_repr,\n",
      "    148             fused_rep=data_fused_repr,\n",
      "--> 149             meta_repr=meta_repr,\n",
      "    150         )\n",
      "    151 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(146)forward()\n",
      "    144                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    145 \n",
      "--> 146         return EncoderOutput(\n",
      "    147             rep=data_repr,\n",
      "    148             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...vBackward0>)})\n",
      "> /tmp/ipykernel_7476/658384959.py(146)forward()\n",
      "    144                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    145 \n",
      "--> 146         return EncoderOutput(\n",
      "    147             rep=data_repr,\n",
      "    148             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...vBackward0>)})\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1520)_call_impl()\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "-> 1520             return forward_call(*args, **kwargs)\n",
      "   1521 \n",
      "   1522         try:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...vBackward0>)})\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1511)_wrapped_call_impl()\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1510         else:\n",
      "-> 1511             return self._call_impl(*args, **kwargs)\n",
      "   1512 \n",
      "   1513     def _call_impl(self, *args, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(175)forward()\n",
      "    173 \n",
      "    174 \n",
      "--> 175         loss = None; lbl2data_o = EncoderOutput()\n",
      "    176         if lbl2data_input_ids is not None:\n",
      "    177             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(176)forward()\n",
      "    174 \n",
      "    175         loss = None; lbl2data_o = EncoderOutput()\n",
      "--> 176         if lbl2data_input_ids is not None:\n",
      "    177             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    178             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(177)forward()\n",
      "    175         loss = None; lbl2data_o = EncoderOutput()\n",
      "    176         if lbl2data_input_ids is not None:\n",
      "--> 177             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    178             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "    179                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(178)forward()\n",
      "    176         if lbl2data_input_ids is not None:\n",
      "    177             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "--> 178             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "    179                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    180 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  lbl2data_meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cat2lbl_attention_mask', 'cat2lbl_input_ids', 'cat2lbl_data2ptr'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(179)forward()\n",
      "    177             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    178             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "--> 179                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    180 \n",
      "    181             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(178)forward()\n",
      "    176         if lbl2data_input_ids is not None:\n",
      "    177             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "--> 178             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "    179                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    180 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(179)forward()\n",
      "    177             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    178             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "--> 179                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    180 \n",
      "    181             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(178)forward()\n",
      "    176         if lbl2data_input_ids is not None:\n",
      "    177             lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "--> 178             lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
      "    179                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    180 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(130)forward()\n",
      "    128         import pdb; pdb.set_trace()\n",
      "    129         #debug\n",
      "--> 130         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    131 \n",
      "    132         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n",
      "ipdb>  \n",
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(132)forward()\n",
      "    130         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    131 \n",
      "--> 132         if data_type is not None and data_type == \"meta\":\n",
      "    133             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    134         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(135)forward()\n",
      "    133             data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
      "    134         else:\n",
      "--> 135             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    136 \n",
      "    137         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(137)forward()\n",
      "    135             data_repr = self.dr(data_o[0], data_attention_mask)\n",
      "    136 \n",
      "--> 137         data_fused_repr = meta_repr = None\n",
      "    138         if data_aug_meta_prefix is not None:\n",
      "    139             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(138)forward()\n",
      "    136 \n",
      "    137         data_fused_repr = meta_repr = None\n",
      "--> 138         if data_aug_meta_prefix is not None:\n",
      "    139             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    140             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(139)forward()\n",
      "    137         data_fused_repr = meta_repr = None\n",
      "    138         if data_aug_meta_prefix is not None:\n",
      "--> 139             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    140             if len(meta_kwargs):\n",
      "    141                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(140)forward()\n",
      "    138         if data_aug_meta_prefix is not None:\n",
      "    139             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "--> 140             if len(meta_kwargs):\n",
      "    141                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    142                                                                              data_attention_mask,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_kwargs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cat2lbl'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(141)forward()\n",
      "    139             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    140             if len(meta_kwargs):\n",
      "--> 141                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    142                                                                              data_attention_mask,\n",
      "    143                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(142)forward()\n",
      "    140             if len(meta_kwargs):\n",
      "    141                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "--> 142                                                                              data_attention_mask,\n",
      "    143                                                                              meta_kwargs)\n",
      "    144                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(143)forward()\n",
      "    141                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    142                                                                              data_attention_mask,\n",
      "--> 143                                                                              meta_kwargs)\n",
      "    144                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    145 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(141)forward()\n",
      "    139             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    140             if len(meta_kwargs):\n",
      "--> 141                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
      "    142                                                                              data_attention_mask,\n",
      "    143                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_7476/658384959.py(84)fuse_meta_into_embeddings()\n",
      "     82 \n",
      "     83 \n",
      "---> 84     def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "     85         meta_repr = {}\n",
      "     86 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(85)fuse_meta_into_embeddings()\n",
      "     83 \n",
      "     84     def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "---> 85         meta_repr = {}\n",
      "     86 \n",
      "     87         for m_key, m_args in meta_kwargs.items():\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(87)fuse_meta_into_embeddings()\n",
      "     85         meta_repr = {}\n",
      "     86 \n",
      "---> 87         for m_key, m_args in meta_kwargs.items():\n",
      "     88             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     89             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(88)fuse_meta_into_embeddings()\n",
      "     86 \n",
      "     87         for m_key, m_args in meta_kwargs.items():\n",
      "---> 88             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     89             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "     90 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_keys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'm_keys' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'cat2lbl'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(89)fuse_meta_into_embeddings()\n",
      "     87         for m_key, m_args in meta_kwargs.items():\n",
      "     88             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "---> 89             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "     90 \n",
      "     91             if len(idx):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  idx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 3, 4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(91)fuse_meta_into_embeddings()\n",
      "     89             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "     90 \n",
      "---> 91             if len(idx):\n",
      "     92                 if 'meta_repr' in m_args:\n",
      "     93                     m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(92)fuse_meta_into_embeddings()\n",
      "     90 \n",
      "     91             if len(idx):\n",
      "---> 92                 if 'meta_repr' in m_args:\n",
      "     93                     m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
      "     94                     m_repr,m_repr_mask = self.resize(m_repr, m_repr_mask, m_args['data2ptr'][idx])\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(97)fuse_meta_into_embeddings()\n",
      "     95                     m_repr_mask = m_repr_mask.bool()\n",
      "     96                 else:\n",
      "---> 97                     m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
      "     98                                                                 m_args['data2ptr'][idx])\n",
      "     99                     n_meta = m_args['data2ptr'].max()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(98)fuse_meta_into_embeddings()\n",
      "     96                 else:\n",
      "     97                     m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
      "---> 98                                                                 m_args['data2ptr'][idx])\n",
      "     99                     n_meta = m_args['data2ptr'].max()\n",
      "    100 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(97)fuse_meta_into_embeddings()\n",
      "     95                     m_repr_mask = m_repr_mask.bool()\n",
      "     96                 else:\n",
      "---> 97                     m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
      "     98                                                                 m_args['data2ptr'][idx])\n",
      "     99                     n_meta = m_args['data2ptr'].max()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_args['data2ptr'][idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 1, 3, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(99)fuse_meta_into_embeddings()\n",
      "     97                     m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
      "     98                                                                 m_args['data2ptr'][idx])\n",
      "---> 99                     n_meta = m_args['data2ptr'].max()\n",
      "    100 \n",
      "    101                     if self.use_noise:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_attention_mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(101)fuse_meta_into_embeddings()\n",
      "     99                     n_meta = m_args['data2ptr'].max()\n",
      "    100 \n",
      "--> 101                     if self.use_noise:\n",
      "    102                         m_input_ids, m_attention_mask = self.add_noise(m_input_ids, m_attention_mask, n_meta)\n",
      "    103 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(102)fuse_meta_into_embeddings()\n",
      "    100 \n",
      "    101                     if self.use_noise:\n",
      "--> 102                         m_input_ids, m_attention_mask = self.add_noise(m_input_ids, m_attention_mask, n_meta)\n",
      "    103 \n",
      "    104                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(104)fuse_meta_into_embeddings()\n",
      "    102                         m_input_ids, m_attention_mask = self.add_noise(m_input_ids, m_attention_mask, n_meta)\n",
      "    103 \n",
      "--> 104                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "    105 \n",
      "    106                     m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(106)fuse_meta_into_embeddings()\n",
      "    104                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "    105 \n",
      "--> 106                     m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
      "    107                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "    108 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(107)fuse_meta_into_embeddings()\n",
      "    105 \n",
      "    106                     m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
      "--> 107                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "    108 \n",
      "    109                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(109)fuse_meta_into_embeddings()\n",
      "    107                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "    108 \n",
      "--> 109                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "    110 \n",
      "    111                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(111)fuse_meta_into_embeddings()\n",
      "    109                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "    110 \n",
      "--> 111                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "    112 \n",
      "    113                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(113)fuse_meta_into_embeddings()\n",
      "    111                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "    112 \n",
      "--> 113                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "    114                 embed[idx] += fused_embed\n",
      "    115 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(114)fuse_meta_into_embeddings()\n",
      "    112 \n",
      "    113                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "--> 114                 embed[idx] += fused_embed\n",
      "    115 \n",
      "    116         return embed, meta_repr\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(87)fuse_meta_into_embeddings()\n",
      "     85         meta_repr = {}\n",
      "     86 \n",
      "---> 87         for m_key, m_args in meta_kwargs.items():\n",
      "     88             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     89             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(116)fuse_meta_into_embeddings()\n",
      "    114                 embed[idx] += fused_embed\n",
      "    115 \n",
      "--> 116         return embed, meta_repr\n",
      "    117 \n",
      "    118     def forward(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[[-0....PutBackward0>), {'cat2lbl': tensor([[-2.1...DivBackward0>)})\n",
      "> /tmp/ipykernel_7476/658384959.py(116)fuse_meta_into_embeddings()\n",
      "    114                 embed[idx] += fused_embed\n",
      "    115 \n",
      "--> 116         return embed, meta_repr\n",
      "    117 \n",
      "    118     def forward(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(144)forward()\n",
      "    142                                                                              data_attention_mask,\n",
      "    143                                                                              meta_kwargs)\n",
      "--> 144                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    145 \n",
      "    146         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(146)forward()\n",
      "    144                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    145 \n",
      "--> 146         return EncoderOutput(\n",
      "    147             rep=data_repr,\n",
      "    148             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(147)forward()\n",
      "    145 \n",
      "    146         return EncoderOutput(\n",
      "--> 147             rep=data_repr,\n",
      "    148             fused_rep=data_fused_repr,\n",
      "    149             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(148)forward()\n",
      "    146         return EncoderOutput(\n",
      "    147             rep=data_repr,\n",
      "--> 148             fused_rep=data_fused_repr,\n",
      "    149             meta_repr=meta_repr,\n",
      "    150         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(149)forward()\n",
      "    147             rep=data_repr,\n",
      "    148             fused_rep=data_fused_repr,\n",
      "--> 149             meta_repr=meta_repr,\n",
      "    150         )\n",
      "    151 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/658384959.py(146)forward()\n",
      "    144                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    145 \n",
      "--> 146         return EncoderOutput(\n",
      "    147             rep=data_repr,\n",
      "    148             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...vBackward0>)})\n",
      "> /tmp/ipykernel_7476/658384959.py(146)forward()\n",
      "    144                 data_fused_repr = self.dr(data_fused_embed, data_attention_mask)\n",
      "    145 \n",
      "--> 146         return EncoderOutput(\n",
      "    147             rep=data_repr,\n",
      "    148             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...vBackward0>)})\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1520)_call_impl()\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "-> 1520             return forward_call(*args, **kwargs)\n",
      "   1521 \n",
      "   1522         try:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...vBackward0>)})\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1511)_wrapped_call_impl()\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1510         else:\n",
      "-> 1511             return self._call_impl(*args, **kwargs)\n",
      "   1512 \n",
      "   1513     def _call_impl(self, *args, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(181)forward()\n",
      "    179                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    180 \n",
      "--> 181             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "    182                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "    183             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(182)forward()\n",
      "    180 \n",
      "    181             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "--> 182                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "    183             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "    184 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(181)forward()\n",
      "    179                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "    180 \n",
      "--> 181             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "    182                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "    183             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(183)forward()\n",
      "    181             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "    182                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "--> 183             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "    184 \n",
      "    185             if self.use_fusion_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_7476/2498770119.py(67)compute_meta_loss()\n",
      "     65         return self.rep_loss_fn(inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
      "     66 \n",
      "---> 67     def compute_meta_loss(self, data_repr, lbl2data_repr, **kwargs):\n",
      "     68         if self.use_encoder_parallel:\n",
      "     69             encoder = XCDataParallel(module=self.encoder)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(68)compute_meta_loss()\n",
      "     66 \n",
      "     67     def compute_meta_loss(self, data_repr, lbl2data_repr, **kwargs):\n",
      "---> 68         if self.use_encoder_parallel:\n",
      "     69             encoder = XCDataParallel(module=self.encoder)\n",
      "     70         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(70)compute_meta_loss()\n",
      "     68         if self.use_encoder_parallel:\n",
      "     69             encoder = XCDataParallel(module=self.encoder)\n",
      "---> 70         else: encoder = self.encoder\n",
      "     71 \n",
      "     72         data_meta_inputs = Parameters.from_meta_pred_prefix(self.data_pred_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(72)compute_meta_loss()\n",
      "     70         else: encoder = self.encoder\n",
      "     71 \n",
      "---> 72         data_meta_inputs = Parameters.from_meta_pred_prefix(self.data_pred_meta_prefix, **kwargs)\n",
      "     73         lbl2data_meta_inputs = Parameters.from_meta_pred_prefix(self.lbl2data_pred_meta_prefix, **kwargs)\n",
      "     74         meta_inputs = {**data_meta_inputs, **lbl2data_meta_inputs}\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(73)compute_meta_loss()\n",
      "     71 \n",
      "     72         data_meta_inputs = Parameters.from_meta_pred_prefix(self.data_pred_meta_prefix, **kwargs)\n",
      "---> 73         lbl2data_meta_inputs = Parameters.from_meta_pred_prefix(self.lbl2data_pred_meta_prefix, **kwargs)\n",
      "     74         meta_inputs = {**data_meta_inputs, **lbl2data_meta_inputs}\n",
      "     75 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(74)compute_meta_loss()\n",
      "     72         data_meta_inputs = Parameters.from_meta_pred_prefix(self.data_pred_meta_prefix, **kwargs)\n",
      "     73         lbl2data_meta_inputs = Parameters.from_meta_pred_prefix(self.lbl2data_pred_meta_prefix, **kwargs)\n",
      "---> 74         meta_inputs = {**data_meta_inputs, **lbl2data_meta_inputs}\n",
      "     75 \n",
      "     76         m_lw = Parameters.get_meta_loss_weights(self.m_lw, len(meta_inputs)) if len(meta_inputs) else []\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(76)compute_meta_loss()\n",
      "     74         meta_inputs = {**data_meta_inputs, **lbl2data_meta_inputs}\n",
      "     75 \n",
      "---> 76         m_lw = Parameters.get_meta_loss_weights(self.m_lw, len(meta_inputs)) if len(meta_inputs) else []\n",
      "     77 \n",
      "     78         loss = 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  len(meta_inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(78)compute_meta_loss()\n",
      "     76         m_lw = Parameters.get_meta_loss_weights(self.m_lw, len(meta_inputs)) if len(meta_inputs) else []\n",
      "     77 \n",
      "---> 78         loss = 0.0\n",
      "     79         for inputs,lw in zip(meta_inputs.values(), m_lw):\n",
      "     80             if 'lbl2data2ptr' in inputs:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(79)compute_meta_loss()\n",
      "     77 \n",
      "     78         loss = 0.0\n",
      "---> 79         for inputs,lw in zip(meta_inputs.values(), m_lw):\n",
      "     80             if 'lbl2data2ptr' in inputs:\n",
      "     81                 idx = torch.where(inputs['lbl2data2ptr'])[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(99)compute_meta_loss()\n",
      "     97 \n",
      "     98             else: raise ValueError('Invalid metadata input arguments.')\n",
      "---> 99         return loss\n",
      "    100 \n",
      "    101     def compute_fusion_loss(self, data_repr, meta_repr:Dict, prefix:str, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "0.0\n",
      "> /tmp/ipykernel_7476/2498770119.py(99)compute_meta_loss()\n",
      "     97 \n",
      "     98             else: raise ValueError('Invalid metadata input arguments.')\n",
      "---> 99         return loss\n",
      "    100 \n",
      "    101     def compute_fusion_loss(self, data_repr, meta_repr:Dict, prefix:str, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(185)forward()\n",
      "    183             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "    184 \n",
      "--> 185             if self.use_fusion_loss:\n",
      "    186                 loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
      "    187                 loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(186)forward()\n",
      "    184 \n",
      "    185             if self.use_fusion_loss:\n",
      "--> 186                 loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
      "    187                 loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    188 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_7476/2498770119.py(101)compute_fusion_loss()\n",
      "     99         return loss\n",
      "    100 \n",
      "--> 101     def compute_fusion_loss(self, data_repr, meta_repr:Dict, prefix:str, **kwargs):\n",
      "    102         meta_inputs = Parameters.from_meta_pred_prefix(prefix, **kwargs)\n",
      "    103 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(102)compute_fusion_loss()\n",
      "    100 \n",
      "    101     def compute_fusion_loss(self, data_repr, meta_repr:Dict, prefix:str, **kwargs):\n",
      "--> 102         meta_inputs = Parameters.from_meta_pred_prefix(prefix, **kwargs)\n",
      "    103 \n",
      "    104         loss = 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(104)compute_fusion_loss()\n",
      "    102         meta_inputs = Parameters.from_meta_pred_prefix(prefix, **kwargs)\n",
      "    103 \n",
      "--> 104         loss = 0.0\n",
      "    105         for key,input_repr in meta_repr.items():\n",
      "    106             inputs = meta_inputs[key]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_inputs.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cat2data'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(105)compute_fusion_loss()\n",
      "    103 \n",
      "    104         loss = 0.0\n",
      "--> 105         for key,input_repr in meta_repr.items():\n",
      "    106             inputs = meta_inputs[key]\n",
      "    107             if 'lbl2data2ptr' in inputs:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  meta_repr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat2data': tensor([[-0.0077,  0.0311, -0.1009,  ..., -0.0220, -0.0373,  0.0008],\n",
      "        [-0.0212, -0.0003, -0.0349,  ..., -0.0195, -0.0281,  0.0302],\n",
      "        [-0.0238,  0.0017, -0.0369,  ..., -0.0190, -0.0277,  0.0301],\n",
      "        ...,\n",
      "        [-0.0352, -0.0064, -0.0240,  ..., -0.0247,  0.0242, -0.0059],\n",
      "        [ 0.0044, -0.0203, -0.0313,  ..., -0.0202, -0.0038, -0.0124],\n",
      "        [-0.0115,  0.0246, -0.0558,  ..., -0.0463,  0.0357, -0.0189]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(106)compute_fusion_loss()\n",
      "    104         loss = 0.0\n",
      "    105         for key,input_repr in meta_repr.items():\n",
      "--> 106             inputs = meta_inputs[key]\n",
      "    107             if 'lbl2data2ptr' in inputs:\n",
      "    108                 idx = torch.where(inputs['lbl2data2ptr'])[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(107)compute_fusion_loss()\n",
      "    105         for key,input_repr in meta_repr.items():\n",
      "    106             inputs = meta_inputs[key]\n",
      "--> 107             if 'lbl2data2ptr' in inputs:\n",
      "    108                 idx = torch.where(inputs['lbl2data2ptr'])[0]\n",
      "    109                 if len(idx) > 0:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  inputs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pidx': tensor([ 72729, 111911, 117344, 138296, 161845, 161846, 161847, 161848, 161849,\n",
      "        161850, 161851, 161852, 161853, 161854, 161855, 161856, 161857, 161858,\n",
      "        161859, 161860, 161861, 161862, 161863, 138151,  54422,  54425,  68239,\n",
      "         69310,  76501,  79431,  81202, 101916, 102550, 102551, 102552, 102553,\n",
      "        102554, 102555, 102556, 102557,  79395, 102791, 102792, 102793, 102794,\n",
      "         84732,  84865,  84866,  84867,  84868,  84869,  84870,  84871,  84872,\n",
      "         84873,  84874,  84875,  84876,  84877,  84878,  84879,  84880,  84881],\n",
      "       device='cuda:0'), 'pdata2ptr': tensor([23,  1, 16,  5, 18], device='cuda:0'), 'idx': tensor([161854, 161862, 161850, 138151, 102554, 102557, 102556, 102794, 102791,\n",
      "        102793,  84871,  84870,  84865], device='cuda:0'), 'input_ids': tensor([[  101, 13140,  4487,  8583,  2696, 16558, 21808,  2015,  1999,  1996,\n",
      "          3803,  3400,   102],\n",
      "        [  101,  3470,  1997,  1996,  4549, 27695,   102,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101, 13839,  4487,  8583,  2696, 16558, 21808,  2015,  1999,  1996,\n",
      "          3803,  3400,   102],\n",
      "        [  101,  4331,  1997, 13491,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2111,  1997,  2662,  1999,  1996,  2137,  2942,  2162,   102,\n",
      "             0,     0,     0],\n",
      "        [  101,  2111,  1997,  1996,  6646,  2162,   102,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101, 20816,  2118,  9441,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  3010, 10996,  2015,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  7649,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  6941,  1997,  2710,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2266,  2163,  1997,  1996,  2148,  4004,  2523,  2005,  3164,\n",
      "          6792,   102,     0],\n",
      "        [  101,  2266,  2163,  1997,  1996,  5502,  1997,  5499,  6792,   102,\n",
      "             0,     0,     0],\n",
      "        [  101,  2430,  4004,  3032,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'data2ptr': tensor([3, 1, 3, 3, 3], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(114)compute_fusion_loss()\n",
      "    112                     loss += self.f_lw * m_loss\n",
      "    113 \n",
      "--> 114             elif 'data2ptr' in inputs:\n",
      "    115                 idx = torch.where(inputs['data2ptr'])[0]\n",
      "    116                 if len(idx) > 0:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(115)compute_fusion_loss()\n",
      "    113 \n",
      "    114             elif 'data2ptr' in inputs:\n",
      "--> 115                 idx = torch.where(inputs['data2ptr'])[0]\n",
      "    116                 if len(idx) > 0:\n",
      "    117                     m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['data2ptr'][idx], inputs['idx'], \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(116)compute_fusion_loss()\n",
      "    114             elif 'data2ptr' in inputs:\n",
      "    115                 idx = torch.where(inputs['data2ptr'])[0]\n",
      "--> 116                 if len(idx) > 0:\n",
      "    117                     m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['data2ptr'][idx], inputs['idx'], \n",
      "    118                                               inputs['pdata2ptr'][idx], inputs['pidx'])\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(117)compute_fusion_loss()\n",
      "    115                 idx = torch.where(inputs['data2ptr'])[0]\n",
      "    116                 if len(idx) > 0:\n",
      "--> 117                     m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['data2ptr'][idx], inputs['idx'], \n",
      "    118                                               inputs['pdata2ptr'][idx], inputs['pidx'])\n",
      "    119                     loss += self.f_lw * m_loss\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(118)compute_fusion_loss()\n",
      "    116                 if len(idx) > 0:\n",
      "    117                     m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['data2ptr'][idx], inputs['idx'], \n",
      "--> 118                                               inputs['pdata2ptr'][idx], inputs['pidx'])\n",
      "    119                     loss += self.f_lw * m_loss\n",
      "    120 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(117)compute_fusion_loss()\n",
      "    115                 idx = torch.where(inputs['data2ptr'])[0]\n",
      "    116                 if len(idx) > 0:\n",
      "--> 117                     m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['data2ptr'][idx], inputs['idx'], \n",
      "    118                                               inputs['pdata2ptr'][idx], inputs['pidx'])\n",
      "    119                     loss += self.f_lw * m_loss\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(119)compute_fusion_loss()\n",
      "    117                     m_loss = self.rep_loss_fn(data_repr[idx], input_repr, inputs['data2ptr'][idx], inputs['idx'], \n",
      "    118                                               inputs['pdata2ptr'][idx], inputs['pidx'])\n",
      "--> 119                     loss += self.f_lw * m_loss\n",
      "    120 \n",
      "    121             else: raise ValueError('Invalid metadata input arguments.')\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(105)compute_fusion_loss()\n",
      "    103 \n",
      "    104         loss = 0.0\n",
      "--> 105         for key,input_repr in meta_repr.items():\n",
      "    106             inputs = meta_inputs[key]\n",
      "    107             if 'lbl2data2ptr' in inputs:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(122)compute_fusion_loss()\n",
      "    120 \n",
      "    121             else: raise ValueError('Invalid metadata input arguments.')\n",
      "--> 122         return loss\n",
      "    123 \n",
      "    124 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor(0.0040...AddBackward0>)\n",
      "> /tmp/ipykernel_7476/2498770119.py(122)compute_fusion_loss()\n",
      "    120 \n",
      "    121             else: raise ValueError('Invalid metadata input arguments.')\n",
      "--> 122         return loss\n",
      "    123 \n",
      "    124 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(187)forward()\n",
      "    185             if self.use_fusion_loss:\n",
      "    186                 loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
      "--> 187                 loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "    188 \n",
      "    189 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(190)forward()\n",
      "    188 \n",
      "    189 \n",
      "--> 190         if not return_dict:\n",
      "    191             o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
      "    192             return ((loss,) + o) if loss is not None else o\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(195)forward()\n",
      "    193 \n",
      "    194 \n",
      "--> 195         return RADOutput(\n",
      "    196             loss=loss,\n",
      "    197 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(196)forward()\n",
      "    194 \n",
      "    195         return RADOutput(\n",
      "--> 196             loss=loss,\n",
      "    197 \n",
      "    198             data_repr=data_o.rep,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(198)forward()\n",
      "    196             loss=loss,\n",
      "    197 \n",
      "--> 198             data_repr=data_o.rep,\n",
      "    199             data_fused_repr=data_o.fused_rep,\n",
      "    200 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(199)forward()\n",
      "    197 \n",
      "    198             data_repr=data_o.rep,\n",
      "--> 199             data_fused_repr=data_o.fused_rep,\n",
      "    200 \n",
      "    201             lbl2data_repr=lbl2data_o.rep,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(201)forward()\n",
      "    199             data_fused_repr=data_o.fused_rep,\n",
      "    200 \n",
      "--> 201             lbl2data_repr=lbl2data_o.rep,\n",
      "    202             lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
      "    203         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(202)forward()\n",
      "    200 \n",
      "    201             lbl2data_repr=lbl2data_o.rep,\n",
      "--> 202             lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
      "    203         )\n",
      "    204 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_7476/2498770119.py(195)forward()\n",
      "    193 \n",
      "    194 \n",
      "--> 195         return RADOutput(\n",
      "    196             loss=loss,\n",
      "    197 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "RADOutput(los...ivBackward0>))\n",
      "> /tmp/ipykernel_7476/2498770119.py(195)forward()\n",
      "    193 \n",
      "    194 \n",
      "--> 195         return RADOutput(\n",
      "    196             loss=loss,\n",
      "    197 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "RADOutput(los...ivBackward0>))\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1520)_call_impl()\n",
      "   1518                 or _global_backward_pre_hooks or _global_backward_hooks\n",
      "   1519                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "-> 1520             return forward_call(*args, **kwargs)\n",
      "   1521 \n",
      "   1522         try:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "RADOutput(los...ivBackward0>))\n",
      "> /scratch/scai/phd/aiz218323/anaconda3/envs/xc_nlg/lib/python3.9/site-packages/torch/nn/modules/module.py(1511)_wrapped_call_impl()\n",
      "   1509             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n",
      "   1510         else:\n",
      "-> 1511             return self._call_impl(*args, **kwargs)\n",
      "   1512 \n",
      "   1513     def _call_impl(self, *args, **kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> /tmp/ipykernel_7476/3352081931.py(1)<module>()\n",
      "----> 1 o = model(**b.to(model.device))\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "> /home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py(3553)run_code()\n",
      "   3551             finally:\n",
      "   3552                 # Reset our crash handler in place\n",
      "-> 3553                 sys.excepthook = old_excepthook\n",
      "   3554         except SystemExit as e:\n",
      "   3555             if result is not None:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d0c0c-3fde-4f03-b714-a1c4582abab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a78666-19fe-4f96-9470-8d9784f9f9a6",
   "metadata": {},
   "source": [
    "## `RAD003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795bd728-b5d5-4a50-9052-8f2348422dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder003(Encoder):\n",
    "\n",
    "    def __init__(self, config:PretrainedConfig, use_noise:Optional[bool]=True, noise_pct:Optional[float]=0.5, resize_length:Optional[int]=None):\n",
    "        super().__init__(config, use_noise, noise_pct, resize_length)        \n",
    "        self.cross_gate = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    \n",
    "    def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
    "            \n",
    "            if len(idx):\n",
    "                if not torch.all(m_args['data2ptr'][idx] == m_args['data2ptr'].max()): \n",
    "                    raise ValueError(f'All datapoints should have same number of metadata.')\n",
    "                    \n",
    "                if 'meta_repr' in m_args:\n",
    "                    m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
    "                    m_repr_mask = m_repr_mask.bool()\n",
    "                else:\n",
    "                    m_input_ids, m_attention_mask = m_args['input_ids'], m_args['attention_mask']\n",
    "                    m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
    "    \n",
    "                    m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
    "                    m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
    "                    \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
    "\n",
    "                meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
    "                \n",
    "                fused_embed, w = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask, output_attentions=False)[0]\n",
    "                embed[idx] += self.cross_gate * fused_embed\n",
    "               \n",
    "        return embed, meta_repr\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_type:Optional[str]=None,\n",
    "        data_unnormalized:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        \n",
    "        if data_type is not None and data_type == \"meta\":\n",
    "            data_repr = self.meta_unnormalized(data_o[0], data_attention_mask) if data_unnormalized else self.meta(data_o[0], data_attention_mask)\n",
    "        else: \n",
    "            data_repr = self.dr(data_o[0], data_attention_mask)\n",
    "        \n",
    "        data_fused_repr = meta_repr = None\n",
    "        if data_aug_meta_prefix is not None:\n",
    "            meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
    "            if len(meta_kwargs):\n",
    "                data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_o[0], \n",
    "                                                                             data_attention_mask, \n",
    "                                                                             meta_kwargs)\n",
    "                data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
    "        \n",
    "        return EncoderOutput(\n",
    "            rep=data_repr,\n",
    "            fused_rep=data_fused_repr,\n",
    "            meta_repr=meta_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ca4ca-c7d2-43af-864e-f197d951fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RAD003(RAD000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self, config,\n",
    "        \n",
    "        calib_margin:Optional[float]=0.3,\n",
    "        calib_num_negatives:Optional[int]=5,\n",
    "        calib_tau:Optional[float]=0.1,\n",
    "        calib_apply_softmax:Optional[bool]=True,\n",
    "        \n",
    "        calib_loss_weight:Optional[float]=0.3,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.c_lw = calib_loss_weight\n",
    "        self.encoder = Encoder003(config, use_noise=False)\n",
    "        \n",
    "        self.post_init()\n",
    "        \n",
    "        self.cab_loss_fn = Calibration(margin=calib_margin, tau=calib_tau, n_negatives=calib_num_negatives, \n",
    "                                       apply_softmax=calib_apply_softmax, reduce='mean')\n",
    "        \n",
    "        self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head(); self.init_cross_gate()\n",
    "\n",
    "    def init_cross_gate(self):\n",
    "        self.encoder.cross_gate.data = torch.zeros(1)\n",
    "            \n",
    "    def remap_post_init(self):\n",
    "         self.distilbert = self.encoder.distilbert\n",
    "        \n",
    "    def calibration_loss(self, einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.c_lw * self.cab_loss_fn(einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "\n",
    "            loss = self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            if data_o.fused_rep is not None:\n",
    "                loss += self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "                \n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78ec3e-dd38-407e-b1ae-9024ba8eabbf",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2030f5b8-0be5-4b8a-b041-4323849faad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RAD003 were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.cross_gate', 'encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RAD003.from_pretrained('distilbert-base-uncased', num_batch_labels=5000, batch_size=100,\n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=5, calib_tau=0.1, calib_apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='aug2data', lbl2data_aug_meta_prefix='aug2lbl', \n",
    "                               data_pred_meta_prefix='cat2data', lbl2data_pred_meta_prefix='cat2lbl',\n",
    "                               \n",
    "                               meta_loss_weight=[0.1, 0.1], calib_loss_weight=0.3,  \n",
    "                               use_encoder_parallel=True)\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93689ea-2cb9-4b55-a44a-e747d1eba305",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "    'pcat2lbl_idx', 'pcat2lbl_lbl2data2ptr', 'pcat2lbl_data2ptr', 'cat2lbl_idx', 'cat2lbl_input_ids', \n",
    "    'cat2lbl_attention_mask', 'cat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efd8eb8-5ed3-4a82-93d1-298c0322cfbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'pcat2lbl_idx', 'pcat2lbl_lbl2data2ptr', 'pcat2lbl_data2ptr', 'cat2lbl_idx', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'cat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', 'cat2data_data2ptr', 'data_input_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ffecf-6ff9-4dc3-b3ba-0f6af31b46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad618fe-d767-4c48-9d56-a3a68afa3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1746b1-fa1e-45a7-b256-ab9fd417b042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0684, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7877ecb-1682-432e-87a1-bf74efa2b135",
   "metadata": {},
   "source": [
    "## `RAD004`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85414319-e6d0-41ce-b275-13231e60f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder004(Encoder):\n",
    "    \n",
    "    def __init__(self, config:PretrainedConfig, use_noise:Optional[bool]=True, noise_pct:Optional[float]=0.5, resize_length:Optional[int]=None,\n",
    "                cross_margin:Optional[float]=0.3, cross_tau:Optional[float]=0.1):\n",
    "        super().__init__(config, use_noise, noise_pct, resize_length) \n",
    "        self.cross_head = GatedCrossAttention(config, margin=cross_margin, tau=cross_tau)\n",
    "        self.cross_gate = nn.Parameter(torch.ones(1))\n",
    "        \n",
    "    \n",
    "    def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
    "            \n",
    "            if len(idx):\n",
    "                if 'meta_repr' in m_args:\n",
    "                    m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
    "                    m_repr,m_repr_mask = self.resize(m_repr, m_repr_mask, m_args['data2ptr'][idx])\n",
    "                    m_repr_mask = m_repr_mask.bool()\n",
    "                else:\n",
    "                    m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
    "                                                                m_args['data2ptr'][idx])\n",
    "                    n_meta = m_args['data2ptr'].max()\n",
    "                    \n",
    "                    if self.use_noise:\n",
    "                        m_input_ids, m_attention_mask = self.add_noise(m_input_ids, m_attention_mask, n_meta)\n",
    "\n",
    "                    m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
    "\n",
    "                    m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
    "                    m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
    "                    \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
    "\n",
    "                meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
    "                \n",
    "                fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                embed[idx] += self.cross_gate * fused_embed\n",
    "                \n",
    "        return embed, meta_repr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8a8df-444a-4782-901e-dc01f2472d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RAD004(RAD000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self, config,\n",
    "        resize_length:Optional[int]=None,\n",
    "        use_noise:Optional[bool]=True,\n",
    "        noise_percent:Optional[float]=0.7,\n",
    "\n",
    "        cross_margin:Optional[float]=0.3,\n",
    "        cross_tau:Optional[float]=0.1,\n",
    "        \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder004(config, use_noise=use_noise, noise_pct=noise_percent, resize_length=resize_length,\n",
    "                                  cross_margin=cross_margin, cross_tau=cross_tau)\n",
    "        \n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head(); self.init_cross_gate()\n",
    "        \n",
    "\n",
    "    def init_cross_gate(self):\n",
    "        self.encoder.cross_gate.data = torch.ones(1)\n",
    "            \n",
    "    def remap_post_init(self):\n",
    "         self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff960a8d-df76-4f99-9502-f3a7f52440bd",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35445b-61f7-44da-af64-380ab364b3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RAD004 were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.cross_gate', 'encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RAD004.from_pretrained('distilbert-base-uncased', num_batch_labels=5000, batch_size=100,\n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "\n",
    "                               resize_length=5000, use_noise=True, noise_percent=0.5,\n",
    "                               \n",
    "                               meta_loss_weight=0.3, fusion_loss_weight=0.1, \n",
    "                               use_fusion_loss=True,  use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_cross_gate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5bab78-e58b-42a4-9f27-42e42ffeabdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df99e3-14f7-447d-bae8-12b7b3a7d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "    'pcat2lbl_idx', 'pcat2lbl_lbl2data2ptr', 'pcat2lbl_data2ptr', 'cat2lbl_idx', 'cat2lbl_input_ids', \n",
    "    'cat2lbl_attention_mask', 'cat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2ceb2-90f9-456d-9a88-bf9cb08962a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'pcat2lbl_idx', 'pcat2lbl_lbl2data2ptr', 'pcat2lbl_data2ptr', 'cat2lbl_idx', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'cat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', 'cat2data_data2ptr', 'data_input_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be19e7-25ce-411f-a434-4aadb132e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb3e40-1cac-4682-b366-e3b1b326a82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0585, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd3d2b6-bcf6-43f7-aca9-ea64db304c86",
   "metadata": {},
   "source": [
    "## `RAD005`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f545a-0278-4929-9fb4-c223b78fa0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder005(Encoder):\n",
    "    \n",
    "    def __init__(self, config:PretrainedConfig, use_noise:Optional[bool]=True, noise_pct:Optional[float]=0.5, resize_length:Optional[int]=None,\n",
    "                cross_margin:Optional[float]=0.3, cross_tau:Optional[float]=0.1, cross_dropout:Optional[float]=0.1):\n",
    "        super().__init__(config, use_noise, noise_pct, resize_length) \n",
    "        self.cross_head = GatedCrossAttention2(config, margin=cross_margin, tau=cross_tau, dropout=cross_dropout)\n",
    "        self.cross_gate = nn.Parameter(torch.ones(1))\n",
    "        \n",
    "    \n",
    "    def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
    "            \n",
    "            if len(idx):\n",
    "                if 'meta_repr' in m_args:\n",
    "                    m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
    "                    m_repr,m_repr_mask = self.resize(m_repr, m_repr_mask, m_args['data2ptr'][idx])\n",
    "                    m_repr_mask = m_repr_mask.bool()\n",
    "                else:\n",
    "                    m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
    "                                                                m_args['data2ptr'][idx])\n",
    "                    n_meta = m_args['data2ptr'].max()\n",
    "                    \n",
    "                    if self.use_noise:\n",
    "                        m_input_ids, m_attention_mask = self.add_noise(m_input_ids, m_attention_mask, n_meta)\n",
    "\n",
    "                    m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
    "\n",
    "                    m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
    "                    m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
    "                    \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
    "\n",
    "                meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
    "                \n",
    "                fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
    "                embed[idx] += self.cross_gate * fused_embed\n",
    "                \n",
    "        return embed, meta_repr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506cd72-512d-4c85-9ca0-5aa76b972a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RAD005(RAD000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self, config,\n",
    "        resize_length:Optional[int]=None,\n",
    "        use_noise:Optional[bool]=True,\n",
    "        noise_percent:Optional[float]=0.7,\n",
    "\n",
    "        cross_margin:Optional[float]=0.3,\n",
    "        cross_tau:Optional[float]=0.1,\n",
    "        cross_dropout:Optional[float]=0.1,\n",
    "        \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder005(config, use_noise=use_noise, noise_pct=noise_percent, resize_length=resize_length,\n",
    "                                  cross_margin=cross_margin, cross_tau=cross_tau, cross_dropout=cross_dropout)\n",
    "        \n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head(); self.init_cross_gate()\n",
    "        \n",
    "\n",
    "    def init_cross_gate(self):\n",
    "        self.encoder.cross_gate.data = torch.ones(1)\n",
    "            \n",
    "    def remap_post_init(self):\n",
    "         self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b368d9-df8e-4e6b-ad34-3c11e2862ddc",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357fd21a-9e05-4cd6-a5c8-33089b4f555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RAD005 were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.cross_gate', 'encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.margin', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.tau', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RAD005.from_pretrained('distilbert-base-uncased', num_batch_labels=5000, batch_size=100,\n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "\n",
    "                               cross_margin=0.3, cross_tau=0.1, cross_dropout=0.1,\n",
    "\n",
    "                               resize_length=5000, use_noise=True, noise_percent=0.5,\n",
    "                               \n",
    "                               meta_loss_weight=0.3, fusion_loss_weight=0.1, \n",
    "                               use_fusion_loss=False,  use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_cross_gate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2147c2f-bafe-4cf8-9d45-0304bcbb3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "    'pcat2lbl_idx', 'pcat2lbl_lbl2data2ptr', 'pcat2lbl_data2ptr', 'cat2lbl_idx', 'cat2lbl_input_ids', \n",
    "    'cat2lbl_attention_mask', 'cat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f6e68-8420-4333-9bea-6662fe80bd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'pcat2lbl_idx', 'pcat2lbl_lbl2data2ptr', 'pcat2lbl_data2ptr', 'cat2lbl_idx', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'cat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', 'cat2data_data2ptr', 'data_input_ids', 'data_attention_mask'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a9c2d2-d7ea-4a47-8a96-93d662c7155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3542d2-5fda-43a3-aed6-c6e33b05d880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0571, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5deb48-d952-47ce-a31f-690aae7a1f1f",
   "metadata": {},
   "source": [
    "## `RAD006`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88339733-d623-4b73-a6d3-ebe4b3a4d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder006(Encoder):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig, \n",
    "        use_noise:Optional[bool]=True, \n",
    "        shuffle_noise_pct:Optional[float]=0.5, \n",
    "        dropout_noise_pct:Optional[float]=0.1, \n",
    "        resize_length:Optional[int]=None\n",
    "    ):\n",
    "        store_attr('dropout_noise_pct')\n",
    "        super().__init__(config, use_noise, shuffle_noise_pct, resize_length)\n",
    "\n",
    "    def add_noise(self, m_repr:torch.Tensor, m_repr_mask:torch.Tensor):\n",
    "        n_data, n_meta, dim = m_repr.shape\n",
    "        noise_mask = torch.rand(n_meta, n_data, device=m_repr.device) < self.noise_pct\n",
    "        for i,mask in enumerate(noise_mask):\n",
    "            rnd_idx = torch.randperm(mask.sum())\n",
    "            m_repr[:,i][mask] = m_repr[:,i][mask][rnd_idx]\n",
    "            m_repr_mask[:,i][mask] = m_repr_mask[:,i][mask][rnd_idx]\n",
    "        return m_repr,m_repr_mask\n",
    "\n",
    "    def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
    "            \n",
    "            if len(idx):\n",
    "                if 'meta_repr' in m_args:\n",
    "                    m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
    "                    m_repr,m_repr_mask = self.resize(m_repr, m_repr_mask, m_args['data2ptr'][idx])\n",
    "                    m_repr_mask = m_repr_mask.bool()\n",
    "                else:\n",
    "                    m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
    "                                                                m_args['data2ptr'][idx])\n",
    "                    n_meta = m_args['data2ptr'].max()\n",
    "                    m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
    "\n",
    "                    m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
    "                    m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
    "                    \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
    "                meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
    "\n",
    "                if self.use_noise: m_repr, m_repr_mask = self.add_noise(m_repr.clone(), m_repr_mask.clone())\n",
    "                \n",
    "                fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
    "\n",
    "                if self.use_noise:\n",
    "                    noise_mask = torch.rand(len(idx), device=fused_embed.device) > self.dropout_noise_pct\n",
    "                    embed[idx[noise_mask]] += fused_embed[noise_mask]\n",
    "                else:\n",
    "                    embed[idx] += fused_embed\n",
    "                \n",
    "        return embed, meta_repr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be0b97-bf5a-4ffa-b8e8-1ef6817d3f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RAD006(RAD000, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self, config,\n",
    "        resize_length:Optional[int]=None,\n",
    "        use_noise:Optional[bool]=False,\n",
    "        shuffle_noise_pct:Optional[float]=0.1,\n",
    "        dropout_noise_pct:Optional[float]=0.1,\n",
    "\n",
    "        calib_margin:Optional[float]=0.3,\n",
    "        calib_num_negatives:Optional[int]=10,\n",
    "        calib_tau:Optional[float]=0.1,\n",
    "        calib_apply_softmax:Optional[bool]=True,\n",
    "        calib_loss_weight:Optional[float]=0.1,\n",
    "        use_calib_loss:Optional[float]=False,\n",
    "\n",
    "        use_query_loss:Optional[float]=False,\n",
    "        \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.c_lw, self.use_calib_loss, self.use_query_loss = calib_loss_weight, use_calib_loss, use_query_loss\n",
    "        self.encoder = Encoder006(config, use_noise=use_noise, shuffle_noise_pct=shuffle_noise_pct, dropout_noise_pct=dropout_noise_pct,\n",
    "                                  resize_length=resize_length)\n",
    "        self.cab_loss_fn = Calibration(margin=calib_margin, tau=calib_tau, n_negatives=calib_num_negatives, \n",
    "                                       apply_softmax=calib_apply_softmax, reduce='mean')\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "        \n",
    "    def calibration_loss(self, einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx):\n",
    "        return self.c_lw * self.cab_loss_fn(einp_repr, inp_repr, targ_repr, targ_ptr, targ_idx, ptarg_ptr, ptarg_idx)\n",
    "        \n",
    "    def remap_post_init(self):\n",
    "         self.distilbert = self.encoder.distilbert\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = XCDataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
    "        data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
    "                         data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
    "        \n",
    "        \n",
    "        loss = None; lbl2data_o = EncoderOutput()\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('lbl2data', self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            lbl2data_o = encoder(data_input_ids=lbl2data_input_ids, data_attention_mask=lbl2data_attention_mask, \n",
    "                                 data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
    "            \n",
    "            loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                     plbl2data_data2ptr,plbl2data_idx)\n",
    "\n",
    "            if self.use_query_loss:\n",
    "                loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                          plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            if self.use_calib_loss:\n",
    "                loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
    "                                              plbl2data_data2ptr,plbl2data_idx)\n",
    "            \n",
    "            loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
    "            \n",
    "            if self.use_fusion_loss:\n",
    "                loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
    "                loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
    "            \n",
    "        if not return_dict:\n",
    "            o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "        \n",
    "        \n",
    "        return RADOutput(\n",
    "            loss=loss,\n",
    "            \n",
    "            data_repr=data_o.rep,\n",
    "            data_fused_repr=data_o.fused_rep,\n",
    "            \n",
    "            lbl2data_repr=lbl2data_o.rep,\n",
    "            lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8420983e-be51-4150-a8d7-42aacd6d3f0e",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f7e876-9691-4663-8cd0-795716fda003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RAD006 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RAD006.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "\n",
    "                               resize_length=5000, use_noise=False, shuffle_noise_pct=0.5, dropout_noise_pct=0.1,\n",
    "                               \n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               calib_margin=0.3, calib_num_negatives=5, calib_tau=0.1, calib_apply_softmax=True, calib_loss_weight=0.1,\n",
    "                               use_calib_loss=False,\n",
    "                               \n",
    "                               meta_loss_weight=0.0, fusion_loss_weight=0.0, use_fusion_loss=False,\n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5723019-5c60-47fe-a791-3a7a8674f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "    'pcat2lbl_idx', 'pcat2lbl_lbl2data2ptr', 'pcat2lbl_data2ptr', 'cat2lbl_idx', 'cat2lbl_input_ids', \n",
    "    'cat2lbl_attention_mask', 'cat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ee2e5-9710-4079-b6fd-a194c5fa96a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84160f70-9472-4e79-a3b4-4380a9c0e263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0087, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8f9be5-4051-47af-bacb-ebe3ff1af1b5",
   "metadata": {},
   "source": [
    "## `RAD007`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb88df8-654d-4678-b155-1250f3c6c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder007(Encoder006):\n",
    "    \n",
    "    def __init__(self, config:PretrainedConfig, use_noise:Optional[bool]=True, shuffle_noise_pct:Optional[float]=0.5, \n",
    "                 dropout_noise_pct:Optional[float]=0.1, resize_length:Optional[int]=None,\n",
    "                 cross_margin:Optional[float]=0.3, cross_tau:Optional[float]=0.1, cross_dropout:Optional[float]=0.1):\n",
    "        \n",
    "        super().__init__(config, use_noise, shuffle_noise_pct, dropout_noise_pct, resize_length)\n",
    "        self.cross_head = GatedCrossAttention2(config, margin=cross_margin, tau=cross_tau, dropout=cross_dropout)\n",
    "        self.cross_gate = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
    "            \n",
    "            if len(idx):\n",
    "                if 'meta_repr' in m_args:\n",
    "                    m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
    "                    m_repr,m_repr_mask = self.resize(m_repr, m_repr_mask, m_args['data2ptr'][idx])\n",
    "                    m_repr_mask = m_repr_mask.bool()\n",
    "                else:\n",
    "                    m_input_ids, m_attention_mask = self.resize(m_args['input_ids'], m_args['attention_mask'], \n",
    "                                                                m_args['data2ptr'][idx])\n",
    "                    n_meta = m_args['data2ptr'].max()\n",
    "                    m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
    "\n",
    "                    m_repr = self.meta_unnormalized(m_embed, m_attention_mask)\n",
    "                    m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
    "                    \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
    "                meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
    "\n",
    "                if self.use_noise: m_repr, m_repr_mask = self.add_noise(m_repr.clone(), m_repr_mask.clone())\n",
    "                \n",
    "                fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
    "\n",
    "                if self.use_noise:\n",
    "                    noise_mask = torch.rand(len(idx), device=fused_embed.device) > self.dropout_noise_pct\n",
    "                    embed[idx[noise_mask]] += self.cross_gate * fused_embed[noise_mask]\n",
    "                else:\n",
    "                    embed[idx] += self.cross_gate * fused_embed\n",
    "                \n",
    "        return embed, meta_repr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686170c-3cad-4135-864a-a4312dc278ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RAD007(RAD006, DistilBertPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "    \n",
    "    def __init__(\n",
    "        self, config,\n",
    "        resize_length:Optional[int]=None,\n",
    "        use_noise:Optional[bool]=True,\n",
    "        shuffle_noise_pct:Optional[float]=0.3,\n",
    "        dropout_noise_pct:Optional[float]=0.3,\n",
    "        \n",
    "        cross_margin:Optional[float]=0.3,\n",
    "        cross_tau:Optional[float]=0.1,\n",
    "        cross_dropout:Optional[float]=0.1,\n",
    "        \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.encoder = Encoder007(config, use_noise=use_noise, shuffle_noise_pct=shuffle_noise_pct, dropout_noise_pct=dropout_noise_pct,\n",
    "                                  resize_length=resize_length, cross_margin=cross_margin, cross_tau=cross_tau, cross_dropout=cross_dropout)\n",
    "        \n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head(); self.init_cross_gate()\n",
    "        \n",
    "\n",
    "    def init_cross_gate(self):\n",
    "        self.encoder.cross_gate.data = torch.ones(1)\n",
    "            \n",
    "    def remap_post_init(self):\n",
    "         self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8692a13e-2ecc-4043-b01c-0577c4a46cbe",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d710169-0c7c-4fe2-b5e6-124e4cc0edd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RAD007 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_gate', 'encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.margin', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.tau', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RAD007.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix='cat2lbl',\n",
    "\n",
    "                               resize_length=5000, use_noise=True, shuffle_noise_pct=0.5, dropout_noise_pct=0.1,\n",
    "                               \n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               cross_margin=0.3, cross_tau=0.1, cross_dropout=0.1,\n",
    "                               \n",
    "                               calib_margin=0.3, calib_num_negatives=10, calib_tau=0.1, calib_apply_softmax=True, calib_loss_weight=1.0,\n",
    "                               use_calib_loss= True,\n",
    "                               \n",
    "                               meta_loss_weight=0.1, fusion_loss_weight=0.1, use_fusion_loss=True,\n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()\n",
    "model.init_cross_gate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bec7bf-3b2d-4cac-8742-c6b4651f391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "    'pcat2lbl_idx', 'pcat2lbl_lbl2data2ptr', 'pcat2lbl_data2ptr', 'cat2lbl_idx', 'cat2lbl_input_ids', \n",
    "    'cat2lbl_attention_mask', 'cat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0ab14-c9c3-41e3-9574-9f0211c12b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4349187a-17ea-4d40-afd0-c365fd898b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1098, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b141e1e-62f1-43a7-a696-ae73916db580",
   "metadata": {},
   "source": [
    "## `RAD008`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaf7b00-82ac-46ad-9e04-362320f89c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder008(Encoder):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config:PretrainedConfig,\n",
    "        num_metadata:int,\n",
    "        use_noise:Optional[bool]=True, \n",
    "        shuffle_noise_pct:Optional[float]=0.5, \n",
    "        dropout_noise_pct:Optional[float]=0.1, \n",
    "        resize_length:Optional[int]=None,\n",
    "    ):\n",
    "        store_attr('dropout_noise_pct')\n",
    "        super().__init__(config, use_noise, shuffle_noise_pct, resize_length)\n",
    "        self.meta_embeddings = nn.Embedding(num_metadata, config.dim)\n",
    "\n",
    "    def freeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(False)\n",
    "\n",
    "    def unfreeze_meta_embeddings(self):\n",
    "        self.meta_embeddings.requires_grad_(True)\n",
    "\n",
    "    def set_meta_embeddings(self, embed:torch.Tensor):\n",
    "        self.meta_embeddings.weight.data = embed\n",
    "\n",
    "    def resize(self, inputs:torch.Tensor, mask:torch.Tensor, idx:torch.Tensor, num_inputs:torch.Tensor):\n",
    "        if torch.any(num_inputs == 0): raise ValueError(\"`num_inputs` should be non-zero positive integer.\")\n",
    "        bsz, dim, total_num_inputs = num_inputs.shape[0], inputs.shape[-1], inputs.shape[0]\n",
    "        \n",
    "        self.ones = self.ones.to(inputs.device)\n",
    "        ones = (\n",
    "            torch.ones(total_num_inputs, dtype=torch.long, device=inputs.device) \n",
    "            if self.ones is None or self.ones.shape[0] < total_num_inputs else self.ones[:total_num_inputs]\n",
    "        )\n",
    "\n",
    "        max_num_inputs = num_inputs.max()\n",
    "        xnum_inputs = max_num_inputs-num_inputs+1\n",
    "\n",
    "        inputs_ptr = num_inputs.cumsum(dim=0)-1\n",
    "        repeat_inputs = ones.scatter(0, inputs_ptr, xnum_inputs)\n",
    "        \n",
    "        resized_inputs = inputs.repeat_interleave(repeat_inputs, dim=0)\n",
    "        resized_mask = mask.repeat_interleave(repeat_inputs, dim=0)\n",
    "        resized_idx = idx.repeat_interleave(repeat_inputs, dim=0)\n",
    "        \n",
    "        ignore_mask_idx = ones.scatter(0, inputs_ptr, 0).repeat_interleave(repeat_inputs, dim=0).view(bsz, -1)\n",
    "        ignore_mask_idx[:, -1] = 1; ignore_mask_idx = ignore_mask_idx.view(-1, 1)\n",
    "        \n",
    "        resized_mask *= ignore_mask_idx\n",
    "        \n",
    "        return resized_inputs,resized_mask,resized_idx\n",
    "\n",
    "    def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
    "        meta_repr = {}\n",
    "        \n",
    "        for m_key, m_args in meta_kwargs.items():\n",
    "            idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
    "            meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
    "            \n",
    "            if len(idx):\n",
    "                if 'meta_repr' in m_args:\n",
    "                    m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
    "                    m_repr,m_repr_mask = self.resize(m_repr, m_repr_mask, m_args['data2ptr'][idx])\n",
    "                    m_repr_mask = m_repr_mask.bool()\n",
    "                else:\n",
    "                    m_input_ids, m_attention_mask, m_idx = self.resize(m_args['input_ids'], m_args['attention_mask'], m_args['idx'],\n",
    "                                                                       m_args['data2ptr'][idx])\n",
    "                    n_meta = m_args['data2ptr'].max()\n",
    "                    m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
    "\n",
    "                    m_repr = self.meta(m_embed, m_attention_mask)\n",
    "                    m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
    "\n",
    "                m_repr = F.normalize(m_repr + self.meta_embeddings(m_idx), dim=-1)\n",
    "                \n",
    "                m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
    "                meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
    "\n",
    "                if self.use_noise: m_repr, m_repr_mask = self.add_noise(m_repr.clone(), m_repr_mask.clone())\n",
    "                \n",
    "                fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
    "\n",
    "                if self.use_noise:\n",
    "                    noise_mask = torch.rand(len(idx), device=fused_embed.device) > self.dropout_noise_pct\n",
    "                    embed[idx[noise_mask]] += fused_embed[noise_mask]\n",
    "                else:\n",
    "                    embed[idx] += fused_embed\n",
    "                \n",
    "        return embed, meta_repr\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        data_input_ids: torch.Tensor, \n",
    "        data_attention_mask: torch.Tensor,\n",
    "        data_aug_meta_prefix: Optional[str]=None,\n",
    "        data_type:Optional[str]=None,\n",
    "        data_unnormalized:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        data_o = self.encode(data_input_ids, data_attention_mask)\n",
    "        data_embed = F.normalize(data_o[0], dim=-1)\n",
    "        \n",
    "        if data_type is not None and data_type == \"meta\":\n",
    "            data_repr = self.meta(data_embed, data_attention_mask) \n",
    "        else: \n",
    "            data_repr = self.dr(data_embed, data_attention_mask)\n",
    "        \n",
    "        data_fused_repr = meta_repr = None\n",
    "        if data_aug_meta_prefix is not None:\n",
    "            meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
    "            if len(meta_kwargs):\n",
    "                data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
    "                                                                             data_attention_mask, \n",
    "                                                                             meta_kwargs)\n",
    "                data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
    "        \n",
    "        return EncoderOutput(\n",
    "            rep=data_repr,\n",
    "            fused_rep=data_fused_repr,\n",
    "            meta_repr=meta_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a5f5d2-c492-4405-86fe-2ae9d1ff8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RAD008(RAD006):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"encoder.distilbert\"]\n",
    "\n",
    "    @delegates(RAD006.__init__)\n",
    "    def __init__(\n",
    "        self, config,\n",
    "        num_metadata:int,\n",
    "        resize_length:Optional[int]=None,\n",
    "        use_noise:Optional[bool]=False,\n",
    "        shuffle_noise_pct:Optional[float]=0.1,\n",
    "        dropout_noise_pct:Optional[float]=0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "\n",
    "        \n",
    "        self.encoder = Encoder008(config, num_metadata=num_metadata, use_noise=use_noise, shuffle_noise_pct=shuffle_noise_pct, \n",
    "                                  dropout_noise_pct=dropout_noise_pct, resize_length=resize_length)\n",
    "        self.post_init(); self.remap_post_init(); self.init_retrieval_head(); self.init_cross_head()\n",
    "        \n",
    "    def remap_post_init(self):\n",
    "        self.distilbert = self.encoder.distilbert\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05024cc-4037-4839-bb49-744e42a7b573",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054089b6-9564-4f46-8252-cb5cacf0bed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RAD008 were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-v4 and are newly initialized: ['encoder.cross_head.k.bias', 'encoder.cross_head.k.weight', 'encoder.cross_head.o.bias', 'encoder.cross_head.o.weight', 'encoder.cross_head.q.bias', 'encoder.cross_head.q.weight', 'encoder.cross_head.v.bias', 'encoder.cross_head.v.weight', 'encoder.dr_fused_head.layer_norm.bias', 'encoder.dr_fused_head.layer_norm.weight', 'encoder.dr_fused_head.projector.bias', 'encoder.dr_fused_head.projector.weight', 'encoder.dr_fused_head.transform.bias', 'encoder.dr_fused_head.transform.weight', 'encoder.dr_head.layer_norm.bias', 'encoder.dr_head.layer_norm.weight', 'encoder.dr_head.projector.bias', 'encoder.dr_head.projector.weight', 'encoder.dr_head.transform.bias', 'encoder.dr_head.transform.weight', 'encoder.meta_embeddings.weight', 'encoder.meta_head.layer_norm.bias', 'encoder.meta_head.layer_norm.weight', 'encoder.meta_head.projector.bias', 'encoder.meta_head.projector.weight', 'encoder.meta_head.transform.bias', 'encoder.meta_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RAD008.from_pretrained('sentence-transformers/msmarco-distilbert-base-v4', batch_size=100, num_batch_labels=5000, \n",
    "                               margin=0.3, num_negatives=5, tau=0.1, apply_softmax=True,\n",
    "                               \n",
    "                               data_aug_meta_prefix='cat2data', lbl2data_aug_meta_prefix=None, \n",
    "                               data_pred_meta_prefix=None, lbl2data_pred_meta_prefix=None,\n",
    "\n",
    "                               num_metadata=block.train.dset.meta['cat_meta'].n_meta, \n",
    "                               resize_length=5000, use_noise=False, shuffle_noise_pct=0.5, dropout_noise_pct=0.1,\n",
    "                               \n",
    "                               use_query_loss=True,\n",
    "\n",
    "                               calib_margin=0.3, calib_num_negatives=5, calib_tau=0.1, calib_apply_softmax=True, calib_loss_weight=0.1,\n",
    "                               use_calib_loss=False,\n",
    "                               \n",
    "                               meta_loss_weight=0.0, fusion_loss_weight=0.0, use_fusion_loss=False,\n",
    "                               use_encoder_parallel=False)\n",
    "\n",
    "model.init_retrieval_head()\n",
    "model.init_cross_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef8e00-1ea9-4666-9320-669f686ebccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prepare_batch(model, batch, m_args=[\n",
    "    'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_input_ids', 'cat2data_attention_mask', \n",
    "    'cat2data_data2ptr',\n",
    "    'pcat2lbl_idx', 'pcat2lbl_lbl2data2ptr', 'pcat2lbl_data2ptr', 'cat2lbl_idx', 'cat2lbl_input_ids', \n",
    "    'cat2lbl_attention_mask', 'cat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0ba23-3bed-46ca-b555-5df8cdc651c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(53)forward()\n",
      "     51         **kwargs\n",
      "     52     ):  \n",
      "---> 53         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     54 \n",
      "     55         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(55)forward()\n",
      "     53         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     54 \n",
      "---> 55         if self.use_encoder_parallel:\n",
      "     56             encoder = XCDataParallel(module=self.encoder)\n",
      "     57         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(57)forward()\n",
      "     55         if self.use_encoder_parallel:\n",
      "     56             encoder = XCDataParallel(module=self.encoder)\n",
      "---> 57         else: encoder = self.encoder\n",
      "     58 \n",
      "     59         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(59)forward()\n",
      "     57         else: encoder = self.encoder\n",
      "     58 \n",
      "---> 59         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     60         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     61                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(60)forward()\n",
      "     58 \n",
      "     59         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 60         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     61                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     62 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(100)forward()\n",
      "     98         **kwargs\n",
      "     99     ):\n",
      "--> 100         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    101         data_embed = F.normalize(data_o[0], dim=-1)\n",
      "    102 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(101)forward()\n",
      "     99     ):\n",
      "    100         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "--> 101         data_embed = F.normalize(data_o[0], dim=-1)\n",
      "    102 \n",
      "    103         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(103)forward()\n",
      "    101         data_embed = F.normalize(data_o[0], dim=-1)\n",
      "    102 \n",
      "--> 103         if data_type is not None and data_type == \"meta\":\n",
      "    104             data_repr = self.meta(data_embed, data_attention_mask)\n",
      "    105         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_embed.norm(dim=-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(106)forward()\n",
      "    104             data_repr = self.meta(data_embed, data_attention_mask)\n",
      "    105         else:\n",
      "--> 106             data_repr = self.dr(data_embed, data_attention_mask)\n",
      "    107 \n",
      "    108         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(108)forward()\n",
      "    106             data_repr = self.dr(data_embed, data_attention_mask)\n",
      "    107 \n",
      "--> 108         data_fused_repr = meta_repr = None\n",
      "    109         if data_aug_meta_prefix is not None:\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(109)forward()\n",
      "    107 \n",
      "    108         data_fused_repr = meta_repr = None\n",
      "--> 109         if data_aug_meta_prefix is not None:\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    111             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(110)forward()\n",
      "    108         data_fused_repr = meta_repr = None\n",
      "    109         if data_aug_meta_prefix is not None:\n",
      "--> 110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    111             if len(meta_kwargs):\n",
      "    112                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(111)forward()\n",
      "    109         if data_aug_meta_prefix is not None:\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "--> 111             if len(meta_kwargs):\n",
      "    112                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
      "    113                                                                              data_attention_mask,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(112)forward()\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    111             if len(meta_kwargs):\n",
      "--> 112                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
      "    113                                                                              data_attention_mask,\n",
      "    114                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(113)forward()\n",
      "    111             if len(meta_kwargs):\n",
      "    112                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
      "--> 113                                                                              data_attention_mask,\n",
      "    114                                                                              meta_kwargs)\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(114)forward()\n",
      "    112                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
      "    113                                                                              data_attention_mask,\n",
      "--> 114                                                                              meta_kwargs)\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(112)forward()\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    111             if len(meta_kwargs):\n",
      "--> 112                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
      "    113                                                                              data_attention_mask,\n",
      "    114                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /tmp/ipykernel_32743/3514307414.py(53)fuse_meta_into_embeddings()\n",
      "     51         return resized_inputs,resized_mask,resized_idx\n",
      "     52 \n",
      "3--> 53     def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "     54         meta_repr = {}\n",
      "     55 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(54)fuse_meta_into_embeddings()\n",
      "     52 \n",
      "3    53     def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "---> 54         meta_repr = {}\n",
      "     55 \n",
      "     56         for m_key, m_args in meta_kwargs.items():\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(56)fuse_meta_into_embeddings()\n",
      "     54         meta_repr = {}\n",
      "     55 \n",
      "---> 56         for m_key, m_args in meta_kwargs.items():\n",
      "     57             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     58             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(57)fuse_meta_into_embeddings()\n",
      "     55 \n",
      "     56         for m_key, m_args in meta_kwargs.items():\n",
      "---> 57             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     58             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "     59 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(58)fuse_meta_into_embeddings()\n",
      "     56         for m_key, m_args in meta_kwargs.items():\n",
      "     57             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "---> 58             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "     59 \n",
      "     60             if len(idx):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(60)fuse_meta_into_embeddings()\n",
      "     58             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "     59 \n",
      "---> 60             if len(idx):\n",
      "     61                 if 'meta_repr' in m_args:\n",
      "     62                     m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(61)fuse_meta_into_embeddings()\n",
      "     59 \n",
      "     60             if len(idx):\n",
      "---> 61                 if 'meta_repr' in m_args:\n",
      "     62                     m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
      "     63                     m_repr,m_repr_mask = self.resize(m_repr, m_repr_mask, m_args['data2ptr'][idx])\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(66)fuse_meta_into_embeddings()\n",
      "     64                     m_repr_mask = m_repr_mask.bool()\n",
      "     65                 else:\n",
      "---> 66                     m_input_ids, m_attention_mask, m_idx = self.resize(m_args['input_ids'], m_args['attention_mask'], m_args['idx'],\n",
      "     67                                                                        m_args['data2ptr'][idx])\n",
      "     68                     n_meta = m_args['data2ptr'].max()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(67)fuse_meta_into_embeddings()\n",
      "     65                 else:\n",
      "     66                     m_input_ids, m_attention_mask, m_idx = self.resize(m_args['input_ids'], m_args['attention_mask'], m_args['idx'],\n",
      "---> 67                                                                        m_args['data2ptr'][idx])\n",
      "     68                     n_meta = m_args['data2ptr'].max()\n",
      "     69                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(66)fuse_meta_into_embeddings()\n",
      "     64                     m_repr_mask = m_repr_mask.bool()\n",
      "     65                 else:\n",
      "---> 66                     m_input_ids, m_attention_mask, m_idx = self.resize(m_args['input_ids'], m_args['attention_mask'], m_args['idx'],\n",
      "     67                                                                        m_args['data2ptr'][idx])\n",
      "     68                     n_meta = m_args['data2ptr'].max()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(68)fuse_meta_into_embeddings()\n",
      "     66                     m_input_ids, m_attention_mask, m_idx = self.resize(m_args['input_ids'], m_args['attention_mask'], m_args['idx'],\n",
      "     67                                                                        m_args['data2ptr'][idx])\n",
      "---> 68                     n_meta = m_args['data2ptr'].max()\n",
      "     69                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "     70 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(69)fuse_meta_into_embeddings()\n",
      "     67                                                                        m_args['data2ptr'][idx])\n",
      "     68                     n_meta = m_args['data2ptr'].max()\n",
      "---> 69                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "     70 \n",
      "     71                     m_repr = self.meta(m_embed, m_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(71)fuse_meta_into_embeddings()\n",
      "     69                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "     70 \n",
      "---> 71                     m_repr = self.meta(m_embed, m_attention_mask)\n",
      "     72                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "     73 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(72)fuse_meta_into_embeddings()\n",
      "     70 \n",
      "     71                     m_repr = self.meta(m_embed, m_attention_mask)\n",
      "---> 72                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "     73 \n",
      "     74                 m_repr = F.normalize(m_repr + self.meta_embeddings(m_idx), dim=-1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(74)fuse_meta_into_embeddings()\n",
      "     72                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "     73 \n",
      "---> 74                 m_repr = F.normalize(m_repr + self.meta_embeddings(m_idx), dim=-1)\n",
      "     75 \n",
      "     76                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(76)fuse_meta_into_embeddings()\n",
      "     74                 m_repr = F.normalize(m_repr + self.meta_embeddings(m_idx), dim=-1)\n",
      "     75 \n",
      "---> 76                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "     77                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "     78 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(77)fuse_meta_into_embeddings()\n",
      "     75 \n",
      "     76                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "---> 77                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "     78 \n",
      "     79                 if self.use_noise: m_repr, m_repr_mask = self.add_noise(m_repr.clone(), m_repr_mask.clone())\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(79)fuse_meta_into_embeddings()\n",
      "     77                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "     78 \n",
      "---> 79                 if self.use_noise: m_repr, m_repr_mask = self.add_noise(m_repr.clone(), m_repr_mask.clone())\n",
      "     80 \n",
      "     81                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(81)fuse_meta_into_embeddings()\n",
      "     79                 if self.use_noise: m_repr, m_repr_mask = self.add_noise(m_repr.clone(), m_repr_mask.clone())\n",
      "     80 \n",
      "---> 81                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "     82 \n",
      "     83                 if self.use_noise:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  embed[idx].norm(dim=-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.norm(dim=-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000]], grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(83)fuse_meta_into_embeddings()\n",
      "     81                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "     82 \n",
      "---> 83                 if self.use_noise:\n",
      "     84                     noise_mask = torch.rand(len(idx), device=fused_embed.device) > self.dropout_noise_pct\n",
      "     85                     embed[idx[noise_mask]] += fused_embed[noise_mask]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(87)fuse_meta_into_embeddings()\n",
      "     85                     embed[idx[noise_mask]] += fused_embed[noise_mask]\n",
      "     86                 else:\n",
      "---> 87                     embed[idx] += fused_embed\n",
      "     88 \n",
      "     89         return embed, meta_repr\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(56)fuse_meta_into_embeddings()\n",
      "     54         meta_repr = {}\n",
      "     55 \n",
      "---> 56         for m_key, m_args in meta_kwargs.items():\n",
      "     57             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     58             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(89)fuse_meta_into_embeddings()\n",
      "     87                     embed[idx] += fused_embed\n",
      "     88 \n",
      "---> 89         return embed, meta_repr\n",
      "     90 \n",
      "2    91     def forward(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[[-0....PutBackward0>), {'cat2data': tensor([[-0.0...DivBackward0>)})\n",
      "> /tmp/ipykernel_32743/3514307414.py(89)fuse_meta_into_embeddings()\n",
      "     87                     embed[idx] += fused_embed\n",
      "     88 \n",
      "---> 89         return embed, meta_repr\n",
      "     90 \n",
      "2    91     def forward(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(115)forward()\n",
      "    113                                                                              data_attention_mask,\n",
      "    114                                                                              meta_kwargs)\n",
      "--> 115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "    117         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(117)forward()\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "--> 117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(118)forward()\n",
      "    116 \n",
      "    117         return EncoderOutput(\n",
      "--> 118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "    120             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(119)forward()\n",
      "    117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "--> 119             fused_rep=data_fused_repr,\n",
      "    120             meta_repr=meta_repr,\n",
      "    121         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(120)forward()\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "--> 120             meta_repr=meta_repr,\n",
      "    121         )\n",
      "    122 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(117)forward()\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "--> 117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...vBackward0>)})\n",
      "> /tmp/ipykernel_32743/3514307414.py(117)forward()\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "--> 117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(100)forward()\n",
      "     98         **kwargs\n",
      "     99     ):\n",
      "--> 100         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    101         data_embed = F.normalize(data_o[0], dim=-1)\n",
      "    102 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(101)forward()\n",
      "     99     ):\n",
      "    100         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "--> 101         data_embed = F.normalize(data_o[0], dim=-1)\n",
      "    102 \n",
      "    103         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(103)forward()\n",
      "    101         data_embed = F.normalize(data_o[0], dim=-1)\n",
      "    102 \n",
      "--> 103         if data_type is not None and data_type == \"meta\":\n",
      "    104             data_repr = self.meta(data_embed, data_attention_mask)\n",
      "    105         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(106)forward()\n",
      "    104             data_repr = self.meta(data_embed, data_attention_mask)\n",
      "    105         else:\n",
      "--> 106             data_repr = self.dr(data_embed, data_attention_mask)\n",
      "    107 \n",
      "    108         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(108)forward()\n",
      "    106             data_repr = self.dr(data_embed, data_attention_mask)\n",
      "    107 \n",
      "--> 108         data_fused_repr = meta_repr = None\n",
      "    109         if data_aug_meta_prefix is not None:\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(109)forward()\n",
      "    107 \n",
      "    108         data_fused_repr = meta_repr = None\n",
      "--> 109         if data_aug_meta_prefix is not None:\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    111             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(117)forward()\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "--> 117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(118)forward()\n",
      "    116 \n",
      "    117         return EncoderOutput(\n",
      "--> 118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "    120             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(119)forward()\n",
      "    117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "--> 119             fused_rep=data_fused_repr,\n",
      "    120             meta_repr=meta_repr,\n",
      "    121         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(120)forward()\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "--> 120             meta_repr=meta_repr,\n",
      "    121         )\n",
      "    122 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(117)forward()\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "--> 117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> /tmp/ipykernel_32743/3514307414.py(117)forward()\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "--> 117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    }
   ],
   "source": [
    "o = model(**b.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0329df0-ace8-486c-8125-593d0a150f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0850, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e6b18a-885f-4e83-9186-09e4abc2338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    return model(**b.to(model.device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32bcbc7-2f3b-4479-8fed-b77c2d7b589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3657616883.py(3)func()\n",
      "      1 def func():\n",
      "      2     import pdb; pdb.set_trace()\n",
      "----> 3     return model(**b.to(model.device))\n",
      "      4 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 1 at /tmp/ipykernel_32743/1454671095.py:38\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.encoder.forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 2 at /tmp/ipykernel_32743/3514307414.py:91\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  b model.encoder.fuse_meta_into_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakpoint 3 at /tmp/ipykernel_32743/3514307414.py:53\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(53)forward()\n",
      "     51         **kwargs\n",
      "     52     ):  \n",
      "---> 53         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     54 \n",
      "     55         if self.use_encoder_parallel:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(55)forward()\n",
      "     53         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
      "     54 \n",
      "---> 55         if self.use_encoder_parallel:\n",
      "     56             encoder = XCDataParallel(module=self.encoder)\n",
      "     57         else: encoder = self.encoder\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(57)forward()\n",
      "     55         if self.use_encoder_parallel:\n",
      "     56             encoder = XCDataParallel(module=self.encoder)\n",
      "---> 57         else: encoder = self.encoder\n",
      "     58 \n",
      "     59         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(59)forward()\n",
      "     57         else: encoder = self.encoder\n",
      "     58 \n",
      "---> 59         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     60         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     61                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(60)forward()\n",
      "     58 \n",
      "     59         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 60         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     61                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     62 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(61)forward()\n",
      "     59         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     60         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 61                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     62 \n",
      "     63 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(60)forward()\n",
      "     58 \n",
      "     59         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 60         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     61                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     62 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(61)forward()\n",
      "     59         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "     60         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "---> 61                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     62 \n",
      "     63 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(60)forward()\n",
      "     58 \n",
      "     59         data_meta_kwargs = Parameters.from_feat_meta_aug_prefix('data', self.data_aug_meta_prefix, **kwargs)\n",
      "---> 60         data_o = encoder(data_input_ids=data_input_ids, data_attention_mask=data_attention_mask, \n",
      "     61                          data_aug_meta_prefix=self.data_aug_meta_prefix, **data_meta_kwargs)\n",
      "     62 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(100)forward()\n",
      "     98         **kwargs\n",
      "     99     ):\n",
      "--> 100         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    101         data_embed = F.normalize(data_o[0], dim=-1)\n",
      "    102 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(101)forward()\n",
      "     99     ):\n",
      "    100         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "--> 101         data_embed = F.normalize(data_o[0], dim=-1)\n",
      "    102 \n",
      "    103         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(103)forward()\n",
      "    101         data_embed = F.normalize(data_o[0], dim=-1)\n",
      "    102 \n",
      "--> 103         if data_type is not None and data_type == \"meta\":\n",
      "    104             data_repr = self.meta(data_embed, data_attention_mask)\n",
      "    105         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_embed.norm(dim=-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(106)forward()\n",
      "    104             data_repr = self.meta(data_embed, data_attention_mask)\n",
      "    105         else:\n",
      "--> 106             data_repr = self.dr(data_embed, data_attention_mask)\n",
      "    107 \n",
      "    108         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(108)forward()\n",
      "    106             data_repr = self.dr(data_embed, data_attention_mask)\n",
      "    107 \n",
      "--> 108         data_fused_repr = meta_repr = None\n",
      "    109         if data_aug_meta_prefix is not None:\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(109)forward()\n",
      "    107 \n",
      "    108         data_fused_repr = meta_repr = None\n",
      "--> 109         if data_aug_meta_prefix is not None:\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    111             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(110)forward()\n",
      "    108         data_fused_repr = meta_repr = None\n",
      "    109         if data_aug_meta_prefix is not None:\n",
      "--> 110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    111             if len(meta_kwargs):\n",
      "    112                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(111)forward()\n",
      "    109         if data_aug_meta_prefix is not None:\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "--> 111             if len(meta_kwargs):\n",
      "    112                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
      "    113                                                                              data_attention_mask,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(112)forward()\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    111             if len(meta_kwargs):\n",
      "--> 112                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
      "    113                                                                              data_attention_mask,\n",
      "    114                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(113)forward()\n",
      "    111             if len(meta_kwargs):\n",
      "    112                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
      "--> 113                                                                              data_attention_mask,\n",
      "    114                                                                              meta_kwargs)\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(114)forward()\n",
      "    112                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
      "    113                                                                              data_attention_mask,\n",
      "--> 114                                                                              meta_kwargs)\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(112)forward()\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    111             if len(meta_kwargs):\n",
      "--> 112                 data_fused_embed, meta_repr = self.fuse_meta_into_embeddings(data_embed, \n",
      "    113                                                                              data_attention_mask,\n",
      "    114                                                                              meta_kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(54)fuse_meta_into_embeddings()\n",
      "     52 \n",
      "3    53     def fuse_meta_into_embeddings(self, embed:torch.Tensor, attention_mask:torch.Tensor, meta_kwargs:Dict):\n",
      "---> 54         meta_repr = {}\n",
      "     55 \n",
      "     56         for m_key, m_args in meta_kwargs.items():\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(56)fuse_meta_into_embeddings()\n",
      "     54         meta_repr = {}\n",
      "     55 \n",
      "---> 56         for m_key, m_args in meta_kwargs.items():\n",
      "     57             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     58             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(57)fuse_meta_into_embeddings()\n",
      "     55 \n",
      "     56         for m_key, m_args in meta_kwargs.items():\n",
      "---> 57             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     58             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "     59 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(58)fuse_meta_into_embeddings()\n",
      "     56         for m_key, m_args in meta_kwargs.items():\n",
      "     57             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "---> 58             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "     59 \n",
      "     60             if len(idx):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(60)fuse_meta_into_embeddings()\n",
      "     58             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "     59 \n",
      "---> 60             if len(idx):\n",
      "     61                 if 'meta_repr' in m_args:\n",
      "     62                     m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(61)fuse_meta_into_embeddings()\n",
      "     59 \n",
      "     60             if len(idx):\n",
      "---> 61                 if 'meta_repr' in m_args:\n",
      "     62                     m_repr,m_repr_mask = m_args['meta_repr'],torch.any(m_args['attention_mask'], dim=1).long().view(-1,1)\n",
      "     63                     m_repr,m_repr_mask = self.resize(m_repr, m_repr_mask, m_args['data2ptr'][idx])\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(66)fuse_meta_into_embeddings()\n",
      "     64                     m_repr_mask = m_repr_mask.bool()\n",
      "     65                 else:\n",
      "---> 66                     m_input_ids, m_attention_mask, m_idx = self.resize(m_args['input_ids'], m_args['attention_mask'], m_args['idx'],\n",
      "     67                                                                        m_args['data2ptr'][idx])\n",
      "     68                     n_meta = m_args['data2ptr'].max()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(67)fuse_meta_into_embeddings()\n",
      "     65                 else:\n",
      "     66                     m_input_ids, m_attention_mask, m_idx = self.resize(m_args['input_ids'], m_args['attention_mask'], m_args['idx'],\n",
      "---> 67                                                                        m_args['data2ptr'][idx])\n",
      "     68                     n_meta = m_args['data2ptr'].max()\n",
      "     69                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(66)fuse_meta_into_embeddings()\n",
      "     64                     m_repr_mask = m_repr_mask.bool()\n",
      "     65                 else:\n",
      "---> 66                     m_input_ids, m_attention_mask, m_idx = self.resize(m_args['input_ids'], m_args['attention_mask'], m_args['idx'],\n",
      "     67                                                                        m_args['data2ptr'][idx])\n",
      "     68                     n_meta = m_args['data2ptr'].max()\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(68)fuse_meta_into_embeddings()\n",
      "     66                     m_input_ids, m_attention_mask, m_idx = self.resize(m_args['input_ids'], m_args['attention_mask'], m_args['idx'],\n",
      "     67                                                                        m_args['data2ptr'][idx])\n",
      "---> 68                     n_meta = m_args['data2ptr'].max()\n",
      "     69                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "     70 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(69)fuse_meta_into_embeddings()\n",
      "     67                                                                        m_args['data2ptr'][idx])\n",
      "     68                     n_meta = m_args['data2ptr'].max()\n",
      "---> 69                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "     70 \n",
      "     71                     m_repr = self.meta(m_embed, m_attention_mask)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(71)fuse_meta_into_embeddings()\n",
      "     69                     m_embed = self.encode(m_input_ids, m_attention_mask)[0]\n",
      "     70 \n",
      "---> 71                     m_repr = self.meta(m_embed, m_attention_mask)\n",
      "     72                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "     73 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(72)fuse_meta_into_embeddings()\n",
      "     70 \n",
      "     71                     m_repr = self.meta(m_embed, m_attention_mask)\n",
      "---> 72                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "     73 \n",
      "     74                 m_repr = F.normalize(m_repr + self.meta_embeddings(m_idx), dim=-1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(74)fuse_meta_into_embeddings()\n",
      "     72                     m_repr_mask = torch.any(m_attention_mask, dim=1)\n",
      "     73 \n",
      "---> 74                 m_repr = F.normalize(m_repr + self.meta_embeddings(m_idx), dim=-1)\n",
      "     75 \n",
      "     76                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr_mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True,  True,  True, False, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(76)fuse_meta_into_embeddings()\n",
      "     74                 m_repr = F.normalize(m_repr + self.meta_embeddings(m_idx), dim=-1)\n",
      "     75 \n",
      "---> 76                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "     77                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "     78 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(77)fuse_meta_into_embeddings()\n",
      "     75 \n",
      "     76                 m_repr, m_repr_mask = m_repr.view(len(idx), -1, self.config.dim), m_repr_mask.view(len(idx), -1)\n",
      "---> 77                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "     78 \n",
      "     79                 if self.use_noise: m_repr, m_repr_mask = self.add_noise(m_repr.clone(), m_repr_mask.clone())\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(79)fuse_meta_into_embeddings()\n",
      "     77                 meta_repr[m_key] = F.normalize(m_repr[m_repr_mask], dim=1)\n",
      "     78 \n",
      "---> 79                 if self.use_noise: m_repr, m_repr_mask = self.add_noise(m_repr.clone(), m_repr_mask.clone())\n",
      "     80 \n",
      "     81                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(81)fuse_meta_into_embeddings()\n",
      "     79                 if self.use_noise: m_repr, m_repr_mask = self.add_noise(m_repr.clone(), m_repr_mask.clone())\n",
      "     80 \n",
      "---> 81                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "     82 \n",
      "     83                 if self.use_noise:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  embed[idx].norm(dim=-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  m_repr.norm(dim=-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000]], grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(83)fuse_meta_into_embeddings()\n",
      "     81                 fused_embed = self.cross_head(embed[idx], attention_mask[idx], m_repr, m_repr_mask)[0]\n",
      "     82 \n",
      "---> 83                 if self.use_noise:\n",
      "     84                     noise_mask = torch.rand(len(idx), device=fused_embed.device) > self.dropout_noise_pct\n",
      "     85                     embed[idx[noise_mask]] += fused_embed[noise_mask]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(87)fuse_meta_into_embeddings()\n",
      "     85                     embed[idx[noise_mask]] += fused_embed[noise_mask]\n",
      "     86                 else:\n",
      "---> 87                     embed[idx] += fused_embed\n",
      "     88 \n",
      "     89         return embed, meta_repr\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(56)fuse_meta_into_embeddings()\n",
      "     54         meta_repr = {}\n",
      "     55 \n",
      "---> 56         for m_key, m_args in meta_kwargs.items():\n",
      "     57             idx = torch.where(m_args['data2ptr'] > 0)[0]\n",
      "     58             meta_repr[m_key] = torch.empty(0, self.config.dim).to(embed)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(89)fuse_meta_into_embeddings()\n",
      "     87                     embed[idx] += fused_embed\n",
      "     88 \n",
      "---> 89         return embed, meta_repr\n",
      "     90 \n",
      "2    91     def forward(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "(tensor([[[-0....PutBackward0>), {'cat2data': tensor([[ 0.0...DivBackward0>)})\n",
      "> /tmp/ipykernel_32743/3514307414.py(89)fuse_meta_into_embeddings()\n",
      "     87                     embed[idx] += fused_embed\n",
      "     88 \n",
      "---> 89         return embed, meta_repr\n",
      "     90 \n",
      "2    91     def forward(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(115)forward()\n",
      "    113                                                                              data_attention_mask,\n",
      "    114                                                                              meta_kwargs)\n",
      "--> 115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "    117         return EncoderOutput(\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  data_fused_embed.norm(dim=-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3055, 1.2600, 1.2811, 1.2890, 1.2858],\n",
      "        [1.8759, 1.8536, 1.8672, 1.8319, 1.8269],\n",
      "        [1.3816, 1.3434, 1.3324, 1.3283, 1.3340],\n",
      "        [1.4855, 1.4616, 1.4759, 1.4511, 1.4630],\n",
      "        [1.4110, 1.3139, 1.3207, 1.3839, 1.3767]],\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(117)forward()\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "--> 117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(118)forward()\n",
      "    116 \n",
      "    117         return EncoderOutput(\n",
      "--> 118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "    120             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(119)forward()\n",
      "    117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "--> 119             fused_rep=data_fused_repr,\n",
      "    120             meta_repr=meta_repr,\n",
      "    121         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(120)forward()\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "--> 120             meta_repr=meta_repr,\n",
      "    121         )\n",
      "    122 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(117)forward()\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "--> 117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...vBackward0>)})\n",
      "> /tmp/ipykernel_32743/3514307414.py(117)forward()\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "--> 117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(100)forward()\n",
      "     98         **kwargs\n",
      "     99     ):\n",
      "--> 100         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "    101         data_embed = F.normalize(data_o[0], dim=-1)\n",
      "    102 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(101)forward()\n",
      "     99     ):\n",
      "    100         data_o = self.encode(data_input_ids, data_attention_mask)\n",
      "--> 101         data_embed = F.normalize(data_o[0], dim=-1)\n",
      "    102 \n",
      "    103         if data_type is not None and data_type == \"meta\":\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(103)forward()\n",
      "    101         data_embed = F.normalize(data_o[0], dim=-1)\n",
      "    102 \n",
      "--> 103         if data_type is not None and data_type == \"meta\":\n",
      "    104             data_repr = self.meta(data_embed, data_attention_mask)\n",
      "    105         else:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(106)forward()\n",
      "    104             data_repr = self.meta(data_embed, data_attention_mask)\n",
      "    105         else:\n",
      "--> 106             data_repr = self.dr(data_embed, data_attention_mask)\n",
      "    107 \n",
      "    108         data_fused_repr = meta_repr = None\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(108)forward()\n",
      "    106             data_repr = self.dr(data_embed, data_attention_mask)\n",
      "    107 \n",
      "--> 108         data_fused_repr = meta_repr = None\n",
      "    109         if data_aug_meta_prefix is not None:\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(109)forward()\n",
      "    107 \n",
      "    108         data_fused_repr = meta_repr = None\n",
      "--> 109         if data_aug_meta_prefix is not None:\n",
      "    110             meta_kwargs = Parameters.from_meta_aug_prefix(data_aug_meta_prefix, **kwargs)\n",
      "    111             if len(meta_kwargs):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(117)forward()\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "--> 117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(118)forward()\n",
      "    116 \n",
      "    117         return EncoderOutput(\n",
      "--> 118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "    120             meta_repr=meta_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(119)forward()\n",
      "    117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "--> 119             fused_rep=data_fused_repr,\n",
      "    120             meta_repr=meta_repr,\n",
      "    121         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(120)forward()\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "--> 120             meta_repr=meta_repr,\n",
      "    121         )\n",
      "    122 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/3514307414.py(117)forward()\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "--> 117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "EncoderOutput...eta_repr=None)\n",
      "> /tmp/ipykernel_32743/3514307414.py(117)forward()\n",
      "    115                 data_fused_repr = self.dr_fused(data_fused_embed, data_attention_mask)\n",
      "    116 \n",
      "--> 117         return EncoderOutput(\n",
      "    118             rep=data_repr,\n",
      "    119             fused_rep=data_fused_repr,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(70)forward()\n",
      "     68                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "     69 \n",
      "---> 70             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     71                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     72 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(71)forward()\n",
      "     69 \n",
      "     70             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "---> 71                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     72 \n",
      "     73             if self.use_query_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(70)forward()\n",
      "     68                                  data_aug_meta_prefix=self.lbl2data_aug_meta_prefix, **lbl2data_meta_kwargs)\n",
      "     69 \n",
      "---> 70             loss = self.compute_loss(data_o.fused_rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     71                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     72 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(73)forward()\n",
      "     71                                      plbl2data_data2ptr,plbl2data_idx)\n",
      "     72 \n",
      "---> 73             if self.use_query_loss:\n",
      "     74                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     75                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(74)forward()\n",
      "     72 \n",
      "     73             if self.use_query_loss:\n",
      "---> 74                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     75                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     76 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(75)forward()\n",
      "     73             if self.use_query_loss:\n",
      "     74                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "---> 75                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     76 \n",
      "     77             if self.use_calib_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(74)forward()\n",
      "     72 \n",
      "     73             if self.use_query_loss:\n",
      "---> 74                 loss += self.compute_loss(data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     75                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     76 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(77)forward()\n",
      "     75                                           plbl2data_data2ptr,plbl2data_idx)\n",
      "     76 \n",
      "---> 77             if self.use_calib_loss:\n",
      "     78                 loss += self.calibration_loss(data_o.fused_rep, data_o.rep, lbl2data_o.rep,lbl2data_data2ptr,lbl2data_idx,\n",
      "     79                                               plbl2data_data2ptr,plbl2data_idx)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(81)forward()\n",
      "     79                                               plbl2data_data2ptr,plbl2data_idx)\n",
      "     80 \n",
      "---> 81             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "     82 \n",
      "     83             if self.use_fusion_loss:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(83)forward()\n",
      "     81             loss += self.compute_meta_loss(data_o.fused_rep, lbl2data_o.rep, **kwargs)\n",
      "     82 \n",
      "---> 83             if self.use_fusion_loss:\n",
      "     84                 loss += self.compute_fusion_loss(data_o.fused_rep, data_o.meta_repr, self.data_aug_meta_prefix, **kwargs)\n",
      "     85                 loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(87)forward()\n",
      "     85                 loss += self.compute_fusion_loss(lbl2data_o.rep, lbl2data_o.meta_repr, self.lbl2data_aug_meta_prefix, **kwargs)\n",
      "     86 \n",
      "---> 87         if not return_dict:\n",
      "     88             o = (data_o.logits,data_o.rep,data_o.fused_rep,lbl2data_o.logits,lbl2data_o.rep,lbl2data_o.fused_rep)\n",
      "     89             return ((loss,) + o) if loss is not None else o\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(92)forward()\n",
      "     90 \n",
      "     91 \n",
      "---> 92         return RADOutput(\n",
      "     93             loss=loss,\n",
      "     94 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(93)forward()\n",
      "     91 \n",
      "     92         return RADOutput(\n",
      "---> 93             loss=loss,\n",
      "     94 \n",
      "     95             data_repr=data_o.rep,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(95)forward()\n",
      "     93             loss=loss,\n",
      "     94 \n",
      "---> 95             data_repr=data_o.rep,\n",
      "     96             data_fused_repr=data_o.fused_rep,\n",
      "     97 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(96)forward()\n",
      "     94 \n",
      "     95             data_repr=data_o.rep,\n",
      "---> 96             data_fused_repr=data_o.fused_rep,\n",
      "     97 \n",
      "     98             lbl2data_repr=lbl2data_o.rep,\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(98)forward()\n",
      "     96             data_fused_repr=data_o.fused_rep,\n",
      "     97 \n",
      "---> 98             lbl2data_repr=lbl2data_o.rep,\n",
      "     99             lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
      "    100         )\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(99)forward()\n",
      "     97 \n",
      "     98             lbl2data_repr=lbl2data_o.rep,\n",
      "---> 99             lbl2data_fused_repr=lbl2data_o.fused_rep,\n",
      "    100         )\n",
      "    101 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /tmp/ipykernel_32743/1454671095.py(92)forward()\n",
      "     90 \n",
      "     91 \n",
      "---> 92         return RADOutput(\n",
      "     93             loss=loss,\n",
      "     94 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "RADOutput(los...sed_repr=None)\n",
      "> /tmp/ipykernel_32743/1454671095.py(92)forward()\n",
      "     90 \n",
      "     91 \n",
      "---> 92         return RADOutput(\n",
      "     93             loss=loss,\n",
      "     94 \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n",
      "    [... skipped 1 hidden frame]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "o = func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ad0ce-3451-4c5c-b832-80c9d2453212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0821, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8a214-fb48-4a3c-96ac-4711d949ac1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
