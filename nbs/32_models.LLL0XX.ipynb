{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1071a98f-579b-47a9-8a19-e5d5ddd21282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.LLL0XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42e7ecc-b859-4656-9dcd-190548be8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "91c3e72c-aed5-4f0d-b6fa-865bc5df5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, re, inspect, pickle, os, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Tuple, Mapping, Any, Union\n",
    "from transformers import (\n",
    "    PretrainedConfig,\n",
    "    LlamaConfig,\n",
    "    LlamaModel,\n",
    "    LlamaPreTrainedModel,\n",
    ")\n",
    "from transformers.activations import ACT2FN\n",
    "\n",
    "from fastcore.meta import *\n",
    "\n",
    "from xcai.losses import *\n",
    "from xcai.core import store_attr\n",
    "from xcai.learner import XCDataParallel\n",
    "from xcai.models.modeling_utils import *\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig, \n",
    "    get_peft_model, \n",
    "    TaskType,\n",
    "    PeftModel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c515cb0-d9a4-414b-b755-eedf8231d1ea",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6f5abb-8e05-4390-9ac7-b0089260d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/scai/phd/aiz218323/Projects/XC_NLG/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a56ec34-4246-4d19-9ea2-7eb03cccbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealsotitles_data_meta-llama-3-8b_oak.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b90b963-fa32-4db7-b2ba-b20948e57624",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10915572-9f1f-43a2-bf1e-42d430c1d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.one_batch(10)\n",
    "for i,batch in enumerate(block.train.dl):\n",
    "    if i > 3: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cc4cada-39f1-4251-8259-a09548f53688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_idx', 'data_input_ids', 'data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx', 'lbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_attention_mask', 'lbl2data_input_ids'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a11d2-0009-488b-8806-63351697f55a",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ca1b5b58-2ee9-49ea-a2e8-9250d2b08c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RepresentationHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.transform = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.projector = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = ACT2FN[config.hidden_act]\n",
    "        \n",
    "        self.post_init()\n",
    "        \n",
    "    def post_init(self):\n",
    "        self.transform.weight.data = torch.eye(self.transform.out_features, self.transform.in_features, \n",
    "                                               dtype=self.transform.weight.dtype)\n",
    "        self.projector.weight.data = torch.eye(self.projector.out_features, self.projector.in_features, \n",
    "                                               dtype=self.projector.weight.dtype)\n",
    "        \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        x = self.transform(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.projector(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d6394a-4e32-4d8b-9003-2f87083e337b",
   "metadata": {},
   "source": [
    "## `LAM009`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "32298157-72b2-4a86-a77a-ea3f3215f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LAM009Encoder(LlamaModel):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        config:LlamaConfig, \n",
    "        *args, **kwargs,\n",
    "    ):\n",
    "        super().__init__(config, *args, **kwargs)\n",
    "        self.dr_head = RepresentationHead(config)\n",
    "        self.post_init()\n",
    "        \n",
    "    @delegates(LlamaModel.__call__)\n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids:Optional[torch.Tensor]=None, \n",
    "        attention_mask:Optional[torch.Tensor]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        o = super().forward(input_ids, attention_mask)\n",
    "        rep = self.dr_head(o[0])\n",
    "        return o, F.normalize(Pooling.mean_pooling(rep, attention_mask), dim=1)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "de4dfbe3-af1f-4a7b-92e2-95aa4bde1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LAM009(LlamaPreTrainedModel):\n",
    "    use_generation,use_representation = False,True\n",
    "    _tied_weights_keys = [\"embed_tokens\", \"layers\", \"norm\"]\n",
    "    \n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 bsz:Optional[int]=None,\n",
    "                 tn_targ:Optional[int]=None,\n",
    "                 margin:Optional[float]=0.3,\n",
    "                 tau:Optional[float]=0.1,\n",
    "                 apply_softmax:Optional[bool]=False,\n",
    "                 n_negatives:Optional[int]=5,\n",
    "                 use_encoder_parallel:Optional[bool]=True,\n",
    "                 *args, **kwargs):\n",
    "        super().__init__(config, *args, **kwargs)\n",
    "        store_attr('use_encoder_parallel')\n",
    "        self.encoder = LAM009Encoder(config)\n",
    "        self.loss_fn = MultiTriplet(bsz=bsz, tn_targ=tn_targ, margin=margin, n_negatives=n_negatives, tau=tau, \n",
    "                                    apply_softmax=apply_softmax, reduce='mean')\n",
    "        self.post_init()\n",
    "        self.remap_post_init()\n",
    "        \n",
    "    def remap_post_init(self):\n",
    "        self.layers = self.encoder.layers\n",
    "        self.norm = self.encoder.norm\n",
    "        self.embed_tokens = self.encoder.embed_tokens\n",
    "\n",
    "    def init_retrieval_head(self):\n",
    "        if self.encoder is None: raise ValueError('`self.encoder` is not initialized.')\n",
    "        self.encoder.dr_head.post_init()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data_input_ids:Optional[torch.Tensor]=None,\n",
    "        data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        lbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        lbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        lbl2data_input_ids:Optional[torch.Tensor]=None,\n",
    "        lbl2data_attention_mask:Optional[torch.Tensor]=None,\n",
    "        plbl2data_data2ptr:Optional[torch.Tensor]=None,\n",
    "        plbl2data_idx:Optional[torch.Tensor]=None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if self.use_encoder_parallel: \n",
    "            encoder = nn.DataParallel(module=self.encoder)\n",
    "        else: encoder = self.encoder\n",
    "        \n",
    "        data_o, data_repr = encoder(data_input_ids, data_attention_mask, output_attentions=output_attentions, \n",
    "                                    output_hidden_states=output_hidden_states, return_dict=return_dict)\n",
    "        \n",
    "        loss, lbl2data_repr = None, None\n",
    "        if lbl2data_input_ids is not None:\n",
    "            lbl2data_o, lbl2data_repr = encoder(lbl2data_input_ids, lbl2data_attention_mask, output_attentions=output_attentions, \n",
    "                                                output_hidden_states=output_hidden_states, return_dict=return_dict)\n",
    "            \n",
    "            loss = self.loss_fn(data_repr, lbl2data_repr, lbl2data_data2ptr, lbl2data_idx, \n",
    "                                plbl2data_data2ptr, plbl2data_idx, **kwargs)\n",
    "\n",
    "        if not return_dict:\n",
    "            o = (data_repr, lbl2data_repr)\n",
    "            return ((loss,) + o) if loss is not None else o\n",
    "\n",
    "        return XCModelOutput(\n",
    "            loss=loss,\n",
    "            data_repr=data_repr,\n",
    "            lbl2data_repr=lbl2data_repr,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ea8b2-9c4c-4d68-b273-76e00d7c1e54",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6b5cb93b-87f1-41b5-9218-8a618d14a64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93dd0fb85384309905f305426056a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LAM009 were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['model.encoder.dr_head.layer_norm.bias', 'model.encoder.dr_head.layer_norm.weight', 'model.encoder.dr_head.projector.bias', 'model.encoder.dr_head.projector.weight', 'model.encoder.dr_head.transform.bias', 'model.encoder.dr_head.transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = LAM009.from_pretrained('meta-llama/Meta-Llama-3-8B', bsz=1024, margin=0.3, tau=0.1, n_negatives=10, apply_softmax=True, \n",
    "                               use_encoder_parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "43f253e3-8812-46fc-b25e-8ac5408444ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_retrieval_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "552deda7-6e83-4a21-a3e4-3791aa714231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(128257, 4096)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = model.encoder.embed_tokens.num_embeddings\n",
    "model.encoder.resize_token_embeddings(vocab_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9037c733-6cb9-4ca3-a93a-1ef3995b9cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e255ec4e-2c67-43e9-b468-269ac3fb7fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/scai/phd/aiz218323/Projects/xcai/xcai/losses.py:22: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(data_ptr, data_idx, scores, device=data_ptr.device)\n"
     ]
    }
   ],
   "source": [
    "o = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b056e773-ffae-4674-8d29-c1d91c086a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0259, grad_fn=<DivBackward0>),\n",
       " torch.Size([10, 4096]),\n",
       " torch.Size([29, 4096]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.loss, o.data_repr.shape, o.lbl2data_repr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1810c9c-8480-49b5-a250-54a55dd5eeac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a3ae497c-fa97-40ba-af00-91479bf2677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"k_proj\",\"v_proj\",\"o_proj\"],\n",
    "    bias='none',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e38f604f-3d55-45c3-988d-f316c4b1c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "10ef97c4-fd45-422a-ab4f-bbed9df941c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepresentationHead(\n",
       "  (transform): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (layer_norm): LayerNorm((4096,), eps=1e-12, elementwise_affine=True)\n",
       "  (projector): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (activation): SiLU()\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.base_model.encoder.dr_head.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e75c5-fc79-45a4-8a47-34b5fe4b1021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e7658e-76f1-4778-b0f4-038ffc3ee89f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
