{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646426c7-93f9-4c40-adeb-7b04b74501a2",
   "metadata": {},
   "source": [
    "# SData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d09450-d08f-4b8c-988c-547430250692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d26b05-a557-4b6f-9500-f668a8d57b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57087ab-f73b-47e5-bf51-494691acb16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch, inspect, numpy as np, scipy.sparse as sp, inspect\n",
    "from typing import Callable, Optional, Union, Dict\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BatchEncoding\n",
    "from itertools import chain\n",
    "\n",
    "from xcai.core import Filterer, Info\n",
    "from xcai.data import MainXCData, MetaXCData\n",
    "from xcai.data import BaseXCDataset, MainXCDataset, MetaXCDataset, XCDataset\n",
    "from xcai.data import MetaXCDatasets, BaseXCDataBlock, XCDataBlock\n",
    "from xcai.data import _read_sparse_file\n",
    "from xcai.graph.operations import *\n",
    "\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import *\n",
    "from plum import dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "752b92f9-98ac-4b2c-9c35-cc889d59b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dc7eb4-9022-4c05-abb9-3c056fb00cc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef80bda6-674a-4597-9dfd-fafa01f330ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_dir = '/Users/suchith720/Projects/data/(mapped)LF-WikiSeeAlsoTitles-320K'\n",
    "data_cfg = {\n",
    "    'info_column_names': ['identifier', 'input_text'],\n",
    "    'use_tokenizer': True,\n",
    "    'tokenizer': 'sentence-transformers/msmarco-distilbert-base-v4',\n",
    "    'tokenization_column': 'input_text',\n",
    "    'main_max_data_sequence_length': 32,\n",
    "    'main_max_lbl_sequence_length': 32,\n",
    "    'meta_max_sequence_length': 32,\n",
    "    'padding': True,\n",
    "    'return_tensors': 'pt',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb62f1c-176a-4adf-8d0b-ce003a7d7a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065e4bbf-0c93-4c30-9d96-e27a10822624",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg = {\n",
    "    'data_lbl': f'{dset_dir}/trn_X_Y.txt',\n",
    "    'data_info': f'{dset_dir}/raw_data/train.raw.txt',\n",
    "    'lbl_info': f'{dset_dir}/raw_data/label.raw.txt',\n",
    "    'data_lbl_filterer': f'{dset_dir}/filter_labels_train.txt',\n",
    "}\n",
    "train_data = MainXCData.from_file(**train_cfg, **data_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b215cd0-9c9b-4e0d-8c0e-87c4e881c0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dedea812-39f8-47b5-bdc4-930da3e8d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_cfg = {\n",
    "    'data_neg': f'{dset_dir}/category_trn_X_Y.txt',\n",
    "    'neg_info': f'{dset_dir}/raw_data/category.raw.txt',\n",
    "}\n",
    "neg_data = NegXCData.from_file(**neg_cfg, **data_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e79417-89dc-481e-bd06-e8c0c16a2989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a79c584-be9a-48bc-a740-242d6168bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suchith720/Projects/pyxclib/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n"
     ]
    }
   ],
   "source": [
    "meta_cfg = {\n",
    "    'prefix': 'hlk',\n",
    "    'data_meta': f'{dset_dir}/category_trn_X_Y.txt',\n",
    "    'lbl_meta': f'{dset_dir}/category_lbl_X_Y.txt',\n",
    "    'neg_meta': f'{dset_dir}/category_neg_X_Y.txt',\n",
    "    'meta_info': f'{dset_dir}/raw_data/category.raw.txt',\n",
    "}\n",
    "meta_data = MetaXCData.from_file(**meta_cfg, **data_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d978a-49f4-4802-ae10-44101112fd15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7bd28b7-d91c-4c41-bafa-9bcec00ff6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def identity_collate_fn(batch): return BatchEncoding(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68132be5-746c-461c-93d6-8bfd71a0b546",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ffa1dd6-c726-4fac-b1b9-f8dac0df01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Sampler:\n",
    "    \n",
    "    @staticmethod\n",
    "    def dropout(idxs:List, remove:Optional[float]=None, replace:Optional[float]=None):\n",
    "        remove_mask, replace_mask = list(), list()\n",
    "        for idx in idxs:\n",
    "            if remove is not None:\n",
    "                if np.random.rand() < remove:\n",
    "                    remove_mask.append([1]*len(idx))\n",
    "                    if replace is not None:\n",
    "                        replace_mask.append([0]*len(idx))\n",
    "                else:\n",
    "                    remove_mask.append([0]*len(idx))\n",
    "                    if replace is not None: \n",
    "                        replace_mask.append([1]*len(idx) if np.random.rand() < replace else [0]*len(idx))\n",
    "            elif replace is not None:\n",
    "                replace_mask.append([1]*len(idx) if np.random.rand() < replace else [0]*len(idx))\n",
    "        return remove_mask, replace_mask\n",
    "\n",
    "    @staticmethod\n",
    "    def prune_indices_and_scores(output:Dict, prefix:str, data_lbl_indices:List, data_lbl_scores:List, \n",
    "                                 indices:List, num_samples:Optional[int]=None, use_distribution:Optional[bool]=False,\n",
    "                                 return_scores:Optional[bool]=False, dtype=torch.int64):\n",
    "        entity = prefix.split('2')[-1]\n",
    "        output[f'p{prefix}_idx'] = [data_lbl_indices[idx] for idx in indices]\n",
    "        scores = [data_lbl_scores[idx] for idx in indices] if use_distribution or return_scores else None\n",
    "        \n",
    "        if num_samples:\n",
    "            if scores is None:\n",
    "                output[f'p{prefix}_idx'] = [[o[i] for i in np.random.permutation(len(o))[:num_samples]] for o in output[f'p{prefix}_idx']]\n",
    "            else:\n",
    "                idxs, sc = list(), list()\n",
    "                for p,q in zip(output[f'p{prefix}_idx'], scores):\n",
    "                    assert len(p) == len(q)\n",
    "                    rnd_idx = np.random.permutation(len(p))[:num_samples]\n",
    "                    idxs.append([p[i] for i in rnd_idx])\n",
    "                    sc.append([q[i] for i in rnd_idx])\n",
    "                output[f'p{prefix}_idx'], scores = idxs, sc\n",
    "                \n",
    "        output[f'p{prefix}_{entity}2ptr'] = torch.tensor([len(o) for o in output[f'p{prefix}_idx']], dtype=dtype)\n",
    "        return scores\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_indices_and_scores(indices:List, scores:Optional[List]=None, num_samples:Optional[int]=1, \n",
    "                                  oversample:Optional[bool]=False, use_distribution:Optional[bool]=False, \n",
    "                                  return_scores:Optional[bool]=False):\n",
    "        if use_distribution and scores is None:\n",
    "            raise ValueError(f'`scores` cannot be empty when `use_distribution` is set.')\n",
    "        \n",
    "        s_indices, s_scores = [], []\n",
    "        for k in range(len(indices)):\n",
    "            probs = scores[k] if use_distribution else None\n",
    "            size = num_samples if oversample else min(num_samples, len(indices[k]))\n",
    "            \n",
    "            rnd_idx = np.random.choice(len(indices[k]), size=size, p=probs, replace=oversample) if len(indices[k]) else []\n",
    "\n",
    "            s_indices.append([indices[k][i] for i in rnd_idx])\n",
    "            if return_scores:\n",
    "                assert len(indices[k]) == len(scores[k]), f'Length of indices({len(indices[k])}) and scores({(len(scores[k]))}) should be equal.'\n",
    "                s_scores.append([scores[k][i] for i in rnd_idx])\n",
    "\n",
    "        return s_indices, s_scores\n",
    "\n",
    "    @staticmethod\n",
    "    def get_info(prefix:str, idxs:List, info:Dict, info_keys:List):\n",
    "        output = dict()\n",
    "        for k,v in info.items():\n",
    "            if k in info_keys:\n",
    "                if isinstance(v, np.ndarray) or isinstance(v, torch.Tensor):\n",
    "                    o = v[idxs]\n",
    "                    if isinstance(o, np.ndarray): o = torch.from_numpy(o)\n",
    "                    output[f'{prefix}_{k}'] = o\n",
    "                else:\n",
    "                    output[f'{prefix}_{k}'] = [v[idx] for idx in idxs]\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_items(\n",
    "        prefix:str,\n",
    "        data_lbl_indices:List,\n",
    "        \n",
    "        indices:List, \n",
    "        num_samples:int, \n",
    "        num_sampler_samples:int, \n",
    "        oversample:bool, \n",
    "                      \n",
    "        info:Dict, \n",
    "        info_keys:List,\n",
    "        \n",
    "        use_distribution:Optional[bool]=False, \n",
    "        data_lbl_scores:Optional[List]=None, \n",
    "                      \n",
    "        dropout_remove:Optional[float]=None, \n",
    "        dropout_replace:Optional[float]=None, \n",
    "        return_scores:Optional[bool]=False,\n",
    "        dtype=torch.int64,\n",
    "    ):\n",
    "        output, entity = dict(), prefix.split('2')[-1]\n",
    "            \n",
    "        scores = Sampler.prune_indices_and_scores(output, prefix, data_lbl_indices, data_lbl_scores, indices, \n",
    "                                                  num_samples, use_distribution, return_scores, dtype=dtype)\n",
    "        \n",
    "        output[f'{prefix}_idx'], scores = Sampler.sample_indices_and_scores(output[f'p{prefix}_idx'], scores, \n",
    "                                                                            num_sampler_samples, oversample, \n",
    "                                                                            use_distribution, return_scores)\n",
    "        if return_scores:\n",
    "            output[f'{prefix}_scores'] = torch.tensor(list(chain(*scores)), dtype=torch.float32)\n",
    "\n",
    "        output[f'{prefix}_{entity}2ptr'] = torch.tensor([len(o) for o in output[f'{prefix}_idx']], dtype=dtype)\n",
    "        output[f'{prefix}_idx'] = torch.tensor(list(chain(*output[f'{prefix}_idx'])), dtype=dtype)\n",
    "        output[f'p{prefix}_idx'] = torch.tensor(list(chain(*output[f'p{prefix}_idx'])), dtype=dtype)\n",
    "        \n",
    "        if info is not None:\n",
    "            output.update(Sampler.get_info(prefix, output[f'{prefix}_idx'], info, info_keys))\n",
    "            \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78df2464-461a-4389-99d6-23abf6d6eafa",
   "metadata": {},
   "source": [
    "## SDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26266ee9-e981-41e3-b485-69ddd17d60af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `SMainXCDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9a0d1d23-3b05-4516-b48d-bd81ef6299b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SMainXCDataset(MainXCDataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_slbl_samples:Optional[int]=1,\n",
    "        n_sneg_samples:Optional[int]=1,\n",
    "        main_oversample:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        store_attr('n_slbl_samples,main_oversample,n_sneg_samples')\n",
    "        \n",
    "    def __getitems__(self, idxs:List):\n",
    "        x = {'data_idx': torch.tensor(idxs, dtype=torch.int64)}\n",
    "        x.update(self.get_info('data', idxs, self.data_info, self.data_info_keys))\n",
    "        if self.data_lbl is not None:\n",
    "            prefix = 'lbl2data'\n",
    "            o = Sampler.extract_items(prefix, self.curr_data_lbl, idxs, self.n_lbl_samples, self.n_slbl_samples, \n",
    "                                      self.main_oversample, self.lbl_info, self.lbl_info_keys, self.use_main_distribution, \n",
    "                                      self.data_lbl_scores, return_scores=self.return_scores)\n",
    "            x.update(o)\n",
    "        if self.data_neg is not None:\n",
    "            prefix = 'neg2data'\n",
    "            o = Sampler.extract_items(prefix, self.curr_data_neg, idxs, self.n_neg_samples, self.n_sneg_samples, \n",
    "                                      self.main_oversample, self.neg_info, self.lbl_info_keys, self.use_main_distribution, \n",
    "                                      self.data_neg_scores, return_scores=self.return_scores)\n",
    "            x.update(o)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf32d6c-ecb1-4af8-a070-ebb82b5c11d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d1d1a90-f3ae-44b2-bd20-1866331886ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_main = SMainXCDataset(**train_data, **neg_data, n_slbl_samples=2, n_sneg_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82c38e-a864-4000-8ead-c0c9531e8fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a3dba53-bb5d-4494-a123-3a3b38a71532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_idx': tensor([100, 200]),\n",
       " 'data_identifier': ['Applet', 'Geography_of_Africa'],\n",
       " 'data_input_text': ['Applet', 'Geography of Africa'],\n",
       " 'data_input_ids': tensor([[  101,  6207,  2102,   102,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 10505,  1997,  3088,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'data_attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'plbl2data_idx': tensor([  927,   928,   929,   930, 23961,  1470,  1471, 27329]),\n",
       " 'plbl2data_data2ptr': tensor([5, 3]),\n",
       " 'lbl2data_idx': tensor([ 930,  929, 1471, 1470]),\n",
       " 'lbl2data_data2ptr': tensor([2, 2]),\n",
       " 'lbl2data_identifier': ['Abstract_Window_Toolkit',\n",
       "  'Widget_engine',\n",
       "  'Outline_of_Africa',\n",
       "  'List_of_national_parks_in_Africa'],\n",
       " 'lbl2data_input_text': ['Abstract Window Toolkit',\n",
       "  'Widget engine',\n",
       "  'Outline of Africa',\n",
       "  'List of national parks in Africa'],\n",
       " 'lbl2data_input_ids': tensor([[  101, 10061,  3332,  6994, 23615,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 15536, 24291,  3194,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 12685,  1997,  3088,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  2862,  1997,  2120,  6328,  1999,  3088,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'lbl2data_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'pneg2data_idx': tensor([  1058, 147261, 149012,  85726]),\n",
       " 'pneg2data_data2ptr': tensor([3, 1]),\n",
       " 'neg2data_idx': tensor([147261,   1058,  85726]),\n",
       " 'neg2data_data2ptr': tensor([2, 1]),\n",
       " 'neg2data_identifier': ['Category:Java_(programming_language)_libraries',\n",
       "  'Category:Technology_neologisms',\n",
       "  'Category:Geography_of_Africa'],\n",
       " 'neg2data_input_text': ['Java (programming language) libraries',\n",
       "  'Technology neologisms',\n",
       "  'Geography of Africa'],\n",
       " 'neg2data_input_ids': tensor([[  101,  9262,  1006,  4730,  2653,  1007,  8860,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  2974,  9253, 21197, 22556,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101, 10505,  1997,  3088,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'neg2data_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_main.__getitems__([100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b7144-619b-454b-977c-e17f6b32a321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6a8ce8c-3933-4bdf-834c-cb38acfc615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_main.oversample = True\n",
    "train_main.n_slbl_samples = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63c977-2561-4b86-b0bb-8b88339fce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    import pdb; pdb.set_trace()\n",
    "    train_main.__getitems__([1,2,3,4])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8db7cbd3-cd4e-4f08-b4f6-4e26db6185ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_main, batch_size=10, collate_fn=identity_collate_fn)\n",
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86d3aac4-38ba-4853-927d-dfe26083b701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_idx': tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'data_identifier': ['Anarchism', 'Autism', 'Aristotle', 'Academy_Awards', 'International_Atomic_Time', 'Altruism', 'Allan_Dwan', 'Anthropology', 'Agricultural_science', 'Animation'], 'data_input_text': ['Anarchism', 'Autism', 'Aristotle', 'Academy Awards', 'International Atomic Time', 'Altruism', 'Allan Dwan', 'Anthropology', 'Agricultural science', 'Animation'], 'data_input_ids': tensor([[  101,  9617, 11140,  2964,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101, 19465,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101, 17484,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  2914,  2982,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  2248,  9593,  2051,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101, 12456,  6820,  2964,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  8926,  1040,  7447,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101, 12795,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  4910,  2671,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  7284,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]]), 'data_attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'plbl2data_idx': tensor([    0,     1,     2,     3,     9, 26766,    12,    13,    14,    15,\n",
       "           16,    17,    18, 56258,    19,    20,    21,    22,    23,    24,\n",
       "           25,    26,    27,    28,    29,    30,    31,    32,    33,    34,\n",
       "           35,    36,    37,    38,    39,    40,    41,    42, 10243,    45,\n",
       "           48,    49,    50,    51,    52,    53,    54,    55,    56,    57,\n",
       "           58,    59,    60,    61,    62,    63,    64,    65,    66,    67,\n",
       "           68,    69,    70, 81953,   101,   102,   103,   104,   105]), 'plbl2data_data2ptr': tensor([ 3,  1,  2,  4,  4, 25,  1, 14, 10,  5]), 'lbl2data_idx': tensor([    2,     1,     0,     3, 26766,     9,    14,    13,    15,    16,\n",
       "           17, 56258,    22,    41,    35,    45,    57,    54,    59,    62,\n",
       "           66,    64,   101,   102,   103]), 'lbl2data_data2ptr': tensor([3, 1, 2, 3, 3, 3, 1, 3, 3, 3]), 'lbl2data_identifier': ['Anarchism', 'Libertarian_socialism', 'Antinomianism', 'Autism', 'Aristotle', 'Conimbricenses', 'List_of_actors_with_Academy_Award_nominations', 'List_of_Academy_Award_records', 'Academy_Awards', 'Clock_synchronization', 'Network_Time_Protocol', 'International_Atomic_Time', 'Effective_altruism', 'Social_psychology', 'Philanthropy', 'Canadian_pioneers_in_early_Hollywood', 'Origins_of_society', 'Intangible_cultural_heritage', 'Prehistoric_medicine', 'Agricultural_sciences_basic_topics', 'Genomics_of_domestication', 'Agroecology', '12_basic_principles_of_animation', 'Anime', 'Computer-generated_imagery'], 'lbl2data_input_text': ['Anarchism', 'Libertarian socialism', 'Antinomianism', 'Autism', 'Aristotle', 'Conimbricenses', 'List of actors with Academy Award nominations', 'List of Academy Award records', 'Academy Awards', 'Clock synchronization', 'Network Time Protocol', 'International Atomic Time', 'Effective altruism', 'Social psychology', 'Philanthropy', 'Canadian pioneers in early Hollywood', 'Origins of society', 'Intangible cultural heritage', 'Prehistoric medicine', 'Agricultural sciences basic topics', 'Genomics of domestication', 'Agroecology', '12 basic principles of animation', 'Anime', 'Computer-generated imagery'], 'lbl2data_input_ids': tensor([[  101,  9617, 11140,  2964,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101, 19297, 14649,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  3424,  3630, 20924,  2964,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101, 19465,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101, 17484,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  9530,  5714, 23736, 19023,  2229,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  2862,  1997,  5889,  2007,  2914,  2400,  9930,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  2862,  1997,  2914,  2400,  2636,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  2914,  2982,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  5119, 26351,  8093, 10698,  9276,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  2897,  2051,  8778,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  2248,  9593,  2051,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  4621, 12456,  6820,  2964,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  2591,  6825,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101, 29291,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  3010, 13200,  1999,  2220,  5365,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  7321,  1997,  2554,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101, 20014,  5654,  7028,  3451,  4348,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101, 14491,  4200,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  4910,  4163,  3937,  7832,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  8991, 25524,  1997,  4968,  3370,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101, 12943,  3217,  8586,  6779,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  2260,  3937,  6481,  1997,  7284,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  8750,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  3274,  1011,  7013, 13425,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]]), 'lbl2data_attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'pneg2data_idx': tensor([ 27146,  47633,  68170,  94657, 130666, 130667, 130668, 130669,    656,\n",
       "         49684,  56026,  72991,  75604,  79350, 129019, 165107, 165108,  70154,\n",
       "         75304,  76961,  81434, 100127, 101577, 104146, 112817, 131262, 131264,\n",
       "        131265, 131284, 131288, 138567, 140781, 144686, 155398, 155399, 155400,\n",
       "        155401, 155402, 155403, 155404, 155405, 155406, 155407, 155408, 155409,\n",
       "        155410, 155411, 155412, 155413, 155414, 155415, 155416, 155417, 155418,\n",
       "        155419,   3056,  10463,  46859,  56287,  71468,  71494,  71495,  71496,\n",
       "         71497,  71498, 144199,    186,  52253,  60100,  61235,  74806,  77773,\n",
       "         81375, 120807, 120808,  53070,  53995,  62858,  63233,  65497,  65499,\n",
       "         82068,  96896, 115952, 115953, 115954, 143634,  83602,  86585,    656,\n",
       "         28165,  82231, 138912]), 'pneg2data_data2ptr': tensor([ 8,  9, 38, 10,  1,  9, 11,  1,  2,  4]), 'neg2data_idx': tensor([ 94657, 130667, 129019,  49684, 155409, 155415,  71497,  71494, 144199,\n",
       "        120807,    186,  53995,  63233, 143634,  86585,  83602, 138912,    656]), 'neg2data_data2ptr': tensor([2, 2, 2, 2, 1, 2, 2, 1, 2, 2]), 'neg2data_identifier': ['Category:Political_ideologies', 'Category:Anti-fascism', 'Category:Communication_disorders', 'Category:RTT', 'Category:Ancient_Stagirites', 'Category:Philosophers_and_tutors_of_Alexander_the_Great', 'Category:Hollywood_history_and_culture', 'Category:American_film_awards', 'Category:Time_scales', 'Category:Philanthropy', 'Category:Social_philosophy', 'Category:1981_deaths', 'Category:Disease-related_deaths_in_California', 'Category:Humanities', 'Category:Agronomy', 'Category:Agriculture', 'Category:Cartooning', 'Category:Articles_containing_video_clips'], 'neg2data_input_text': ['Political ideologies', 'Anti-fascism', 'Communication disorders', 'RTT', 'Ancient Stagirites', 'Philosophers and tutors of Alexander the Great', 'Hollywood history and culture', 'American film awards', 'Time scales', 'Philanthropy', 'Social philosophy', '1981 deaths', 'Disease-related deaths in California', 'Humanities', 'Agronomy', 'Agriculture', 'Cartooning', 'Articles containing video clips'], 'neg2data_input_ids': tensor([[  101,  2576,  8909,  8780, 21615,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  3424,  1011, 23779,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  4807, 10840,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101, 19387,  2102,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  3418,  2358, 22974, 28884,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101, 17586,  1998, 14924,  2015,  1997,  3656,  1996,  2307,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  5365,  2381,  1998,  3226,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2137,  2143,  2982,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2051,  9539,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101, 29291,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2591,  4695,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  3261,  6677,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  4295,  1011,  3141,  6677,  1999,  2662,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101, 11406,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101, 12943,  4948, 16940,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  5237,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  9476,  2075,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  4790,  4820,  2678, 15281,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'neg2data_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138603c1-ccec-4fc9-91d5-4470d4ff8bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokz = AutoTokenizer.from_pretrained(data_cfg['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fc2eef-e8f7-47ad-becc-30e910f9bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['plbl2data_data2ptr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57589218-fc9d-44c3-aea3-60992791b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokz.batch_decode(batch['data_input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ff3e2-a50b-41e3-a53f-be9cb818a402",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `SMetaXCDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f4215992-e99e-4fc3-b20c-4b639f547517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SMetaXCDataset(MetaXCDataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_sdata_meta_samples:Optional[int]=1,\n",
    "        n_slbl_meta_samples:Optional[int]=1,\n",
    "        n_sneg_meta_samples:Optional[int]=1,\n",
    "        meta_oversample:Optional[bool]=False,\n",
    "        meta_dropout_remove:Optional[float]=None,\n",
    "        meta_dropout_replace:Optional[float]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        store_attr('n_sdata_meta_samples,n_slbl_meta_samples,n_sneg_meta_samples,meta_oversample')\n",
    "        store_attr('meta_dropout_remove,meta_dropout_replace')\n",
    "        \n",
    "    def get_data_meta(self, idxs:List):\n",
    "        x, prefix = dict(), f'{self.prefix}2data'\n",
    "        o = Sampler.extract_items(prefix, self.curr_data_meta, idxs, self.n_data_meta_samples, self.n_sdata_meta_samples, \n",
    "                                  self.meta_oversample, self.meta_info, self.meta_info_keys, self.use_meta_distribution, \n",
    "                                  self.data_meta_scores, dropout_remove=self.meta_dropout_remove, \n",
    "                                  dropout_replace=self.meta_dropout_replace, return_scores=self.return_scores)\n",
    "        x.update(o)\n",
    "        return x\n",
    "        \n",
    "    def get_lbl_meta(self, idxs:List):\n",
    "        if self.curr_lbl_meta is None: return {}\n",
    "        x, prefix = dict(), f'{self.prefix}2lbl'\n",
    "        o = Sampler.extract_items(prefix, self.curr_lbl_meta, idxs, self.n_lbl_meta_samples, self.n_slbl_meta_samples, \n",
    "                                  self.meta_oversample, self.meta_info, self.meta_info_keys, self.use_meta_distribution, \n",
    "                                  self.lbl_meta_scores, dropout_remove=self.meta_dropout_remove, \n",
    "                                  dropout_replace=self.meta_dropout_replace, return_scores=self.return_scores)\n",
    "        x.update(o)\n",
    "        return x\n",
    "\n",
    "    def get_neg_meta(self, idxs:List):\n",
    "        if self.curr_neg_meta is None: return {}\n",
    "        x, prefix = dict(), f'{self.prefix}2neg'\n",
    "        o = Sampler.extract_items(prefix, self.curr_neg_meta, idxs, self.n_neg_meta_samples, self.n_sneg_meta_samples, \n",
    "                                  self.meta_oversample, self.meta_info, self.meta_info_keys, self.use_meta_distribution, \n",
    "                                  self.neg_meta_scores, dropout_remove=self.meta_dropout_remove, \n",
    "                                  dropout_replace=self.meta_dropout_replace, return_scores=self.return_scores)\n",
    "        x.update(o)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b40080-e07e-4d00-929f-77247cf2f1d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f456f40c-89f4-445f-b3c2-1f74ed54b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = SMetaXCDataset(**meta_data, neg_meta=neg_meta, n_sdata_meta_samples=2, n_slbl_meta_samples=2, \n",
    "                            n_sneg_meta_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "182a9b58-8edd-4dd6-b78b-5d0df121bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta.meta_oversample = True\n",
    "train_meta.n_sdata_meta_samples = 3\n",
    "train_meta.n_slbl_meta_samples = 3\n",
    "train_meta.n_sneg_meta_samples = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7b0ba-5789-4852-98b3-f28041b31402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d418f48e-3278-4f39-9f6d-62c4f408c00f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phlk2data_idx': tensor([  1058, 147261, 149012,  85726]),\n",
       " 'phlk2data_data2ptr': tensor([3, 1]),\n",
       " 'hlk2data_idx': tensor([149012,   1058, 149012,  85726,  85726,  85726]),\n",
       " 'hlk2data_data2ptr': tensor([3, 3]),\n",
       " 'hlk2data_identifier': ['Category:Component-based_software_engineering',\n",
       "  'Category:Technology_neologisms',\n",
       "  'Category:Component-based_software_engineering',\n",
       "  'Category:Geography_of_Africa',\n",
       "  'Category:Geography_of_Africa',\n",
       "  'Category:Geography_of_Africa'],\n",
       " 'hlk2data_input_text': ['Component-based software engineering',\n",
       "  'Technology neologisms',\n",
       "  'Component-based software engineering',\n",
       "  'Geography of Africa',\n",
       "  'Geography of Africa',\n",
       "  'Geography of Africa'],\n",
       " 'hlk2data_input_ids': tensor([[  101,  6922,  1011,  2241,  4007,  3330,   102,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  2974,  9253, 21197, 22556,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  6922,  1011,  2241,  4007,  3330,   102,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101, 10505,  1997,  3088,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101, 10505,  1997,  3088,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101, 10505,  1997,  3088,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'hlk2data_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta.get_data_meta([100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "73b58370-cc74-4605-9932-acc737beea93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phlk2lbl_idx': tensor([3384]),\n",
       " 'phlk2lbl_lbl2ptr': tensor([1, 0]),\n",
       " 'hlk2lbl_idx': tensor([3384, 3384, 3384]),\n",
       " 'hlk2lbl_lbl2ptr': tensor([3, 0]),\n",
       " 'hlk2lbl_identifier': ['Category:Animation_techniques',\n",
       "  'Category:Animation_techniques',\n",
       "  'Category:Animation_techniques'],\n",
       " 'hlk2lbl_input_text': ['Animation techniques',\n",
       "  'Animation techniques',\n",
       "  'Animation techniques'],\n",
       " 'hlk2lbl_input_ids': tensor([[ 101, 7284, 5461,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0],\n",
       "         [ 101, 7284, 5461,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0],\n",
       "         [ 101, 7284, 5461,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0]]),\n",
       " 'hlk2lbl_attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta.get_lbl_meta([101, 201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7157858c-716c-4fc1-86e3-d10862667316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phlk2neg_idx': tensor([ 53645,  54045,  54047,  56785,  62960,  63222,  63256,  64904,  66535,\n",
       "          66572,  68944,  75927,  75931,  75932,  76291,  76463,  80839,  81564,\n",
       "          81754,  93653,  99742,  99743,  99744,  99745,  99746,  99747,  99748,\n",
       "          99749,  99750,  99751,  99752,  99753,  99754,  99755,  99756,  99757,\n",
       "          99758,  99759,  99760,  99761,  99762,  99763,  99764,  99765,  99766,\n",
       "          99767,  99768,  99769,  58495,  64668, 125890, 155570, 155737, 155740,\n",
       "         155741, 155742, 155743]),\n",
       " 'phlk2neg_neg2ptr': tensor([48,  9]),\n",
       " 'hlk2neg_idx': tensor([ 66572,  75927,  99768, 155741,  58495, 125890]),\n",
       " 'hlk2neg_neg2ptr': tensor([3, 3]),\n",
       " 'hlk2neg_identifier': ['Category:Fellows_of_the_Royal_Society',\n",
       "  'Category:Computer_designers',\n",
       "  'Category:LGBT_and_suicide',\n",
       "  'Category:Public_universities_and_colleges_in_Arizona',\n",
       "  'Category:Arizona_State_University',\n",
       "  'Category:Natural_Science_Collections_Alliance_members'],\n",
       " 'hlk2neg_input_text': ['Fellows of the Royal Society',\n",
       "  'Computer designers',\n",
       "  'LGBT and suicide',\n",
       "  'Public universities and colleges in Arizona',\n",
       "  'Arizona State University',\n",
       "  'Natural Science Collections Alliance members'],\n",
       " 'hlk2neg_input_ids': tensor([[  101, 13572,  1997,  1996,  2548,  2554,   102,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  3274, 11216,   102,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101, 12010,  1998,  5920,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  2270,  5534,  1998,  6667,  1999,  5334,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  5334,  2110,  2118,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  3019,  2671,  6407,  4707,  2372,   102,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'hlk2neg_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta.get_neg_meta([101, 201])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c371b7-6fd2-4561-be7a-790ce4695f59",
   "metadata": {},
   "source": [
    "### `SXCDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e0e4cf79-14dc-4228-b00b-b1d0f22be966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SXCDataset(XCDataset):\n",
    "\n",
    "    def __init__(self, data:SMainXCDataset, **kwargs):\n",
    "        self.data, self.meta = data, MetaXCDatasets({k:kwargs[k] for k in self.get_meta_args(**kwargs) if isinstance(kwargs[k], SMetaXCDataset)})\n",
    "        self._verify_inputs()\n",
    "        \n",
    "    @classmethod\n",
    "    @delegates(SMainXCDataset.from_file)\n",
    "    def from_file(cls, **kwargs):\n",
    "        data = SMainXCDataset.from_file(**kwargs)\n",
    "        meta_kwargs = {o:kwargs.pop(o) for o in cls.get_meta_args(**kwargs)}\n",
    "\n",
    "        meta = dict()\n",
    "        for k,v in meta_kwargs.items():\n",
    "            input_kwargs = {p:q.get(k,None) if isinstance(q, dict) else q for p,q in kwargs.items()}\n",
    "            for o in v: input_kwargs.pop(o, None)\n",
    "            meta[k] = SMetaXCDataset.from_file(**v, **input_kwargs)  \n",
    "        # meta = {k:SMetaXCDataset.from_file(**v, **kwargs) for k,v in meta_kwargs.items()}\n",
    "        \n",
    "        return cls(data, **meta)\n",
    "        \n",
    "    def __getitems__(self, idxs:List):\n",
    "        x = self.data.__getitems__(idxs)\n",
    "        if self.n_meta:\n",
    "            for meta in self.meta.values():\n",
    "                x.update(meta.get_data_meta(idxs))\n",
    "                if self.n_lbl:\n",
    "                    z = meta.get_lbl_meta(x['lbl2data_idx'])\n",
    "                    if len(z):\n",
    "                        z[f'{meta.prefix}2lbl_data2ptr'] = torch.tensor([o.sum() for o in z[f'{meta.prefix}2lbl_lbl2ptr'].split_with_sizes(x[f'lbl2data_data2ptr'].tolist())])\n",
    "                        z[f'p{meta.prefix}2lbl_data2ptr'] = torch.tensor([o.sum() for o in z[f'p{meta.prefix}2lbl_lbl2ptr'].split_with_sizes(x[f'lbl2data_data2ptr'].tolist())])\n",
    "                    x.update(z)\n",
    "                if self.n_neg:\n",
    "                    z = meta.get_neg_meta(x['neg2data_idx'])\n",
    "                    if len(z):\n",
    "                        z[f'{meta.prefix}2neg_data2ptr'] = torch.tensor([o.sum() for o in z[f'{meta.prefix}2neg_neg2ptr'].split_with_sizes(x[f'neg2data_data2ptr'].tolist())])\n",
    "                        z[f'p{meta.prefix}2neg_data2ptr'] = torch.tensor([o.sum() for o in z[f'p{meta.prefix}2neg_neg2ptr'].split_with_sizes(x[f'neg2data_data2ptr'].tolist())])\n",
    "                    x.update(z)\n",
    "        return x\n",
    "\n",
    "    def get_one_hop_metadata(self, batch_size:Optional[int]=1024, thresh:Optional[int]=10, \n",
    "                             topk:Optional[int]=10, **kwargs):\n",
    "        data_lbl = Graph.threshold_on_degree(self.data.data_lbl, thresh=thresh)\n",
    "        data_meta, lbl_meta = Graph.one_hop_matrix(data_lbl, batch_size=batch_size, topk=topk, \n",
    "                                                   do_normalize=True)\n",
    "        \n",
    "        self.meta['ohm_meta'] = SMetaXCDataset(prefix='ohm', data_meta=data_meta, lbl_meta=lbl_meta, \n",
    "                                               meta_info=dset.data.lbl_info, **kwargs)\n",
    "        \n",
    "    def get_data_lbl_random_walk_metadata(self, batch_size:Optional[int]=1024, walk_to:Optional[int]=100, \n",
    "                                          prob_reset:Optional[float]=0.8, topk_thresh:Optional[int]=10, \n",
    "                                          degree_thresh=20, **kwargs):\n",
    "        data_meta, lbl_meta = Operations.get_random_walk_matrix(self.data.data_lbl, batch_size, walk_to, \n",
    "                                                                prob_reset, topk_thresh, degree_thresh)\n",
    "        self.meta['rnw_meta'] = SMetaXCDataset(prefix='rnw', data_meta=data_meta, lbl_meta=lbl_meta,\n",
    "                                               meta_info=self.data.lbl_info, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c6bffa-f910-49d2-8768-aaf3cdf3307e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bc7f4e65-ec24-4ccd-b549-b294710f355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = SXCDataset(train_main, hlk_meta=train_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "34af6a17-4677-4432-b1e1-5b20ea85bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = train_dset.__getitems__([100, 200, 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc11f7-0ff7-43f7-9c20-81e8dd38a0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0ebfa06c-8951-4807-b596-274c7a7ca2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dset, batch_size=10, collate_fn=identity_collate_fn)\n",
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a2698e0e-046a-495b-b33f-0537a16f8af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_idx',\n",
       " 'data_identifier',\n",
       " 'data_input_text',\n",
       " 'data_input_ids',\n",
       " 'data_attention_mask',\n",
       " 'plbl2data_idx',\n",
       " 'plbl2data_data2ptr',\n",
       " 'lbl2data_idx',\n",
       " 'lbl2data_data2ptr',\n",
       " 'lbl2data_identifier',\n",
       " 'lbl2data_input_text',\n",
       " 'lbl2data_input_ids',\n",
       " 'lbl2data_attention_mask',\n",
       " 'pneg2data_idx',\n",
       " 'pneg2data_data2ptr',\n",
       " 'neg2data_idx',\n",
       " 'neg2data_data2ptr',\n",
       " 'neg2data_identifier',\n",
       " 'neg2data_input_text',\n",
       " 'neg2data_input_ids',\n",
       " 'neg2data_attention_mask',\n",
       " 'phlk2data_idx',\n",
       " 'phlk2data_data2ptr',\n",
       " 'hlk2data_idx',\n",
       " 'hlk2data_data2ptr',\n",
       " 'hlk2data_identifier',\n",
       " 'hlk2data_input_text',\n",
       " 'hlk2data_input_ids',\n",
       " 'hlk2data_attention_mask',\n",
       " 'phlk2lbl_idx',\n",
       " 'phlk2lbl_lbl2ptr',\n",
       " 'hlk2lbl_idx',\n",
       " 'hlk2lbl_lbl2ptr',\n",
       " 'hlk2lbl_identifier',\n",
       " 'hlk2lbl_input_text',\n",
       " 'hlk2lbl_input_ids',\n",
       " 'hlk2lbl_attention_mask',\n",
       " 'hlk2lbl_data2ptr',\n",
       " 'phlk2lbl_data2ptr',\n",
       " 'phlk2neg_idx',\n",
       " 'phlk2neg_neg2ptr',\n",
       " 'hlk2neg_idx',\n",
       " 'hlk2neg_neg2ptr',\n",
       " 'hlk2neg_identifier',\n",
       " 'hlk2neg_input_text',\n",
       " 'hlk2neg_input_ids',\n",
       " 'hlk2neg_attention_mask',\n",
       " 'hlk2neg_data2ptr',\n",
       " 'phlk2neg_data2ptr']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76066769-9ad8-4517-a8f9-bc3959551919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97c19d34-89af-44ba-b37b-35f542c1017d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `SBaseXCDataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "40685068-05c1-47f3-b185-c6384266800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SBaseXCDataBlock(BaseXCDataBlock):\n",
    "    \n",
    "    @classmethod\n",
    "    @delegates(SXCDataset.from_file)\n",
    "    def from_file(cls, collate_fn:Callable=identity_collate_fn, **kwargs):\n",
    "        return cls(SXCDataset.from_file(**kwargs), collate_fn, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f5540-8c21-425f-a4e9-15fa9df61d1d",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "31ab7517-43b9-4f21-bdaa-a03c50f48aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_block = SBaseXCDataBlock(train_dset, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e3cdac-4a66-4595-a633-a215b6669d93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### `SXCDataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "09b24a62-8db4-4d46-88bf-3af0cc0ec3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SXCDataBlock(XCDataBlock):\n",
    "\n",
    "    @staticmethod\n",
    "    def inference_dset(data_info:Dict, data_lbl:sp.csr_matrix, lbl_info:Dict, data_lbl_filterer, \n",
    "                       **kwargs):\n",
    "        x_idx = np.where(data_lbl.getnnz(axis=1) == 0)[0].reshape(-1,1)\n",
    "        y_idx = np.zeros((len(x_idx),1), dtype=np.int64)\n",
    "        data_lbl[x_idx, y_idx] = 1\n",
    "        data_lbl_filterer = np.hstack([x_idx, y_idx]) if data_lbl_filterer is None else np.vstack([np.hstack([x_idx, y_idx]), data_lbl_filterer])\n",
    "    \n",
    "        pred_dset = SXCDataset(SMainXCDataset(data_info=data_info, data_lbl=data_lbl, lbl_info=lbl_info,\n",
    "                                              data_lbl_filterer=data_lbl_filterer, **kwargs))\n",
    "        return pred_dset\n",
    "    \n",
    "    @classmethod\n",
    "    def from_cfg(\n",
    "        cls, \n",
    "        cfg:Union[str,Dict],\n",
    "        collate_fn:Optional[Callable]=identity_collate_fn,\n",
    "        valid_pct:Optional[float]=0.2,\n",
    "        seed=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if isinstance(cfg, str): cfg = cls.load_cfg(cfg)\n",
    "\n",
    "        blocks = dict()\n",
    "        for split in ['train', 'valid', 'test', 'label']:\n",
    "            \n",
    "            if split in cfg['path']:\n",
    "                \n",
    "                params = cfg['parameters'].copy()\n",
    "                params.update(kwargs)\n",
    "                \n",
    "                if split != 'train': params['meta_dropout_remove'], params['meta_dropout_replace'] = None, None\n",
    "\n",
    "                if split != 'train' and 'train' in blocks:\n",
    "                    if 'lbl_info' not in cfg['path'][split]:\n",
    "                        cfg['path'][split]['lbl_info'] = blocks['train'].dset.data.lbl_info\n",
    "    \n",
    "                    if blocks['train'].dset.meta is not None:\n",
    "                        for meta_name in blocks['train'].dset.meta:\n",
    "                            if meta_name in cfg['path'][split] and 'meta_info' not in cfg['path'][split][meta_name]:\n",
    "                                cfg['path'][split][meta_name]['meta_info'] = blocks['train'].dset.meta[meta_name].meta_info\n",
    "                                \n",
    "                blocks[split] = SBaseXCDataBlock.from_file(**cfg['path'][split], **params, collate_fn=collate_fn)\n",
    "                \n",
    "        return cls(**blocks)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa16f7-4370-450b-b43f-0e3a5f4ea481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed004a61-5ede-490a-85a5-5771fd33a53a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b3a21f-1de2-4b1f-ac65-eb401210d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.config import WIKISEEALSOTITLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c260e-a02a-438a-a81c-c537523584cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = SXCDataBlock(train=train_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b8194-6733-4938-a9cb-c278b4985a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker_dset = block.linker_dset('hlk_meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d91ba-9a68-4761-91d0-a5bdaf2ad782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194342b4-4515-4315-84e1-45124cd72afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(block.train.dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f1099-f0ad-4df9-8ff5-2a5090685b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f3aaa-822f-48b6-9ed8-cf068d6cf539",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = WIKISEEALSOTITLES('/home/scai/phd/aiz218323/Projects/XC/data')['data_lnk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10505c9f-603a-440b-9f21-be93c4614210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'transform_type': 'xc', 'smp_features': [('lbl2data', 1, 2), ('hlk2data', 1, 1), ('hlk2lbl2data', 2, 1)], 'pad_token': 0, 'oversample': False, 'sampling_features': [('lbl2data', 2), ('hlk2data', 1), ('hlk2lbl2data', 1)], 'num_labels': 1, 'num_metadata': 1, 'metadata_name': None, 'info_column_names': ['identifier', 'input_text'], 'use_tokenizer': True, 'tokenizer': 'bert-base-cased', 'tokenization_column': 'input_text', 'max_sequence_length': 32, 'padding': False, 'return_tensors': None, 'sep': '->', 'prompt_func': None, 'pad_side': 'right', 'drop': True, 'ret_t': True, 'in_place': True, 'collapse': True, 'device': 'cpu', 'inp': 'data', 'targ': 'lbl2data', 'ptr': 'lbl2data_data2ptr', 'n_lbl_samples': None, 'data_info_keys': None, 'lbl_info_keys': None, 'n_slbl_samples': 1, 'main_oversample': False, 'n_data_meta_samples': 1, 'n_lbl_meta_samples': 1, 'meta_info_keys': None, 'meta_oversample': False}\n"
     ]
    }
   ],
   "source": [
    "print(config['parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d5990f-6000-4473-8cda-53f73b2938c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'return_tensors':'pt', 'padding':True}\n",
    "\n",
    "for k,v in params.items():\n",
    "    config['parameters'][k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e74e2e-1321-4405-af56-b86805bdfe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = SXCDataBlock.from_cfg(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136c3ae-b689-479f-95d7-565c102b56b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.__getitems__([100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c88bf-3b9b-4e04-a1a4-9afc5ab02b22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_idx': tensor([100, 200]),\n",
       " 'data_identifier': ['Applet', 'Geography_of_Africa'],\n",
       " 'data_input_text': ['Applet', 'Geography of Africa'],\n",
       " 'data_input_ids': tensor([[  101,  7302,  1204,   102,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 20678,  1104,  2201,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'data_token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'data_attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'plbl2data_idx': tensor([  927,   928,   929,   930, 23961,  1470,  1471, 27329]),\n",
       " 'plbl2data_data2ptr': tensor([5, 3]),\n",
       " 'lbl2data_idx': tensor([  930, 27329]),\n",
       " 'lbl2data_data2ptr': tensor([1, 1]),\n",
       " 'lbl2data_identifier': ['Abstract_Window_Toolkit', 'Geography_of_Africa'],\n",
       " 'lbl2data_input_text': ['Abstract Window Toolkit', 'Geography of Africa'],\n",
       " 'lbl2data_input_ids': tensor([[  101,   138,  4832, 15017, 24769,  6466, 10493,  2875,   102,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101, 20678,  1104,  2201,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'lbl2data_token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'lbl2data_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'plnk2data_idx': tensor([   762, 202927]),\n",
       " 'plnk2data_data2ptr': tensor([1, 1]),\n",
       " 'lnk2data_idx': tensor([   762, 202927]),\n",
       " 'lnk2data_data2ptr': tensor([1, 1]),\n",
       " 'lnk2data_identifier': ['Category:Free_computer_libraries',\n",
       "  'Category:Geography_of_the_Indian_Ocean'],\n",
       " 'lnk2data_input_text': ['Free computer libraries',\n",
       "  'Geography of the Indian Ocean'],\n",
       " 'lnk2data_input_ids': tensor([[  101,  4299,  2775,  9818,   102,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101, 20678,  1104,  1103,  1890,  4879,   102,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'lnk2data_token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]]),\n",
       " 'lnk2data_attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]]),\n",
       " 'plnk2lbl_idx': tensor([], dtype=torch.int64),\n",
       " 'plnk2lbl_lbl2ptr': tensor([0, 0]),\n",
       " 'lnk2lbl_idx': tensor([], dtype=torch.int64),\n",
       " 'lnk2lbl_lbl2ptr': tensor([0, 0]),\n",
       " 'lnk2lbl_identifier': [],\n",
       " 'lnk2lbl_input_text': [],\n",
       " 'lnk2lbl_input_ids': tensor([], size=(0, 29), dtype=torch.int64),\n",
       " 'lnk2lbl_token_type_ids': tensor([], size=(0, 29), dtype=torch.int64),\n",
       " 'lnk2lbl_attention_mask': tensor([], size=(0, 29), dtype=torch.int64),\n",
       " 'lnk2lbl_data2ptr': tensor([0, 0])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad5f296-1e5c-464a-9db5-fbdc4df0a272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
