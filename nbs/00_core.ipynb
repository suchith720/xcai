{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd, numpy as np, logging, sys, re, os, torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Sampler\n",
    "from itertools import chain\n",
    "from scipy import sparse\n",
    "from IPython.display import display\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerBase\n",
    "from typing import List, Dict, Union, Optional, Any\n",
    "from fastcore.dispatch import *\n",
    "from fastcore.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Info`: LOADS METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_data(x:Dict, n:Optional[int]=10, seed:Optional[int]=None):\n",
    "    with pd.option_context('display.max_colwidth', None):\n",
    "        display(pd.DataFrame(x).sample(n, random_state=seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Info():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tokz, self.info = None, None\n",
    "        \n",
    "    @staticmethod\n",
    "    def _read_text(fname:str, enc:Optional[str]='latin-1'):\n",
    "        with open(fname, encoding=enc) as f:\n",
    "            info = [o[:-1] for o in f]\n",
    "        return info\n",
    "        \n",
    "    @staticmethod\n",
    "    def _read_info(fname:str, sep:Optional[str]='->', cols:Optional[List]=None, enc:Optional[str]='latin-1'):\n",
    "        info = Info._read_text(fname, enc=enc)\n",
    "        info = list(zip(*[o.split(sep) for o in info]))\n",
    "        cols = list(range(len(info))) if cols is None else cols\n",
    "        if len(cols) != len(info): raise ValueError(f'`cols` and `info` should have same number of elements.')\n",
    "        return {p:q for p,q in zip(cols, info)}\n",
    "\n",
    "    def read_info(self, fname:Optional[str], sep:Optional[str]='->', cols:Optional[List]=None, enc:Optional[str]='latin-1'):\n",
    "        self.info = Info._read_info(fname, sep, cols, enc)\n",
    "        return self.info\n",
    "    \n",
    "    def tokenize(self, fld:Union[int, str], tokz:Union[str, PreTrainedTokenizerBase], max_len:Optional[int]=None):\n",
    "        if self.tokz is None: self.tokz = tokz if isinstance(tokz, PreTrainedTokenizerBase) else AutoTokenizer.from_pretrained(tokz)\n",
    "        fld = list(self.info.keys())[0] if fld is None else fld\n",
    "        if fld is None: logging.info(f'`fld` not given as input, so value set to {fld}.')\n",
    "        if fld not in self.info: raise ValueError(f'`{fld}` is invalid `fld` value.')\n",
    "        self.info.update(self.tokz(self.info[fld], truncation=True, max_length=max_len))\n",
    "        return self.info\n",
    "\n",
    "    def show_data(self, n:Optional[int]=10, seed:Optional[int]=None):\n",
    "        with pd.option_context('display.max_colwidth', None):\n",
    "            display(pd.DataFrame(self.info).sample(n, random_state=seed))\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.info is None: return 0\n",
    "        n_info = [len(v) for v in self.info.values()]\n",
    "        if len(n_info) == 0: raise ValueError('`info` cannot be empty.')\n",
    "        if not np.all([o == n_info[0] for o in n_info]): raise ValueError('`info` should contain features with same length.')\n",
    "        return n_info[0]\n",
    "\n",
    "    @classmethod\n",
    "    def from_txt(cls, \n",
    "                 fname:str, \n",
    "                 sep:Optional[str]='->', \n",
    "                 cols:Optional[List]=None, \n",
    "                 enc:Optional[str]='latin-1',\n",
    "                 use_tokz:Optional[bool]=False,\n",
    "                 tokz:Optional[Union[str,PreTrainedTokenizerBase]]=None,\n",
    "                 fld:Optional[str]=None,\n",
    "                 max_len:Optional[int]=None, \n",
    "                 **kwargs):\n",
    "        self = cls()\n",
    "        self.info = self.read_info(fname, sep, cols, enc)\n",
    "        if use_tokz: self.tokenize(fld, tokz, max_len)\n",
    "        return self.info\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'/home/scai/phd/aiz218323/Projects/XC_NLG/data/(mapped)LF-WikiSeeAlsoTitles-320K/raw_data/train.raw.txt'\n",
    "cols = ['identifier', 'input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = Info.from_txt(fname, cols=cols, use_tokz=True, tokz='bert-base-uncased', fld=cols[1], max_len=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>input_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91182</th>\n",
       "      <td>Convertible_arbitrage</td>\n",
       "      <td>Convertible arbitrage</td>\n",
       "      <td>[101, 22840, 12098, 16313, 24449, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31680</th>\n",
       "      <td>Leopoldo_Lugones</td>\n",
       "      <td>Leopoldo Lugones</td>\n",
       "      <td>[101, 12752, 2080, 11320, 7446, 2229, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158476</th>\n",
       "      <td>Interstate_269</td>\n",
       "      <td>Interstate 269</td>\n",
       "      <td>[101, 7553, 25717, 102]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390138</th>\n",
       "      <td>Institute_for_Health_Freedom</td>\n",
       "      <td>Institute for Health Freedom</td>\n",
       "      <td>[101, 2820, 2005, 2740, 4071, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248643</th>\n",
       "      <td>Abuja_Securities_and_Commodities_Exchange</td>\n",
       "      <td>Abuja Securities and Commodities Exchange</td>\n",
       "      <td>[101, 8273, 3900, 12012, 1998, 21955, 3863, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       identifier  \\\n",
       "91182                       Convertible_arbitrage   \n",
       "31680                            Leopoldo_Lugones   \n",
       "158476                             Interstate_269   \n",
       "390138               Institute_for_Health_Freedom   \n",
       "248643  Abuja_Securities_and_Commodities_Exchange   \n",
       "\n",
       "                                       input_text  \\\n",
       "91182                       Convertible arbitrage   \n",
       "31680                            Leopoldo Lugones   \n",
       "158476                             Interstate 269   \n",
       "390138               Institute for Health Freedom   \n",
       "248643  Abuja Securities and Commodities Exchange   \n",
       "\n",
       "                                               input_ids  \\\n",
       "91182             [101, 22840, 12098, 16313, 24449, 102]   \n",
       "31680         [101, 12752, 2080, 11320, 7446, 2229, 102]   \n",
       "158476                           [101, 7553, 25717, 102]   \n",
       "390138                [101, 2820, 2005, 2740, 4071, 102]   \n",
       "248643  [101, 8273, 3900, 12012, 1998, 21955, 3863, 102]   \n",
       "\n",
       "                  token_type_ids            attention_mask  \n",
       "91182         [0, 0, 0, 0, 0, 0]        [1, 1, 1, 1, 1, 1]  \n",
       "31680      [0, 0, 0, 0, 0, 0, 0]     [1, 1, 1, 1, 1, 1, 1]  \n",
       "158476              [0, 0, 0, 0]              [1, 1, 1, 1]  \n",
       "390138        [0, 0, 0, 0, 0, 0]        [1, 1, 1, 1, 1, 1]  \n",
       "248643  [0, 0, 0, 0, 0, 0, 0, 0]  [1, 1, 1, 1, 1, 1, 1, 1]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_data(info, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = Info()\n",
    "_ = info.read_info(fname, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>247245</th>\n",
       "      <td>20_minutes_(Switzerland)</td>\n",
       "      <td>20 minutes (Switzerland)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>Isoelectric_point</td>\n",
       "      <td>Isoelectric point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538866</th>\n",
       "      <td>Moldova_in_the_Eurovision_Song_Contest_2013</td>\n",
       "      <td>Moldova in the Eurovision Song Contest 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100310</th>\n",
       "      <td>Lemhi_Pass</td>\n",
       "      <td>Lemhi Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639082</th>\n",
       "      <td>Order_of_precedence_in_Kelantan</td>\n",
       "      <td>Order of precedence in Kelantan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510129</th>\n",
       "      <td>RTS,S</td>\n",
       "      <td>RTS,S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216809</th>\n",
       "      <td>Geering_(automobile)</td>\n",
       "      <td>Geering (automobile)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569292</th>\n",
       "      <td>Sole_Survivor_(2013_film)</td>\n",
       "      <td>Sole Survivor (2013 film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175818</th>\n",
       "      <td>Puerto_Rico_National_Cemetery</td>\n",
       "      <td>Puerto Rico National Cemetery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615747</th>\n",
       "      <td>Anna_IllÃ©s</td>\n",
       "      <td>Anna IllÃ©s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         identifier  \\\n",
       "247245                     20_minutes_(Switzerland)   \n",
       "2305                              Isoelectric_point   \n",
       "538866  Moldova_in_the_Eurovision_Song_Contest_2013   \n",
       "100310                                   Lemhi_Pass   \n",
       "639082              Order_of_precedence_in_Kelantan   \n",
       "510129                                        RTS,S   \n",
       "216809                         Geering_(automobile)   \n",
       "569292                    Sole_Survivor_(2013_film)   \n",
       "175818                Puerto_Rico_National_Cemetery   \n",
       "615747                                  Anna_IllÃ©s   \n",
       "\n",
       "                                         input_text  \n",
       "247245                     20 minutes (Switzerland)  \n",
       "2305                              Isoelectric point  \n",
       "538866  Moldova in the Eurovision Song Contest 2013  \n",
       "100310                                   Lemhi Pass  \n",
       "639082              Order of precedence in Kelantan  \n",
       "510129                                        RTS,S  \n",
       "216809                         Geering (automobile)  \n",
       "569292                    Sole Survivor (2013 film)  \n",
       "175818                Puerto Rico National Cemetery  \n",
       "615747                                  Anna IllÃ©s  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "info.show_data(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "693082"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Filterer`: XC FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Filterer:\n",
    "\n",
    "    @staticmethod\n",
    "    def load_filter(fname:str):\n",
    "        if fname is not None and os.path.exists(fname): return np.loadtxt(fname, dtype=np.int64)\n",
    "        \n",
    "    @staticmethod\n",
    "    def generate(train_id:List, test_id:List, lbl_id:List, train_lbl:sparse.csr_matrix, test_lbl:sparse.csr_matrix):\n",
    "        _, train_idx, lbl2train_idx = np.intersect1d(train_id, lbl_id, return_indices=True)\n",
    "        train_lbl_filterer = np.vstack([train_idx, lbl2train_idx]).T\n",
    "        \n",
    "        _, test_idx, lbl2test_idx = np.intersect1d(test_id, lbl_id, return_indices=True)\n",
    "        test_lbl_filterer = np.vstack([test_idx, lbl2test_idx]).T\n",
    "        \n",
    "        train_udx, train_udx2idx = np.unique(train_idx, return_index=True)\n",
    "        lbl2test_udx, lbl2test_udx2idx = np.unique(lbl2test_idx, return_index=True)\n",
    "        \n",
    "        _test_lbl_filterer = train_lbl[train_udx][:, lbl2test_udx].T\n",
    "        \n",
    "        rows, cols = _test_lbl_filterer.nonzero()\n",
    "        test_idx = test_idx[lbl2test_udx2idx[rows]]\n",
    "        lbl2test_idx = lbl2train_idx[train_udx2idx[cols]]\n",
    "        \n",
    "        _test_lbl_filterer = np.vstack([test_idx, lbl2test_idx]).T\n",
    "        test_lbl_filterer = np.vstack([test_lbl_filterer, _test_lbl_filterer])\n",
    "    \n",
    "        return train_lbl_filterer, test_lbl_filterer\n",
    "\n",
    "    @staticmethod\n",
    "    def sample(f:np.array, sz:tuple, idx:List):\n",
    "        f = sparse.coo_matrix((np.full(f.shape[0],1), (f[:, 0], f[:, 1])), shape=sz).tocsr()\n",
    "        f = f[idx].tocoo()\n",
    "        return np.vstack([f.row, f.col]).T\n",
    "\n",
    "    @staticmethod\n",
    "    def prune(data:sparse.csr_matrix, data_filterer:np.array):\n",
    "        data = data.copy()\n",
    "        data[data_filterer[:,0], data_filterer[:,1]] = 0\n",
    "        data.eliminate_zeros()\n",
    "        \n",
    "        idx = np.where(data.getnnz(axis=1) > 0)[0]\n",
    "        return data[idx], Filterer.sample(data_filterer, data.shape, idx), idx\n",
    "\n",
    "    @staticmethod\n",
    "    def apply(data:sparse.csr_matrix, data_filterer:np.array):\n",
    "        data[data_filterer[:,0], data_filterer[:,1]] = 0\n",
    "        data.eliminate_zeros()\n",
    "        return data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def store_attr(names=None, self=None, but='', cast=False, store_args=None, is_none=True, **attrs):\n",
    "    fr = sys._getframe(1)\n",
    "    args = argnames(fr, True)\n",
    "    if self: args = ('self', *args)\n",
    "    else: self = fr.f_locals[args[0]]\n",
    "    if store_args is None: store_args = not hasattr(self,'__slots__')\n",
    "    if store_args and not hasattr(self, '__stored_args__'): self.__stored_args__ = {}\n",
    "    anno = annotations(self) if cast else {}\n",
    "    if names and isinstance(names,str): names = re.split(', *', names)\n",
    "    ns = names if names is not None else getattr(self, '__slots__', args[1:])\n",
    "    added = {n:fr.f_locals[n] for n in ns}\n",
    "    attrs = {**attrs, **added}\n",
    "    if isinstance(but,str): but = re.split(', *', but)\n",
    "    attrs = {k:v for k,v in attrs.items() if k not in but}\n",
    "    return _store_attr(self, anno, is_none, **attrs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _store_attr(self, anno, is_none, **attrs):\n",
    "    stored = getattr(self, '__stored_args__', None)\n",
    "    for n,v in attrs.items():\n",
    "        if n in anno: v = anno[n](v)\n",
    "        if is_none or v is not None: setattr(self, n, v)\n",
    "        if stored is not None: stored[n] = v\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_attr(x, attr:str):\n",
    "    for a in attr.split('.'): x = getattr(x, a)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `BalancedClusters`: CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BalancedClusters:\n",
    "\n",
    "    @staticmethod\n",
    "    def binary_kmeans(x:torch.Tensor, idx:Optional[torch.Tensor]=None, tol:Optional[float]=1e-4):\n",
    "        n, x = x.shape[0], F.normalize(x)\n",
    "        if n == 1: return (idx,)\n",
    "            \n",
    "        rnd_idx = torch.randperm(n)[:2]\n",
    "        c = x[rnd_idx]\n",
    "        sim = x@c.T\n",
    "        \n",
    "        old_sc, new_sc = None, None\n",
    "        while old_sc is None or new_sc - old_sc >= tol:\n",
    "            p,q = torch.chunk(torch.argsort(sim[:,1]-sim[:,0]), 2)\n",
    "            c = torch.vstack([x[p].mean(dim=0, keepdim=True), x[q].mean(dim=0, keepdim=True)])\n",
    "            sim = x@c.T\n",
    "            sc = sim[p,0].sum() + sim[q,1].sum()\n",
    "            new_sc, old_sc = sc/n, new_sc\n",
    "        if idx is None: return p,q\n",
    "        else: return (idx[p],idx[q])\n",
    "\n",
    "    @staticmethod\n",
    "    def proc(x:torch.Tensor, n_cluster:int, cluster:Optional[List[torch.Tensor]]=None):\n",
    "        def _nearest_two_power(x): return 2**int(np.ceil(np.log2(x)))\n",
    "        n_cluster = _nearest_two_power(n_cluster)\n",
    "        cluster = (torch.arange(x.shape[0]),) if cluster is None else cluster\n",
    "        nsz, osz = None, None\n",
    "        while len(cluster) < n_cluster and (nsz != osz or osz is None):\n",
    "            cluster = list(chain(*[BalancedClusters.binary_kmeans(x[o],o) for o in cluster]))\n",
    "            nsz,osz = len(cluster),nsz\n",
    "        x2cluster = torch.zeros(len(x), dtype=torch.int64)\n",
    "        for i,c in enumerate(cluster): x2cluster[c] = i\n",
    "        return cluster, x2cluster\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([8, 0, 7]), tensor([1, 6]), tensor([9, 5, 2]), tensor([3, 4])],\n",
       " tensor([0, 1, 2, 3, 3, 2, 1, 0, 0, 2]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BalancedClusters.proc(x, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ClusterGroupedSampler`: CLUSTER BASED SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ClusterGroupedSampler(Sampler):\n",
    "\n",
    "    def __init__(self, n:int, cluster:Optional[List]=None, generator:Optional[Any]=None):\n",
    "        store_attr('n,cluster,generator')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def set_cluster(self, cluster): self.cluster = cluster\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.cluster is None: return iter(torch.randperm(self.n).tolist())\n",
    "        csz = sum([len(o) for o in self.cluster])\n",
    "        if len(self) != csz: raise ValueError(f'`n`({len(self)}) should be equal to total elements in `cluster`({csz})')\n",
    "        cluster = [self.cluster[i] for i in torch.randperm(len(self.cluster))]\n",
    "        indices = torch.hstack([o[torch.randperm(len(o))] for o in cluster]).tolist()\n",
    "        return iter(indices)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 16\n",
    "x = torch.randn(n, 3)\n",
    "\n",
    "def dlo(dl): \n",
    "    for b in dl: print(x2cluster[b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ClusterGroupedSampler(n)\n",
    "dl = DataLoader(torch.arange(len(x)), batch_size=2, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4])\n",
      "tensor([4, 7])\n",
      "tensor([0, 7])\n",
      "tensor([5, 2])\n",
      "tensor([6, 2])\n",
      "tensor([1, 3])\n",
      "tensor([1, 5])\n",
      "tensor([0, 6])\n"
     ]
    }
   ],
   "source": [
    "dlo(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster, x2cluster = BalancedClusters.proc(x, 5)\n",
    "dl.sampler.set_cluster(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1])\n",
      "tensor([3, 3])\n",
      "tensor([5, 5])\n",
      "tensor([2, 2])\n",
      "tensor([6, 6])\n",
      "tensor([4, 4])\n",
      "tensor([7, 7])\n",
      "tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "dlo(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster, x2cluster = BalancedClusters.proc(x, 5)\n",
    "dl.sampler.set_cluster(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0])\n",
      "tensor([1, 1])\n",
      "tensor([3, 3])\n",
      "tensor([6, 6])\n",
      "tensor([4, 4])\n",
      "tensor([2, 2])\n",
      "tensor([5, 5])\n",
      "tensor([7, 7])\n"
     ]
    }
   ],
   "source": [
    "dlo(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
