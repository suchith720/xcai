{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a91108-d71b-40a0-8458-33efa73854a2",
   "metadata": {},
   "source": [
    "# Data sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "327b0718-198e-40b7-9910-7106459dc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ecf885-bfa1-4413-8a90-71949be38f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a66b2865-35df-4f1b-9341-9530f1cbecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os,pickle,torch,re, numpy as np\n",
    "from typing import Optional,List,Dict\n",
    "from itertools import chain\n",
    "\n",
    "from transformers import BatchEncoding, AutoTokenizer\n",
    "\n",
    "from fastcore.utils import *\n",
    "\n",
    "from xcai.transform import PadFeatTfm,CollapseTfm\n",
    "from xcai.core import store_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81edfd1-cda7-4a66-87e6-5687a5912de7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8195c254-4468-4644-9ffc-2962bb128a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcai.block import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fe65ac-18ae-45a2-85fa-0c95a40f08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30ab99da-14d6-4397-ae3f-e66ab9fb9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/home/scai/phd/aiz218323/scratch/datasets'\n",
    "pkl_file = f'{pkl_dir}/processed/wikiseealsotitles_data-meta_distilbert-base-uncased_xcs.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b02e0c-0b1a-46a7-9cfe-97e50bd0c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as file: block = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3991a-c7d6-4eca-be3d-02713990b230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edde8af5-6b31-4f9f-856c-1bb7fbad4d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scai/phd/aiz218323/.local/lib/python3.9/site-packages/xclib-0.97-py3.9-linux-x86_64.egg/xclib/data/data_utils.py:263: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/scai/phd/aiz218323/Projects/XC_NLG/data'\n",
    "\n",
    "block = XCBlock.from_cfg(data_dir, 'data_meta', transform_type='xcs', tokenizer='distilbert-base-uncased', \n",
    "                         sampling_features=[('lbl2data',4)], oversample=False, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf3e41-9ce3-4a21-9b0c-5de09b9456d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45ca14dc-6d45-45c1-acb8-e88cf74cbe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "block.collator.tfms.tfms[0].sampling_features = [('lbl2data,cat2lbl2data', (4,1)), ('cat2data', 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dcf16db-c855-4203-af79-2b1cb9884e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch(bsz=5, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67a38d34-68fb-46f1-bf33-a85ee91f8670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'data_idx', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'cat2data_idx', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'cat2lbl2data_idx', 'cat2lbl2data_identifier', 'cat2lbl2data_input_text', 'cat2lbl2data_input_ids', 'cat2lbl2data_attention_mask'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3872cc-049d-4aae-925a-e1099d47e10a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `XCSamplerFeatTfm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f1b468b-713b-4eb3-9413-24be7c735e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XCSamplerFeatTfm:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pad_token:Optional[int]=0,\n",
    "        oversample:Optional[bool]=False,\n",
    "        sampling_features:Optional[List]=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        store_attr('sampling_features,oversample')\n",
    "        self.pad_proc = PadFeatTfm(pad_tok=pad_token, in_place=False, drop=False)\n",
    "        self.col_proc = CollapseTfm()\n",
    "\n",
    "    def sample_feature(self, batch, names, n_samples, oversample):\n",
    "        feature_names = names.split(',')\n",
    "        \n",
    "        if isinstance(n_samples, int): \n",
    "            n_samples = (n_samples,)*len(feature_names)\n",
    "\n",
    "        if len(feature_names) != len(n_samples):\n",
    "            raise ValueError(f'`feature_names` and `n_samples` should have same length.')\n",
    "        \n",
    "        base_name, dep_names = feature_names[0], feature_names[1:]\n",
    "        base_n_sample, dep_n_samples = n_samples[0], n_samples[1:]\n",
    "\n",
    "        for p in dep_names:\n",
    "            if not p.endswith(base_name): \n",
    "                raise ValueError(f'{p} does not end with the base prefix `{base_name}`.')\n",
    "\n",
    "        sampled_batch, sbatch = self.sample_base_feature(batch, names, base_name, base_n_sample, oversample)\n",
    "        return self.sample_dep_features(sampled_batch, sbatch, dep_names, dep_n_samples, oversample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79f941b9-2cd9-4cc5-8a81-3ec15449ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def rename_idx_ptr(self:XCSamplerFeatTfm, x, prefix, sampling_prefix=None):\n",
    "    prefixes = prefix.split('2')\n",
    "    for i,n in enumerate(range(len(prefixes)-1,0,-1)):\n",
    "        s = '2'.join(prefixes[n:])\n",
    "        p = prefix if sampling_prefix is None else sampling_prefix\n",
    "        x[f'{p}_{s}2ptr'] = x[f'{prefix}_idx_ptr-{i+1}']\n",
    "        del x[f'{prefix}_idx_ptr-{i+1}']\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf1a8f40-b230-453b-bad8-2a4cecf03651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def collate_feature_idx(self:XCSamplerFeatTfm, x, name, sampling_name=None):\n",
    "    level = name.count('2')\n",
    "    o = self.pad_proc(x, prefix=f'{name}_idx', lev=level)\n",
    "\n",
    "    if f'{name}_idx' in o:\n",
    "        if sampling_name is not None and f'{sampling_name}_idx' not in o:\n",
    "            o[f'{sampling_name}_idx'] = o[f'{name}_idx']\n",
    "            del o[f'{name}_idx']\n",
    "        o = self.rename_idx_ptr(o, name, sampling_name)\n",
    "        o = {f'p{k}':v for k,v in o.items()}\n",
    "        \n",
    "    return o \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf4b429c-5f4e-4924-ad81-03ab4ff88565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_rnd_idx_from_ptr(self:XCSamplerFeatTfm, x, n_samples, oversample=True):\n",
    "    if oversample: return [torch.randint(i, size=(n_samples,)) if i>0 else torch.tensor([-1]) for i in x]\n",
    "    else: return [torch.randperm(i)[:n_samples] if i>0 else torch.tensor([-1]) for i in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b8bc57c-a04f-4d9e-ac43-669fec47f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_features(self:XCSamplerFeatTfm, x, prefix:str):\n",
    "    pat = f'^({prefix.replace(\",\",\"|\")})_.*'\n",
    "    return [o for o in x if re.match(pat, o)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76816cd3-b6c3-4018-a1c0-65deb11f37be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def sample_batch(self:XCSamplerFeatTfm, batch, features, idxs, level):\n",
    "    sbatch = []\n",
    "    for b,idx in zip(batch, idxs):\n",
    "        sfeatures = {}\n",
    "        for feature in features:\n",
    "            cfeature = self.col_proc(b[feature], level)[0]\n",
    "            sfeatures[feature] = [] if idx[0] == -1 else [cfeature[i] for i in idx]\n",
    "        sbatch.append(sfeatures)\n",
    "    return sbatch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48317d30-9509-44b0-991c-7dc88b837e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def remove_unwanted_ptr(self:XCSamplerFeatTfm, x):\n",
    "    return {k:v for k,v in x.items() if not re.match('.*_ptr-[0-9]+$', k)}\n",
    "\n",
    "@patch\n",
    "def rename_keys(self:XCSamplerFeatTfm, x, prefix):\n",
    "    keys = list(x.keys())\n",
    "    for k in keys:\n",
    "        nk = k.split('_', maxsplit=1)[1]\n",
    "        nk = f'{prefix}_{nk}'\n",
    "        if nk not in x:\n",
    "            x[nk] = x[k]\n",
    "            del x[k]\n",
    "    return x\n",
    "\n",
    "@patch\n",
    "def collate_features(self:XCSamplerFeatTfm, x, name, sampling_name=None):\n",
    "    level = name.count('2')\n",
    "    o = self.pad_proc(x, prefix=name, lev=level)\n",
    "    o = self.rename_idx_ptr(o, name, sampling_name)\n",
    "    o = self.remove_unwanted_ptr(o)\n",
    "    if sampling_name is not None: o = self.rename_keys(o, sampling_name)\n",
    "    return o\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b1439fe-7049-4410-8bd0-1d60424794de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def sample_base_feature(self:XCSamplerFeatTfm, batch:List, prefix_names:str, name:str, n_sample:int, oversample:Optional[bool]=True):\n",
    "    sampled_batch, sbatch = {}, {}\n",
    "    \n",
    "    feat_prefix = name.split('2')\n",
    "    sampling_name,ptr_name = f'{feat_prefix[0]}2{feat_prefix[-1]}',feat_prefix[-1]\n",
    "    \n",
    "    o = self.collate_feature_idx(batch, name=name, sampling_name=sampling_name)\n",
    "\n",
    "    if len(o):\n",
    "        sampling_idx = self.get_rnd_idx_from_ptr(o[f'p{sampling_name}_{ptr_name}2ptr'], n_sample, oversample=oversample)\n",
    "        \n",
    "        sampled_batch.update(o)\n",
    "        \n",
    "        feats,level = self.get_features(batch[0], prefix_names), name.count('2')-1\n",
    "        sbatch = self.sample_batch(batch, feats, sampling_idx, level)\n",
    "    \n",
    "        o = self.collate_features(sbatch, name=name, sampling_name=sampling_name)\n",
    "        sampled_batch.update(o)\n",
    "    \n",
    "    return sampled_batch, sbatch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c3ff6da-f20e-4bfd-add6-88dfb6488aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def sample_sbatch(self:XCSamplerFeatTfm, batch, features, n_samples, oversample=True):\n",
    "    sbatch = []\n",
    "    for b in batch:\n",
    "        \n",
    "        idxs = []\n",
    "        for val in b[features[0]]:\n",
    "            if oversample: idx = np.random.randint(len(val), size=n_samples) if len(val) > 0 else []\n",
    "            else: idx = np.random.permutation(len(val))[:n_samples]\n",
    "            idxs.append(idx)\n",
    "        \n",
    "        sfeatures = {}\n",
    "        for feature in features:\n",
    "            \n",
    "            svalues = []\n",
    "            for val,idx in zip(b[feature],idxs):\n",
    "                svalues.append([val[i] for i in idx])\n",
    "                \n",
    "            sfeatures[feature] = svalues\n",
    "            \n",
    "        sbatch.append(sfeatures)\n",
    "    return sbatch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4830482-738a-48b8-a3fb-aa509542a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def sample_dep_features(\n",
    "    self:XCSamplerFeatTfm, \n",
    "    sampled_batch:List, \n",
    "    sbatch:List, \n",
    "    names:List, \n",
    "    n_samples:List, \n",
    "    oversample:Optional[bool]=True\n",
    "):\n",
    "    for name,n_sample in zip(names,n_samples):\n",
    "        sampling_name = '2'.join(name.split('2')[:2])\n",
    "        o = self.collate_feature_idx(sbatch, name=name, sampling_name=sampling_name)\n",
    "\n",
    "        if len(o):\n",
    "            sampled_batch.update(o)\n",
    "            \n",
    "            feats = self.get_features(sbatch[0], name)\n",
    "            o = self.sample_sbatch(sbatch, feats, n_sample, oversample=oversample)\n",
    "            o = self.collate_features(o, name=name, sampling_name=sampling_name)\n",
    "            sampled_batch.update(o)\n",
    "\n",
    "    return sampled_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdc82038-3b06-4fb6-9cf0-77cef4dcd388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def process_features(self:XCSamplerFeatTfm, sampled_batch:BatchEncoding, batch:BatchEncoding, names:List):\n",
    "    for name in names:\n",
    "        o = self.collate_features(batch, name=name)\n",
    "        sampled_batch.update(o)\n",
    "    return sampled_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09eb60e3-5cd2-49ca-971b-87bd4f8e29fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def __call__(\n",
    "    self:XCSamplerFeatTfm, \n",
    "    batch:List, \n",
    "    sampling_features:Optional[List]=None,\n",
    "    oversample:Optional[bool]=None,\n",
    "):  \n",
    "    store_attr('sampling_features,oversample', is_none=False)\n",
    "\n",
    "    sampled_features = set()\n",
    "    out = BatchEncoding({})\n",
    "    for name, n_sample in self.sampling_features:\n",
    "        o = self.sample_feature(batch, name, n_sample, self.oversample)\n",
    "        out.update(o)\n",
    "\n",
    "        sampled_features.update(name.split(','))\n",
    "\n",
    "    all_features = set([k.split('_')[0] for k in batch[0].keys()])\n",
    "    remaining_features = all_features.difference(sampled_features)\n",
    "    out = self.process_features(out, batch, remaining_features)\n",
    "    \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd622b5-f71e-4d9e-b5e5-d2cfe6f733d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d283c8e-0502-4667-a91d-ed5798995560",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch(bsz=1600, seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bee5af6-a9dc-4cc8-8cf0-b9e893462908",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = XCSamplerFeatTfm(pad_token=0, sampling_features=[('lbl2data,cat2lbl2data', (4,1)), ('cat2data', 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "937cfd2c-d657-477b-b23b-ea355144e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = sampler(batch, oversample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e66f4ba2-17ba-41bc-930b-a6f8ddf50676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2373, 17]), torch.Size([2373, 17]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o['cat2lbl_input_ids'].shape, o['cat2lbl_attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49d949c7-4503-4bea-9920-8e2effe7db42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['plbl2data_idx', 'plbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_identifier', 'lbl2data_input_text', 'lbl2data_input_ids', 'lbl2data_attention_mask', 'lbl2data_data2ptr', 'pcat2lbl_idx', 'pcat2lbl_data2ptr', 'pcat2lbl_lbl2data2ptr', 'cat2lbl_data2ptr', 'cat2lbl_lbl2data2ptr', 'cat2lbl_idx', 'cat2lbl_identifier', 'cat2lbl_input_text', 'cat2lbl_input_ids', 'cat2lbl_attention_mask', 'pcat2data_idx', 'pcat2data_data2ptr', 'cat2data_idx', 'cat2data_identifier', 'cat2data_input_text', 'cat2data_input_ids', 'cat2data_attention_mask', 'cat2data_data2ptr', 'data_identifier', 'data_input_text', 'data_input_ids', 'data_attention_mask', 'data_idx'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3f7ddef-8b1f-4bf5-925a-e45085ecfeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7b61389-f0a8-4c82-9c05-25f9e8eb2425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e6a3ae98584941b135592f787a8f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in tqdm(block.train.dl):\n",
    "    a = torch.where(batch['cat2lbl_input_ids'] == 102)[1] + 1 \n",
    "    b = batch['cat2lbl_attention_mask'].sum(dim=1)\n",
    "    assert torch.all(a == b).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5496d47-2b7a-45e1-a8bb-10cea788e830",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### XCSamplerFeatTfm code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3beb75-ad3c-4e58-b0be-7aa057c3c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_proc = PadFeatTfm(pad_tok=0, in_place=False, drop=False)\n",
    "col_proc = CollapseTfm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda0117-88b5-4fa1-b141-22787eb2c843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9bdcc7-90fe-4542-b710-6eda5b14e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'lbl2data,cat2lbl2data'\n",
    "n_samples = [2,3]\n",
    "\n",
    "names = prefix.split(',')\n",
    "base_name, smp_names = names[0], names[1:]\n",
    "\n",
    "for p in smp_names:\n",
    "    if not p.endswith(base_name): \n",
    "        raise ValueError(f'{p} does not end with the base prefix `{base_name}`.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf3a75-eaf2-4f2c-8e6f-b29b7a116cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(n_samples, int): \n",
    "    n_samples = (n_samples,)*len(smp_names)\n",
    "\n",
    "if len(names) != len(n_samples):\n",
    "    raise ValueError(f'`prefixes` and `n_samples` should have same length.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe5617-8306-40c1-9e84-48663692de0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998ccc9-c8fe-4639-90de-f56ef2a52999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b91a1-5447-4573-a918-26ed9d153acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_batch = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a346480-0a93-4607-b2bf-86cf974761b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name, n_sample = base_name, n_samples[0]\n",
    "\n",
    "feat_prefix = name.split('2')\n",
    "sampling_name,ptr_name = f'{feat_prefix[0]}2{feat_prefix[-1]}',feat_prefix[-1]\n",
    "\n",
    "\n",
    "o = collate_feature_idx(batch, name=name, sampling_name=sampling_name)\n",
    "sampling_idx = get_rnd_idx_from_ptr(o[f'p{sampling_name}_{ptr_name}2ptr'], n_sample, oversample=True)\n",
    "\n",
    "sampled_batch.update(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21d1f7-4fb4-4201-8fc5-ce6f87ffc91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats,level = get_features(batch[0], prefix), name.count('2')-1\n",
    "sbatch = sample_batch(batch, feats, sampling_idx, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c3db0-135b-45b0-9d1b-60ea9e9d95e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecbcb50-5ebb-4aa3-91c4-77ad5ba661ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = collate_features(sbatch, name=name, sampling_name=sampling_name)\n",
    "sampled_batch.update(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3666bb02-6657-47c6-9bb6-3adf725f194b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f99a5e-9522-4f42-88be-9f6b254c8c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d87027-3071-4e12-9ab0-4ae854d43407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fdb9bf-b74d-46aa-918a-84dbe9355ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name, n_sample = smp_names[0], n_samples[0]\n",
    "sampling_name = '2'.join(name.split('2')[:2])\n",
    "\n",
    "o = collate_feature_idx(batch, name=name, sampling_name=sampling_name)\n",
    "sampled_batch.update(o)\n",
    "\n",
    "feats = get_features(sbatch[0], name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea0b2ce-e47e-4968-b15e-cdc4b78635d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = sample_sbatch(sbatch, feats, n_samples[1], oversample=True)\n",
    "o = collate_features(o, name=name, sampling_name=sampling_name)\n",
    "sampled_batch.update(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce596e-91a9-4d1a-985c-a7d37e76ea1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7d91d-9bad-486b-b323-b76d7129b452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plbl2data_data2ptr': tensor([ 1, 14,  1,  1,  1]),\n",
       " 'lbl2data_idx': tensor([ 97475,  97475, 134705,  14241, 196033, 196033,  26569,  26569, 195049,\n",
       "         195049]),\n",
       " 'lbl2data_identifier': ['List_of_Test_cricket_umpires',\n",
       "  'List_of_Test_cricket_umpires',\n",
       "  'List_of_drugs_used_by_militaries',\n",
       "  'Military_medicine',\n",
       "  'List_of_rivers_of_Mexico',\n",
       "  'List_of_rivers_of_Mexico',\n",
       "  'List_of_New_South_Wales_representative_cricketers',\n",
       "  'List_of_New_South_Wales_representative_cricketers',\n",
       "  'List_of_antarctic_and_sub-antarctic_islands',\n",
       "  'List_of_antarctic_and_sub-antarctic_islands'],\n",
       " 'lbl2data_input_text': ['List of Test cricket umpires',\n",
       "  'List of Test cricket umpires',\n",
       "  'List of drugs used by militaries',\n",
       "  'Military medicine',\n",
       "  'List of rivers of Mexico',\n",
       "  'List of rivers of Mexico',\n",
       "  'List of New South Wales representative cricketers',\n",
       "  'List of New South Wales representative cricketers',\n",
       "  'List of antarctic and sub-antarctic islands',\n",
       "  'List of antarctic and sub-antarctic islands'],\n",
       " 'lbl2data_input_ids': tensor([[  101,  2862,  1997,  3231,  4533, 20887,  2015,   102,     0,     0],\n",
       "         [  101,  2862,  1997,  3231,  4533, 20887,  2015,   102,     0,     0],\n",
       "         [  101,  2862,  1997,  5850,  2109,  2011, 23689,  6590,  5134,   102],\n",
       "         [  101,  2510,  4200,   102,     0,     0,     0,     0,     0,     0],\n",
       "         [  101,  2862,  1997,  5485,  1997,  3290,   102,     0,     0,     0],\n",
       "         [  101,  2862,  1997,  5485,  1997,  3290,   102,     0,     0,     0],\n",
       "         [  101,  2862,  1997,  2047,  2148,  3575,  4387,  9490,  2015,   102],\n",
       "         [  101,  2862,  1997,  2047,  2148,  3575,  4387,  9490,  2015,   102],\n",
       "         [  101,  2862,  1997, 10227,  1998,  4942,  1011, 10227,  3470,   102],\n",
       "         [  101,  2862,  1997, 10227,  1998,  4942,  1011, 10227,  3470,   102]]),\n",
       " 'lbl2data_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'lbl2data_data2ptr': tensor([2, 2, 2, 2, 2]),\n",
       " 'cat2lbl_data2ptr': tensor([6, 6, 6, 6, 0]),\n",
       " 'cat2lbl_lbl2data2ptr': tensor([3, 3, 3, 3, 3, 3, 3, 3, 0, 0]),\n",
       " 'cat2lbl_idx': tensor([497117, 497117, 497117, 497116, 402688, 497117, 341204, 341204, 175085,\n",
       "         230285, 199444, 199444, 499473, 504533, 499473,  72163, 499473, 504533,\n",
       "         490629, 490629,  62743, 490629, 490629, 426229]),\n",
       " 'cat2lbl_identifier': ['Category:Cricket-related_lists',\n",
       "  'Category:Test_cricket',\n",
       "  'Category:Cricket-related_lists',\n",
       "  'Category:Cricket-related_lists',\n",
       "  'Category:International_cricket_umpires',\n",
       "  'Category:International_cricket_umpires',\n",
       "  'Category:Drug-related_lists',\n",
       "  'Category:Drugs_and_the_military',\n",
       "  'Category:Military_comparisons',\n",
       "  'Category:Military_supporting_service_occupations',\n",
       "  'Category:Military_supporting_service_occupations',\n",
       "  'Category:Military_supporting_service_occupations',\n",
       "  'Category:Lists_of_landforms_of_Mexico',\n",
       "  'Category:Rivers_of_Mexico',\n",
       "  'Category:Lists_of_landforms_of_Mexico',\n",
       "  'Category:Lists_of_landforms_of_Mexico',\n",
       "  'Category:Rivers_of_Mexico',\n",
       "  'Category:Lists_of_rivers_by_country',\n",
       "  'Category:New_South_Wales-related_lists',\n",
       "  'Category:New_South_Wales-related_lists',\n",
       "  'Category:New_South_Wales_cricketers',\n",
       "  'Category:New_South_Wales-related_lists',\n",
       "  'Category:New_South_Wales-related_lists',\n",
       "  'Category:New_South_Wales-related_lists'],\n",
       " 'cat2lbl_input_text': ['Cricket-related lists',\n",
       "  'International cricket umpires',\n",
       "  'Test cricket',\n",
       "  'Test cricket umpires',\n",
       "  'Test cricket',\n",
       "  'Test cricket umpires',\n",
       "  'Military comparisons',\n",
       "  'Military comparisons',\n",
       "  'Drug-related lists',\n",
       "  'Military medicine',\n",
       "  'Military supporting service occupations',\n",
       "  'Military supporting service occupations',\n",
       "  'Rivers of Mexico',\n",
       "  'Lists of landforms of Mexico',\n",
       "  'Rivers of Mexico',\n",
       "  'Rivers of Mexico',\n",
       "  'Lists of rivers by country',\n",
       "  'Lists of rivers by country',\n",
       "  'New South Wales cricketers',\n",
       "  'New South Wales cricketers',\n",
       "  'New South Wales cricketers',\n",
       "  'New South Wales-related lists',\n",
       "  'Lists of Australian cricketers',\n",
       "  'New South Wales-related lists'],\n",
       " 'cat2lbl_input_ids': tensor([[  101,  3231,  4533, 20887,  2015,   102,     0,     0],\n",
       "         [  101,  3231,  4533, 20887,  2015,   102,     0,     0],\n",
       "         [  101,  2248,  4533, 20887,  2015,   102,     0,     0],\n",
       "         [  101,  2248,  4533, 20887,  2015,   102,     0,     0],\n",
       "         [  101,  2248,  4533, 20887,  2015,   102,     0,     0],\n",
       "         [  101,  3231,  4533, 20887,  2015,   102,     0,     0],\n",
       "         [  101,  2510, 18539,   102,     0,     0,     0,     0],\n",
       "         [  101,  4319,  1011,  3141,  7201,   102,     0,     0],\n",
       "         [  101,  2510, 18539,   102,     0,     0,     0,     0],\n",
       "         [  101,  2510,  4637,  2326, 23374,   102,     0,     0],\n",
       "         [  101,  2510,  4637,  2326, 23374,   102,     0,     0],\n",
       "         [  101,  2510,  4637,  2326, 23374,   102,     0,     0],\n",
       "         [  101,  7201,  1997,  5485,  2011,  2406,   102,     0],\n",
       "         [  101,  7201,  1997,  5485,  2011,  2406,   102,     0],\n",
       "         [  101,  7201,  1997,  5485,  2011,  2406,   102,     0],\n",
       "         [  101,  7201,  1997,  2455, 22694,  1997,  3290,   102],\n",
       "         [  101,  5485,  1997,  3290,   102,     0,     0,     0],\n",
       "         [  101,  7201,  1997,  2455, 22694,  1997,  3290,   102],\n",
       "         [  101,  2047,  2148,  3575,  9490,  2015,   102,     0],\n",
       "         [  101,  7201,  1997,  2827,  9490,  2015,   102,     0],\n",
       "         [  101,  2047,  2148,  3575,  9490,  2015,   102,     0],\n",
       "         [  101,  2047,  2148,  3575,  1011,  3141,  7201,   102],\n",
       "         [  101,  2047,  2148,  3575,  9490,  2015,   102,     0],\n",
       "         [  101,  7201,  1997,  2827,  9490,  2015,   102,     0]]),\n",
       " 'cat2lbl_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'pcat2lbl_idx': tensor([402688, 495564, 497116, 497117,   1126,   1168,  28083,  47655,  48334,\n",
       "          49684,  50572,  71968,  81433, 155239, 199444, 230285,  91333, 110949,\n",
       "          55311,  57683,  74600, 381870, 464092,  26169,  27058,  68004, 146852,\n",
       "         199444, 293358,  68421,  74306, 138605, 149109, 199444, 175085, 317962,\n",
       "         341204,  92770, 199444,  50581, 126874,  46719,  91289,  91290,  91291,\n",
       "         181242, 199444,  55310, 199444,   1070,  92772, 379355,  72163, 499473,\n",
       "         504533,  62743, 426229, 490629]),\n",
       " 'pcat2lbl_data2ptr': tensor([ 4, 48,  3,  3,  0]),\n",
       " 'pcat2lbl_lbl2data2ptr': tensor([ 4, 10,  2,  2,  5,  6,  5,  3,  2,  2,  1,  0,  5,  2,  3,  3,  3,  0])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a1840a-0d69-4f39-b907-1e8ee4a5fe61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a97a96dd-fdca-45d2-93e7-dff568d7128e",
   "metadata": {},
   "source": [
    "## `OAKSamplerFeatTfm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f5f9ff-fe8f-4b70-a330-c4e276ee9144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OAKSamplerFeatTfm:\n",
    "\n",
    "    def __init__(self, metadata_name:str, num_labels:Optional[int]=1, num_metadata:Optional[int]=1, **kwargs):\n",
    "        self.meta_name,self.n_labels,self.n_meta = metadata_name,num_labels,num_metadata\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_data(batch:Dict, features:List):\n",
    "        batch['data_idx'] = torch.tensor([o['data_idx'] for o in features], dtype=torch.int64)\n",
    "        batch['data_input_ids'] = torch.vstack([o['data_input_ids'] for o in features])\n",
    "        batch['data_attention_mask'] = torch.vstack([o['data_attention_mask'] for o in features])\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_labels(batch:Dict, features:List, n_labels:Optional[int]=1):\n",
    "        batch['plbl2data_data2ptr'] = torch.tensor([len(o['lbl2data_idx']) for o in features], dtype=torch.int64)\n",
    "        batch['plbl2data_idx'] = torch.tensor(list(chain(*[o['lbl2data_idx'] for o in features])), dtype=torch.int64)\n",
    "    \n",
    "        input_ids = torch.vstack(list(chain(*[o['lbl2data_input_ids'] for o in features])))\n",
    "        attention_mask = torch.vstack(list(chain(*[o['lbl2data_attention_mask'] for o in features])))\n",
    "    \n",
    "        indptr = torch.cat([ torch.zeros((1,), dtype=torch.int64), batch['plbl2data_data2ptr'].cumsum(dim=0)])\n",
    "        idx = torch.hstack([torch.randperm(n)[:n_labels]+offset for n,offset in zip(batch['plbl2data_data2ptr'], indptr)])\n",
    "    \n",
    "        batch['lbl2data_data2ptr'] = torch.clamp(batch['plbl2data_data2ptr'], max=n_labels)\n",
    "        batch['lbl2data_idx'] = batch['plbl2data_idx'][idx]\n",
    "        batch['lbl2data_attention_mask'] = attention_mask[idx]\n",
    "        batch['lbl2data_input_ids'] = input_ids[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_metadata(batch:Dict, features:List, meta_name:str, n_meta:Optional[int]=1):\n",
    "        batch[f'p{meta_name}2data_data2ptr'] = torch.tensor([len(o[f'{meta_name}2data_idx']) for o in features], dtype=torch.int64)\n",
    "        batch[f'p{meta_name}2data_idx'] = torch.tensor(list(chain(*[o[f'{meta_name}2data_idx'] for o in features])), dtype=torch.int64)\n",
    "        \n",
    "        indptr = torch.cat([ torch.zeros((1,), dtype=torch.int64), batch[f'p{meta_name}2data_data2ptr'].cumsum(dim=0)])\n",
    "        idx = torch.hstack([torch.randperm(n)[:n_meta]+offset for n,offset in zip(batch[f'p{meta_name}2data_data2ptr'], indptr)])\n",
    "    \n",
    "        batch[f'{meta_name}2data_data2ptr'] = torch.clamp(batch[f'p{meta_name}2data_data2ptr'], max=n_meta)\n",
    "        batch[f'{meta_name}2data_idx'] = batch[f'p{meta_name}2data_idx'][idx]\n",
    "\n",
    "    def __call__(self, features:List):\n",
    "        batch = {}\n",
    "        self.collate_data(batch, features)\n",
    "        self.collate_labels(batch, features, n_labels=self.n_labels)\n",
    "        if self.meta_name:\n",
    "            self.collate_metadata(batch, features, self.meta_name, n_meta=self.n_meta)\n",
    "        return batch\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb7390-d03b-49e5-8180-ad5d4e15e9f0",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5483d0b-872a-43f8-98cf-7d049753ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = block.train.dset.one_batch(bsz=1600, seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77815077-f49b-42d3-ad68-08689b891902",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = OAKSamplerFeatTfm(num_labels=2, num_metadata=3, metadata_name='cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c97029e2-9383-4898-9054-1f9211ad348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = sampler(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a016669d-7b7b-4db6-9f2d-b25825e6ab1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_idx', 'data_input_ids', 'data_attention_mask', 'plbl2data_data2ptr', 'plbl2data_idx', 'lbl2data_data2ptr', 'lbl2data_idx', 'lbl2data_attention_mask', 'lbl2data_input_ids', 'pcat2data_data2ptr', 'pcat2data_idx', 'cat2data_data2ptr', 'cat2data_idx'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d6c5d69-3d5b-4964-85ce-5cd4f872cce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_idx : torch.Size([1600])\n",
      "data_input_ids : torch.Size([1600, 32])\n",
      "data_attention_mask : torch.Size([1600, 32])\n",
      "plbl2data_data2ptr : torch.Size([1600])\n",
      "plbl2data_idx : torch.Size([3361])\n",
      "lbl2data_data2ptr : torch.Size([1600])\n",
      "lbl2data_idx : torch.Size([2387])\n",
      "lbl2data_attention_mask : torch.Size([2387, 32])\n",
      "lbl2data_input_ids : torch.Size([2387, 32])\n",
      "pcat2data_data2ptr : torch.Size([1600])\n",
      "pcat2data_idx : torch.Size([7952])\n",
      "cat2data_data2ptr : torch.Size([1600])\n",
      "cat2data_idx : torch.Size([3961])\n"
     ]
    }
   ],
   "source": [
    "for k,v in o.items():\n",
    "    print(k, ':', v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92776c20-89cd-4875-aa71-b89a2177e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokz = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97400ed6-c004-4c48-b49e-686efcaae381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1260349c-89a8-4ee6-8acd-cb45efe19175",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e2954ec7-b485-4897-8e76-d5c979f6b5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'republic of maryland'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.decode(o['data_input_ids'][n], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed86e6ac-9194-4ce4-87de-66915b7e57eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indptr = o['lbl2data_data2ptr'].cumsum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6f1314f7-479b-46bb-8e48-1fd351ccbf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([90687, 89859])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o['lbl2data_idx'][indptr[n-1]:indptr[n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "352e020d-1a76-471e-95c3-5ef0fae4a93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['history of liberia', 'history of slavery in maryland']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.batch_decode(o['lbl2data_input_ids'][indptr[n-1]:indptr[n]], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "402f550d-24ef-4963-abaf-676306245ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indptr = o['plbl2data_data2ptr'].cumsum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ddc611e3-6a36-4741-8c09-0614025f292a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([89859, 90687, 90688])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o['plbl2data_idx'][indptr[n-1]:indptr[n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69290179-c0f8-4930-8f40-72f08985a83e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
